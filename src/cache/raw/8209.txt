## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [低精度Attention可能存在有...](https://kexue.fm/archives/11371)
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328)
- [为什么线性注意力要加Short C...](https://kexue.fm/archives/11320)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11307)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11301)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11285)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11280)
- [为什么Adam的Update RM...](https://kexue.fm/archives/11267)

## COMMENTS

- [chenda: \> 舍去位数越多，偏差越小\
请问这句话如何理解呢？舍去位数越多...](https://kexue.fm/archives/11371/comment-page-1#comment-28715)
- [pang: 好的谢谢您，还想请教一下，目前K=V的MQA应该是不存在的吧，...](https://kexue.fm/archives/10862/comment-page-1#comment-28714)
- [Feng Lin: 我有些好奇为什么 MFA 没有被广泛地使用呢？从结果上看，它能...](https://kexue.fm/archives/11111/comment-page-2#comment-28712)
- [npuichigo: 试了一下在SimVQ中加入directional\_repara...](https://kexue.fm/archives/11328/comment-page-1#comment-28711)
- [WellP.C: 过来](https://kexue.fm/archives/11241/comment-page-1#comment-28710)
- [WellP.C: 从papers.cool过了，居然还在更新，太强了](https://kexue.fm/archives/11241/comment-page-1#comment-28709)
- [xlf: 苏神您好！浅问下有啥版本可以获取您的博客的latex版本吗？这...](https://kexue.fm/archives/11371/comment-page-1#comment-28708)
- [李润中: 想要说一些本文中，关于DeltaFormer，没有写到的内容。...](https://kexue.fm/archives/11033/comment-page-2#comment-28706)
- [weiyixuan: 苏神确实让人敬佩，十数年一致的生活方式](https://kexue.fm/archives/10869/comment-page-1#comment-28705)
- [苏剑林: 感谢分享，学习了！](https://kexue.fm/archives/11328/comment-page-1#comment-28704)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) T5 PEGASUS：开源一个中文生成式预训练模型

3Mar

# [T5 PEGASUS：开源一个中文生成式预训练模型](https://kexue.fm/archives/8209)

By 苏剑林 \|
2021-03-03 \|
261767位读者\|

去年在文章 [《那个屠榜的T5模型，现在可以在中文上玩玩了》](https://kexue.fm/archives/7867) 中我们介绍了Google的多国语言版T5模型（mT5），并给出了用mT5进行中文文本生成任务的例子。诚然，mT5做中文生成任务也是一个可用的方案，但缺乏完全由中文语料训练出来模型总感觉有点别扭，于是决心要搞一个出来。

经过反复斟酌测试，我们决定以mT5为基础架构和初始权重，先结合中文的特点完善Tokenizer，然后模仿 [PEGASUS](https://papers.cool/arxiv/1912.08777) 来构建预训练任务，从而训练一版新的T5模型，这就是本文所开源的T5 PEGASUS。

## Tokenizer [\#](https://kexue.fm/kexue.fm\#Tokenizer)

首先，这里介绍我们对Tokenizer的完善工作。mT5使用的Tokenizer是 [sentencepiece](https://github.com/google/sentencepiece)，这是一个C++所写的分词库，具有高效轻便的特点，但是很遗憾，对于中文来说它并不是特别友好，主要体现为：

> 1、sentencepiece会把某些全角符号强制转化为半角符号，这在某些情况下是难以接受的，而且还可能影响任务的评测结果；
>
> 2、sentencepiece内置的算法虽然有能力分出中文词来，但对于中文分词来说其实还是不够智能的；
>
> 3、sentencepiece用C++写的，虽然开源了，但对于用惯Python的人来说C++就相当于黑箱，难以阅读源码，改起来也不容易。

这些特点让我们决定将Tokenizer切换回BERT的Tokenizer。但直接替换原始版本的中文BERT的Tokenizer是不够的，一来是我们之前的工作 [《提速不掉点：基于词颗粒度的中文WoBERT》](https://kexue.fm/archives/7758) 已经表明以词为单位来做生成模型能获得更好的效果，二来哪怕只看字中文BERT的vocab.txt也是很不完善的，漏了一些常见的标点符号（如双引号）和中文字（比如“琊”等）。为此，我们选择给BERT的tokenizer加入分词功能，并进一步完善vocab.txt。

具体来说，我们往原始中文BERT的token\_dict里边加入结巴分词的前20万个词，然后修改Tokenizer的逻辑，使得它能够切分出词来，这些改动都已经内置在bert4keras中了，直接调用就行。接着，我们用这个修改后的Tokenizer去遍历切分我们准备的预训练语料，统计各个token的频数，最后只保留最高频的5万个token，得到一个规模为5万的vocab.txt来构建我们最终的Tokenizer。

除了用这个新Tokenizer来训练T5 PEGASUS外，我们还用它来重新训练了一版WoBERT模型（WoBERT+），也欢迎读者尝试（ [链接](https://github.com/ZhuiyiTechnology/WoBERT)）。

## 预训练任务 [\#](https://kexue.fm/kexue.fm\#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1)

对于预训练任务，我们希望更加接近自然语言生成（而不是像T5那样的只预测挖空部分），并且尽可能具有实用价值。为此，我们关注到了PEGASUS，来自论文 [《PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization》](https://papers.cool/arxiv/1912.08777)。PEGASUS在其论文称是专门为摘要定制的预训练模型，但在我们看来，它也可以作为通用的生成式预训练任务。PEGASUS的大体思路是通过最长公共子序列的方式该摘要类似的数据对，T5 PEGASUS并没有完全复现PEGASUS的做法，只是借鉴了PEGASUS的思路做语料构建。

T5 PEGASUS的训练数据示例

具体来说，假设一个文档有$n$个句子，我们从中挑出大约$n/4$个句子（可以不连续），使得这$n/4$个句子拼起来的文本，跟剩下的$3n/4$个句子拼起来的文本，最长公共子序列尽可能长，然后我们将$3n/4$个句子拼起来的文本视为原文，$n/4$个句子拼起来的文本视为摘要，这样就构成了一个“(原文, 摘要)”的伪摘要数据对了，就用这些数据对去训练Seq2Seq模型即可。注意，如果文档里没有重复句子的话，那么原文跟摘要的句子是不会有交集的，所以这样的生成任务并非是原文的简单复制，因此还是有一定难度的。

搜索算法则是通过如下的贪心算法逐步搜索至满足长度要求：

> 1、先找出1个句子，使得它跟生成的$n-1$个句子的最长公共子序列最长；
>
> 2、假设已经找到了$k$个句子，那么继续找第$k+1$个句子，使得这$k+1$个句子拼起来的文本，跟剩下的$n-k-1$个句子拼起来的文本的最长公共子序列最长。

## 参数与配置 [\#](https://kexue.fm/kexue.fm\#%E5%8F%82%E6%95%B0%E4%B8%8E%E9%85%8D%E7%BD%AE)

目前开源的T5 PEGASUS是base版，总参数量为2.75亿，训练时最大长度为512，batch\_size为96，学习率为$10^{-4}$，使用6张3090训练了100万步，训练时间约13天，数据是30多G的精处理通用语料，训练acc约47%，训练loss约2.97。模型使用 [bert4keras](https://kexue.fm/bert4keras) 进行编写、训练和测试。

> **Github地址： [https://github.com/ZhuiyiTechnology/t5-pegasus](https://github.com/ZhuiyiTechnology/t5-pegasus)**

## 实验与评测 [\#](https://kexue.fm/kexue.fm\#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E8%AF%84%E6%B5%8B)

在CSL和LCSTS两个文本生成任务上，T5 PEGASUS是我们已知的所有模型中的SOTA：
\\begin{array}{c}
\\text{CSL摘要生成实验结果}\\\
{\\begin{array}{c\|c\|cccc}
\\hline
& \\text{beam size} & \\text{Rouge-L} & \\text{Rouge-1} & \\text{Rouge-2} & \\text{BLEU} \\\
\\hline
\\text{BERT} & 1 & 63.81 & 65.45 & 54.91 & 45.52 \\\
\\text{WoBERT} & 1 & 66.38 & 68.22 & 57.83 & 47.76 \\\
\\text{mT5} & 1 & 66.96 & 69.00 & 58.74 & \\textbf{49.79} \\\
\\text{T5 PEGASUS} & 1 & \\textbf{67.68} & \\textbf{69.87} & \\textbf{59.8} & 49.37 \\\
\\hline
\\text{BERT} & 2 & 64.44 & 66.09 & 55.75 & 46.39 \\\
\\text{WoBERT} & 2 & 66.65 & 68.68 & 58.5 & 48.4 \\\
\\text{mT5} & 2 & 67.25 & 69.19 & 59.10 & \\textbf{50.17} \\\
\\text{T5 PEGASUS} & 2 & \\textbf{68.26} & \\textbf{70.45} & \\textbf{60.57} & 50.06 \\\
\\hline
\\text{BERT} & 3 & 64.75 & 66.34 & 56.06 & 46.7 \\\
\\text{WoBERT} & 3 & 66.83 & 68.81 & 58.67 & 48.6 \\\
\\text{mT5} & 3 & 67.17 & 69.11 & 59.05 & 50.13 \\\
\\text{T5 PEGASUS} & 3 & \\textbf{68.39} & \\textbf{70.54} & \\textbf{60.69} & \\textbf{50.19} \\\
\\hline
\\end{array}}\\\
\\\
\\text{LCSTS摘要生成实验结果}\\\
{\\begin{array}{c\|c\|cccc}
\\hline
& \\text{beam size} & \\text{Rouge-L} & \\text{Rouge-1} & \\text{Rouge-2} & \\text{BLEU} \\\
\\hline
\\text{BERT} & 1 & 27.99 & 29.57 & 18.04 & 11.72 \\\
\\text{WoBERT} & 1 & \\textbf{31.51} & 32.90 & 21.13 & 13.74 \\\
\\text{mT5} & 1 & 28.92 & 30.75 & 19.54 & 13.21 \\\
\\text{T5 PEGASUS} & 1 & 31.21 & \\textbf{33.53} & \\textbf{21.54} & \\textbf{14.47} \\\
\\hline
\\text{BERT} & 2 & 29.20 & 30.70 & 19.17 & 12.64 \\\
\\text{WoBERT} & 2 & \\textbf{31.91} & 33.35 & 21.55 & 14.13 \\\
\\text{mT5} & 2 & 29.96 & 31.67 & 20.40 & 13.84 \\\
\\text{T5 PEGASUS} & 2 & 31.47 & \\textbf{34.00} & \\textbf{21.98} & \\textbf{14.75} \\\
\\hline
\\text{BERT} & 3 & 29.45 & 30.95 & 19.50 & 12.93 \\\
\\text{WoBERT} & 3 & \\textbf{32.19} & 33.72 & 21.81 & 14.29 \\\
\\text{mT5} & 3 & 30.15 & 31.97 & 20.72 & 14.05 \\\
\\text{T5 PEGASUS} & 3 & 31.78 & \\textbf{34.12} & \\textbf{22.23} & \\textbf{14.96} \\\
\\hline
\\end{array}}
\\end{array}

更重要的是，T5 PEGASUS有着非常出色的小样本学习能力：
\\begin{array}{c}
\\text{CSL摘要生成实验结果(小样本, beam size=1)}\\\
{\\begin{array}{c\|c\|cccc}
\\hline
& \\text{样本数} & \\text{Rouge-L} & \\text{Rouge-1} & \\text{Rouge-2} & \\text{BLEU} \\\
\\hline
\\text{WoBERT} & 10000 & 66.38 & 68.22 & 57.83 & 47.76 \\\
\\text{mT5} & 10000 & 66.96 & 69.00 & 58.74 & \\textbf{49.79} \\\
\\text{T5 PEGASUS} & 10000 & \\textbf{67.68} & \\textbf{69.87} & \\textbf{59.8} & 49.37 \\\
\\hline
\\text{WoBERT} & 1000 & 59.34 & 60.42 & 49.07 & 37.87 \\\
\\text{mT5} & 1000 & 59.91 & 61.52 & 50.38 & 40.87 \\\
\\text{T5 PEGASUS} & 1000 & \\textbf{63.12} & \\textbf{65.28} & \\textbf{54.54} & \\textbf{43.55} \\\
\\hline
\\text{WoBERT} & 100 & 55.68 & 55.33 & 43.10 & 31.55 \\\
\\text{mT5} & 100 & 55.33 & 54.62 & 42.78 & 32.50 \\\
\\text{T5 PEGASUS} & 100 & \\textbf{60.87} & \\textbf{62.78} & \\textbf{52.30} & \\textbf{41.40} \\\
\\hline
\\text{WoBERT} & 10 & 26.32 & 20.99 & 12.29 & 5.76 \\\
\\text{mT5} & 10 & 26.62 & 27.00 & 17.95 & 13.11 \\\
\\text{T5 PEGASUS} & 10 & \\textbf{55.85} & \\textbf{57.66} & \\textbf{47.52} & \\textbf{35.97} \\\
\\hline
\\end{array}}
\\end{array}

哪怕样本标注样本降低到10个，T5 PEGASUS依然可以微调出一个摘要（标题）生成模型出来，性能显著超过其他模型。在LCSTS上，T5 PEGASUS具有类似的小样本学习效果，只不过非T5 PEGASUS模型效果实在太差了，所以就没有把表格整理在此了。

## 小样本演示 [\#](https://kexue.fm/kexue.fm\#%E5%B0%8F%E6%A0%B7%E6%9C%AC%E6%BC%94%E7%A4%BA)

下面是标注样本数为10个时训练出来的模型生成效果演示：

> **输入：** 针对以超立方体网络为蓝本的多处理机系统的可靠性和容错能力的精准度量问题,结合多处理机系统遭受计算机病毒攻击时常常发生结构性故障的特点,研究了n维超立方体网络的结构连通性和子结构连通性评价问题。首先,使 用构造n维超立方体网络的3路结构割的方法得到其3路结构连通度的一个上界;然后,使用构造n维超立方体网络的3路子结构集的等价变换或约简变换的方法,得到其3路结构子连通度的一个下界;最后,利用任意网络的3路结构连通度不小于3路子结构连通度的性质,证实了超立方体网络的3路结构连通度和子结构连通度均为该超立方体网络维数
> **标题：** 超立方体网络的3路结构连通度及子结构连通度 **预测：** 基于n维超立方体网络结构连通性和子结构连通性评价研究
>
> **输入：** 针对传统无线体域网(WBAN)预测模型对感知数据预测精度低、计算量大、能耗高的问题,提出一种基于惩罚误差矩阵的自适应三次指数平滑算法。首先在感知节点与路由节点之间建立轻量级预测模型,其次采用地毯式搜索方式 对预测模型进行参数优化处理,最后采用惩罚误差矩阵对预测模型参数作进一步的细粒化处理。实验结果表明,与Zig Bee协议相比,在1000时隙范围内,所提方法可节省12%左右的能量;而采用惩罚误差矩阵与地毯式搜索方式相比,预测精度提高了3. 306%。所提方法在有效降低计算复杂度的同时能进一步降低WBAN的能耗
> **标题：** 基于惩罚误差矩阵的同步预测无线体域网节能方法 **预测：** 基于惩罚误差矩阵的自适应三次指数平滑算法
>
> **输入：** 针对车联网(IoV)环境下消息传输效率低下、网络资源开销较大等诸多问题,提出一种适用于城市交通场景下基于车辆节点认知交互的路由算法。首先,依据信任理论提出节点认知交互度的概念,并在此基础上对车联网中的车辆 节点进行分类,赋予它们不同的认知交互度初值;同时还引入车辆节点交互时间、交互频率、车辆节点物理间隔距离、间隔跳数以及消息生存时间等影响因子,进而构建了车辆节点认知交互评估模型。基于该模型计算并更新节点的认知 交互度,并通过比较对应车辆节点间的认知交互度值来选取认知交互度相对较高的邻居节点作为中继节点进行消息转
> **标题：** 车联网环境下基于节点认知交互的路由算法 **预测：** 基于车辆节点认知交互的路由算法
>
> **输入：** 针对近场源波达方向(DOA)和距离的联合估计问题,提出一种近场迭代自适应算法(NF-IAA)。首先通过划分二维网格表示出近场区域内信源所有可能的位置,每个位置都看作存在一个潜在的信源入射到阵列上,表示出阵列输出的 数据模型;然后通过循环迭代利用上一次谱估计的结果构建信号的协方差矩阵,将协方差矩阵的逆作为加权矩阵估计出每个位置对应的潜在信源能量;最后绘制出三维能量谱图,由于只有真实存在的信源能量不为0,因此谱峰对应的位置即为真实存在信源的位置。仿真实验表明在10个快拍条件下,NF-IAA的DOA分辨概率达到了9
> **标题：** 基于迭代自适应方法的近场源二维参数联合估计 **预测：** 基于nf-iaa的近场迭代自适应算法
>
> **输入：** 针对现有的软件众包工人选择机制对工人间协同开发考虑不足的问题,在竞标模式的基础上提出一种基于活跃时间分组的软件众包工人选择机制。首先,基于活跃时间将众包工人划分为多个协同开发组;然后,根据组内工人开发 能力和协同因子计算协同工作组权重;最后,选定权重最大的协同工作组为最优工作组,并根据模块复杂度为每个任务模块从该组内选择最适合的工人。实验结果表明,该机制相比能力优先选择方法在工人平均能力上仅有0\. 57%的差距, 同时因为保证了工人间的协同而使项目风险平均降低了32%,能有效指导需多人协同进行的众包软件任务的工
> **标题：** 基于活跃时间分组的软件众包工人选择机制 **预测：** 基于活跃时间分组的软件众包工人选择机制

可以看到哪怕标注样本很少，但依然能够得到可读性较好的生成结果，这得益于PEGASUS式的伪摘要预训练与下游任务是很贴近的。

## 简单的总结 [\#](https://kexue.fm/kexue.fm\#%E7%AE%80%E5%8D%95%E7%9A%84%E6%80%BB%E7%BB%93)

本文主要分享了我们的中文生成式预训练模型T5 PEGASUS，它以mT5为基础，在中文语料上使用PEGASUS式的伪摘要预训练，最终有着不错的文本生成表现，尤其是出色的小样本学习能力，欢迎有文本生成需求的读者使用。

_**转载到请包括本文地址：** [https://kexue.fm/archives/8209](https://kexue.fm/archives/8209)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Mar. 03, 2021). 《T5 PEGASUS：开源一个中文生成式预训练模型 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/8209](https://kexue.fm/archives/8209)

@online{kexuefm-8209,
        title={T5 PEGASUS：开源一个中文生成式预训练模型},
        author={苏剑林},
        year={2021},
        month={Mar},
        url={\\url{https://kexue.fm/archives/8209}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/), [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/), [attention](https://kexue.fm/tag/attention/)[107 评论](https://kexue.fm/archives/8209#comments)

< [【搜出来的文本】⋅（四）通过增、删、改来用词造句](https://kexue.fm/archives/8194) \| [短文本匹配Baseline：脱敏数据使用预训练模型的尝试](https://kexue.fm/archives/8213) >

### 你也许还对下面的内容感兴趣

- [低精度Attention可能存在有偏的舍入误差](https://kexue.fm/archives/11371)
- [为什么线性注意力要加Short Conv？](https://kexue.fm/archives/11320)
- [QK-Clip：让Muon在Scaleup之路上更进一步](https://kexue.fm/archives/11126)
- [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111)
- [“对角+低秩”三角阵的高效求逆方法](https://kexue.fm/archives/11072)
- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
- [Transformer升级之路：20、MLA好在哪里?（上）](https://kexue.fm/archives/10907)
- [Transformer升级之路：19、第二类旋转位置编码](https://kexue.fm/archives/10862)
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
- [“闭门造车”之多模态思路浅谈（三）：位置编码](https://kexue.fm/archives/10352)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

1. [«](https://kexue.fm/archives/8209/comment-page-4#comments)
2. [1](https://kexue.fm/archives/8209/comment-page-1#comments)
3. [2](https://kexue.fm/archives/8209/comment-page-2#comments)
4. [3](https://kexue.fm/archives/8209/comment-page-3#comments)
5. [4](https://kexue.fm/archives/8209/comment-page-4#comments)
6. [5](https://kexue.fm/archives/8209/comment-page-5#comments)

[中文生成模型T5-Pegasus详解与实践\_Johngo学长](https://www.johngo689.com/706992/)

July 21st, 2023

\[...\]\[5\] T5 PEGASUS：开源一个中文生成式预训练模型\[...\]

[回复评论](https://kexue.fm/archives/8209/comment-page-5?replyTo=22317#respond-post-8209)

[中文生成模型T5-Pegasus详解与实践 \| Coding栈](https://www.itcode1024.com/190671/)

July 22nd, 2023

\[...\]\[5\] T5 PEGASUS：开源一个中文生成式预训练模型\[...\]

[回复评论](https://kexue.fm/archives/8209/comment-page-5?replyTo=22332#respond-post-8209)

1. [«](https://kexue.fm/archives/8209/comment-page-4#comments)
2. [1](https://kexue.fm/archives/8209/comment-page-1#comments)
3. [2](https://kexue.fm/archives/8209/comment-page-2#comments)
4. [3](https://kexue.fm/archives/8209/comment-page-3#comments)
5. [4](https://kexue.fm/archives/8209/comment-page-4#comments)
6. [5](https://kexue.fm/archives/8209/comment-page-5#comments)

[取消回复](https://kexue.fm/archives/8209#respond-post-8209)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[Tokenizer](https://kexue.fm/kexue.fm#Tokenizer)
[预训练任务](https://kexue.fm/kexue.fm#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1)
[参数与配置](https://kexue.fm/kexue.fm#%E5%8F%82%E6%95%B0%E4%B8%8E%E9%85%8D%E7%BD%AE)
[实验与评测](https://kexue.fm/kexue.fm#%E5%AE%9E%E9%AA%8C%E4%B8%8E%E8%AF%84%E6%B5%8B)
[小样本演示](https://kexue.fm/kexue.fm#%E5%B0%8F%E6%A0%B7%E6%9C%AC%E6%BC%94%E7%A4%BA)
[简单的总结](https://kexue.fm/kexue.fm#%E7%AE%80%E5%8D%95%E7%9A%84%E6%80%BB%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [倒立单摆之分离频率](https://kexue.fm/archives/2471)
- [薛定谔方程的启发式推导](https://kexue.fm/archives/1799)
- [更别致的词向量模型(一)：simpler glove](https://kexue.fm/archives/4667)
- [翻到新的维度，把积分解决！](https://kexue.fm/archives/2380)
- [从“0.999...等于1”说开来](https://kexue.fm/archives/3402)
- [算符的艺术：差分、微分与伯努利数](https://kexue.fm/archives/3018)
- [多任务学习漫谈（二）：行梯度之事](https://kexue.fm/archives/8896)
- [从费马大定理谈起（六）：n=4（2）](https://kexue.fm/archives/2858)
- [“Cool Papers + 站内搜索”的一些新尝试](https://kexue.fm/archives/10311)
- [中文任务还是SOTA吗？我们给SimCSE补充了一些实验](https://kexue.fm/archives/8348)

### 最近评论

- [chenda](https://kexue.fm/archives/11371/comment-page-1#comment-28715): \> 舍去位数越多，偏差越小
请问这句话如何理解呢？舍去位数越多，应该丢失了更多的数值，那偏差应...
- [pang](https://kexue.fm/archives/10862/comment-page-1#comment-28714): 好的谢谢您，还想请教一下，目前K=V的MQA应该是不存在的吧，我理解最接近K=V的MQA其实就...
- [Feng Lin](https://kexue.fm/archives/11111/comment-page-2#comment-28712): 我有些好奇为什么 MFA 没有被广泛地使用呢？从结果上看，它能打 MLA 且不用 partia...
- [npuichigo](https://kexue.fm/archives/11328/comment-page-1#comment-28711): 试了一下在SimVQ中加入directional\_reparam好像不太收敛，苏神有什么想法吗
- [WellP.C](https://kexue.fm/archives/11241/comment-page-1#comment-28710): 过来
- [WellP.C](https://kexue.fm/archives/11241/comment-page-1#comment-28709): 从papers.cool过了，居然还在更新，太强了
- [xlf](https://kexue.fm/archives/11371/comment-page-1#comment-28708): 苏神您好！浅问下有啥版本可以获取您的博客的latex版本吗？这样给LLM帮我理解的时候，比单纯...
- [李润中](https://kexue.fm/archives/11033/comment-page-2#comment-28706): 想要说一些本文中，关于DeltaFormer，没有写到的内容。虽然是比较浅显的事情，但是希望对...
- [weiyixuan](https://kexue.fm/archives/10869/comment-page-1#comment-28705): 苏神确实让人敬佩，十数年一致的生活方式
- [苏剑林](https://kexue.fm/archives/11328/comment-page-1#comment-28704): 感谢分享，学习了！

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。