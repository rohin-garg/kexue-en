## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [从无穷范数求导到等值振荡定理](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)
- [Transformer升级之路：1...](https://kexue.fm/archives/10862)

## COMMENTS

- [PengchengMa: 牛啊](https://kexue.fm/archives/10996/comment-page-1#comment-27811)
- [xczh: 已使用mean flow policy，一步推理效果确实惊人，...](https://kexue.fm/archives/10958/comment-page-1#comment-27810)
- [Cosine: 是不是因为shared experts每次都激活，而route...](https://kexue.fm/archives/10945/comment-page-1#comment-27809)
- [rpsun: 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减...](https://kexue.fm/archives/10699/comment-page-1#comment-27808)
- [贵阳机场接机: 怎么不更新啦](https://kexue.fm/archives/1490/comment-page-1#comment-27807)
- [czvzb: 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。...](https://kexue.fm/archives/10958/comment-page-1#comment-27806)
- [Shawn\_yang: 不好意思，以为网页卡了0.0点了三下](https://kexue.fm/archives/10945/comment-page-1#comment-27805)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27804)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27803)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27802)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 新词发现的信息熵方法与实现

26Oct

# [新词发现的信息熵方法与实现](https://kexue.fm/archives/3491)

By 苏剑林 \|
2015-10-26 \|
124982位读者\|

在本博客的前面文章中，已经简单提到过中文文本处理与挖掘的问题了，中文数据挖掘与英语同类问题中最大的差别是，中文没有空格，如果要较好地完成语言任务，首先得分词。目前流行的分词方法都是基于词库的，然而重要的问题就来了：词库哪里来？人工可以把一些常用的词语收集到词库中，然而这却应付不了层出不穷的新词，尤其是网络新词等——而这往往是语言任务的关键地方。因此，中文语言处理很核心的一个任务就是完善新词发现算法。

新词发现说的就是不加入任何先验素材，直接从大规模的语料库中，自动发现可能成词的语言片段。前两天我去小虾的公司膜拜，并且试着加入了他们的一个开发项目中，主要任务就是网络文章处理。因此，补习了一下新词发现的算法知识，参考了Matrix67.com的文章 [《互联网时代的社会语言学：基于SNS的文本数据挖掘》](http://www.matrix67.com/blog/archives/5044)，尤其是里边的信息熵思想，并且根据他的思路，用Python写了个简单的脚本。

程序的算法完全来自于Matrix67.com的文章，感兴趣的读者可以移步到他的博客仔细阅读，相信会获益匪浅的。在此主要简单讨论一下代码的实现思路。具体程序请见文末。为了处理更大的文本，尽量不用Python内置的循环，尽可能用到第三方库所带的函数，如Numpy、Pandas。由于涉及到词语数量较多，要做好索引工作，比如词语先要排好序，会大大提高检索的速度。

下面是用本文程序对金庸小说《天龙八部》世纪新修版（txt电子版2.5M）做的新词发现结果（部分），用时20秒左右，感觉结果还不错，主要角色的人名都自动发现了。当然因为代码比较短，没做什么特殊处理，还有很多可以改善的地方。

> 段誉,3535
> 什么,2537
> 萧峰,1897
> 自己,1730
> 虚竹,1671
> 乔峰,1243
> 阿紫,1157
> 武功,1109
> 阿朱,1106
> 姑娘,1047
> 笑道,992
> 咱们,832
> 师父,805
> 如何,771
> 如此,682
> 大理,665
> 丐帮,645
> 突然,640
> 王语嫣,920
> 慕容复,900
> 段正淳,780
> 木婉清,751
> 鸠摩智,600
> 游坦之,515
> 丁春秋,463
> 有什么,460
> 包不同,447
> 少林寺,379
> 保定帝,344
> 马夫人,324
> 段延庆,302
> 乌老大,294
> 不由得,275
> 王夫人,265
> 为什么,258
> 只听得,255
> 是什么,237
> 云中鹤,236
> 那少女,234
> 巴天石,230
> 王姑娘,227
> 忽听得,221
> 钟万仇,218
> 少林派,216
> 叶二娘,216
> 朱丹臣,213
> 风波恶,209
> 契丹人,208
> 南海鳄神,485
> 慕容公子,230
> 耶律洪基,189
> 六脉神剑,168
> 站起身来,116
> 带头大哥,103
> 这几句话,100
> 点了点头,96
> 星宿老怪,92
> 神仙姊姊,90
> 吃了一惊,87
> 大吃一惊,86
> 慕容先生,86
> 又有什么,86

**完整代码（3.x版本，简单修改可以用于2.x版本，主要是输出函数不同而已）：**

```
import numpy as np
import pandas as pd
import re
from numpy import log,min

f = open('data.txt', 'r') #读取文章
s = f.read() #读取为一个字符串

#定义要去掉的标点字
drop_dict = [u'，', u'\n', u'。', u'、', u'：', u'(', u')', u'[', u']', u'.', u',', u' ', u'\u3000', u'”', u'“', u'？', u'?', u'！', u'‘', u'’', u'…']
for i in drop_dict: #去掉标点字
 s = s.replace(i, '')

#为了方便调用，自定义了一个正则表达式的词典
myre = {2:'(..)', 3:'(...)', 4:'(....)', 5:'(.....)', 6:'(......)', 7:'(.......)'}

min_count = 10 #录取词语最小出现次数
min_support = 30 #录取词语最低支持度，1代表着随机组合
min_s = 3 #录取词语最低信息熵，越大说明越有可能独立成词
max_sep = 4 #候选词语的最大字数
t=[] #保存结果用。

t.append(pd.Series(list(s)).value_counts()) #逐字统计
tsum = t[0].sum() #统计总字数
rt = [] #保存结果用

for m in range(2, max_sep+1):
 print(u'正在生成%s字词...'%m)
 t.append([])
 for i in range(m): #生成所有可能的m字词
 t[m-1] = t[m-1] + re.findall(myre[m], s[i:])

 t[m-1] = pd.Series(t[m-1]).value_counts() #逐词统计
 t[m-1] = t[m-1][t[m-1] > min_count] #最小次数筛选
 tt = t[m-1][:]
 for k in range(m-1):
 qq = np.array(list(map(lambda ms: tsum*t[m-1][ms]/t[m-2-k][ms[:m-1-k]]/t[k][ms[m-1-k:]], tt.index))) > min_support #最小支持度筛选。
 tt = tt[qq]
 rt.append(tt.index)

def cal_S(sl): #信息熵计算函数
 return -((sl/sl.sum()).apply(log)*sl/sl.sum()).sum()

for i in range(2, max_sep+1):
 print(u'正在进行%s字词的最大熵筛选(%s)...'%(i, len(rt[i-2])))
 pp = [] #保存所有的左右邻结果
 for j in range(i+2):
 pp = pp + re.findall('(.)%s(.)'%myre[i], s[j:])
 pp = pd.DataFrame(pp).set_index(1).sort_index() #先排序，这个很重要，可以加快检索速度
 index = np.sort(np.intersect1d(rt[i-2], pp.index)) #作交集
 #下面两句分别是左邻和右邻信息熵筛选
 index = index[np.array(list(map(lambda s: cal_S(pd.Series(pp[0][s]).value_counts()), index))) > min_s]
 rt[i-2] = index[np.array(list(map(lambda s: cal_S(pd.Series(pp[2][s]).value_counts()), index))) > min_s]

#下面都是输出前处理
for i in range(len(rt)):
 t[i+1] = t[i+1][rt[i]]
 t[i+1].sort(ascending = False)

#保存结果并输出
pd.DataFrame(pd.concat(t[1:])).to_csv('result.txt', header = False)
```

_**转载到请包括本文地址：** [https://kexue.fm/archives/3491](https://kexue.fm/archives/3491)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/3491#share)/ [打赏](https://kexue.fm/archives/3491#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Oct. 26, 2015). 《新词发现的信息熵方法与实现 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/3491](https://kexue.fm/archives/3491)

@online{kexuefm-3491,
        title={新词发现的信息熵方法与实现},
        author={苏剑林},
        year={2015},
        month={Oct},
        url={\\url{https://kexue.fm/archives/3491}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [python](https://kexue.fm/tag/python/), [最大熵](https://kexue.fm/tag/%E6%9C%80%E5%A4%A7%E7%86%B5/), [词库](https://kexue.fm/tag/%E8%AF%8D%E5%BA%93/), [新词发现](https://kexue.fm/tag/%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0/)[24 评论](https://kexue.fm/archives/3491#comments)

< [把Python脚本放到手机上定时运行](https://kexue.fm/archives/3477) \| [朋友们，来瓶汽水吧！有趣的换汽水问题](https://kexue.fm/archives/3495) >

### 你也许还对下面的内容感兴趣

- [旁门左道之如何让Python的重试代码更加优雅](https://kexue.fm/archives/9938)
- [随机分词浅探：从Viterbi Decoding到Viterbi Sampling](https://kexue.fm/archives/9768)
- [BytePiece：更纯粹、更高压缩率的Tokenizer](https://kexue.fm/archives/9752)
- [有限内存下全局打乱几百G文件（Python）](https://kexue.fm/archives/8662)
- [无监督分词和句法分析！原来BERT还可以这样用](https://kexue.fm/archives/7476)
- [EAE：自编码器 + BN + 最大熵 = 生成模型](https://kexue.fm/archives/7343)
- [6个派生优化器的简单介绍及其实现](https://kexue.fm/archives/7094)
- [什么时候多进程的加速比可以大于1？](https://kexue.fm/archives/7031)
- [重新写了之前的新词发现算法：更快更好的新词发现](https://kexue.fm/archives/6920)
- [分享一次专业领域词汇的无监督挖掘](https://kexue.fm/archives/6540)

[发表你的看法](https://kexue.fm/archives/3491#comment_form)

kjhdsvb

October 28th, 2015

如果楼主没读过《数学之美》的话，推荐楼主读一下吴军老师的《数学之美》，里面也有谈到最大熵思想。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=7117#respond-post-3491)

[苏剑林](http://kexue.fm) 发表于
October 28th, 2015

谢谢您的推荐。这本书我以前就已经听说过了，一直没机会拜读。今天查看了一下，才发现原来也是跟自然语言处理相关的，看上去确实值得一读。我会抽时间看一下的。再次感谢！

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=7118#respond-post-3491)

无何有

September 22nd, 2016

你好！
请问：min\_support = 30 #录取词语最低支持度，1代表着随机组合
这个最低支持度怎么理解？

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=7443#respond-post-3491)

[YanchaoMa](http://kexue.fm/archives/3922/) 发表于
May 25th, 2017

请问这个问题是怎么理解的？最低支持度？

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=8124#respond-post-3491)

[YanchaoMa](http://kexue.fm/archives/3922/) 发表于
May 26th, 2017

这个最低支持度，应该是PMI的最小值

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=8128#respond-post-3491)

lusir

July 26th, 2017

for m in range(2, max\_sep+1):
print(u'正在生成%s字词...'%m)
t.append(\[\])
for i in range(m): #生成所有可能的m字词
t\[m-1\] = t\[m-1\] + re.findall(myre\[m\], s\[i:\])
这部分for i in range(m): #生成所有可能的m字词
t\[m-1\] = t\[m-1\] + re.findall(myre\[m\], s\[i:\])
这里不应该是range(m) 吧？应该是range(len(len(s))).
你这么写是没有从头取到尾的。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=8210#respond-post-3491)

longman

November 14th, 2017

t\[i+1\].sort(ascending = False)

#保存结果并输出
pd.DataFrame(pd.concat(t\[1:\])).to\_csv('result.txt', header = False)
为什么我这报 没有sort 函数，改成sorted() 后再出现TypeError: cannot concatenate object of type ""; only pd.Series, pd.DataFrame, and pd.Panel (deprecated) objs are valid
这是什么情况啊

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=8353#respond-post-3491)

[苏剑林](http://kexue.fm) 发表于
November 15th, 2017

请查看pandas的官方帮助文档，sort函数后来已经改为sort\_values

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=8356#respond-post-3491)

[yunshan](https://github.com/312shan)

September 21st, 2018

大神，请问，如果我要对特定领域的文本抽取特定领域的专有名词，为了达到最理想的效果，如何一步步调整min\_count
min\_support
min\_s
max\_sep
，这些参数的选择和调整你有什么经验和文献可以分享一下吗？谢谢。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=9812#respond-post-3491)

[苏剑林](https://kexue.fm) 发表于
September 21st, 2018

你在做那个电力专业词抽取？没有好的标准，你理解各参数的含义后会可以慢慢调整了，而且抽取出词表后还要和平行语料的词典对比。

http://www.matrix67.com/blog/archives/5044

这里边可以稍微参考一下。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=9815#respond-post-3491)

[yunshan](https://github.com/312shan) 发表于
September 26th, 2018

哈哈，没错，正是在做电力专业词抽取。这个任务很特殊，不像一般的分类这些是有监督，我们可以通过log\_loss 或者 F1 这些指标来分辨当前算法和参数是否更好。
还是有两个疑惑：
1\. 这种无监督问题，难道我调整完参数只能通过线上分数才能知道我这个算法的优劣？
2\. 你提到和平行语料的词典对比，这个是个什么操作？具体怎么做？貌似 matrix67 这篇文章中没有提到吧。能否给一些参考的链接？

再次感谢！！！

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=9826#respond-post-3491)

[苏剑林](https://kexue.fm) 发表于
September 27th, 2018

1\. 无监督问题只能通过提交得到答案（鬼知道官方对专业词汇的定义是什么？）
2\. “和平行语料对比”已经够清晰了，就是同样的算法在比赛语料做一次，在平行语料做一次，然后就可以对比出比赛语料中比较突出的词汇。matrix67文章提供了一种对比算法。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=9833#respond-post-3491)

liyi

September 29th, 2018

您的47行好像有问题：
pp = \[\] #保存所有的左右邻结果
for j in range(i):
pp = pp + re.findall('(.)%s(.)'%myre\[i\], s\[j:\])
用python3做实验如下:
>>\> a = 'abcdefghijklmnopqrstuvwxyz'
>>\> b = re.findall('(.)(..)(.)',a)
>>\> print(b)
\[('a', 'bc', 'd'), ('e', 'fg', 'h'), ('i', 'jk', 'l'), ('m', 'no', 'p'), ('q', 'rs', 't'), ('u', 'vw', 'x')\]
>>\> b = re.findall('(.)(..)(.)',a\[1:\])
>>\> print(b)
\[('b', 'cd', 'e'), ('f', 'gh', 'i'), ('j', 'kl', 'm'), ('n', 'op', 'q'), ('r', 'st', 'u'), ('v', 'wx', 'y')\]
我觉得您需要获得的应该形如：
\[('a', 'bc', 'd'), ('b', 'cd', 'e'), ('c', 'de', 'f'), ('d', 'ef', 'g'), ('e', 'fg', 'h'), ...\]
您的代码是分别获取a\[0:\]和a\[1:\]，然后将它们合并，从这里看似乎不够。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=9863#respond-post-3491)

[苏剑林](https://kexue.fm) 发表于
September 29th, 2018

谢谢，你是对的，应该要加上2

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=9864#respond-post-3491)

liyi 发表于
September 30th, 2018

^\_^

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=9869#respond-post-3491)

熊俊峰 发表于
July 26th, 2022

在苏神的代码里面是没有问题的，你这里需要修改i，是因为你要找的正则表达式比较特殊吧

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=19535#respond-post-3491)

jackli777

October 7th, 2020

您好！
原文中对“凝合程度”的定义是：
“令 p(x) 为文本片段 x 在整个语料中出现的概率，那么我们定义“电影院”的凝合程度就是 p(电影院) 与 p(电) · p(影院) 比值和 p(电影院) 与 p(电影) · p(院) 的比值中的较小值，“的电影”的凝合程度则是 p(的电影) 分别除以 p(的) · p(电影) 和 p(的电) · p(影) 所得的商的较小值。”

而您的处理逻辑是：
待判断值 = 总字数 \\* 候选词出现的次数 / 词切分组合左出现的次数 / 词切分组合右出现的次数
待判断值 > 录取词语最低支持度 =\> 合法词，否则为非法
且以上切分组合只要有一个符合上述条件，即可进入合法词列表，即qq
如：
“一笑说道”的切分组合：
一 \+ 笑说到
一笑 \+ 说到
一笑说 \+ 到

与原文中关于“凝合程度”的定义还是有差异的，请问如何理解？

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=14503#respond-post-3491)

[苏剑林](https://kexue.fm) 发表于
October 9th, 2020

1、“总字数 \* 候选词出现的次数 / 词切分组合左出现的次数 / 词切分组合右出现的次数”这个公式并没有错误，只要根据词频的定义去化简一下就行了；

2、“以上切分组合只要有一个符合上述条件，即可进入合法词列表”，本文不是这样实现的，请仔细阅读，不要轻率下结论：是每一种切分都算一个qq，然后用qq去筛选，每个n-gram都要经过n-1个qq去筛选。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=14514#respond-post-3491)

jackli777 发表于
October 10th, 2020

精妙之处在于【for k in range(m-1):】中的【tt = tt\[qq\]】，这样就是【以上切分组合必须所有符合上述条件，方可进入合法词列表】，这样也就解释了对每种切分组合的待判断值逐个过滤，也就自然满足原文定义中的所有组合的较小值，tql！

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=14533#respond-post-3491)

jackli777 发表于
October 10th, 2020

苏神是否考虑加个对自己的评论的删除功能？这样之前不妥的结论可自行删除？

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=14534#respond-post-3491)

[苏剑林](https://kexue.fm) 发表于
October 10th, 2020

一般不考虑，如果真的不妥我也会自行删除的。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=14543#respond-post-3491)

enjlife

January 19th, 2021

从分词一路追到了这里，苏神的代码写的很巧妙！有两个小问题
1.matrix67提到的“相同的候选词便都集中在了一起，从头到尾扫描一遍便能算出各个候选词的频数和右邻字信息熵。将整个语料逆序后重新排列所有的后缀，再扫描一遍后便能统计出每个候选词的左邻字信息熵”，苏神有没有实践过，不是很理解
2.np.sort(np.intersect1d(rt\[i-2\], pp.index))中np.intersect1d我查了下是返回的交集排序结果，所以np.sort应该可以省去

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=15290#respond-post-3491)

[苏剑林](https://kexue.fm) 发表于
January 19th, 2021

1、没有试过；
2、印象中好像不sort会影响速度？不大记得了。

总的来说，由于后面研究了其他新词发现算法，所以这份代码也就没怎么更新和维护了。

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=15295#respond-post-3491)

enjlife 发表于
January 19th, 2021

谢谢苏神回复，继续学习苏神的博客，哈哈

[回复评论](https://kexue.fm/archives/3491/comment-page-1?replyTo=15296#respond-post-3491)

[取消回复](https://kexue.fm/archives/3491#respond-post-3491)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请不要重复点击提交。

### 关于站长

**苏剑林\|BoJone**，科学空间博主，【数学、天文、理论物理、写作、阅读、计算机、中国象棋、厨房】爱好者（但不专业）......目前32岁，还在单调递增。希望能一直在此分享科学之美～

**你也许会关心：** [科学空间\|Scientific Spaces 介绍](https://kexue.fm/me.html)
科学空间QQ交流群：67729435
科学空间微信交流群： [spaces\_ac\_cn](https://kexue.fm/archives/4096/)
常见问题集： [《科学空间FAQ》](https://kexue.fm/archives/6508/)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [基于双向GRU和语言模型的视角情感分析](https://kexue.fm/archives/4118)
- [数独的自动推理](https://kexue.fm/archives/2527)
- [温馨\|生活一角](https://kexue.fm/archives/144)
- [最新调查解“毒”珠江：工业水污染触目惊心！](https://kexue.fm/archives/222)
- [新浪sina.cn邮箱体验(免费邀请您来体验)](https://kexue.fm/archives/126)
- [浅谈Transformer的初始化、参数化与标准化](https://kexue.fm/archives/8620)
- [玩转Keras之seq2seq自动生成标题](https://kexue.fm/archives/5861)
- [思考：两个椭圆片能粘合成一个立体吗？](https://kexue.fm/archives/6818)
- [【个人翻译】变暖的地球对冷血动物来说过热？](https://kexue.fm/archives/11)
- [生成扩散模型漫谈（七）：最优扩散方差估计（上）](https://kexue.fm/archives/9245)

### 最近评论

- [PengchengMa](https://kexue.fm/archives/10996/comment-page-1#comment-27811): 牛啊
- [xczh](https://kexue.fm/archives/10958/comment-page-1#comment-27810): 已使用mean flow policy，一步推理效果确实惊人，性能跟多步推理的diffusio...
- [Cosine](https://kexue.fm/archives/10945/comment-page-1#comment-27809): 是不是因为shared experts每次都激活，而routed experts是依概率被选中...
- [rpsun](https://kexue.fm/archives/10699/comment-page-1#comment-27808): 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减掉之后做正交分解。那么如果单纯地...
- [贵阳机场接机](https://kexue.fm/archives/1490/comment-page-1#comment-27807): 怎么不更新啦
- [czvzb](https://kexue.fm/archives/10958/comment-page-1#comment-27806): 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。
苏神推荐你看这几篇文章：
1....
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27805): 不好意思，以为网页卡了0.0点了三下
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27804): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27803): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27802): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。