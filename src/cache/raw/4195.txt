Loading \[MathJax\]/jax/output/HTML-CSS/fonts/TeX/fontdata.js

![MobileSideBar](https://kexue.fm/usr/themes/geekg/images/slide-button.png)

## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [让炼丹更科学一些（五）：基于梯度精...](https://kexue.fm/archives/11530)
- [让炼丹更科学一些（四）：新恒等式，...](https://kexue.fm/archives/11494)
- [为什么DeltaNet要加L2 N...](https://kexue.fm/archives/11486)
- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)

## COMMENTS

- [Bin: 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院...](https://kexue.fm/archives/1990/comment-page-2#comment-29105)
- [Rapture D: 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。](https://kexue.fm/archives/11530/comment-page-1#comment-29104)
- [mofheka: 苏神是还在用jax是么？最近在做基于Google Pathwa...](https://kexue.fm/archives/11390/comment-page-1#comment-29103)
- [长琴: 看懂这篇博客也不是一件容易的事情。](https://kexue.fm/archives/11530/comment-page-1#comment-29102)
- [AlexLi: 苏老师，请教一下(7)式中将 \\mu(x\_t) 传给 $p...](https://kexue.fm/archives/9257/comment-page-4#comment-29101)
- [tyler\_zxc: "Performer的思想是将标准的Attention线性化，...](https://kexue.fm/archives/7921/comment-page-2#comment-29100)
- [我: 似乎并非mHC提出矩阵的思想？之前hyper connecti...](https://kexue.fm/archives/11494/comment-page-1#comment-29099)
- [winter: 苏神您好，假如对于比较均匀的attention weightP...](https://kexue.fm/archives/10847/comment-page-1#comment-29098)
- [苏剑林: KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个](https://kexue.fm/archives/8512/comment-page-2#comment-29097)
- [苏剑林: 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理...](https://kexue.fm/archives/9119/comment-page-14#comment-29096)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm/)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [![](https://kexue.fm/usr/themes/geekg/images/rss.png)\\
\\
欢迎订阅](https://kexue.fm/feed)
- [![](https://kexue.fm/usr/themes/geekg/images/mail.png)\\
\\
个性邮箱](https://kexue.fm/archives/119)
- [![](https://kexue.fm/usr/themes/geekg/images/Saturn.png)\\
\\
天象信息](https://kexue.fm/ac.html)
- [![](https://kexue.fm/usr/themes/geekg/images/iss.png)\\
\\
观测ISS](https://kexue.fm/archives/41)
- [![](https://kexue.fm/usr/themes/geekg/images/pi.png)\\
\\
LaTeX](https://kexue.fm/latex.html)
- [![](https://kexue.fm/usr/themes/geekg/images/mlogo.png)\\
\\
关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm/) [信息时代](https://kexue.fm/category/Big-Data) 【中文分词系列】 6\. 基于全卷积网络的中文分词

13Jan

# [【中文分词系列】 6\. 基于全卷积网络的中文分词](https://kexue.fm/archives/4195)

By 苏剑林 \|
2017-01-13 \|
76174位读者 \|

之前已经写过用LSTM来做分词的方案了，今天再来一篇用CNN的，准确来说是FCN，全卷积网络。其实这个模型的主要目的并非研究中文分词，而是练习tensorflow。从两年前就开始用Keras了，可以说对它比较熟了，也渐渐发现了它的一些不足，比如处理变长输入时不方便、加入自定义的约束比较困难等，所以干脆试试原生的tensorflow了，试了之后发现其实也不复杂。嗯，都是python，能有多复杂。本文就是练习一下如何用tensorflow处理不定长输入任务，以中文分词为例，并在最后加入了 **硬解码**， **将深度学习与词典分词结合了起来**。

## CNN [\#](https://kexue.fm/archives/4195\#CNN)

另外，就是关于FCN的。放到语言任务中看，（一维）卷积其实就是ngram模型，从这个角度来看其实CNN远比RNN来得自然，RNN好像就是为序列任务精心设计的，而CNN则是传统ngram模型的一个延伸。另外不管CNN和RNN都有权值共享，看上去只是为了降低运算量的一个折中选择，但事实上里边大有道理。 **CNN中的权值共享是平移不变性的必然结果**，而不是仅仅是降低运算量的一个选择，试想一下，将一幅图像平移一点点，或者在一个句子前插入一个无意义的空格（导致后面所有字都向后平移了一位），这样应该给出一个相似甚至相同的结果，而这要求卷积必然是权值共享的，即权值不能跟位置有关系。

RNN类模型，尤其是LSTM，一直语言任务的霸主，但最近引入门机制的卷积GCNN据说在语言模型上已经超过了LSTM（一点点），这说明哪怕在语言任务中CNN还是很有潜力的。LSTM的优势就是能够捕捉长距离的信息，但事实上语言任务中真正长距离的任务不多，哪怕是语言模型，事实上后一个字的概率只取决于前面几个字罢了，不用取决于前面的全文，而CNN只要层数多一点，卷积核大一点，其实也能达到这个效果了。但CNN还有一个特别的优势：CNN比RNN快多了。用显卡加速的话，显卡最擅长的就是作卷积了，因为显卡本身就是用来处理图像的，GPU对CNN的加速要比对RNN的加速明显多了...

以上内容，就使得我更偏爱CNN，就像facebook那个团队一样（那个GCNN就是他们搞出来的）。全卷积网络则是从头到尾都使用卷积，可以应对不定长输入，而输入不定长、但是输入输出长度相等的任务就更适合了。

## 语料 [\#](https://kexue.fm/archives/4195\#%E8%AF%AD%E6%96%99)

本文的任务是用FCN做一个中文分词系统，思路还是sbme字标注法，不清楚的读者可以看回前几篇文章，有监督训练，因此需要选语料。比较好的语料有两个，一是2014年人民日报语料，二是 [backoff2005](http://sighan.cs.uchicago.edu/bakeoff2005/) 比赛中的语料，后者还带有评测系统。我在两个语料中都实践过了。

如果用2014人民日报语料，那么预处理代码为

```python

```

如果用backoff2005语料，那么预处理代码为

```python

```

然后将语料按照字符串长度排序，这是因为tensorflow虽然支持变长输入，但是在训练的时候，每个batch内的长度要想等，因此需要做一个简单的聚类（按长度聚类）。接着得到一个映射表，这都是很常规的：

```python

```

做一个生成器，用来生成每个batch的训练样本。要注意的是，这里的batch\_size只是一个上限，因为要求每个batch内的句子长度都要相同，这样子并非每个batch的size都能达到1024。

```python

```

## 模型 [\#](https://kexue.fm/archives/4195\#%E6%A8%A1%E5%9E%8B)

到了搭建模型的时候了，其实很简单，就是用了三层卷积叠起来，不指定输入长度，就设为None，设置padding='SAME'使得输入输出同样长度（基于这个目的，也不用池化），中间用relu激活，最后用softmax激活，用交叉熵作为损失函数，就完了。用tensorlfow的话，得自己写好每个过程，但其实也没多复杂。

```python

```

以上就是模型的全部了，然后训练。 **再次给大家推荐一下，用tqdm来辅助显示进度（实时显示进度、速度、精度），简直是绝配啊**。

```python

```

训练过程输出（这是用macbook的cpu训练的，用gtx1060加速只需要3s一个epcho）

> Epcho 1, Accuracy: 0.717359: 347it \[01:06, 5.21it/s\]
>
> Epcho 1 Mean Accuracy: 0.56555
>
> Epcho 2, Accuracy: 0.759943: 347it \[01:08, 8.62it/s\]
>
> Epcho 2 Mean Accuracy: 0.74762
>
> Epcho 3, Accuracy: 0.598692: 347it \[01:08, 5.08it/s\]
>
> Epcho 3 Mean Accuracy: 0.693505
>
> Epcho 4, Accuracy: 0.634529: 347it \[01:07, 5.14it/s\]
>
> Epcho 4 Mean Accuracy: 0.613064
>
> Epcho 5, Accuracy: 0.659949: 347it \[01:07, 5.16it/s\]
>
> Epcho 5 Mean Accuracy: 0.643388
>
> Epcho 6, Accuracy: 0.709635: 347it \[01:07, 5.14it/s\]
>
> Epcho 6 Mean Accuracy: 0.679544
>
> Epcho 7, Accuracy: 0.742839: 271it \[00:42, 2.45it/s\]
>
> ...

## 硬解码 [\#](https://kexue.fm/archives/4195\#%E7%A1%AC%E8%A7%A3%E7%A0%81)

训练完之后，剩下的就是预测、标注、分词了，这都是很基本的，没什么好说。 **最后可以在backoff2005的评测集上达到93%的准确率（backoff2005提供的score脚本算出的准确率），不算最优，但够了，主要还是下面的调整。**

但众所周知，基于字标注法的分词，需要标签语料训练，训练完之后，就适应那一批语料了，比较难拓展到新领域；又或者说，如果发现有分错的地方，则没法很快调整过来。而基于词表的方法则容易调整，只需要增减词典或者调整词频即可。这样可以考虑怎么将深度学习与词典结合起来，这里简单地在最后的解码阶段加入 **硬解码**（人工干预解码）。

模型预测可以得到各个标签的概率，接下来是用viterbi算法得到最优路径，但是在viterbi之前，可以利用词表对各个标签的概率进行调整。这里的做法是：添加一个add\_dict.txt文件，每一行是一个词，包括词语和倍数，这个倍数就是要将相应的标签概率扩大的倍数，比如词表中指定词语“科学空间,10”，而对“科学空间挺好”进行分词时，先用模型得到这六个字的标签概率，然后查找发现“科学空间”这个词在这个句子里边，所以将第一个字为s的概率乘以10，将第二、三个字为m的概率乘以10，将第4个字为e的概率乘以10（不用归一化，因为只看相对值就行了），同样地，如果某些地方切漏了（该切的没有切），也可以加入到词表中，然后设置小于1的倍数就行了。

效果：

> 加入词典前：扫描 二维码 ， 关注 微 信号 。
>
> （加入词典：微信号,10）加入词典后：扫描 二维码 ， 关注 微信号 。

当然，这只是一个经验方法。后面部分代码如下，由于这里只是演示效果，用了正则表达式遍历查找，如果追求效率，应当用AC自动机等多模式匹配工具：

```python

```

_**转载到请包括本文地址：** [https://kexue.fm/archives/4195](https://kexue.fm/archives/4195 "【中文分词系列】 6. 基于全卷积网络的中文分词")_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/4195#share)/ [打赏](https://kexue.fm/archives/4195#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。

你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jan. 13, 2017). 《【中文分词系列】 6. 基于全卷积网络的中文分词 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/4195](https://kexue.fm/archives/4195)

@online{kexuefm-4195,

         title={【中文分词系列】 6. 基于全卷积网络的中文分词},

         author={苏剑林},

         year={2017},

         month={Jan},

         url={\\url{https://kexue.fm/archives/4195}},

}


分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/), [分词](https://kexue.fm/tag/%E5%88%86%E8%AF%8D/), [自然语言处理](https://kexue.fm/tag/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/)[10 评论](https://kexue.fm/archives/4195#comments)

< [狄拉克函数：级数逼近](https://kexue.fm/archives/4187 "狄拉克函数：级数逼近") \| [SVD分解(一)：自编码器与人工智能](https://kexue.fm/archives/4208 "SVD分解(一)：自编码器与人工智能") >

### 你也许还对下面的内容感兴趣

- [随机分词再探：从Viterbi Sampling到完美采样算法](https://kexue.fm/archives/9811 "随机分词再探：从Viterbi Sampling到完美采样算法")
- [随机分词浅探：从Viterbi Decoding到Viterbi Sampling](https://kexue.fm/archives/9768 "随机分词浅探：从Viterbi Decoding到Viterbi Sampling")
- [BytePiece：更纯粹、更高压缩率的Tokenizer](https://kexue.fm/archives/9752 "BytePiece：更纯粹、更高压缩率的Tokenizer")
- [为什么需要残差？一个来自DeepNet的视角](https://kexue.fm/archives/8994 "为什么需要残差？一个来自DeepNet的视角")
- [多任务学习漫谈（三）：分主次之序](https://kexue.fm/archives/8907 "多任务学习漫谈（三）：分主次之序")
- [多任务学习漫谈（二）：行梯度之事](https://kexue.fm/archives/8896 "多任务学习漫谈（二）：行梯度之事")
- [多任务学习漫谈（一）：以损失之名](https://kexue.fm/archives/8870 "多任务学习漫谈（一）：以损失之名")
- [一个二值化词向量模型，是怎么跟果蝇搭上关系的？](https://kexue.fm/archives/8159 "一个二值化词向量模型，是怎么跟果蝇搭上关系的？")
- [也来谈谈RNN的梯度消失/爆炸问题](https://kexue.fm/archives/7888 "也来谈谈RNN的梯度消失/爆炸问题")
- [L2正则没有想象那么好？可能是“权重尺度偏移”惹的祸](https://kexue.fm/archives/7681 "L2正则没有想象那么好？可能是“权重尺度偏移”惹的祸")

[发表你的看法](https://kexue.fm/archives/4195#comment_form)

秦

February 13th, 2017

你好，运行你的代码过程中发现错误，tf.nn.relu(tf.nn.conv1d(embedded\_dropout, W\_conv1, stride=1, padding='SAME') + b\_conv1)这行有问题。

显示AttributeError: 'module' object has no attribute 'conv1d

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=7687#respond-post-4195)

[苏剑林](http://kexue.fm/) 发表于
February 16th, 2017

升级tensorflow到最新版本看看

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=7693#respond-post-4195)

强

March 13th, 2018

博主您好，写的很棒。请问有完整代码吗？

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=8780#respond-post-4195)

liuqi

April 13th, 2018

哈喽站长，我看到网上的文章是 Embedding + Conv1D + MaxPooling + Flatten + ..

用keras的Conv1D提取句子特征，但是keras的Conv1D是不支持掩码操作的，所以他们吧Embedding的mask\_zero设为False，trainable=True，这样做可以代表句子的语义信息吗？填充的部分的意义可以被表达出来吗？

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=9009#respond-post-4195)

[苏剑林](https://kexue.fm/) 发表于
April 14th, 2018

可以不mask，实验效果说话罢了～mask了其实也未必更好，只是mask了会更符合事实而已。

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=9011#respond-post-4195)

liao

November 7th, 2018

博主你好，请问能不能公开利用训练好的模型进行 预测、标注、分词的代码？我把你的程序跑通了，可是我用msr数据集测试的时候达不到93% 只有80左右，我觉得是我用模型预测的时候没有处理好

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=10094#respond-post-4195)

[苏剑林](https://kexue.fm/) 发表于
November 7th, 2018

https://github.com/bojone/crf/blob/master/word\_seg.py

这个可以参考。

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=10095#respond-post-4195)

[NLP+词法系列（二）︱中文分词技术简述、深度学习分词实践（CIPS2016、超多案例） - 站壳网](https://www.zhankr.net/9184.html)

November 6th, 2022

\[...\]苏剑林，基于全卷积网络的中文分词\[...\]

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=20286#respond-post-4195)

[NLP+词法系列（二）︱中文分词技术简述、深度学习分词实践（CIPS2016、超多案例） - SEOOS技术门户](https://www.seoos.net/25298.html)

November 6th, 2022

\[...\]苏剑林，基于全卷积网络的中文分词\[...\]

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=20288#respond-post-4195)

[简明条件随机场CRF介绍（附带纯Keras实现） R11; 白墨代码网](http://code.bmoook.com/%e7%ae%80%e6%98%8e%e6%9d%a1%e4%bb%b6%e9%9a%8f%e6%9c%ba%e5%9c%bacrf%e4%bb%8b%e7%bb%8d%ef%bc%88%e9%99%84%e5%b8%a6%e7%ba%afkeras%e5%ae%9e%e7%8e%b0%ef%bc%89/)

March 13th, 2023

\[...\]2、【中文分词系列】 6. 基于全卷积网络的中文分词\[...\]

[回复评论](https://kexue.fm/archives/4195/comment-page-1?replyTo=21144#respond-post-4195)

[取消回复](https://kexue.fm/archives/4195#respond-post-4195)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；

2\. 可以通过点击评论楼层编号来引用该楼层；

3\. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[CNN](https://kexue.fm/archives/4195#CNN)
[语料](https://kexue.fm/archives/4195#%E8%AF%AD%E6%96%99)
[模型](https://kexue.fm/archives/4195#%E6%A8%A1%E5%9E%8B)
[硬解码](https://kexue.fm/archives/4195#%E7%A1%AC%E8%A7%A3%E7%A0%81)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [三年,两年,一年...](https://kexue.fm/archives/531)
- [生成扩散模型漫谈（四）：DDIM = 高观点DDPM](https://kexue.fm/archives/9181)
- [我害怕](https://kexue.fm/archives/1928)
- [【搜出来的文本】⋅（四）通过增、删、改来用词造句](https://kexue.fm/archives/8194)
- [深度学习中的Lipschitz约束：泛化与生成模型](https://kexue.fm/archives/6051)
- [奔向固原，追逐梦想...](https://kexue.fm/archives/650)
- [集训结束了——入选了IOAA](https://kexue.fm/archives/696)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [Google新搜出的优化器Lion：效率与效果兼得的“训练狮”](https://kexue.fm/archives/9473)
- [用Numpy实现高效的Apriori算法](https://kexue.fm/archives/5525)

### 最近评论

- [Bin](https://kexue.fm/archives/1990/comment-page-2#comment-29105): 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院的往届师兄！看到这篇2013年的...
- [Rapture D](https://kexue.fm/archives/11530/comment-page-1#comment-29104): 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。
- [mofheka](https://kexue.fm/archives/11390/comment-page-1#comment-29103): 苏神是还在用jax是么？最近在做基于Google Pathway的理念做一个动态版的MPMD框...
- [长琴](https://kexue.fm/archives/11530/comment-page-1#comment-29102): 看懂这篇博客也不是一件容易的事情。
- [AlexLi](https://kexue.fm/archives/9257/comment-page-4#comment-29101): 苏老师，请教一下(7)式中将 \\mu(x\_t) 传给 p\_o 进行推理的操作。 $x\_...
- [tyler\_zxc](https://kexue.fm/archives/7921/comment-page-2#comment-29100): "Performer的思想是将标准的Attention线性化，所以为什么不干脆直接训练一个线性...
- [我](https://kexue.fm/archives/11494/comment-page-1#comment-29099): 似乎并非mHC提出矩阵的思想？之前hyper connection就是了
- [winter](https://kexue.fm/archives/10847/comment-page-1#comment-29098): 苏神您好，假如对于比较均匀的attention weightP，往往呈现long tail分布...
- [苏剑林](https://kexue.fm/archives/8512/comment-page-2#comment-29097): KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个
- [苏剑林](https://kexue.fm/archives/9119/comment-page-14#comment-29096): 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理成本和推理效果，那么有的方法可以...

### 友情链接

- [Cool Papers](https://papers.cool/)
- [数学研发](https://bbs.emath.ac.cn/)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com/)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

[![署名-非商业用途-保持一致](https://kexue.fm/usr/themes/geekg/images/cc.gif)](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/) 本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。



© 2009-2026 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com/). Powered by [Typecho](http://typecho.org/). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/ "粤ICP备09093259号")。