![MobileSideBar](https://kexue.fm/usr/themes/geekg/images/slide-button.png)

## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)
- [Transformer升级之路：1...](https://kexue.fm/archives/10862)
- [矩阵的有效秩（Effective ...](https://kexue.fm/archives/10847)
- [通过梯度近似寻找Normaliza...](https://kexue.fm/archives/10831)
- [MoE环游记：4、难处应当多投入](https://kexue.fm/archives/10815)
- [高阶muP：更简明但更高明的谱条件缩放](https://kexue.fm/archives/10795)
- [初探muP：超参数的跨模型尺度迁移规律](https://kexue.fm/archives/10770)
- [MoE环游记：3、换个思路来分配](https://kexue.fm/archives/10757)
- [Muon续集：为什么我们选择尝试M...](https://kexue.fm/archives/10739)

## COMMENTS

- [苏剑林: 1、明白了，我将$q\_{\\phi}(z\|x)$看成$q\_{\\p...](https://kexue.fm/archives/5239/comment-page-3#comment-27496)
- [Suahi: 谢谢苏老师的回复！1\. 首先回复您为什么ELBO不带KL，并不...](https://kexue.fm/archives/5239/comment-page-3#comment-27493)
- [eular: 是的，当$k$比较大时会出现这种情况。](https://kexue.fm/archives/10373/comment-page-1#comment-27492)
- [苏剑林: 肯定是$\\mathbb{E}\_{x \\sim p\_{data}...](https://kexue.fm/archives/5239/comment-page-3#comment-27491)
- [苏剑林: 你的意思是$\\lambda(\\boldsymbol{x}) <...](https://kexue.fm/archives/10373/comment-page-1#comment-27490)
- [苏剑林: 好问题，下一篇文章可能会讨论这个问题](https://kexue.fm/archives/10735/comment-page-1#comment-27489)
- [苏剑林: 不大熟悉，但都diffusion forcing了，还有必要CM吗](https://kexue.fm/archives/10633/comment-page-1#comment-27488)
- [苏剑林: 简单看了一下，好像没什么新东西呀？还是我看漏了什么？](https://kexue.fm/archives/10711/comment-page-2#comment-27487)
- [苏剑林: 感谢指出，已修正。](https://kexue.fm/archives/8601/comment-page-1#comment-27486)
- [苏剑林: 扩散桥确实时不时刷到，但没理解这一套东西有什么特别价值或者应用...](https://kexue.fm/archives/9209/comment-page-7#comment-27485)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [![](https://kexue.fm/usr/themes/geekg/images/rss.png)\
\
欢迎订阅](https://kexue.fm/feed)
- [![](https://kexue.fm/usr/themes/geekg/images/mail.png)\
\
个性邮箱](https://kexue.fm/archives/119)
- [![](https://kexue.fm/usr/themes/geekg/images/Saturn.png)\
\
天象信息](https://kexue.fm/ac.html)
- [![](https://kexue.fm/usr/themes/geekg/images/iss.png)\
\
观测ISS](https://kexue.fm/archives/41)
- [![](https://kexue.fm/usr/themes/geekg/images/pi.png)\
\
LaTeX](https://kexue.fm/latex.html)
- [![](https://kexue.fm/usr/themes/geekg/images/mlogo.png)\
\
关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 基于Bert的NL2SQL模型：一个简明的Baseline

29Jun

# [基于Bert的NL2SQL模型：一个简明的Baseline](https://kexue.fm/archives/6771)

By 苏剑林 \|
2019-06-29 \|
160448位读者\|

在之前的文章 [《当Bert遇上Keras：这可能是Bert最简单的打开姿势》](https://kexue.fm/archives/6736) 中，我们介绍了基于微调Bert的三个NLP例子，算是体验了一把Bert的强大和Keras的便捷。而在这篇文章中，我们再添一个例子：基于Bert的NL2SQL模型。

NL2SQL的NL也就是Natural Language，所以NL2SQL的意思就是“自然语言转SQL语句”，近年来也颇多研究，它算是人工智能领域中比较实用的一个任务。而笔者做这个模型的契机，则是今年我司举办的 [首届“中文NL2SQL挑战赛”](https://tianchi.aliyun.com/markets/tianchi/zhuiyi_cn)：

> 首届中文NL2SQL挑战赛，使用金融以及通用领域的表格数据作为数据源，提供在此基础上标注的自然语言与SQL语句的匹配对，希望选手可以利用数据训练出可以准确转换自然语言到SQL的模型。

这个NL2SQL比赛算是今年比较大型的NLP赛事了，赛前投入了颇多人力物力进行宣传推广，比赛的奖金也颇丰富，唯一的问题是NL2SQL本身算是偏冷门的研究领域，所以注定不会太火爆，为此主办方也放出了一个 [Baseline](https://github.com/ZhuiyiTechnology/nl2sql_baseline)，基于Pytorch写的，希望能降低大家的入门难度。

抱着“Baseline怎么能少得了Keras版”的心态，我抽时间自己用Keras做了做这个比赛，为了简化模型并且提升效果也加载了预训练的Bert模型，最终形成此文。

## 数据示例 [\#](https://kexue.fm/archives/6771\#%E6%95%B0%E6%8D%AE%E7%A4%BA%E4%BE%8B)

每个数据样本如下：

```
{
 "table_id": "a1b2c3d4", # 相应表格的id
 "question": "世茂茂悦府新盘容积率大于1，请问它的套均面积是多少？", # 自然语言问句
 "sql":{ # 真实SQL
 "sel": [7], # SQL选择的列
 "agg": [0], # 选择的列相应的聚合函数, '0'代表无
 "cond_conn_op": 0, # 条件之间的关系
 "conds": [
 [1, 2, "世茂茂悦府"], # 条件列, 条件类型, 条件值，col_1 == "世茂茂悦府"
 [6, 0, "1"]
 ]
 }
}

# 其中条件运算符、聚合符、连接符分别如下
op_sql_dict = {0:">", 1:"<", 2:"==", 3:"!="}
agg_sql_dict = {0:"", 1:"AVG", 2:"MAX", 3:"MIN", 4:"COUNT", 5:"SUM"}
conn_sql_dict = {0:"", 1:"and", 2:"or"}
```

然后每个样本都对应着一个数据表，里边包含该表的所有列名，以及相应的数据记录，而原则上生成的SQL语句在对应的数据表上是可以执行的，并且都能返回有效的结果。

可以看到，虽然说是NL2SQL，但事实上主办方已经将SQL语句做了十分清晰的格式化，这样一来这个任务就可以相当大地简化了。比如sel这个字段，其实就是一个多标签分类模型，只不过类别可能会随时变化，因为这里的类别实际上对应着数据表的列，而每个样本的数据表及其含义都不尽相同，所以我们要根据表的列名来动态地编码一个类别向量；至于agg则跟sel一一对应，并且类别是固定的，cond\_conn\_op则是一个单标签分类问题。

最后的conds相对复杂一些，它需要结合字标注和分类，因为要同时决定哪一列是条件，条件的运算关系，以及条件对应的值，并且要注意的是，条件值并不总是question的一个片段，它有可能是格式化后的结果，比如question里边是“16年”，那么条件值可能是格式化之后的“2016”，不过，由于主办方保证生成的sql是能够在对应数据表中执行并且出有效结果的，所以如果条件运算符是“==”的时候，那么条件值肯定会出现在数据表对应列的值之中，比如上述示例样本中，数据表的第一列肯定会有“世茂茂悦府”这个值，而通过这个信息我们也可以去校正预测结果。

## 模型结构 [\#](https://kexue.fm/archives/6771\#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84)

**正式看本模型之前，读者不妨自己思考一番，想一下自己会怎么做。只有经过思考之后，才会明白其中的困难所在，也就这样才能理解本模型的一些处理技巧的要点。**

本文的模型示意图如下：

[![本文的NL2SQL模型示意图。主要包括4个不同的分类器:序列标注器](https://kexue.fm/usr/uploads/2019/06/2888177543.png)](https://kexue.fm/usr/uploads/2019/06/2888177543.png)

本文的NL2SQL模型示意图。主要包括4个不同的分类器:序列标注器

作为一个SQL，最基本的是要决定哪些列会被select，而每个表的列的含义均不一样，所以我们要将question句子连同数据表的所有表头拼起来，一同输入到Bert模型中进行实时编码，其中每一个表头也视为一个句子，用\[CLS\]\*\*\*\[SEP\]括住。经过Bert之后，我们就得到了一系列编码向量，然后就看我们怎么去用这些向量了。

第一个\[CLS\]对应的向量，我们可以认为是整个问题的句向量，我们用它来预测conds的连接符。后面的每个\[CLS\]对应的向量，我们认为是每个表头的编码向量，我们把它拿出来，用来预测该表头表示的列是否应该被select。注意，此处预测有一个技巧，就是前面说了除了预测sel外，还要预测对应的agg，其中agg一共有6个类别，代表不同的距离运算，既然如此，我们干脆多增加一个类别，第7个类别代表着此列不被select，这样一来，每一列都对应着一个7分类问题，如果分到前6类，那么代表着此类被select而且同时预测到了agg，如果分到了第7类，那意味着此类不被select。

现在就剩下比较复杂的conds了，就是 `where col_1 == value_1` 这样子的，col\_1、value\_1以及运算符==都要找出来。conds的预测分两步，第一步预测条件值，第二步预测条件列，预测条件值其实就是一个序列标注问题，而条件值对应的运算符有4个，我们同样新增一类变成5类，第5类代表着当前字不被标注，否则就被标注，这样我们就能预测出条件值和运算符了。剩下的就是预测条件值对应的列，我们将标注出来的值的字向量跟每个表头的向量一一算相似度，然后softmax。我这里算相似度的方法是最简单的，直接将字向量和表头向量拼接起来，然后过一个全连接层后再接一个 `Dense(1)`，做得这么简单，一是因为本文主要目的是给出一个基本可行的demo而非一个完善的程序，需要留些改进空间给读者，二是因为做得复杂了，就很容易显存不足而OOM了。

**顺便说一下，本文的模型是自己根据比赛任务“闭门造车”出来的，如果读者需要跟我讨论主流的NL2SQL模型，我可能就无能为力了，请见谅。**

## 实验结果 [\#](https://kexue.fm/archives/6771\#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C)

本文的模型代码位于：

[https://github.com/bojone/bert\_in\_keras/blob/master/nl2sql\_baseline.py](https://github.com/bojone/bert_in_keras/blob/master/nl2sql_baseline.py)

注意，如果你执行此代码报错，那么你可能需要修改一下Keras的 `backend/tensorflow_backend.py`，将 `sparse_categorical_crossentropy` 函数中原本是

```
logits = tf.reshape(output, [-1, int(output_shape[-1])])
```

的那一行改为

```
logits = tf.reshape(output, [-1, tf.shape(output)[-1]])
```

我已经向官方提了这个修正，并且已经通过了（请看 [这里](https://github.com/keras-team/keras/commit/613aeff37a721450d94906df1a3f3cc51e2299d4)），在未来的版本应该就自动包含这个特性了。

还是那句话，只要你认真地观察过比赛数据、独立思考过这个任务，上面本文介绍的模型其实很容易理解，而简单的模型能够有不错的效果，则得益于Bert强大的语义编码能力。在线下valid集上，本文的模型生成的SQL全匹配率大概为58%左右，而官方的评估指标是(全匹配率 \+ 执行匹配率) / 2，也就是说你有可能写出跟标注答案不同的SQL语句，但执行结果是一致的，这也算正确一半。

这样一来最终得分肯定会比58%要高，我估计是 **65%** 左右吧，我看了看当前榜单，如果65%的话还可以排在前几名（第一名的大佬现在是70%）。由于公司员工不允许打榜评测，所以我没参与过评测，也不知道线上提交会有多少，有兴趣试用的选手自行提交测试吧。

对了，要跑这个脚本最好有个1080ti或者以上的显卡，如果你没有那么多显存，你可以试着降低maxlen和batch size。还有，现在Bert可用的中文预训练权重有两个，一个是 [官方版](https://github.com/google-research/bert) 的，一个是 [哈工大版](https://github.com/ymcui/Chinese-BERT-wwm) 的，两个的最终效果差不多，但是哈工大版的收敛更快。

纵观整个模型，在实现上，最困难的应当是要精细地考虑各种mask，在上述脚本中， `xm, hm, cm` 是三个mask变量，就是要去除训练过程中padding部分带来的效应。注意mask不是Keras独有，不管你用Tensorflow还是Pytorch，理论上你都要仔细地处理好mask。如果读者实在读不懂mask部分，欢迎留言提问讨论，但是在提问之前，请你回答以下问题：

> mask之前的序列大概是怎样的？mask之后序列的哪些位置发生了变化？变成了怎么样？

回答这个问题是证明“你已经能明白程序做了什么运算了，只是不明白为什么这样运算”。而如果你连这个运算本身都看不明白，我想我们很难沟通下去了（哪部分发生了变化总能知道吧...），还是好好学学Keras或者Tensorflow再来玩吧，不能想着一蹴而就。

## 前后处理 [\#](https://kexue.fm/archives/6771\#%E5%89%8D%E5%90%8E%E5%A4%84%E7%90%86)

对于模型来说，实现的困难部分在于mask。不过如果看整个脚本的话，其实代码占比最多的就是数据的读取和预处理、结果的后处理这两部分罢了，真正搭建模型也就只有二十行左右（再次惊叹Keras的简洁和Bert的强大吧）。

其中我们说过条件值不一定出现在question中，那如何用对question字标注的方法来抽取条件值呢？

我的方法是，如果条件值不出现在question，那么我就对question分词，然后找出question的所有1gram、2gram、3gram，然后根据条件值找出一个最相近的ngram作为标注片段。而在预测的时候，如果找到了一个ngram作为条件值、并且运算符为==时，我们会判断这个ngram有没有在数据库出现过，如果有直接保留，如果没有则在数据库中找一个最相近的值。

相应的过程在代码中都有体现，欢迎细读。

## 文章小结 [\#](https://kexue.fm/archives/6771\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

欢迎大家来玩～

[![首届中文NL2SQL挑战赛](https://kexue.fm/usr/uploads/2019/06/3389819572.png)](https://kexue.fm/usr/uploads/2019/06/3389819572.png)

首届中文NL2SQL挑战赛

> [https://tianchi.aliyun.com/markets/tianchi/zhuiyi\_cn](https://tianchi.aliyun.com/markets/tianchi/zhuiyi_cn)

祝大家取得好成绩！

_**转载到请包括本文地址：** [https://kexue.fm/archives/6771](https://kexue.fm/archives/6771)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/6771#share)/ [打赏](https://kexue.fm/archives/6771#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。

你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jun. 29, 2019). 《 基于Bert的NL2SQL模型：一个简明的Baseline 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/6771](https://kexue.fm/archives/6771)

@online{kexuefm-6771,

        title={ 基于Bert的NL2SQL模型：一个简明的Baseline},

        author={苏剑林},

        year={2019},

        month={Jun},

        url={\\url{https://kexue.fm/archives/6771}},

}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/), [比赛](https://kexue.fm/tag/%E6%AF%94%E8%B5%9B/), [sql](https://kexue.fm/tag/sql/), [attention](https://kexue.fm/tag/attention/)[45 评论](https://kexue.fm/archives/6771#comments)

< [VQ-VAE的简明介绍：量子化自编码器](https://kexue.fm/archives/6760) \| [你跳绳的时候，想过绳子的形状曲线是怎样的吗？](https://kexue.fm/archives/6784) >

### 你也许还对下面的内容感兴趣

- [Transformer升级之路：19、第二类旋转位置编码](https://kexue.fm/archives/10862)
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
- [“闭门造车”之多模态思路浅谈（三）：位置编码](https://kexue.fm/archives/10352)
- [Decoder-only的LLM为什么需要位置编码？](https://kexue.fm/archives/10347)
- [Monarch矩阵：计算高效的稀疏型矩阵分解](https://kexue.fm/archives/10249)
- [Transformer升级之路：18、RoPE的底数选择原则](https://kexue.fm/archives/10122)
- [缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA](https://kexue.fm/archives/10091)
- [Transformer升级之路：17、多模态位置编码的简单思考](https://kexue.fm/archives/10040)
- [时空之章：将Attention视为平方复杂度的RNN](https://kexue.fm/archives/10017)
- [“闭门造车”之多模态思路浅谈（一）：无损输入](https://kexue.fm/archives/9984)

[发表你的看法](https://kexue.fm/archives/6771#comment_form)

1. [«](https://kexue.fm/archives/6771/comment-page-1#comments)
2. [1](https://kexue.fm/archives/6771/comment-page-1#comments)
3. [2](https://kexue.fm/archives/6771/comment-page-2#comments)

DANDAN

July 19th, 2019

苏神，我看了你的代码，想做一些改动，比如cls输出得全局向量和batch\_gather获得的None h\_len 768向量做一个简单的attention，这里需要repeat cls 扩大他的维度，但是您全输入的都是None，所以想问一下 ，批次喂入是保证了一个批次内长度一致 不易浪费 单数也导致了不同批次 长度不一致，所以输入input的维度全是None 这样的话 该怎么操作呢！对未知的维度，有些指定的操作就不行了，比如repeat需要获得一个repeat的数量！这该怎么解决阿 还是推倒全部重来！

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=11642#respond-post-6771)

[苏剑林](https://kexue.fm) 发表于
July 19th, 2019

K.shape(x)\[1\]可以动态获取seq的长度，K.tile可以实现重复。

你能遇到的问题，别人都想到过了...所以不用“阿”也不用“！”，冷静找找资料吧。

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=11646#respond-post-6771)

DANDAN 发表于
July 19th, 2019

哈哈哈哈 爱死你了 苏神，我是试过什么K.int\_shape()啊 hm.shape(1)啊等 都没成功，才来回复的呢！感谢感谢。以后好好学keras好好爱keras

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=11652#respond-post-6771)

[ningshixian](https://ningshixian.github.io/) 发表于
November 13th, 2019

DANDAN 你好

我想请教下你对苏神代码的改进 是如何实现的？我现在有同样的需求，但是不太清楚怎么实现...

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=12351#respond-post-6771)

beader

September 10th, 2019

"剩下的就是预测条件值对应的列，我们将标注出来的值的字向量跟每个表头的向量一一算相似度，然后softmax。"

这里利用向量拼接然后 Dense(1) 求"相似度"，然后 softmax 的方式，也许有点点小问题。

这事实上等价于将一个相同的值 "Dense(1)(字向量)"，加到每一个 "Dense(1)(表头向量)" 中，但其实这个操作并不影响最终的 softmax 值。您在源码中确实也是这么实现的。

https://github.com/bojone/bert\_in\_keras/blob/master/nl2sql\_baseline.py#L226-L232

\`\`\`python

x = Lambda(lambda x: K.expand\_dims(x, 2))(x)

x4h = Lambda(lambda x: K.expand\_dims(x, 1))(x4h)

pcsel\_1 = Dense(1)(x)

pcsel\_2 = Dense(1)(x4h)

pcsel = Lambda(lambda x: x\[0\] + x\[1\])(\[pcsel\_1, pcsel\_2\])

pcsel = Lambda(lambda x: x\[0\]\[..., 0\] - (1 - x\[1\]) \* 1e10)(\[pcsel, hm\])

pcsel = Activation('softmax')(pcsel)

\`\`\`

假设 header 有 n 个 column，

pcsel\_1 + pcsel\_2 的时候，pcsel\_1 在 dim=1 这个维度上复制了 n 次，所以相当于 pcsel\_2 中每个值加上了一个常数，不影响 softmax 之后的值，其后果就是 cond 中 col 的选择和当前的字向量无关。

通过如下代码观察 pcsel 的值:

\`\`\`python

model\_pcsel = Model(

\[x1\_in, x2\_in, h\_in, hm\_in\],

\[pcsel\]

)

\`\`\`

可以发现，对于同一个句子，question 中所有的字选择的 column 是完全一样的。

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=11967#respond-post-6771)

[苏剑林](https://kexue.fm) 发表于
September 10th, 2019

是的，我明白你说的问题了，感谢你的细致思考和反馈，确实是我的疏忽。

我已经修正了代码，并在文章中修正了评测结果～

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=11969#respond-post-6771)

doc-coder

April 2nd, 2020

所以这个数据默认最多2个条件吗？（2个conds，一个cond\_conn\_op)？如果是这样那其实这个数据集还是有点太简单了。

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=13132#respond-post-6771)

[苏剑林](https://kexue.fm) 发表于
April 2nd, 2020

是的

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=13133#respond-post-6771)

sly

April 21st, 2020

苏神您好，想上手试试，苦于错过了比赛，无法得到数据集，请问您这边有数据集可以分享下吗？

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=13207#respond-post-6771)

[苏剑林](https://kexue.fm) 发表于
April 21st, 2020

没有

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=13210#respond-post-6771)

雨天和

April 26th, 2020

苏神这个不出个 bert4keras版吗

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=13226#respond-post-6771)

liixiaozh 发表于
October 23rd, 2020

这个不难呀

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=14629#respond-post-6771)

zzzz

March 14th, 2022

return K.tf.batch\_gather(seq, idxs)这个一直报错，怎么改呢？

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=18693#respond-post-6771)

[苏剑林](https://kexue.fm) 发表于
March 15th, 2022

自己import tensorflow as tf，然后改为tf

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=18700#respond-post-6771)

water68

January 30th, 2024

想知道NL2sql这个数据集是怎么标注的，全部手工标注吗，没有工具辅助吗

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=23627#respond-post-6771)

[苏剑林](https://kexue.fm) 发表于
January 31st, 2024

有带界面的标注工具吧

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=23641#respond-post-6771)

stone2024

February 21st, 2024

https://github.com/ZhuiyiTechnology/nl2sql\_baseline.git--项目中用到的数据集没有找到，请问如何获取数据集？

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=23712#respond-post-6771)

[苏剑林](https://kexue.fm) 发表于
February 21st, 2024

我现在也没有了，可以尝试联系主办方～

[回复评论](https://kexue.fm/archives/6771/comment-page-2?replyTo=23736#respond-post-6771)

1. [«](https://kexue.fm/archives/6771/comment-page-1#comments)
2. [1](https://kexue.fm/archives/6771/comment-page-1#comments)
3. [2](https://kexue.fm/archives/6771/comment-page-2#comments)

[取消回复](https://kexue.fm/archives/6771#respond-post-6771)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；

2\. 可以通过点击评论楼层编号来引用该楼层；

3\. 网站可能会有点卡，如非确认评论失败，请不要重复点击提交。

### 内容速览

[数据示例](https://kexue.fm/archives/6771#%E6%95%B0%E6%8D%AE%E7%A4%BA%E4%BE%8B)
[模型结构](https://kexue.fm/archives/6771#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84)
[实验结果](https://kexue.fm/archives/6771#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C)
[前后处理](https://kexue.fm/archives/6771#%E5%89%8D%E5%90%8E%E5%A4%84%E7%90%86)
[文章小结](https://kexue.fm/archives/6771#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [端到端的腾讯验证码识别（46%正确率）](https://kexue.fm/archives/4138)
- [停！](https://kexue.fm/archives/72)
- [【分享】兴隆山的双子座流星雨](https://kexue.fm/archives/3580)
- [网站PR升到3了！](https://kexue.fm/archives/335)
- [UniVAE：基于Transformer的单模型、多尺度的VAE模型](https://kexue.fm/archives/8475)
- [《积分公式大全》网络版本](https://kexue.fm/archives/976)
- [行星的逆行,顺行和留(计算公式)](https://kexue.fm/archives/608)
- [\[问题解答\]运煤车的最大路程（更正）](https://kexue.fm/archives/2587)
- [生成扩散模型漫谈（二十）：从ReFlow到WGAN-GP](https://kexue.fm/archives/9668)
- [【NASA每日一图】太阳系中的木卫三](https://kexue.fm/archives/130)

### 最近评论

- [苏剑林](https://kexue.fm/archives/5239/comment-page-3#comment-27496): 1、明白了，我将$q\_{\\phi}(z\|x)$看成$q\_{\\phi}(x\|z)$了（ELBO厌...
- [Suahi](https://kexue.fm/archives/5239/comment-page-3#comment-27493): 谢谢苏老师的回复！1\. 首先回复您为什么ELBO不带KL，并不是最终损失函数形式，需要做如下变...
- [eular](https://kexue.fm/archives/10373/comment-page-1#comment-27492): 是的，当$k$比较大时会出现这种情况。
- [苏剑林](https://kexue.fm/archives/5239/comment-page-3#comment-27491): 肯定是$\\mathbb{E}\_{x \\sim p\_{data}(x)}\[\\log(p\_{\\th...
- [苏剑林](https://kexue.fm/archives/10373/comment-page-1#comment-27490): 你的意思是$\\lambda(\\boldsymbol{x}) < x\_{\\min}$，一般情况下...
- [苏剑林](https://kexue.fm/archives/10735/comment-page-1#comment-27489): 好问题，下一篇文章可能会讨论这个问题
- [苏剑林](https://kexue.fm/archives/10633/comment-page-1#comment-27488): 不大熟悉，但都diffusion forcing了，还有必要CM吗
- [苏剑林](https://kexue.fm/archives/10711/comment-page-2#comment-27487): 简单看了一下，好像没什么新东西呀？还是我看漏了什么？
- [苏剑林](https://kexue.fm/archives/8601/comment-page-1#comment-27486): 感谢指出，已修正。
- [苏剑林](https://kexue.fm/archives/9209/comment-page-7#comment-27485): 扩散桥确实时不时刷到，但没理解这一套东西有什么特别价值或者应用，所以也就没去学习。如果您了解它...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

[![署名-非商业用途-保持一致](https://kexue.fm/usr/themes/geekg/images/cc.gif)](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/) 本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。

© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。