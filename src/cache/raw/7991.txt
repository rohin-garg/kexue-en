## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)

## COMMENTS

- [苏剑林: 刚入门那会的文章，不用深究了。](https://kexue.fm/archives/481/comment-page-1#comment-27835)
- [苏剑林: 目前各方面的实测效果看来不会，我觉得本质上就是因为partia...](https://kexue.fm/archives/10122/comment-page-1#comment-27834)
- [苏剑林: 首先，瞬时速度为什么跟$t$无关？其次，现在reflow和me...](https://kexue.fm/archives/10958/comment-page-1#comment-27833)
- [苏剑林: 对于每一步数据都严格对齐来说，0.01的loss差距不小了，因...](https://kexue.fm/archives/10907/comment-page-2#comment-27832)
- [苏剑林: \[comment=27808\]rpsun\[/comment\]\
...](https://kexue.fm/archives/10699/comment-page-1#comment-27831)
- [苏剑林: 自己都没怎么关注天象了，惭愧](https://kexue.fm/archives/1490/comment-page-1#comment-27830)
- [苏剑林: 原来如此。其实只要预测空间是连续空间，并且任务本质是一对多的输...](https://kexue.fm/archives/10958/comment-page-1#comment-27829)
- [苏剑林: 你可以拿一批语料去eval，看各个expert分别激活了多少次呀。](https://kexue.fm/archives/10945/comment-page-1#comment-27828)
- [苏剑林: 首先这个分布肯定是存在的（贝叶斯公式无关分布），然后它的概率密...](https://kexue.fm/archives/9164/comment-page-4#comment-27827)
- [苏剑林: 这两天看了下FoPE，感觉它的分析有点道理，但它实现的代码跟论...](https://kexue.fm/archives/10907/comment-page-2#comment-27826)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) Mitchell近似：乘法变为加法，误差不超过1/9

14Dec

# [Mitchell近似：乘法变为加法，误差不超过1/9](https://kexue.fm/archives/7991)

By 苏剑林 \|
2020-12-14 \|
48381位读者\|

今天给大家介绍一篇1962年的论文 [《Computer Multiplication and Division Using Binary Logarithms》](https://ieeexplore.ieee.org/document/5219391)，作者是John N. Mitchell，他在里边提出了一个相当有意思的算法：在二进制下，可以完全通过加法来近似完成两个数的相乘，最大误差不超过1/9。整个算法相当巧妙，更有意思的是它还有着非常简洁的编程实现，让人拍案叫绝。然而，笔者发现网上居然找不到介绍这个算法的网页，所以在此介绍一番。

你以为这只是过时的玩意？那你就错了，前不久才有人利用它发了一篇NeurIPS 2020呢！所以，确定不来了解一下吗？

## 快速对数与指数 [\#](https://kexue.fm/archives/7991\#%E5%BF%AB%E9%80%9F%E5%AF%B9%E6%95%B0%E4%B8%8E%E6%8C%87%E6%95%B0)

说到乘法变加法，大家应该很自然能联想到对数和指数，即
\\begin{equation}pq = a^s, \\quad s = \\log\_a p + \\log\_a q\\end{equation}
本文是基于二进制的，所以$a=2$。问题在于上式虽然确实将乘法转为加法了，但是对数$\\log\_2 p, \\log\_2 q$和转换后的指数$2^s$算起来都不是一件容易的事情。所以要利用这个等式做乘法，关键在于要实现快速对数和指数运算。

对于十进制的非负数$p$，我们假设它的二进制表示为
\\begin{equation}z\_n z\_{n-1} \\cdots z\_1 z\_0 . z\_{-1} z\_{-2} \\cdots z\_{-(m-1)} z\_{-m}\\end{equation}
其中$z\_n = 1$且各个$z\_i\\in\\{0,1\\}$，那么我们就有
\\begin{equation}p = 2^n + \\sum\_{i=-m}^{n-1} z\_i 2^i = 2^n\\left(1 + \\sum\_{i=-m}^{n-1} z\_i 2^{i-n}\\right)\\end{equation}
记$x = \\sum\\limits\_{i=-m}^{n-1} z\_i 2^{i-n}$，我们得到
\\begin{equation}\\log\_2 p = n + \\log\_2\\left(1 + x\\right)\\end{equation}
在这里，Mitchell做了一个相当果断而美妙的近似，那就是$\\log\_2\\left(1 + x\\right)\\approx x$（后面我们会再进行误差分析），于是得到
\\begin{equation}\\log\_2 p \\approx n + x\\end{equation}
这个结果妙在何处呢？首先$n$是一个整数，等于$p$的二进制的整数部分的位数减去1，它转换为二进制自然自然也是整数；那$x$呢？根据$x$的定义我们不难看出，实际上$x$的二进制表示就是
\\begin{equation}0 . z\_{n-1} \\cdots z\_1 z\_0 z\_{-1} z\_{-2} \\cdots z\_{-(m-1)} z\_{-m}\\end{equation}
也就是说$x$其实就是上述近似的小数部分，它的二进制表示只不过是$p$的二进制表示的简单变形（小数点平移）。

综上所述，我们得到对数的Mitchell近似算法：

> 1、输入十进制的$p$；
> 2、将$p$转换为二进制数$z\_n z\_{n-1} \\cdots z\_1 z\_0 . z\_{-1} z\_{-2} \\cdots z\_{-(m-1)} z\_{-m}$，这里$z\_n=1$；
> 3、将$n$转换为二进制数$y\_k y\_{k-1} \\cdots y\_1 y\_0$；
> 4、那么$\\log\_2 p$的二进制近似为$y\_k y\_{k-1} \\cdots y\_1 y\_0 . z\_{n-1} \\cdots z\_1 z\_0 z\_{-1} z\_{-2} \\cdots z\_{-(m-1)} z\_{-m}$。

将上述过程逆过来，就得到了指数的Mitchell近似算法：

> 1、输入二进制的$z\_n z\_{n-1} \\cdots z\_1 z\_0 . z\_{-1} z\_{-2} \\cdots z\_{-(m-1)} z\_{-m}$；
> 2、将$z\_n z\_{n-1} \\cdots z\_1 z\_0$转换为十进制数$n$；
> 3、那么它的指数的二进制近似为$1 z\_{-1} z\_{-2} \\cdots z\_{-(n-1)} z\_{-n} . z\_{-(n+1)} z\_{-(n+2)}\\cdots z\_{-(m-1)} z\_{-m}$；
> 4、将上述结果转换为十进制。

所以，在二进制下对数和指数的近似计算就只是数数和拼接操作而已！惊艳不？神奇不？

## 一个乘法的例子 [\#](https://kexue.fm/archives/7991\#%E4%B8%80%E4%B8%AA%E4%B9%98%E6%B3%95%E7%9A%84%E4%BE%8B%E5%AD%90)

有了快速的（近似的）对数和指数算法，我们就可以乘法了，现在我们就用这个思路来算一个具体例子，由此加深我们对上述过程理解。

我们要算的是$12.3\\times 4.56$，计算流程如下表（近似指数是对求和的结果算的）：
$$\\begin{array}{c\|cc}
\\hline
p,q\|\_\\text{十进制} & 12.3 & 4.56 \\\
\\hline
p,q\|\_\\text{二进制} & 1100.0100110 & 100.1000111 \\\
\\hline
n\|\_\\text{十进制} & 3 & 2 \\\
\\hline
n\|\_\\text{二进制} & 11 & 10 \\\
\\hline
x\|\_\\text{二进制} & 0.1000100110 & 0.001000111 \\\
\\hline
n+x\|\_\\text{二进制} & 11.1000100110 & 10.001000111 \\\
\\hline
\\text{求和}\|\_\\text{二进制} & \\rlap{\\,\\,\\,101.10101101} \\\
\\hline
n\|\_\\text{二进制} & \\rlap{\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,101} \\\
\\hline
n\|\_\\text{十进制} & \\rlap{\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,5} \\\
\\hline
x\|\_\\text{二进制} & \\rlap{\\,\\,\\,\\,\\,\\,0.10101101} \\\
\\hline
\\text{近似指数}\|\_\\text{二进制} & \\rlap{\\,\\,\\,\\,\\,\\,110101.101} \\\
\\hline
\\text{近似指数}\|\_\\text{十进制} & \\rlap{\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,53.625} \\\
\\hline
\\text{精确乘积}\|\_\\text{十进制} & \\rlap{\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,56.088} \\\
\\hline
\\text{相对误差}\|\_\\text{十进制} & \\rlap{\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,4.39\\%} \\\
\\hline
\\end{array}$$
其中$p,q$二进制表示为无限循环小数，这里只截断了有限位，如果保留精确的二进制表示，那么最终结果是53.68，跟上表的53.625相差不大。可以看到，整个过程的主要计算量有两部分：求和、十进制与二进制之间的转换。然而，尽管十进制与二进制之间的转换对于我们人来说是计算量比较大的操作，但对于计算机来说，它本身就是二进制存储的，我们可以认为两者之间的转换计算量可以忽略不计；又或者说，只要我们还是以十进制为输出，那么不管什么算法这部分计算量都是必然存在的，因此我们不把它算进去算法的复杂度中。所以，整个算法的计算量就只有求和这一步，实现了将乘法（近似地）转化为加法运算。

## 神奇的C++实现 [\#](https://kexue.fm/archives/7991\#%E7%A5%9E%E5%A5%87%E7%9A%84C++%E5%AE%9E%E7%8E%B0)

更妙的是，上述过程有一个非常简单的C++实现，参考如下：

```
#include 

int main() {
 float a = 12.3f;
 float b = 4.56f;
 int c = *(int*)&a + *(int*)&b - 0x3f800000;
 printf("近似结果：%f\n", *(float*)&c);
 printf("精确结果：%f\n", a * b);
 return 0;
}

```

没有C++编译环境的朋友也可以找个网页版的在线C++运行程序试跑一下，测试一下它的结果。就算是不懂C++的朋友（比如笔者）大概也可以感觉到，这段代码大概就是转化为两个数相加并且减去一个常数，这怎么就能实现乘法了？还有的读者可能问Python里边能这样写吗？

首先，后一个问题的答案是不能，因为Python的数据类型已经经过了高度封装了，而上述C++代码的可行性在于浮点数的IEEE754表示法：一个十进制浮点数首先会被转化为二进制，然后标准化为科学计数法，最后用一个特定的结构将科学计数法的结果存下来。具体来说，IEEE754用32个0/1表示一个浮点数，其中1位表示正负号（0为正），8位表示科学计数法的指数，23位表示科学计数法的小数，以9.75为例，它的二进制为1001.11，写成科学计数法就是$1.00111\\times 10^{11}$，这里的10、11都是二进制，$10^{11}$对应十进制的$2^3$，注意指数部分我们还需要加上偏移量127，即3次方实际上存的是130（二进制表示为10000010），因为前面126个数要用来表示负整数幂，而主要部分1.00111，由于第一位必然是1，因此只需要把0.00111存下来，所以9.75背后的表示方式为：
\\begin{array}{c\|c\|c}
\\hline
\\text{符号} & \\text{指数} & \\text{小数} \\\
\\hline
0 & 10000010 & 0011100\\, 00000000\\, 00000000 \\\
\\hline
\\end{array}

知道IEEE754表示法之后，就可以理解上述代码了， `*(int*)&a` 和 `*(int*)&b` 其实就是把$a,b$的IEEE754表示拿出来，当作普通的整数来运算，两者相加，其实正好对应着Mitchell近似对数后的相加结果，但是指数部分会多出一个偏移量，所以要减去整个偏移量，由于偏移量是127，并且后面还有23位，所以减去偏移量相当于减去常数$127\\times 2^{23}$，表示为十六进制就是3f800000（因为二进制表示太长了，所以计算机一般用十六进制来代替二进制进行IO），最后将加减后的结果恢复为浮点数。

（注：其实笔者也不懂C++，上述理解是东拼西凑勉强得到的，如果不当之处，请大家指出。）

## 最大误差的分析 [\#](https://kexue.fm/archives/7991\#%E6%9C%80%E5%A4%A7%E8%AF%AF%E5%B7%AE%E7%9A%84%E5%88%86%E6%9E%90)

标题写到，这个算法的误差不超1/9，现在我们就来证明这一点。证明需要全部转换到十进制来理解，Mitchell近似实际上是用了如下近似式：
\\begin{equation}\\log\_2 2^n(1+x)\\approx n + x,\\quad 2^{n+x}\\approx 2^n(1+x)\\end{equation}
其中$n$是整数，而$x\\in\[0, 1)$，所以分析误差也是从这两个近似入手。

假设两个数为$p=2^{n\_1} (1 + x\_1), q = 2^{n\_2} (1 + x\_2)$，那么根据近似就有$\\log\_2 p + \\log\_2 q \\approx n\_1 + n\_2 + x\_1 + x\_2$，可见要分两种情况讨论：第一种情况$x\_1 + x\_2 < 1$，那么近似指数的结果就是$2^{n\_1 + n\_2}(1 + x\_1 + x\_2)$，因此近似程度就是
\\begin{equation}\\begin{aligned}
\\frac{2^{n\_1 + n\_2}(1 + x\_1 + x\_2)}{2^{n\_1} (1 + x\_1)\\times 2^{n\_2} (1 + x\_2)} = \\frac{1 + x\_1 + x\_2}{1 + x\_1 + x\_2 + x\_1 x\_2}
\\end{aligned}\\end{equation}
第二种情况$x\_1 + x\_2 \\geq 1$，这时候近似指数的结果就是$2^{n\_1 + n\_2 + 1}(x\_1 + x\_2)$，因此近似程度就是
\\begin{equation}\\begin{aligned}
\\frac{2^{n\_1 + n\_2 + 1}(x\_1 + x\_2)}{2^{n\_1} (1 + x\_1)\\times 2^{n\_2} (1 + x\_2)} = \\frac{2 (x\_1 + x\_2)}{1 + x\_1 + x\_2 + x\_1 x\_2}
\\end{aligned}\\end{equation}
可以按部就班地证明，上面两种情况的最小值，都是在$x\_1 = x\_2 = 0.5$时取到，其结果为$8/9$，所以最大的相对误差为$1/9$（如果是除法变成减法，那么它的最大误差是$12.5\\%$）。因为按部就班的证明有点繁琐，我们这里就不重复了，而是直接用软件画出它的等高线图，看出误差最大的地方应该是中心处：

近似程度的等高线图。可以看出最小的近似程度应该在中心点处。

作图代码：

```
import numpy as np
import matplotlib.pyplot as plt

x = np.arange(0, 1, 0.001)
y = np.arange(0, 1, 0.001)

X, Y = np.meshgrid(x, y)
Z1 = (1 + X + Y) / (1 + X + Y + X * Y)
Z2 = 2 * (X + Y) / (1 + X + Y + X * Y)
Z = (X + Y < 1) * Z1 + (X + Y >= 1) * Z2
plt.figure(figsize=(7, 6))
contourf = plt.contourf(X, Y, Z)
plt.contour(X, Y, Z)
plt.colorbar(contourf)
plt.show()
```

其实这个误差本质上取决于$\\log\_2 (1 + x)\\approx x$的近似程度，我们知道$x$是自然对数$\\ln (1 + x)$的一阶泰勒展开式，而$e=2.71828\\dots$更加接近于3，所以如果计算机使用3进制的话，本算法会有更高的平均精度。事实上，确实有一些理论分析表明，对于计算机来说其实最理想是$e$进制，而3比2更接近于$e$，所以三进制计算机在不少方面会比二进制更优，我国和前苏联都曾研究过三进制计算机，不过由于二进制实现起来更加容易，所以当前还是二进制计算机的天下了。

## 搬到深度学习中 [\#](https://kexue.fm/archives/7991\#%E6%90%AC%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD)

Mitchell近似的介绍就到这里了。读者可能会困惑，这不该是计算机基础和数据机构那一块的东西吗？你研究它干嘛？还能在深度学习中有什么应用吗？

笔者学习它的原因有两个：一是它确实很漂亮，值得学习；二是它还真的可以用到深度学习中。事实上，笔者是NeurIPS 2020的一篇论文 [《Deep Neural Network Training without Multiplications》](https://papers.cool/arxiv/2012.03458) 中发现它的，该论文在“ImageNet+ResNet50”验证了直接将神经网络中的乘法换成Mitchell近似的加法形式，准确率只有轻微的下降，甚至可能不下降。

当然，作者目前的实现只是验证了这种替换在效果上是可接受的，在速度上其实是变慢了的。这是因为虽然从理论上来讲乘法换成近似加法速度一定会有提升，但要实现这个提升需要从硬件底层进行优化才行，因为当前标准的乘法肯定也是经过了硬件级别的优化，所以作者是提供了未来深度学习硬件优化的一个方向吧。此外，Mitchell近似在深度学习中的应用分析，也不是第一次被讨论了，直接Google就可以搜到两篇，分别是 [《Efficient Mitchell’s Approximate Log Multipliers for Convolutional Neural Networks》](https://ieeexplore.ieee.org/document/8532287) 和 [《Low-power implementation of Mitchell's approximate logarithmic multiplication for convolutional neural networks》](https://ieeexplore.ieee.org/document/8297391)。

可能读者联想到了华为之前提出的加法神经网络 [AdderNet](https://papers.cool/arxiv/1912.13200)，其目的确实有类似之处，但方法上其实差别很大。AdderNet是将神经网络的内积换成了$l\_1$距离，从而去掉了乘法；这篇论文则是修改了乘法的实现，降低了乘法的计算量，已有的神经网络运算可能都可以保留下来。

## 也把新瓶装旧酒 [\#](https://kexue.fm/archives/7991\#%E4%B9%9F%E6%8A%8A%E6%96%B0%E7%93%B6%E8%A3%85%E6%97%A7%E9%85%92)

本文介绍了1962年发表的Mitchell近似算法，它是一种近似的对数和指数计算，基于此我们可以将乘法转化为加法，并保持一定的精度。看上去已经过时，但将这个算法“新瓶装旧酒”一下，就成为了NeurIPS 2020中一篇论文了。

所以，你还发现了哪些可以装到新瓶的“旧酒”呢？

_**转载到请包括本文地址：** [https://kexue.fm/archives/7991](https://kexue.fm/archives/7991)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/7991#share)/ [打赏](https://kexue.fm/archives/7991#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Dec. 14, 2020). 《Mitchell近似：乘法变为加法，误差不超过1/9 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/7991](https://kexue.fm/archives/7991)

@online{kexuefm-7991,
        title={Mitchell近似：乘法变为加法，误差不超过1/9},
        author={苏剑林},
        year={2020},
        month={Dec},
        url={\\url{https://kexue.fm/archives/7991}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/), [算法](https://kexue.fm/tag/%E7%AE%97%E6%B3%95/), [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/)[11 评论](https://kexue.fm/archives/7991#comments)

< [从动力学角度看优化算法（六）：为什么SimSiam不退化？](https://kexue.fm/archives/7980) \| [从动力学角度看优化算法（七）：SGD ≈ SVM？](https://kexue.fm/archives/8009) >

### 你也许还对下面的内容感兴趣

- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [Transformer升级之路：20、MLA究竟好在哪里？](https://kexue.fm/archives/10907)
- [MoE环游记：4、难处应当多投入](https://kexue.fm/archives/10815)
- [MoE环游记：1、从几何意义出发](https://kexue.fm/archives/10699)
- [为什么梯度裁剪的默认模长是1？](https://kexue.fm/archives/10657)
- [从谱范数梯度到新式权重衰减的思考](https://kexue.fm/archives/10648)
- [从Hessian近似看自适应学习率优化器](https://kexue.fm/archives/10588)
- [通向最优分布之路：概率空间的最小化](https://kexue.fm/archives/10289)
- [缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA](https://kexue.fm/archives/10091)
- [旁门左道之如何让Python的重试代码更加优雅](https://kexue.fm/archives/9938)

[发表你的看法](https://kexue.fm/archives/7991#comment_form)

[LinkerLin](http://bbs.zhipu.us/)

December 14th, 2020

或许乘法计算本身可以视为是卷积的近似，而用1个电容就可以实现卷积的近似。
所以，从硬件上可以用一排电容近似实现向量的内积和求和。

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=15028#respond-post-7991)

hanwei 发表于
December 15th, 2020

电容体积太大了吧，可能量子计算更合适，

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=15036#respond-post-7991)

[苏剑林](https://kexue.fm) 发表于
December 16th, 2020

反正我看不懂。

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=15038#respond-post-7991)

cnstrong 发表于
June 25th, 2023

确实有光计算实现的机器学习，就是模拟电路的。

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=22055#respond-post-7991)

xml123

December 21st, 2020

感觉这个算法应该和快速开平方的那个有些联系

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=15064#respond-post-7991)

[苏剑林](https://kexue.fm) 发表于
December 22nd, 2020

直接的联系倒没有，只不过有些异曲同工的地方。

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=15066#respond-post-7991)

kongmuqiuren

April 7th, 2021

目前乘法主要应用在了矩阵乘这一块，把这个计算应用到矩阵乘能快多少？有和mkl或者openblas这样的库比较过吗

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=16021#respond-post-7991)

[苏剑林](https://kexue.fm) 发表于
April 7th, 2021

目前的快都是理论上的，似乎要从硬件上优化才能真正超过标准乘法。

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=16025#respond-post-7991)

flyer

December 22nd, 2024

想请教下苏神，这个分情况的误差分析怎么得到的？我只能通过对$2^{n\_1 + n\_2}$进行泰勒展开，计算得到当$n\_1 + n\_2 = 1$时，如果展开项数到4-5阶时，这个相对误差可以小于1/9

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=26056#respond-post-7991)

flyer 发表于
December 22nd, 2024

对$2^{x\_1 + x\_2}$进行泰勒展开

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=26057#respond-post-7991)

[苏剑林](https://kexue.fm) 发表于
December 26th, 2024

不是很明白你的疑问是什么？误差分析的过程不是在文中给出了吗？

[回复评论](https://kexue.fm/archives/7991/comment-page-1?replyTo=26091#respond-post-7991)

[取消回复](https://kexue.fm/archives/7991#respond-post-7991)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[快速对数与指数](https://kexue.fm/archives/7991#%E5%BF%AB%E9%80%9F%E5%AF%B9%E6%95%B0%E4%B8%8E%E6%8C%87%E6%95%B0)
[一个乘法的例子](https://kexue.fm/archives/7991#%E4%B8%80%E4%B8%AA%E4%B9%98%E6%B3%95%E7%9A%84%E4%BE%8B%E5%AD%90)
[神奇的C++实现](https://kexue.fm/archives/7991#%E7%A5%9E%E5%A5%87%E7%9A%84C++%E5%AE%9E%E7%8E%B0)
[最大误差的分析](https://kexue.fm/archives/7991#%E6%9C%80%E5%A4%A7%E8%AF%AF%E5%B7%AE%E7%9A%84%E5%88%86%E6%9E%90)
[搬到深度学习中](https://kexue.fm/archives/7991#%E6%90%AC%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD)
[也把新瓶装旧酒](https://kexue.fm/archives/7991#%E4%B9%9F%E6%8A%8A%E6%96%B0%E7%93%B6%E8%A3%85%E6%97%A7%E9%85%92)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [数学歌曲：《歌德巴赫猜》](https://kexue.fm/archives/42)
- [生活\|我家的几只小鸡](https://kexue.fm/archives/177)
- [四次方程的根式求解（通俗版）](https://kexue.fm/archives/114)
- [把Python脚本放到手机上定时运行](https://kexue.fm/archives/3477)
- [生成扩散模型漫谈（十八）：得分匹配 = 条件得分匹配](https://kexue.fm/archives/9509)
- [RealFormer：把残差转移到Attention矩阵上面去](https://kexue.fm/archives/8027)
- [采样定理：有限个点构建出整个函数](https://kexue.fm/archives/3266)
- [收到新版《量子力学与路径积分》](https://kexue.fm/archives/3345)
- [两道无穷级数：自然数及其平方的倒数和](https://kexue.fm/archives/56)
- [泰迪杯赛前培训之数据挖掘与建模“慢谈”](https://kexue.fm/archives/4271)

### 最近评论

- [苏剑林](https://kexue.fm/archives/481/comment-page-1#comment-27835): 刚入门那会的文章，不用深究了。
- [苏剑林](https://kexue.fm/archives/10122/comment-page-1#comment-27834): 目前各方面的实测效果看来不会，我觉得本质上就是因为partial rope的实测效果优于rop...
- [苏剑林](https://kexue.fm/archives/10958/comment-page-1#comment-27833): 首先，瞬时速度为什么跟$t$无关？其次，现在reflow和meanflow的第一、第二目标，不...
- [苏剑林](https://kexue.fm/archives/10907/comment-page-2#comment-27832): 对于每一步数据都严格对齐来说，0.01的loss差距不小了，因为它代表了每一个step的los...
- [苏剑林](https://kexue.fm/archives/10699/comment-page-1#comment-27831): \[comment=27808\]rpsun\[/comment\]
有人这样做了：https://a...
- [苏剑林](https://kexue.fm/archives/1490/comment-page-1#comment-27830): 自己都没怎么关注天象了，惭愧
- [苏剑林](https://kexue.fm/archives/10958/comment-page-1#comment-27829): 原来如此。其实只要预测空间是连续空间，并且任务本质是一对多的输出，那么都有可能关联到Diffu...
- [苏剑林](https://kexue.fm/archives/10945/comment-page-1#comment-27828): 你可以拿一批语料去eval，看各个expert分别激活了多少次呀。
- [苏剑林](https://kexue.fm/archives/9164/comment-page-4#comment-27827): 首先这个分布肯定是存在的（贝叶斯公式无关分布），然后它的概率密度对数是二次函数形式，概率密度的...
- [苏剑林](https://kexue.fm/archives/10907/comment-page-2#comment-27826): 这两天看了下FoPE，感觉它的分析有点道理，但它实现的代码跟论文其实是不一样的。看论文的描述，...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。