## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [低精度Attention可能存在有...](https://kexue.fm/archives/11371)
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328)
- [为什么线性注意力要加Short C...](https://kexue.fm/archives/11320)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11307)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11301)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11285)

## COMMENTS

- [出售公众号吗: 您好，请问您出售停更的公众号吗，有出售意向可以加v：Follo...](https://kexue.fm/archives/11390/comment-page-1#comment-28816)
- [pki: 苏老师您好，weightdecay=0 也不需要重新调整吗](https://kexue.fm/archives/10739/comment-page-2#comment-28815)
- [pang: 还有一个蛮有意思的想法想跟您讨论下，请问您怎么看目前一些端侧模...](https://kexue.fm/archives/10862/comment-page-1#comment-28814)
- [zgz: \[comment=25121\]苏剑林\[/comment\]我理解...](https://kexue.fm/archives/8791/comment-page-1#comment-28813)
- [Cuddle: 苏神，在 linear-attention的应用场景中，如果去...](https://kexue.fm/archives/8265/comment-page-8#comment-28812)
- [pang: 好的，感谢您](https://kexue.fm/archives/10862/comment-page-1#comment-28811)
- [danyao12: "理想的根治办法是Stochastic Rounding，也就...](https://kexue.fm/archives/11371/comment-page-1#comment-28805)
- [wade: 那公式18，是缺少了，$-\\frac{1}{2} \\left ...](https://kexue.fm/archives/5977/comment-page-3#comment-28804)
- [李双良: 你好，公式23中分母的H对角线元素求和的因子为什么只有（1−β...](https://kexue.fm/archives/11280/comment-page-1#comment-28802)
- [ljj: 博主您好，我在您的另一篇文章中（https://spaces....](https://kexue.fm/archives/10542/comment-page-1#comment-28801)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) 随机矩阵的谱范数的快速估计

12Oct

# [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)

By 苏剑林 \|
2025-10-12 \|
15779位读者\|

在 [《高阶MuP：更简明但更高明的谱条件缩放》](https://kexue.fm/archives/10795) 的“近似估计”一节中，我们曾“预支”了一个结论：“一个服从标准正态分布的$n\\times m$大小的随机矩阵，它的谱范数大致是$\\sqrt{n}+\\sqrt{m}$。”

这篇文章我们来补充讨论这个结论，给出随机矩阵谱范数的快速估计方法。

## 随机矩阵论 [\#](https://kexue.fm/kexue.fm\#%E9%9A%8F%E6%9C%BA%E7%9F%A9%E9%98%B5%E8%AE%BA)

设有随机矩阵$\\boldsymbol{W}\\in\\mathbb{R}^{n\\times m}$，每个元素都是从标准正态分布$\\mathcal{N}(0,1)$中独立重复地采样出来的，要求估计$\\boldsymbol{W}$的谱范数，也就是最大奇异值，我们以$\\mathbb{E}\[\\Vert\\boldsymbol{W}\\Vert\_2\]$为最终的估计结果。

首先要指出的是，随机矩阵的性态分析已经形成了一个专门的分支，就正态矩阵的谱范数估计来说，关系到关键词包括“ [Marchenko–Pastur分布](https://en.wikipedia.org/wiki/Marchenko%E2%80%93Pastur_distribution)”、“Bai-Yin law”、“Gordon’s theorem”等，它们包含了关于奇异值分布的详细估计结果。不过我们都不打算介绍这些内容，而是介绍一种快速得到$\\sqrt{n}+\\sqrt{m}$的方法。

该方法由笔者基于 [《Introduction to the non-asymptotic analysis of random matrices》](https://papers.cool/arxiv/1011.3027) 的“5.3.1节”简化而来，它实际上只能算是一个“科普”，让大家快速理解到$\\sqrt{n}+\\sqrt{m}$的来源。严格的证明需要补充很多繁琐且单调的细节，这里就不展开了。

## 谱范数估计 [\#](https://kexue.fm/kexue.fm\#%E8%B0%B1%E8%8C%83%E6%95%B0%E4%BC%B0%E8%AE%A1)

我们的出发点是恒等式
\\begin{equation}\\Vert\\boldsymbol{W}\\Vert\_2 = \\max\_{\\Vert \\boldsymbol{u}\\Vert=1, \\Vert \\boldsymbol{v}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v}\\label{eq:w-uv}\\end{equation}
其中$\\boldsymbol{u}\\in\\mathbb{R}^n,\\boldsymbol{v}\\in\\mathbb{R}^m$。直接计算$\\Vert\\boldsymbol{W}\\Vert\_2$通常都是不容易的，所以很自然地想到寻找某种近似。我们考虑下面两个“半成品”：
\\begin{equation}\\max\_{\\Vert \\boldsymbol{u}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v}\\qquad\\qquad \\max\_{\\Vert \\boldsymbol{v}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v}\\end{equation}
直观来看，相比式$\\eqref{eq:w-uv}$，上面两个式子都只完成了一半的工作，我们做个大胆的假设：它们结果也是完整结果的一半。于是，将它们叠加起来，我们认为是最终结果的一个好近似：
\\begin{equation}\\Vert\\boldsymbol{W}\\Vert\_2 = \\max\_{\\Vert \\boldsymbol{u}\\Vert=1, \\Vert \\boldsymbol{v}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v} \\approx \\max\_{\\Vert \\boldsymbol{u}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v} + \\max\_{\\Vert \\boldsymbol{v}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v} = \\Vert \\boldsymbol{W}\\boldsymbol{v}\\Vert + \\Vert \\boldsymbol{u}^{\\top}\\boldsymbol{W}\\Vert \\label{eq:core-approx}\\end{equation}
也就是说，从$\\mathbb{R}^n,\\mathbb{R}^m$的单位超球面上分别采样$\\boldsymbol{u},\\boldsymbol{v}$，然后根据上式来得到$\\boldsymbol{W}$谱范数的一个近似。

## 计算期望值 [\#](https://kexue.fm/kexue.fm\#%E8%AE%A1%E7%AE%97%E6%9C%9F%E6%9C%9B%E5%80%BC)

有了这个近似，我们就可以计算
\\begin{equation}\\mathbb{E}\[\\Vert\\boldsymbol{W}\\Vert\_2\]\\approx\\mathbb{E}\[\\Vert \\boldsymbol{W}\\boldsymbol{v}\\Vert\] + \\mathbb{E}\[\\Vert \\boldsymbol{u}^{\\top}\\boldsymbol{W}\\Vert\] \\approx \\sqrt{\\mathbb{E}\[\\Vert \\boldsymbol{W}\\boldsymbol{v}\\Vert^2\]} + \\sqrt{\\mathbb{E}\[\\Vert \\boldsymbol{u}^{\\top}\\boldsymbol{W}\\Vert^2\]}\\end{equation}
其中
\\begin{equation}\\mathbb{E}\[\\Vert \\boldsymbol{W}\\boldsymbol{v}\\Vert^2\] = \\mathbb{E}\[ \\boldsymbol{v}^{\\top}\\boldsymbol{W}^{\\top}\\boldsymbol{W}\\boldsymbol{v}\] = \\boldsymbol{v}^{\\top}\\mathbb{E}\[\\boldsymbol{W}^{\\top}\\boldsymbol{W}\]\\boldsymbol{v} = \\boldsymbol{v}^{\\top}(n\\boldsymbol{I}\_m)\\boldsymbol{v} = n\\end{equation}
同理$\\mathbb{E}\[\\Vert \\boldsymbol{u}^{\\top}\\boldsymbol{W}\\Vert^2\]=m$，所以
\\begin{equation}\\mathbb{E}\[\\Vert\\boldsymbol{W}\\Vert\_2\]\\approx\\sqrt{n} + \\sqrt{m}\\end{equation}
这个结果其实非常准（可以通过模拟实验来验证它），具体来说，如果$n=ka,m=kb$，$a,b$都是常数，那么
\\begin{equation}\\lim\_{k\\to\\infty} \\frac{\\Vert\\boldsymbol{W}\\Vert\_2}{\\sqrt{n} + \\sqrt{m}} = 1,\\qquad \\boldsymbol{W}\\sim\\mathcal{N}(0,1)\\end{equation}
之所以如此准确，是因为我们作了弊——最关键的式$\\eqref{eq:core-approx}$本质上是从已知的正确答案反向推测出来的。除了式$\\eqref{eq:core-approx}$外，我们还用到的条件只有$\\mathbb{E}\[\\boldsymbol{W}^{\\top}\\boldsymbol{W}\]=n\\boldsymbol{I}\_m$和$\\mathbb{E}\[\\boldsymbol{W}\\boldsymbol{W}^{\\top}\]=m\\boldsymbol{I}\_n$，因此可以认为上述近似对于任意0均值、1方差的分布都成立。

## 最小奇异值 [\#](https://kexue.fm/kexue.fm\#%E6%9C%80%E5%B0%8F%E5%A5%87%E5%BC%82%E5%80%BC)

谱范数是最大奇异值，事实上，我们还可以用同样的思路估计最小奇异值。当然，这里的最小需要更严格定义一下，设$n\\geq m$，这里的最小奇异值，指的是$\\boldsymbol{W}$从大到小的第$m$个奇异值，它等于
\\begin{equation}\\sigma\_{\\min}(\\boldsymbol{W}) = \\min\_{\\Vert \\boldsymbol{v}\\Vert=1}\\max\_{\\Vert \\boldsymbol{u}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v}\\end{equation}
注意这里的$\\min$和$\\max$的位置和对象都不能交换。类似地，我们考虑分别$\\min$和$\\max$的两个“半成品”之和，作为它的近似
\\begin{equation}\\sigma\_{\\min}(\\boldsymbol{W}) = \\min\_{\\Vert \\boldsymbol{v}\\Vert=1}\\max\_{\\Vert \\boldsymbol{u}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v}\\approx \\min\_{\\Vert \\boldsymbol{v}\\Vert=1}\\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v} + \\max\_{\\Vert \\boldsymbol{u}\\Vert=1} \\boldsymbol{u}^{\\top}\\boldsymbol{W} \\boldsymbol{v} = -\\Vert \\boldsymbol{u}^{\\top}\\boldsymbol{W}\\Vert + \\Vert \\boldsymbol{W}\\boldsymbol{v}\\Vert \\end{equation}
接下来的事情就跟前面一样了，结果是$\\mathbb{E}\[\\sigma\_{\\min}(\\boldsymbol{W})\]\\approx\\sqrt{n}-\\sqrt{m}$。

## 最后的提示 [\#](https://kexue.fm/kexue.fm\#%E6%9C%80%E5%90%8E%E7%9A%84%E6%8F%90%E7%A4%BA)

本文提供了估计随机矩阵谱范数的一个快速思路，或者更严格是说，是一个科普式、启发式的讲解，而不是严格的、准确的推导。它存在严格化的可能，但需要补上非常多的理论细节，这些全都跳过了。

_**转载到请包括本文地址：** [https://kexue.fm/archives/11335](https://kexue.fm/archives/11335)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Oct. 12, 2025). 《随机矩阵的谱范数的快速估计 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/11335](https://kexue.fm/archives/11335)

@online{kexuefm-11335,
        title={随机矩阵的谱范数的快速估计},
        author={苏剑林},
        year={2025},
        month={Oct},
        url={\\url{https://kexue.fm/archives/11335}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [近似](https://kexue.fm/tag/%E8%BF%91%E4%BC%BC/), [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/), [估计](https://kexue.fm/tag/%E4%BC%B0%E8%AE%A1/), [谱范数](https://kexue.fm/tag/%E8%B0%B1%E8%8C%83%E6%95%B0/)[抢沙发](https://kexue.fm/archives/11335#comments)

< [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328) \| [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340) >

### 你也许还对下面的内容感兴趣

- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [低精度Attention可能存在有偏的舍入误差](https://kexue.fm/archives/11371)
- [AdamW的Weight RMS的渐近估计](https://kexue.fm/archives/11307)
- [流形上的最速下降：4\. Muon + 谱球面](https://kexue.fm/archives/11241)
- [流形上的最速下降：3\. Muon + Stiefel](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon + 正交](https://kexue.fm/archives/11215)
- [矩阵r次方根和逆r次方根的高效计算](https://kexue.fm/archives/11175)
- [矩阵平方根和逆平方根的高效计算](https://kexue.fm/archives/11158)
- [“对角+低秩”三角阵的高效求逆方法](https://kexue.fm/archives/11072)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

[取消回复](https://kexue.fm/archives/11335#respond-post-11335)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[随机矩阵论](https://kexue.fm/kexue.fm#%E9%9A%8F%E6%9C%BA%E7%9F%A9%E9%98%B5%E8%AE%BA)
[谱范数估计](https://kexue.fm/kexue.fm#%E8%B0%B1%E8%8C%83%E6%95%B0%E4%BC%B0%E8%AE%A1)
[计算期望值](https://kexue.fm/kexue.fm#%E8%AE%A1%E7%AE%97%E6%9C%9F%E6%9C%9B%E5%80%BC)
[最小奇异值](https://kexue.fm/kexue.fm#%E6%9C%80%E5%B0%8F%E5%A5%87%E5%BC%82%E5%80%BC)
[最后的提示](https://kexue.fm/kexue.fm#%E6%9C%80%E5%90%8E%E7%9A%84%E6%8F%90%E7%A4%BA)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [轻微的扰动——摄动法简介(1)](https://kexue.fm/archives/1878)
- [“让Keras更酷一些！”：随意的输出和灵活的归一化](https://kexue.fm/archives/6311)
- [Keras中自定义复杂的loss函数](https://kexue.fm/archives/4493)
- [算子与线性常微分方程(上)](https://kexue.fm/archives/1791)
- [2012年快乐！](https://kexue.fm/archives/1523)
- [Transformer升级之路：4、二维位置的旋转式位置编码](https://kexue.fm/archives/8397)
- [收谷问题(1)](https://kexue.fm/archives/1439)
- [2^29365247-1也不是素数！](https://kexue.fm/archives/1963)
- [用变分推断统一理解生成模型（VAE、GAN、AAE、ALI）](https://kexue.fm/archives/5716)
- [2020年全年天象](https://kexue.fm/archives/7144)

### 最近评论

- [出售公众号吗](https://kexue.fm/archives/11390/comment-page-1#comment-28816): 您好，请问您出售停更的公众号吗，有出售意向可以加v：Followmeinsh
- [pki](https://kexue.fm/archives/10739/comment-page-2#comment-28815): 苏老师您好，weightdecay=0 也不需要重新调整吗
- [pang](https://kexue.fm/archives/10862/comment-page-1#comment-28814): 还有一个蛮有意思的想法想跟您讨论下，请问您怎么看目前一些端侧模型中的embedding和lmh...
- [zgz](https://kexue.fm/archives/8791/comment-page-1#comment-28813): \[comment=25121\]苏剑林\[/comment\]我理解在模型训练完后要计算某一个样本的...
- [Cuddle](https://kexue.fm/archives/8265/comment-page-8#comment-28812): 苏神，在 linear-attention的应用场景中，如果去掉分母中的 rope好像需要多一...
- [pang](https://kexue.fm/archives/10862/comment-page-1#comment-28811): 好的，感谢您
- [danyao12](https://kexue.fm/archives/11371/comment-page-1#comment-28805): "理想的根治办法是Stochastic Rounding，也就是依概率向上/向下舍入，这样最大...
- [wade](https://kexue.fm/archives/5977/comment-page-3#comment-28804): 那公式18，是缺少了，$-\\frac{1}{2} \\left \\\| u \\right \\\| ...
- [李双良](https://kexue.fm/archives/11280/comment-page-1#comment-28802): 你好，公式23中分母的H对角线元素求和的因子为什么只有（1−β^2）了，νi^2β^2为什么删...
- [ljj](https://kexue.fm/archives/10542/comment-page-1#comment-28801): 博主您好，我在您的另一篇文章中（https://spaces.ac.cn/archives/5...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。