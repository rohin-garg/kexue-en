## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)

## COMMENTS

- [tll1945tll1937: 真心实意的向大家请教问题：看了文章“对齐全量微调！这是我看过最...](https://kexue.fm/archives/10266/comment-page-1#comment-27901)
- [oYo\_logan: \[comment=27017\]苏剑林\[/comment\]苏神，...](https://kexue.fm/archives/10757/comment-page-1#comment-27897)
- [z123: 在参数矩阵较多的CNN小模型上，Muon会明显慢于Adam，这...](https://kexue.fm/archives/10592/comment-page-1#comment-27896)
- [dry: 苏神好，一直有个疑问，ReFlow构建的ODE是$dx\_t/d...](https://kexue.fm/archives/10958/comment-page-2#comment-27895)
- [tyj: 感觉和之前的一篇文章很像，应该算是concurrent wor...](https://kexue.fm/archives/10958/comment-page-2#comment-27894)
- [li6626: 苏老师，Normalizing Flow有了新进展，论文链接:...](https://kexue.fm/archives/10667/comment-page-1#comment-27893)
- [tesslqy: Evans那本书感觉就挺好的，不过长了一点且有点难（姜萍拿来装...](https://kexue.fm/archives/4718/comment-page-1#comment-27891)
- [Bauree: 渴望大图，万分感谢！](https://kexue.fm/archives/443/comment-page-1#comment-27890)
- [tesslqy: 感觉应该是狄拉克测度，不过我也没系统学过Lebesgue以外的...](https://kexue.fm/archives/4187/comment-page-1#comment-27888)
- [tesslqy: 假设只有作者懂，但我不是作者，我懂了，假设不成立](https://kexue.fm/archives/4187/comment-page-1#comment-27887)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) “熵”不起：从熵、最大熵原理到最大熵模型（一）

1Dec

# [“熵”不起：从熵、最大熵原理到最大熵模型（一）](https://kexue.fm/archives/3534)

By 苏剑林 \|
2015-12-01 \|
95469位读者\|

## 熵的概念 [\#](https://kexue.fm/archives/3534\#%E7%86%B5%E7%9A%84%E6%A6%82%E5%BF%B5)

作为一名物理爱好者，我一直对统计力学中“熵”这个概念感到神秘和好奇。因此，当我接触数据科学的时候，我也对最大熵模型产生了浓厚的兴趣。

熵是什么？在通俗的介绍中，熵一般有两种解释：（1）熵是不确定性的度量；（2）熵是信息的度量。看上去说的不是一回事，其实它们说的就是同一个意思。首先，熵是不确定性的度量，它衡量着我们对某个事物的 **“无知程度”**。熵为什么又是信息的度量呢？既然熵代表了我们对事物的无知，那么当我们从“无知”到“完全认识”这个过程中，就会获得一定的信息量，我们开始越无知，那么到达“完全认识”时，获得的信息量就越大，因此，作为不确定性的度量的熵，也可以看作是信息的度量，说准确点，是我们能从中获得的最大的信息量。

如何去衡量不确定性？也就是说，如何计算熵？要回答这个问题，我们可以想到，我们是用概率来描述不确定性的，我们可以给出系统出现某种状态的概率（或者概率密度，这里不作区分），只要概率不为1，就意味着出现不确定性。因此，熵必定与概率分布有关。具体怎么计算熵呢？本来，按照一般教科书或者科普的做法，是直接给出熵的公式，而这里，笔者尝试从两个角度给出熵的公式的来源，企图让读者了解其来龙去脉。

熵的基本计算公式为
$$S=-\\sum\_x p(x)\\log p(x)\\tag{1}$$
这里的$\\log$可以是自然对数，也可以是以2为底的对数，事实上，任意大于1的底都是成立的，因为换底只不过相当于换了信息的单位。$p(x)$是量$X$取值为$x$的概率。对于连续的概率分布，熵类似地定义为（把求和换成积分）
$$S=-\\int p(x)\\log p(x) dx\\tag{2}$$
$p(x)$是$X$的概率密度函数。

请留意，$(1)$式和$(2)$式的几个特征是：对数$\\log$、求和$\\sum\_x$以及前面的负号，下面将着重解释这几个特征，从两个方面，一个是比较通俗的，一个是比较抽象的（数学化的）。

### 通俗的角度 [\#](https://kexue.fm/archives/3534\#%E9%80%9A%E4%BF%97%E7%9A%84%E8%A7%92%E5%BA%A6)

从下面的例子出发

> 世界杯结束后，大家都很关心谁会是冠军。假如我错过了看世界杯，赛后我问一个知道比赛结果的观众“哪支球队是冠军”？他不愿意直接告诉我，而要让我猜，并且我每猜一次，他要收一元钱才肯告诉我是否猜对了，那么我需要付给他多少钱才能知道谁是冠军呢？我可以把球队编上号，从1到32，然后提问：“冠军的球队在1-16号中吗？”假如他告诉我猜对了，我会接着问：“冠军在1-8号中吗？”假如他告诉我猜错了，我自然知道冠军队在9-16中。这样只需要5次，我就能知道哪支球队是冠军。所以，谁是世界杯冠军这条消息的信息量只值5块钱。

以上例子引自吴军老师的著作《数学之美》中的“谈谈最大熵模型”这一章。以上例子成立的前提是：“我”对足球一无所知——“我”既没有研究足球，也没有听说过任何关于足球的消息。在这种情况下，我只能靠猜，最朴素的方法就是一支支队伍地猜：是中国吗？是巴西吗？是日本吗？...这样我们有可能问到第31个问题才得到最终结果。显然，这不是最高效率的方法。在例子中，我们先对球队编号（在数据处理时，我们称之为建立“索引”），然后用二分法查找，效率是$\\mathcal{O}(\\log\_2 N)$。

这给我们两个启示： **一是建立索引，并通过二分法，能够大大加快查找的速度，不过这跟本文没多大关系；第二就是$\\log\_2 N$，对数出现了！** 它可以改写为
$$\\log\_2 N=-\\log\_2 \\frac{1}{N}=-\\sum\_{N\\text{支队伍}}\\frac{1}{N}\\log\_2 \\frac{1}{N}$$
这正好是$(1)$式的形式，这里因为我们对足球一无所知，所以每支队伍得冠军的概率都是一样的，也就是$p=1/N$。

可能读者觉得这个例子太特殊，结果没什么代表性。确实，这只不过是一个感性的认知。从更抽象的、更精准的数学角度来理解也是可以的，这时候，我们的思路是反过来的。

### 抽象的角度 [\#](https://kexue.fm/archives/3534\#%E6%8A%BD%E8%B1%A1%E7%9A%84%E8%A7%92%E5%BA%A6)

首先，我们希望构造出一个公式来表示信息量，或者等价地，不确定的程度，叫做“熵”（注意，这里是我们希望根据我们所想的用途去构造一个量，而不是我们已经得到了这个量，然后才证明它有这样的用途。这里边的逻辑刚好是反过来的，是我们需要什么，我们就去构造什么。）。既然“熵”用来表示信息量，那么它应该具有下面的简单的性质：

> 1、它是概率分布$p(x)$的函数，为了研究的方便，我们还希望它是一个光滑函数；
> 2、它具有可加性，这意味着熵具有形式
> $$S\[p(x)\]=\\sum\_{x}f(p(x))\\tag{3}$$

现在的问题是，$f()$的具体形式是什么，我们需要一些额外的信息来确定它，比如，假如$X,Y$是两个独立的随机变量，它们的概率分布分别是$p(x)$和$p(y)$，那么$X,Y$的联合概率是$p(x)p(y)$。因为两个随机变量是独立的，那么它们的联合分布$p(x)p(y)$和单独的两个分布$p(x),p(y)$，所具有的信息量是等价的（从联合密度分布可以算得单个的密度分布，从单个的密度分布，可以算得联合密度分布），也就是

> 3、当$X,Y$是独立随机变量时，有
> $$S\[p(x)p(y)\]=S\[p(x)\]+S\[p(y)\]\\tag{4}$$

事实上，1、2、3三个约束，就可以确定熵的表达式。为了从$(4)$式确定$f()$的形式，我们只需要从最简单的二元分布出发，假设$X,Y$都是二元随机变量，$X$的概率分布为$p,1-p$，$Y$的概率分布为$q,1-q$，那么联合分布为$pq,p(1-q),(1-p)q,(1-p)(1-q)$，根据$(4)$式，就有
$$\\begin{aligned}&f(pq)+f\\big(p(1-q)\\big)+f\\big((1-p)q\\big)+f\\big((1-p)(1-q)\\big)\\\
=&f(p)+f(1-p)+f(q)+f(1-q)\\end{aligned}\\tag{5}$$
这是关于$f()$的一个函数方程，只要加上适当的合理的限制，那么它就具有唯一解。这里我们尝试求解它，但不去证明解的唯一性。求解的过程是试探性的，我们发现，左边是自变量的积的形式，如$pq$，右边是单个的自变量的形式，如$p$，回想数学中的概念，我们可以想起来，能够把乘积变为求和的运算是取对数，所以我们不妨设$f(x)=h(x)\\ln x$，得到
$$\\begin{aligned}&h(p)\\ln p+h(1-p) \\ln (1-p)+h(q)\\ln q+h(1-q)\\ln (1-q)\\\
=&h(pq)\\ln p+h(pq)\\ln q \\\
&\+ h\\big(p(1-q)\\big)\\ln p + h\\big(p(1-q)\\big)\\ln(1-q)\\\
&+h\\big((1-p)q\\big)\\ln(1-p)+h\\big((1-p)q\\big)\\ln q \\\
&\+ h\\big((1-p)(1-q)\\big)\\ln(1-p)+h\\big((1-p)(1-q)\\big)\\ln(1-q)\\end{aligned}\\tag{6}$$
很长很乱很晕？不要紧，快到终点了。我们把相同对数的项合并起来，比如$\\ln p$项，是
$$\\big\[h(p)-h(pq)-h(p(1-q))\\big\]\\ln p\\tag{7}$$
剩余三项也类似。我们发现，如果$h()$取线性函数，那么上式刚好是0，剩余三项也是0，等式自动满足！所以，我们就找到了一个解：
$$f(x)=\\alpha x\\ln x\\tag{8}$$
所以我们有了熵的表达式：
$$S=\\sum\_{x}\\alpha p(x)\\ln p(x)\\tag{9}$$

最后，还要确定$\\alpha$，当然，$\\alpha$本身的值不重要，它只不过是信息的单位而已，但是$\\alpha$的符号是很重要的。我们要求熵有下面的性质：

> 4、信息量越大，熵越大。

第4点是为了符合我们的习惯而已，如果你喜欢，你也可以定义“信息量越大，熵越小”。既然这样定义，我们就知道，确定性事件的熵肯定比不确定的事件的熵要小（不确定的事情蕴含的信息越大），确定性事件的概率分布也就是恒等于1，对应的熵是0，而不确定性事件，我们还是取二元分布，概率分布为$p,1-p$，那么必然有
$$\\alpha p\\ln p + \\alpha (1-p)\\ln (1-p) > 0\\tag{10}$$
因此只有$\\alpha < 0$。

## 多扯一点 [\#](https://kexue.fm/archives/3534\#%E5%A4%9A%E6%89%AF%E4%B8%80%E7%82%B9)

现在我们已经得到了熵的表达式，到这里我们已经走得比较远了，读者不一定都需要它们。笔者只是想把自己对熵的来龙去脉的认识分享给大家，对于关心熵的应用，不是太关心熵的来源的读者，可以忽略这部分内容，而对于希望从更多角度来深入认识熵的朋友，我觉得这部分内容是比较有意义的参考。

**再次强调，本文是通过约束1、2、3、4来确定熵的表达式的，1、2、3、4是熵的性质，是由这些性质来确定熵的表达式。而一般的教程往往是反过来，首先给出熵的表达式，然后去推导1、2、3、4等性质。事实上，这有本末倒置之嫌。**

根据以上讨论，我们已经发现，熵已经不再是物理概念的抽象，而已经是一个完全独立的对象。熵来源于物理，但基本上已经脱胎于物理，成为了一个能够贯穿信息、物理、生物等领域的强大工具。事实上，作为物理方面的应用，我们可以反过来，从后面要谈到的最大熵原理出发，建立起物理定律，这时候，熵不仅不是衍生物，还成为了物理定律的来源。

## 熵的“衍生物” [\#](https://kexue.fm/archives/3534\#%E7%86%B5%E7%9A%84%E2%80%9C%E8%A1%8D%E7%94%9F%E7%89%A9%E2%80%9D)

有了熵的定义式$(1)$和$(2)$，我们就可以得到一些“衍生品”了，比如“联合熵”
$$S\[p(x,y)\]=-\\sum\_{x}\\sum\_{y} p(x,y)\\ln p(x,y)\\tag{11}$$
这是一元熵的等价推广罢了。

为了后面要讲到的最大熵模型，需要引入一个条件熵，它跟条件分布$p(y\|x)$有关。但是我觉得，很多教程都写得化简为繁了，让人云里雾里的，比如，有些教程直接将条件熵定义为
$$S(Y\|X)=\\sum\_x p(x)S(Y\|X=x)=-\\sum\_x p(x)\\sum\_y p(y\|x)\\log p(y\|x)\\tag{12}$$
也有直接定义为
$$S(Y\|X)=-\\sum\_x\\sum\_y p(x,y)\\log p(y\|x)\\tag{13}$$
这两个式子都是等价的，当然也都是正确的。但是我真想问，这是哪门子的定义？读者的第一反应可能就是： **凭什么这样定义？你想怎么定义就怎么定义呀，你在耍我吗？**

我真搞不懂，为什么最直接、最容易理解的定义不给出来呢？我们已经知道，条件分布就是在联合分布$p(x,y)$的基础上，已经知道$p(x)$的分布，求$X$确定时，$Y$的分布情况。那么条件熵自然是在联合熵的基础上，再引入$X$的熵，所剩下的熵值：
$$S(Y\|X)=S\[p(x,y)\]-S\[p(x)\]\\tag{14}$$
说白了，条件熵就是说本来不确定性有$S\[p(x,y)\]$这么多，然后$p(x)$能带来量为$S\[p(x)\]$的信息，减少掉一定的不确定性，剩下的不确定性，就是条件熵。不难证明这个$(14)$式跟$(12),(13)$式都等价，但是显然，$(14)$式才具有明显的意义。

_**转载到请包括本文地址：** [https://kexue.fm/archives/3534](https://kexue.fm/archives/3534)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/3534#share)/ [打赏](https://kexue.fm/archives/3534#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Dec. 01, 2015). 《“熵”不起：从熵、最大熵原理到最大熵模型（一） 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/3534](https://kexue.fm/archives/3534)

@online{kexuefm-3534,
        title={“熵”不起：从熵、最大熵原理到最大熵模型（一）},
        author={苏剑林},
        year={2015},
        month={Dec},
        url={\\url{https://kexue.fm/archives/3534}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/), [最大熵](https://kexue.fm/tag/%E6%9C%80%E5%A4%A7%E7%86%B5/), [熵](https://kexue.fm/tag/%E7%86%B5/)[14 评论](https://kexue.fm/archives/3534#comments)

< [《量子力学与路径积分》习题解答V0.3](https://kexue.fm/archives/3522) \| [人生苦短，我用Python！](https://kexue.fm/archives/3546) >

### 你也许还对下面的内容感兴趣

- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [矩阵的有效秩（Effective Rank）](https://kexue.fm/archives/10847)
- [Softmax后传：寻找Top-K的光滑近似](https://kexue.fm/archives/10373)
- [通向最优分布之路：概率空间的最小化](https://kexue.fm/archives/10289)
- [通向概率分布之路：盘点Softmax及其替代品](https://kexue.fm/archives/10145)
- [用傅里叶级数拟合一维概率密度函数](https://kexue.fm/archives/10007)
- [注意力机制真的可以“集中注意力”吗？](https://kexue.fm/archives/9889)
- [随机分词再探：从Viterbi Sampling到完美采样算法](https://kexue.fm/archives/9811)
- [EMO：基于最优传输思想设计的分类损失函数](https://kexue.fm/archives/9797)
- [随机分词浅探：从Viterbi Decoding到Viterbi Sampling](https://kexue.fm/archives/9768)

[发表你的看法](https://kexue.fm/archives/3534#comment_form)

先忧后乐者

December 10th, 2015

知乎上一个回答
http://www.zhihu.com/question/30828247

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=7175#respond-post-3534)

[苏剑林](http://kexue.fm) 发表于
December 11th, 2015

我发现我跟这个链接的思考有相同之处，而不同的地方在于，它那里几个作者都把熵理解为某种平均，我觉得并不是特别好。本文的思路是，先解释为什么熵跟概率分布有关，然后列出熵有的性质，然后直接导出$-x\\log x$这个表达式，窃以为这样更清晰。

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=7178#respond-post-3534)

Phymet

December 28th, 2015

条件熵的那部分说得很精辟~另外，关于本文定义熵的思路，信息论课本里也是这么讲的

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=7201#respond-post-3534)

davy

September 25th, 2017

熵是不确定性的度量，所以“确定性事件的熵肯定比不确定的事件的熵要大”这句话说反了。。

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=8280#respond-post-3534)

[苏剑林](http://kexue.fm) 发表于
September 30th, 2017

已修正，感谢

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=8283#respond-post-3534)

tzjz89 发表于
February 2nd, 2020

层主没看上下文，指的是在信息量越大，熵越小的前提下。 作者不用改，现在反而错了。

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=12790#respond-post-3534)

Allen

May 3rd, 2019

怎麼從$(14)$式推導出$(13)$式這裡看了很久，後來是反過來從$(13)$式推到$(14)$ 式：
$$
\\begin{align\*}
S(Y\|X)&=-\\sum\_x\\sum\_y p(x,y)\\log p(y\|x)\\tag{13}\\\
&=-\\sum\_x\\sum\_y p(x,y)\\log \\frac{p(y\|x)p(x)}{p(x)}\\\
&=-\\sum\_x\\sum\_y p(x,y)\\log p(x,y) - p(x,y) \\log p(x)\\\
&=-\\sum\_x\\sum\_y p(x,y)\\log p(x,y) - p(y\|x)p(x) \\log p(x)\\\
&=S(p(x,y)) - \\mathbb{E}\_{y\\sim p(y\|x)}\[S(p(x))\]\\\
&=S(p(x,y)) - S(p(x))\\tag{14}
\\end{align\*}
$$

倒數第二行的 $\\mathbb{E}\_{y\\sim p(y\|x)}\[S(p(x))\]$ 是關鍵，因為$S(p(x))$與$y$無關，所以可以直接從取期望值中拿出來。

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=11094#respond-post-3534)

zbh 发表于
July 17th, 2020

(14)式推(13)式很简单，利用$p(x) = \\sum\_y p(x,y)$

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=13848#respond-post-3534)

宇航员

October 9th, 2021

熵和能量的关系可否展开讲讲呢？谢谢

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=17513#respond-post-3534)

诺言

August 9th, 2022

研1前来考古学习，苏神讲的真的清晰

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=19604#respond-post-3534)

sxj

November 18th, 2023

我底子太浅，敢问5式从上怎么推出到下面的式子的？

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=23094#respond-post-3534)

[苏剑林](https://kexue.fm) 发表于
November 20th, 2023

你说它的等号为什么成立？这是$(4)$决定的。

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=23123#respond-post-3534)

House Li

March 21st, 2024

感谢苏剑林老师（：

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=23970#respond-post-3534)

张诗贤\_deep\_learner

April 25th, 2025

眼前一亮的感觉，谢谢苏神。这篇是通过约束来确定熵的表达式，思路很自然，国内的教科书本末倒置了

[回复评论](https://kexue.fm/archives/3534/comment-page-1?replyTo=27474#respond-post-3534)

[取消回复](https://kexue.fm/archives/3534#respond-post-3534)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[熵的概念](https://kexue.fm/archives/3534#%E7%86%B5%E7%9A%84%E6%A6%82%E5%BF%B5)
[通俗的角度](https://kexue.fm/archives/3534#%E9%80%9A%E4%BF%97%E7%9A%84%E8%A7%92%E5%BA%A6)
[抽象的角度](https://kexue.fm/archives/3534#%E6%8A%BD%E8%B1%A1%E7%9A%84%E8%A7%92%E5%BA%A6)
[多扯一点](https://kexue.fm/archives/3534#%E5%A4%9A%E6%89%AF%E4%B8%80%E7%82%B9)
[熵的“衍生物”](https://kexue.fm/archives/3534#%E7%86%B5%E7%9A%84%E2%80%9C%E8%A1%8D%E7%94%9F%E7%89%A9%E2%80%9D)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [\[欧拉数学\]素数倒数之和](https://kexue.fm/archives/1510)
- [“熵”不起：从熵、最大熵原理到最大熵模型（三）](https://kexue.fm/archives/3567)
- [宇宙驿站十岁啦](https://kexue.fm/archives/1557)
- [当Matlab遇上牛顿法](https://kexue.fm/archives/1995)
- [“二体+恒力”问题](https://kexue.fm/archives/1358)
- [从SamplePairing到mixup：神奇的正则项](https://kexue.fm/archives/5693)
- [【理解黎曼几何】2\. 从勾股定理到黎曼度量](https://kexue.fm/archives/3969)
- [当概率遇上复变：解析概率](https://kexue.fm/archives/2550)
- [世界最复杂的机器11月重启,温度宇宙最低](https://kexue.fm/archives/207)
- [现在可以用Keras玩中文GPT2了（GPT2\_ML）](https://kexue.fm/archives/7292)

### 最近评论

- [tll1945tll1937](https://kexue.fm/archives/10266/comment-page-1#comment-27901): 真心实意的向大家请教问题：看了文章“对齐全量微调！这是我看过最精彩的LoRA改进（二）”，我实...
- [oYo\_logan](https://kexue.fm/archives/10757/comment-page-1#comment-27897): \[comment=27017\]苏剑林\[/comment\]苏神，想请教一下，我理解在一个batc...
- [z123](https://kexue.fm/archives/10592/comment-page-1#comment-27896): 在参数矩阵较多的CNN小模型上，Muon会明显慢于Adam，这方面有什么优化提速的方案吗？
- [dry](https://kexue.fm/archives/10958/comment-page-2#comment-27895): 苏神好，一直有个疑问，ReFlow构建的ODE是$dx\_t/dt=x\_1-x\_0$，为什么这并...
- [tyj](https://kexue.fm/archives/10958/comment-page-2#comment-27894): 感觉和之前的一篇文章很像，应该算是concurrent work： https://arxiv...
- [li6626](https://kexue.fm/archives/10667/comment-page-1#comment-27893): 苏老师，Normalizing Flow有了新进展，论文链接:https://arxiv.or...
- [tesslqy](https://kexue.fm/archives/4718/comment-page-1#comment-27891): Evans那本书感觉就挺好的，不过长了一点且有点难（姜萍拿来装的就是这本书，可见流传度之广
- [Bauree](https://kexue.fm/archives/443/comment-page-1#comment-27890): 渴望大图，万分感谢！
- [tesslqy](https://kexue.fm/archives/4187/comment-page-1#comment-27888): 感觉应该是狄拉克测度，不过我也没系统学过Lebesgue以外的测度只是有这个感觉
- [tesslqy](https://kexue.fm/archives/4187/comment-page-1#comment-27887): 假设只有作者懂，但我不是作者，我懂了，假设不成立

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。