## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [低精度Attention可能存在有...](https://kexue.fm/archives/11371)
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)

## COMMENTS

- [cmlin: 本人对这方面不太熟悉，想了解这三个条件的意义及动机，且希望这系...](https://kexue.fm/archives/11340/comment-page-1#comment-29031)
- [喝一口可乐: 理解了，感谢苏神回复，数学上给出建模分析确实清晰了很多，再次感...](https://kexue.fm/archives/10958/comment-page-3#comment-29030)
- [CuddleSabe1: 感觉普通的 flow matching 可以看成 degrad...](https://kexue.fm/archives/10958/comment-page-1#comment-29029)
- [岁月如书: 受教了，感谢](https://kexue.fm/archives/11126/comment-page-3#comment-29028)
- [苏剑林: 是](https://kexue.fm/archives/11126/comment-page-3#comment-29027)
- [岁月如书: 哦哦，原来是有实验结论，那是我盲目了。多问一句，你说的atte...](https://kexue.fm/archives/11126/comment-page-3#comment-29026)
- [苏剑林: attention sink指的是第一个token的atten...](https://kexue.fm/archives/11126/comment-page-3#comment-29025)
- [苏剑林: 这也许是好事呢？SGD倒是保留了模长，但它就普遍不如不保留模长...](https://kexue.fm/archives/11459/comment-page-1#comment-29024)
- [岁月如书: maxlogit 是attention qk乘积中出现了大值，...](https://kexue.fm/archives/11126/comment-page-3#comment-29023)
- [岁月如书: \[comment=29016\]苏剑林\[/comment\]他通过...](https://kexue.fm/archives/11459/comment-page-1#comment-29022)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) 矩阵r次方根和逆r次方根的高效计算

21Jul

# [矩阵r次方根和逆r次方根的高效计算](https://kexue.fm/archives/11175)

By 苏剑林 \|
2025-07-21 \|
16810位读者\|

上一篇文章 [《矩阵平方根和逆平方根的高效计算》](https://kexue.fm/archives/11158) 中，笔者从$\\newcommand{mcsgn}{\\mathop{\\text{mcsgn}}}\\mcsgn$算子出发，提出了一种很漂亮的矩阵平方根和逆平方根的计算方法。比较神奇的是，该方案经过化简之后，最终公式已经看不到最初$\\mcsgn$形式的样子。这不禁引发了更深层的思考：该方案更本质的工作原理是什么？是否有推广到任意$r$次方根的可能性？

沿着这个角度进行分析后，笔者惊喜地发现，我们可以从一个更简单的角度去理解之前的迭代算法，并且在新角度下可以很轻松推广到任意$r$次方根和逆$r$次方根的计算。接下来我们将分享这一过程。

## 前情回顾 [\#](https://kexue.fm/kexue.fm\#%E5%89%8D%E6%83%85%E5%9B%9E%E9%A1%BE)

设$\\boldsymbol{G}\\in\\mathbb{R}^{m\\times n}$是任意矩阵，$\\boldsymbol{P}\\in\\mathbb{R}^{n\\times n}$是任意特征值都在$\[0,1\]$内的矩阵，上一篇文章给出：
\\begin{gather}
\\boldsymbol{G}\_0 = \\boldsymbol{G}, \\quad \\boldsymbol{P}\_0 = \\boldsymbol{P} \\notag\\\\[6pt\]
\\boldsymbol{G}\_{t+1} = \\boldsymbol{G}\_t(a\_{t+1}\\boldsymbol{I} + b\_{t+1}\\boldsymbol{P}\_t + c\_{t+1}\\boldsymbol{P}\_t^2) \\label{eq:r2-rsqrt}\\\\[6pt\]
\\boldsymbol{P}\_{t+1} = (a\_{t+1}\\boldsymbol{I} + b\_{t+1}\\boldsymbol{P}\_t + c\_{t+1}\\boldsymbol{P}\_t^2)^2\\boldsymbol{P}\_t \\label{eq:r3-rsqrt}\\\\[6pt\]
\\lim\_{t\\to\\infty} \\boldsymbol{G}\_t = \\boldsymbol{G}\\boldsymbol{P}^{-1/2}\\notag
\\end{gather}
代入$\\boldsymbol{G}=\\boldsymbol{P}$就可以求得$\\boldsymbol{P}^{1/2}$，代入$\\boldsymbol{G}=\\boldsymbol{I}$就可以求得$\\boldsymbol{P}^{-1/2}$。仔细观察我们就会发现，上述迭代实际上是如下极限的体现：
\\begin{equation} \\prod\_{t=0}^{\\infty}(a\_{t+1}\\boldsymbol{I} + b\_{t+1}\\boldsymbol{P}\_t + c\_{t+1}\\boldsymbol{P}\_t^2) = \\boldsymbol{P}^{-1/2}\\label{eq:prod-rsqrt}\\end{equation}
有趣的是，直接证明这个极限并不复杂，直接对式$\\eqref{eq:r3-rsqrt}$两边开方，然后代入上式可得
\\begin{equation} \\prod\_{t=0}^{\\infty}(a\_{t+1}\\boldsymbol{I} + b\_{t+1}\\boldsymbol{P}\_t + c\_{t+1}\\boldsymbol{P}\_t^2) = \\prod\_{t=0}^{\\infty} \\boldsymbol{P}\_{t+1}^{1/2}\\boldsymbol{P}\_t^{-1/2} = \\lim\_{t\\to\\infty} \\boldsymbol{P}\_t^{1/2}\\boldsymbol{P}\_0^{-1/2} = \\lim\_{t\\to\\infty} \\boldsymbol{P}\_t^{1/2}\\boldsymbol{P}^{-1/2}\\end{equation}
由此可见，只要序列$\\{\\boldsymbol{P}\_t\\}$始终保持可逆，并且最终极限为$\\boldsymbol{I}$，那么极限$\\eqref{eq:prod-rsqrt}$自动成立。至于迭代$\\eqref{eq:r3-rsqrt}$如何让$\\{\\boldsymbol{P}\_t\\}$保持这两个条件，我们等会再一起讨论。

## 一般形式 [\#](https://kexue.fm/kexue.fm\#%E4%B8%80%E8%88%AC%E5%BD%A2%E5%BC%8F)

我们不妨一般地考虑迭代
\\begin{gather}
\\boldsymbol{G}\_0 = \\boldsymbol{G}, \\quad \\boldsymbol{P}\_0 = \\boldsymbol{P} \\notag\\\\[6pt\]
\\boldsymbol{G}\_{t+1} = \\boldsymbol{G}\_t(a\_{t+1}\\boldsymbol{I} + b\_{t+1}\\boldsymbol{P}\_t + c\_{t+1}\\boldsymbol{P}\_t^2)^s\\\\[6pt\]
\\boldsymbol{P}\_{t+1} = (a\_{t+1}\\boldsymbol{I} + b\_{t+1}\\boldsymbol{P}\_t + c\_{t+1}\\boldsymbol{P}\_t^2)^r\\boldsymbol{P}\_t
\\end{gather}
类似地，如果序列$\\{\\boldsymbol{P}\_t\\}$始终保持可逆，并且最终极限为$\\boldsymbol{I}$，那么可以证明成立
\\begin{equation}\\lim\_{t\\to\\infty} \\boldsymbol{G}\_t = \\boldsymbol{G}\\boldsymbol{P}^{-s/r}\\end{equation}
于是我们就得到了一种求矩阵的任意$-s/r$次幂的通用迭代形式。在这个结果之上，我们只需选择$\\boldsymbol{G}=\\boldsymbol{P}, s=r-1$，就可以得到$\\boldsymbol{P}^{1/r}$了，所以只需要集中精力解决$0\\sim 1$次幂的逆就可以了。

这样一来，问题变成了如何选择适当$\\{a\_t,b\_t,c\_t\\}$，让序列$\\{\\boldsymbol{P}\_t\\}$能够尽可能快地收敛到$\\boldsymbol{I}$，收敛速度越快，意味着我们可以用越少的迭代步数达到指定精度。

## 迭代系数 [\#](https://kexue.fm/kexue.fm\#%E8%BF%AD%E4%BB%A3%E7%B3%BB%E6%95%B0)

根据假设，$\\boldsymbol{P}\_0 = \\boldsymbol{P}$是一个特征值都在$\[0,1\]$内的矩阵，而目标矩阵$\\boldsymbol{I}$则是特征值全为1的矩阵，所以序列$\\{\\boldsymbol{P}\_t\\}$实际上就是特征值从任意$\[0,1\]$内的数变成$1$的过程，这实际上就是$\\mcsgn$所做的事情！

我们设$\\boldsymbol{X}\_t = \\boldsymbol{P}\_t^{1/r}$，那么$\\boldsymbol{X}\_0 = \\boldsymbol{P}^{1/r}$同样是一个特征值都在$\[0,1\]$内的矩阵，且迭代方程变为
\\begin{equation}\\boldsymbol{X}\_{t+1} = a\_{t+1}\\boldsymbol{X}\_t + b\_{t+1}\\boldsymbol{X}\_t^{r+1} + c\_{t+1}\\boldsymbol{X}\_t^{2r+1}\\end{equation}
现在问题则变成了如何让$\\boldsymbol{X}\_0$尽可能快地变成$\\boldsymbol{I}$，这跟我们在 [《msign算子的Newton-Schulz迭代（上）》](https://kexue.fm/archives/10922) 和 [《msign算子的Newton-Schulz迭代（下）》](https://kexue.fm/archives/10996) 所讨论的问题实质是一样的。其中，“ [下篇](https://kexue.fm/archives/10996)”给出了$r=2$的理论最优解，但它的求解过程和结论都可以推广到任意$r$的。

具体来说，我们先将问题转化为标量的迭代：
\\begin{equation}x\_{t+1} = f\_t(x\_t) = a\_{t+1}x\_t + b\_{t+1}x\_t^{r+1} + c\_{t+1}x\_t^{2r+1}\\end{equation}
然后证明贪心解就是最优解，而求贪心解则变成了解方程
\\begin{equation}\\begin{gathered}
f\_t(l\_t) = 1 - \\mathcal{E}, \\quad f\_t(u\_t) = 1 + \\mathcal{E} \\\
f\_t(x\_1) = 1 + \\mathcal{E}, \\quad f\_t(x\_2) = 1 - \\mathcal{E} \\\
f\_t'(x\_1) = 0, \\quad f\_t'(x\_2) = 0
\\end{gathered}\\end{equation}
简单起见，将$f\_t$参数化为
\\begin{equation}f\_t'(x) = k(x^r-x\_1^r)(x^r-x\_2^r)\\end{equation}
那么就可以像“ [下篇](https://kexue.fm/archives/10996) 一样，用Mathematica求解了。

## 初始分析 [\#](https://kexue.fm/kexue.fm\#%E5%88%9D%E5%A7%8B%E5%88%86%E6%9E%90)

不过正式求解之前，我们还要分析一下初始化。在上一篇文章 [《矩阵平方根和逆平方根的高效计算》](https://kexue.fm/archives/11158) 中我们提到，在$\\boldsymbol{P}$的特征值均非负的假设下，我们可以通过除以$\\newcommand{tr}{\\mathop{\\text{tr}}}\\tr(\\boldsymbol{P})$将特征值都压缩到$\[0,1\]$内。不过这个压缩比例往往过大了，本文我们改为
\\begin{equation}\\boldsymbol{P}\_0 = \\frac{\\boldsymbol{P}}{\\sqrt{\\tr(\\boldsymbol{P}^2)}}\\end{equation}
我们知道，$\\tr(\\boldsymbol{P}^2)$等于全体特征值的平方和，$\\tr(\\boldsymbol{P})^2$则等于全体特征值的和平方，在特征值非负时恒成立$\\tr(\\boldsymbol{P}^2)\\leq\\tr(\\boldsymbol{P})^2$，所以上式提供了一个更紧凑的初始值。特别地，算$\\tr(\\boldsymbol{P}^2)$并不需要把$\\boldsymbol{P}^2$显式计算出来，因为我们有恒等式
\\begin{equation}\\tr(\\boldsymbol{P}^2) = \\langle \\boldsymbol{P}, \\boldsymbol{P}^{\\top}\\rangle\_F\\end{equation}

接着，我们还要分析需要处理多小的特征值，这跟 [《msign算子的Newton-Schulz迭代（上）》](https://kexue.fm/archives/10922) 的初始奇异值分析是一样的。除以$\\sqrt{\\tr(\\boldsymbol{P}^2)}$后，$\\boldsymbol{P}\_0$的特征值组成一个单位向量，如果特征值全部相等，那么每个特征值是$1/\\sqrt{n}$。由鸽笼原理可知一般情况下必然存在小于$1/\\sqrt{n}$的特征值，保守起见我们兼容到$0.01/\\sqrt{n}$。

考虑到足够大的LLM，$n$已经到了$100^2$这个级别，所以我们需要兼容到$0.0001$。注意这只是$\\boldsymbol{P}\_0$的特征值，而$\\boldsymbol{X}\_0 = \\boldsymbol{P}\_0^{1/r}$，所以$\\boldsymbol{X}\_0$我们只需要兼容到$0.0001^{1/r}$，这比$\\mcsgn$、$\\newcommand{msign}{\\mathop{\\text{msign}}}\\msign$的情况要理想一些，因为$\\mcsgn$、$\\msign$的输入是$\\boldsymbol{X}\_0$，我们需要兼容$\\boldsymbol{X}\_0$的小特征值，但这里的输入是$\\boldsymbol{P}\_0$，我们只需要从$\\boldsymbol{P}\_0$出发考虑。

## 计算结果 [\#](https://kexue.fm/kexue.fm\#%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C)

综合上述考虑，我们最终的求解代码如下

```
r = 4;
df[x_] = k*(x^r - x1^r) (x^r - x2^r);
f[x_] = Integrate[df[x], {x, 0, x}];
sol[l_, u_] :=
 NSolve[{f[l] == 1 - e, f[x1] == 1 + e, f[x2] == 1 - e, f[u] == 1 + e,
 l < x1 < x2 < u, e > 0, k > 0}, {k, x1, x2, e}]
ff[x_, l_, u_] = f[x]*2/(f[l] + f[u]) // Expand;
lt = 0.0001^(1/r); ut = 1; lambda = 0.1;
While[1 - lt > 0.0001,
 fff[x_] = ff[x, lt, ut] /. sol[Max[lt, lambda*ut], ut][[1]];
 Print[fff[x]];
 lt = fff[lt]; ut = 2 - lt]
f[x] /. Solve[f[1] == 1, k][[1]] /. {x1 -> 1, x2 -> 1}

```

$r=1\\sim 5$的计算结果如下：
\\begin{array}{c\|ccc}
\\hline
r & t & a & b & c \\\
\\hline
& \\quad 1\\quad & 14.2975 & -31.2203 & 18.9214 \\\
& 2 & 7.12258 & -7.78207 & 2.35989 \\\
\\quad 1\\quad & 3 & 6.9396 & -7.61544 & 2.3195 \\\
& 4 & 5.98456 & -6.77016 & 2.12571 \\\
& 5 & 3.79109 & -4.18664 & 1.39555 \\\
& \\geq 6 & 3 & -3 & 1 \\\
\\hline
& 1 & 7.42487 & -18.3958 & 12.8967 \\\
& 2 & 3.48773 & -2.33004 & 0.440469 \\\
2 & 3 & 2.77661 & -2.07064 & 0.463023 \\\
& 4 & 1.99131 & -1.37394 & 0.387593 \\\
& \\geq 5 & 15/8 & -5/4 & 3/8 \\\
\\hline
& 1 & 5.05052 & -13.5427 & 10.2579 \\\
& 2 & 2.31728 & -1.06581 & 0.144441 \\\
3 & 3 & 1.79293 & -0.913562 & 0.186699 \\\
& 4 & 1.56683 & -0.786609 & 0.220008 \\\
& \\geq 5 & 14/9 & -7/9 & 2/9 \\\
\\hline
& 1 & 3.85003 & -10.8539 & 8.61893 \\\
4 & 2 & 1.80992 & -0.587778 & 0.0647852 \\\
& 3 & 1.50394 & -0.594516 & 0.121161 \\\
& \\geq 4 & 45/32 & -9/16 & 5/32 \\\
\\hline
& 1 & 3.11194 & -8.28217 & 6.67716 \\\
5 & 2 & 1.5752 & -0.393327 & 0.0380364 \\\
& 3 & 1.3736 & -0.44661 & 0.0911259 \\\
& \\geq 4 & 33/25 & -11/25 & 3/25 \\\
\\hline
\\end{array}

其中最后一步的收敛值，由$x\_1=x\_2=1$和$f(1)=1$得出。

## 测试一下 [\#](https://kexue.fm/kexue.fm\#%E6%B5%8B%E8%AF%95%E4%B8%80%E4%B8%8B)

一个简单的测试代码如下：

```
import numpy as np
import jax.numpy as jnp

coefs = [
 None,
 [
 (14.2975, -31.2203, 18.9214),
 (7.12258, -7.78207, 2.35989),
 (6.9396, -7.61544, 2.3195),
 (5.98456, -6.77016, 2.12571),
 (3.79109, -4.18664, 1.39555),
 (3, -3, 1),
 ],
 [
 (7.42487, -18.3958, 12.8967),
 (3.48773, -2.33004, 0.440469),
 (2.77661, -2.07064, 0.463023),
 (1.99131, -1.37394, 0.387593),
 (15 / 8, -5 / 4, 3 / 8),
 ],
 [
 (5.05052, -13.5427, 10.2579),
 (2.31728, -1.06581, 0.144441),
 (1.79293, -0.913562, 0.186699),
 (1.56683, -0.786609, 0.220008),
 (14 / 9, -7 / 9, 2 / 9),
 ],
 [
 (3.85003, -10.8539, 8.61893),
 (1.80992, -0.587778, 0.0647852),
 (1.50394, -0.594516, 0.121161),
 (45 / 32, -9 / 16, 5 / 32),
 ],
 [
 (3.11194, -8.28217, 6.67716),
 (1.5752, -0.393327, 0.0380364),
 (1.3736, -0.44661, 0.0911259),
 (33 / 25, -11 / 25, 3 / 25),
 ],
]

def abc(r=1, steps=None, scale=1):
 w, steps = coefs[r], steps or len(coefs[r])
 for a, b, c in w[:steps] + w[-1:] * max(steps - len(w), 0):
 yield a / scale, b / scale**(r + 1), c / scale**(2 * r + 1)

def matmul_invroot(G, P, r, s=1, steps=None, eps=1e-5):
 """return G @ P^(-s/r)
 """
 I = jnp.eye(P.shape[0], dtype=P.dtype)
 P = P / (t := (P * P.mT).sum()**0.5) + eps * I
 for a, b, c in abc(r, steps, 1.001):
 W = a * I + b * P + c * P @ P
 W1, W2 = jnp.linalg.matrix_power(W, s), jnp.linalg.matrix_power(W, r)
 G, P = G @ W1, P @ W2
 return G * t**(-s / r)

def matmul_invroot_by_eigh(G, P, r, s=1):
 """return G @ P^(-s/r)
 """
 S, Q = jnp.linalg.eigh(P)
 return G @ Q @ jnp.diag(S**(-s / r)) @ jnp.linalg.inv(Q)

d = 1000
s, r = 1, 4
G = np.random.randn(2 * d, d) / d**0.5
P = (x := np.random.randn(d, d) / d**0.5) @ x.T + 0.001 * np.eye(d)

X1 = matmul_invroot_by_eigh(G, P, r, s)
X2 = matmul_invroot(G, P, r, s, eps=0)
jnp.abs(X1 - X2).mean() # ~= 1e-3

X2 = matmul_invroot(jnp.array(G, dtype='bfloat16'), jnp.array(P, dtype='bfloat16'), r, s, eps=0)
jnp.abs(X1 - X2).mean() # ~= 2e-3
```

这里有几点注意事项。首先输入$\\boldsymbol{P}$的最小特征值不能太小，否则迭代过程极其容易爆炸，哪怕我们只想要求正数次幂如$\\boldsymbol{P}^{1/2}$也是如此。这个其实不难理解，因为$\\sqrt{x}$在$x=0$处也是比较病态的，一旦由于误差问题“不小心”到了负半轴，那直接就不存在（实数解）了，这时候迭代的表现就无法预估。

多小才不算“太小”呢？大概是$\\boldsymbol{P}/\\sqrt{\\tr(\\boldsymbol{P}^2)}$的最小特征值明显不能小于我们考虑的最小特征值，即$0.0001$。如果没法保证这一点，那么建议直接设置
\\begin{equation}\\boldsymbol{P}\_0 = \\frac{\\boldsymbol{P}}{\\sqrt{\\tr(\\boldsymbol{P}^2)}} + \\epsilon \\cdot\\boldsymbol{I} \\end{equation}
其中$\\epsilon\\sim 0.0001$。这样会损失一点精度，但能够明显增加数值稳定性。

此外，迭代步数在大多数情况下不需要超过推荐值 `len(coefs[r])`，尤其是低精度计算场景，因为迭代步数越多，越容易由于累积误差而爆炸。实际上只要特征值在考虑范围内，推荐步数已经足够达到理想精度了，除非我们用fp32甚至更高精度迭代，那么可以考虑设置$\\epsilon=0$、 `scale=1` 以及使用更多的迭代步数。

## 文章小结 [\#](https://kexue.fm/kexue.fm\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文将上一篇文章的结果，推广到任意的$r$次方根和逆$r$次方根的计算，得到了一种矩阵的任意$-1/r$次方的通用迭代格式。

_**转载到请包括本文地址：** [https://kexue.fm/archives/11175](https://kexue.fm/archives/11175)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jul. 21, 2025). 《矩阵r次方根和逆r次方根的高效计算 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/11175](https://kexue.fm/archives/11175)

@online{kexuefm-11175,
        title={矩阵r次方根和逆r次方根的高效计算},
        author={苏剑林},
        year={2025},
        month={Jul},
        url={\\url{https://kexue.fm/archives/11175}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [代数](https://kexue.fm/tag/%E4%BB%A3%E6%95%B0/), [迭代](https://kexue.fm/tag/%E8%BF%AD%E4%BB%A3/), [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/), [线性](https://kexue.fm/tag/%E7%BA%BF%E6%80%A7/)[抢沙发](https://kexue.fm/archives/11175#comments)

< [矩阵平方根和逆平方根的高效计算](https://kexue.fm/archives/11158) \| [流形上的最速下降：1\. SGD + 超球面](https://kexue.fm/archives/11196) >

### 你也许还对下面的内容感兴趣

- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [为什么线性注意力要加Short Conv？](https://kexue.fm/archives/11320)
- [流形上的最速下降：4\. Muon + 谱球面](https://kexue.fm/archives/11241)
- [流形上的最速下降：3\. Muon + Stiefel](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon + 正交](https://kexue.fm/archives/11215)
- [矩阵平方根和逆平方根的高效计算](https://kexue.fm/archives/11158)
- [“对角+低秩”三角阵的高效求逆方法](https://kexue.fm/archives/11072)
- [通过msign来计算奇异值裁剪mclip（下）](https://kexue.fm/archives/11059)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

[取消回复](https://kexue.fm/archives/11175#respond-post-11175)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[前情回顾](https://kexue.fm/kexue.fm#%E5%89%8D%E6%83%85%E5%9B%9E%E9%A1%BE)
[一般形式](https://kexue.fm/kexue.fm#%E4%B8%80%E8%88%AC%E5%BD%A2%E5%BC%8F)
[迭代系数](https://kexue.fm/kexue.fm#%E8%BF%AD%E4%BB%A3%E7%B3%BB%E6%95%B0)
[初始分析](https://kexue.fm/kexue.fm#%E5%88%9D%E5%A7%8B%E5%88%86%E6%9E%90)
[计算结果](https://kexue.fm/kexue.fm#%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C)
[测试一下](https://kexue.fm/kexue.fm#%E6%B5%8B%E8%AF%95%E4%B8%80%E4%B8%8B)
[文章小结](https://kexue.fm/kexue.fm#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [变分自编码器（八）：估计样本概率密度](https://kexue.fm/archives/8791)
- [神秘的圆——三角形的“六接圆”(添加新方法)](https://kexue.fm/archives/744)
- [《自然极值》系列——5.最速降线的故事](https://kexue.fm/archives/1094)
- [\[问题解答\]有多少位数字？](https://kexue.fm/archives/1922)
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
- [哈哈，我的“《圣经》”到了](https://kexue.fm/archives/2008)
- [三百年之谜——费马大定理(历史+证明)](https://kexue.fm/archives/38)
- [《新理解矩阵2》：矩阵是什么？](https://kexue.fm/archives/1768)
- [【NASA每日一图】沙子般的 NGC 1313](https://kexue.fm/archives/64)
- [素数之美2：Bertrand假设的证明](https://kexue.fm/archives/2800)

### 最近评论

- [cmlin](https://kexue.fm/archives/11340/comment-page-1#comment-29031): 本人对这方面不太熟悉，想了解这三个条件的意义及动机，且希望这系列可以继续写下去。以下想发表一些...
- [喝一口可乐](https://kexue.fm/archives/10958/comment-page-3#comment-29030): 理解了，感谢苏神回复，数学上给出建模分析确实清晰了很多，再次感谢苏神回复！
- [CuddleSabe1](https://kexue.fm/archives/10958/comment-page-1#comment-29029): 感觉普通的 flow matching 可以看成 degrade-aware image de...
- [岁月如书](https://kexue.fm/archives/11126/comment-page-3#comment-29028): 受教了，感谢
- [苏剑林](https://kexue.fm/archives/11126/comment-page-3#comment-29027): 是
- [岁月如书](https://kexue.fm/archives/11126/comment-page-3#comment-29026): 哦哦，原来是有实验结论，那是我盲目了。多问一句，你说的attention + output g...
- [苏剑林](https://kexue.fm/archives/11126/comment-page-3#comment-29025): attention sink指的是第一个token的attention普遍不可忽略，不一定是爆...
- [苏剑林](https://kexue.fm/archives/11459/comment-page-1#comment-29024): 这也许是好事呢？SGD倒是保留了模长，但它就普遍不如不保留模长的SignSGD或者Normal...
- [岁月如书](https://kexue.fm/archives/11126/comment-page-3#comment-29023): maxlogit 是attention qk乘积中出现了大值，attention sink等于...
- [岁月如书](https://kexue.fm/archives/11459/comment-page-1#comment-29022): \[comment=29016\]苏剑林\[/comment\]他通过Newton-schulz迭代近...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。