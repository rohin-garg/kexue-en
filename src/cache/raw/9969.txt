Loading \[MathJax\]/jax/element/mml/optable/BasicLatin.js

![MobileSideBar](https://kexue.fm/usr/themes/geekg/images/slide-button.png)

## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [让炼丹更科学一些（五）：基于梯度精...](https://kexue.fm/archives/11530)
- [让炼丹更科学一些（四）：新恒等式，...](https://kexue.fm/archives/11494)
- [为什么DeltaNet要加L2 N...](https://kexue.fm/archives/11486)
- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)

## COMMENTS

- [Bin: 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院...](https://kexue.fm/archives/1990/comment-page-2#comment-29105)
- [Rapture D: 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。](https://kexue.fm/archives/11530/comment-page-1#comment-29104)
- [mofheka: 苏神是还在用jax是么？最近在做基于Google Pathwa...](https://kexue.fm/archives/11390/comment-page-1#comment-29103)
- [长琴: 看懂这篇博客也不是一件容易的事情。](https://kexue.fm/archives/11530/comment-page-1#comment-29102)
- [AlexLi: 苏老师，请教一下(7)式中将 μ(xt) 传给 $p...](https://kexue.fm/archives/9257/comment-page-4#comment-29101)
- [tyler\_zxc: "Performer的思想是将标准的Attention线性化，...](https://kexue.fm/archives/7921/comment-page-2#comment-29100)
- [我: 似乎并非mHC提出矩阵的思想？之前hyper connecti...](https://kexue.fm/archives/11494/comment-page-1#comment-29099)
- [winter: 苏神您好，假如对于比较均匀的attention weightP...](https://kexue.fm/archives/10847/comment-page-1#comment-29098)
- [苏剑林: KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个](https://kexue.fm/archives/8512/comment-page-2#comment-29097)
- [苏剑林: 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理...](https://kexue.fm/archives/9119/comment-page-14#comment-29096)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm/)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [![](https://kexue.fm/usr/themes/geekg/images/rss.png)\\
\\
欢迎订阅](https://kexue.fm/feed)
- [![](https://kexue.fm/usr/themes/geekg/images/mail.png)\\
\\
个性邮箱](https://kexue.fm/archives/119)
- [![](https://kexue.fm/usr/themes/geekg/images/Saturn.png)\\
\\
天象信息](https://kexue.fm/ac.html)
- [![](https://kexue.fm/usr/themes/geekg/images/iss.png)\\
\\
观测ISS](https://kexue.fm/archives/41)
- [![](https://kexue.fm/usr/themes/geekg/images/pi.png)\\
\\
LaTeX](https://kexue.fm/latex.html)
- [![](https://kexue.fm/usr/themes/geekg/images/mlogo.png)\\
\\
关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm/) [信息时代](https://kexue.fm/category/Big-Data) 幂等生成网络IGN：试图将判别和生成合二为一的GAN

31Jan

# [幂等生成网络IGN：试图将判别和生成合二为一的GAN](https://kexue.fm/archives/9969)

By 苏剑林 \|
2024-01-31 \|
79307位读者 \|

前段时间，一个名为“ [幂等生成网络（Idempotent Generative Network，IGN）](https://papers.cool/arxiv/2311.01462)”的生成模型引起了一定的关注。它自称是一种独立于已有的VAE、GAN、flow、Diffusion之外的新型生成模型，并且具有单步采样的特点。也许是大家苦于当前主流的扩散模型的多步采样生成过程久矣，因此任何声称可以实现单步采样的“风吹草动”都很容易吸引人们的关注。此外，IGN名称中的“幂等”一词也增加了它的神秘感，进一步扩大了人们的期待，也成功引起了笔者的兴趣，只不过之前一直有别的事情要忙，所以没来得及认真阅读模型细节。

最近闲了一点，想起来还有个IGN没读，于是重新把论文翻了出来，但阅读之后却颇感困惑：这哪里是个新模型，不就是个GAN的变种吗？跟常规GAN不同的是，它将生成器和判别器合二为一了。那这个“合二为一”是不是有什么特别的好处，比如训练更稳定？个人又感觉没有。下面将分享笔者从GAN角度理解IGN的过程和疑问。

## 生成对抗 [\#](https://kexue.fm/archives/9969\#%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97)

关于GAN（Generative Adversarial Network，生成对抗网络），笔者前几年系统地学习过一段时间（查看 [GAN](https://kexue.fm/tag/GAN/) 标签可以查看到相关文章），但近几年没有持续地关注了，因此这里先对GAN做个简单的回顾，也方便后续章节中我们对比GAN与IGN之间的异同。

GAN有两个基本组件：判别器（Discriminator）和生成器（Generator），也可以形象地类别为“鉴别者”和“伪造者”，其中判别器负责区分出真实样本和生成器生成的假样本，而生成器负责将简单的随机噪声映射为目标样本，并借助判别器的信号改进自己的生成质量，在不断的“攻守对抗”之中，生成器的生成质量越来越优，直到判别器完全无法区分真假样本，达到了以假乱真的效果。

以WGAN为例，判别器Dθ的训练目标是拉大真假样本的分数差距：

max

其中x是训练集的真样本，z是随机噪声，G\_{\\varphi}是生成器，G\_{\\varphi}(z)自然是生成器生成的假样本。生成器的训练目标是缩小真假样本的得分差距，即最小化上式，不过对于生成器来说，不包含参数的x就相当于是常数，因此可以简化为

\\begin{equation}\\min\_{\\varphi} D\_{\\theta}(G\_{\\varphi}(z))\\label{eq:g-loss}\\end{equation}

除此之外，还少了关于L约束的内容，但这属于细节了，这里不展开，有兴趣的读者可以进一步阅读 [《互怼的艺术：从零直达WGAN-GP》](https://kexue.fm/archives/4439) 和 [《从Wasserstein距离、对偶理论到WGAN》](https://kexue.fm/archives/6280) 等。

一般情况下，GAN是两个Loss交替训练，有时候也可以写成单个Loss往两个方向优化——部分参数执行梯度下降，另外一部分参数则执行梯度上升。这种同时存在相反方向的训练过程（即\\min\\text{-}\\max）通常不稳定，比较容易崩溃，又或者训练出来了，但存在模式坍缩（Mode Collapse）的问题，具体表现就是生成结果单一，多样性丧失。

## 单个损失 [\#](https://kexue.fm/archives/9969\#%E5%8D%95%E4%B8%AA%E6%8D%9F%E5%A4%B1)

可能有读者反对：你都说GAN是两个Loss交替优化了，而IGN明明是单个Loss的呀，怎么能够说IGN是GAN的特例？

事实上，IGN的单个Loss的写法是有点“耍无赖”的，照它的写法，GAN同样可以写成单个Loss的形式。具体怎么做呢？很简单，假设\\theta',\\varphi'是\\theta,\\varphi的权重副本，即\\theta'\\equiv\\theta,\\varphi'\\equiv\\varphi，但是它们不求梯度，于是式\\eqref{eq:d-loss}和式\\eqref{eq:g-loss}可以合并起来写成：

\\begin{equation}\\min\_{\\theta,\\varphi} D\_{\\theta}(x) - D\_{\\theta}(G\_{\\varphi'}(z)) + D\_{\\theta'}(G\_{\\varphi}(z))\\label{eq:pure-one-loss}\\end{equation}

此时它关于\\theta,\\varphi的梯度跟分开两个Loss时所求的一样，因此是等价实现。可为什么说这种写法是“耍无赖”呢？因为它没有一丁点的技巧，就纯粹将原本的\\min\\text{-}\\max换了个记号，真的按照上式实现的话，需要不断地克隆D\_{\\theta'},G\_{\\varphi'}出来然后停止梯度，非常影响训练效率。

事实上，要想将GAN写成单个Loss的训练形式并保持实用性，可以参考笔者之前写的 [《巧断梯度：单个loss实现GAN模型》](https://kexue.fm/archives/6387)，通过框架自带`stop_gradient`算子，加上一些梯度运算技巧，就可以实现这一目的。具体来说，`stop_gradient`就是强制模型某一部分的梯度为0，比如

\\begin{equation}\\nabla\_{\\theta,\\varphi} D\_{\\theta}(G\_{\\varphi}(z)) = \\left(\\frac{\\partial D\_{\\theta}(G\_{\\varphi}(z))}{\\partial\\theta},\\frac{\\partial D\_{\\theta}(G\_{\\varphi}(z))}{\\partial\\varphi}\\right)\\label{eq:full-grad}\\end{equation}

加了`stop_gradient`算子（简写为\\color{skyblue}{\\text{sg}}）后，就有

\\begin{equation}\\nabla\_{\\theta,\\varphi} D\_{\\theta}(\\color{skyblue}{\\text{sg}(}G\_{\\varphi}(z)\\color{skyblue}{)}) = \\left(\\frac{\\partial D\_{\\theta}(G\_{\\varphi}(z))}{\\partial\\theta},0\\right)\\label{eq:stop-grad}\\end{equation}

所以通过`stop_gradient`算子，我们可以很容易屏蔽嵌套函数内层梯度（即\\varphi的梯度）。那么像生成器那样，需要屏蔽嵌套函数外层梯度（即\\theta的梯度）呢？没有直接的办法，但我们可以用一个技巧实现：将式\\eqref{eq:full-grad}和式\\eqref{eq:stop-grad}相减，就得到

\\begin{equation}\\nabla\_{\\theta,\\varphi} D\_{\\theta}(G\_{\\varphi}(z)) - \\nabla\_{\\theta,\\varphi} D\_{\\theta}(\\color{skyblue}{\\text{sg}(}G\_{\\varphi}(z)\\color{skyblue}{)}) = \\left(0,\\frac{\\partial D\_{\\theta}(G\_{\\varphi}(z))}{\\partial\\varphi}\\right)\\end{equation}

这就达到了屏蔽嵌套函数外层梯度。于是将两个式子结合起来，我们就得到单个Loss训练GAN的一种方式

\\begin{equation}\\begin{gathered}
\\min\_{\\theta,\\varphi} \\underbrace{D\_{\\theta}(x) - D\_{\\theta}(\\color{skyblue}{\\text{sg}(}G\_{\\varphi}(z)\\color{skyblue}{)})}\_{\\text{去掉了}\\varphi\\text{的梯度}} + \\underbrace{D\_{\\theta}(G\_{\\varphi}(z)) - D\_{\\theta}(\\color{skyblue}{\\text{sg}(}G\_{\\varphi}(z)\\color{skyblue}{)})}\_{\\text{去掉了}\\theta\\text{的梯度}} \\\\[8pt\]
= \\min\_{\\theta,\\varphi} D\_{\\theta}(x) - 2 D\_{\\theta}(\\color{skyblue}{\\text{sg}(}G\_{\\varphi}(z)\\color{skyblue}{)}) + D\_{\\theta}(G\_{\\varphi}(z))\\end{gathered}\\end{equation}

这样就不需要反复克隆模型，也在单个Loss中实现了梯度的等价性。

## 幂等生成 [\#](https://kexue.fm/archives/9969\#%E5%B9%82%E7%AD%89%E7%94%9F%E6%88%90)

说了那么多，总算可以邀请本文的主角——幂等生成网络IGN登场了。不过在正式登场之前，还请大家再等一会，我们先来谈谈IGN的动机。

GAN有一个明显的特点，就是当GAN训练成功后，往往只保留其中的生成器，判别器大多数是“弃之不用”的。然而，一个合理的GAN，生成器和判别器通常具有同等数量级的参数，判别器弃之不用，意味着一半参数量被浪费了，这是比较可惜的。为此，有些工作尝试过往GAN里边加入编码器，并共享判别器与编码器的部分参数，提高参数利用率。其中，最极简的工作是笔者提的 [O-GAN](https://kexue.fm/archives/6409)，它仅微改了判别器的结构，然后添加一项额外的Loss，就可以将判别器变成编码器，并且不增加参数和计算量，它是笔者比较满意的作品。

本文标题就开门见山，IGN是一个试图将判别器和生成器合二为一的GAN，生成器“既当选手，又当裁判”，所以从这个角度来看，IGN也可以视为提高参数利用率的一种方式。首先，IGN假设z和x的大小一样，那么生成器G\_{\\varphi}的输出输入的大小都一样，这跟一般的GAN中z的维度通常要比x的维度小不一样；在输入输出同大小的设计之下，图片本身也可以当成输入，传入到生成器中做进一步运算，于是IGN将判别器设计为重构损失：

\\begin{equation}\\delta\_{\\varphi}(x) = \\Vert G\_{\\varphi}(x) - x\\Vert^2\\label{eq:ign-d}\\end{equation}

\\delta\_{\\varphi}是重用了IGN论文原本的记号，没有特殊的含义。这样的设计完全重用了生成器的参数，且没有增加额外的参数，看上去确实是一种很优雅的设计。现在我们将上述判别器代入式\\eqref{eq:pure-one-loss}，得到

\\begin{equation}\\min\_{\\varphi}\\underbrace{\\delta\_{\\varphi}(x) - \\delta\_{\\varphi}(G\_{\\varphi'}(z))}\_{\\text{判别器损失}} + \\underbrace{\\delta\_{\\varphi'}(G\_{\\varphi}(z))}\_{\\text{生成器损失}}\\end{equation}

这不就跟IGN原论文的 **Final optimization objective** 如出一辙？当然原论文还多了两个可调的系数，事实上式\\eqref{eq:pure-one-loss}的每一项系数也是可调的，这不是什么特殊的地方。所以很显然，IGN完全可以从GAN推出，它就是GAN的一个特例——尽管作者说他并不是GAN的角度思考IGN的。

“幂等”一词，源于作者认为IGN在训练成功时，判别器对于真实样本的打分为0，此时G\_{\\varphi}(x) = x，那么可以继续推出

\\begin{equation}G\_{\\varphi}(\\cdots G\_{\\varphi}(x)) = \\cdots = G\_{\\varphi}(G\_{\\varphi}(x)) = G\_{\\varphi}(x) = x\\end{equation}

也就是说，对真实样本x多次应用G\_{\\varphi}，结果仍然保持不变，这正是数学上“幂等”的含义。然而，从理论上来说，我们并没办法保证GAN的判别器（对于真实样本的）损失是零，所以很难做到真正意义上的幂等，原论文的实验结果也表明了这一点。

## 个人分析 [\#](https://kexue.fm/archives/9969\#%E4%B8%AA%E4%BA%BA%E5%88%86%E6%9E%90)

一个非常值得思考的问题是： **重构损失\\eqref{eq:ign-d}为什么可以成功作为判别器呢？或者说，基于G\_{\\varphi}(x)和x可以构建的表达式非常多，任意一个都可以作为判别器吗？**

单从“重构损失作为判别器”这一点来看，IGN跟 [EBGAN](https://papers.cool/arxiv/1609.03126) 很相似，可这不意味着EBGAN的成功就能解释IGN的成功，因为EBGAN的生成器是独立于判别器之外的，并没有完全共享参数的约束，所以EBGAN的成功是“情理之中”，符合GAN的原始设计。但IGN却不一样，因为它的判别器和生成器完全共享了参数，并且GAN本身训练存在很大的不稳定因素，所以很容易“一损俱损”，让两者一起训崩。

在笔者看来，IGN能有机会不训崩，是因为刚好满足了“自洽性”。首先，GAN的根本目标，是希望对于输入噪声z，G\_{\\varphi}(z)能够输出一张真实图片；而对于IGN中“重构损失作为判别器”的设计，即便判别器的最优损失不是零，也可能是大差不差，即G\_{\\varphi}(x)\\approx x是近似满足的，于是它同时满足了“对于输入图片x，G\_{\\varphi}(x)能够输出一张真实图片”的条件。也就是说，不管输入如何，输出的空间都是真实样本，这一点自洽性非常重要，否则生成器可能因为需要往两个方向进行生成而“分崩离析”。

既然如此，IGN相比于一般的GAN，有什么实质的改进呢？请恕在下愚钝，笔者实在是看不出IGN的好处所在。就拿参数利用率来说，看上去IGN的参数共享确实提高了参数利用率，但事实上为了保证生成器G\_{\\varphi}的输入输出一样，IGN使用了自编码器结构，其参数量和计算量，就等于一般GAN的判别器和生成器之和！换句话说，IGN非但没有降低参数量，反而因为增大了生成器的体积而增加了总的计算量。

笔者也简单实验了一下IGN，发现IGN的训练同样有不稳定的问题，甚至可以说更不稳定，因为“参数共享+欧氏距离”这种硬约束更容易放大这种不稳定性，导致“一损俱损”而不是“一荣俱荣”。此外，IGN的生成器输入输出同大小的特点，也失去了一般GAN的生成器从低维流形投影到高维数据的优点，以及IGN同样容易模式坍缩，并且由于欧式距离的问题，生成的图片更像VAE那样偏模糊。

## 文章小结 [\#](https://kexue.fm/archives/9969\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文从GAN的角度介绍了前段时间引起了一定关注的幂等生成网络IGN，对比了它与GAN的联系与区别，并分享了自己对IGN的分析。

_**转载到请包括本文地址：** [https://kexue.fm/archives/9969](https://kexue.fm/archives/9969 "幂等生成网络IGN：试图将判别和生成合二为一的GAN")_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/9969#share)/ [打赏](https://kexue.fm/archives/9969#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。

你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jan. 31, 2024). 《幂等生成网络IGN：试图将判别和生成合二为一的GAN 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/9969](https://kexue.fm/archives/9969)

@online{kexuefm-9969,

         title={幂等生成网络IGN：试图将判别和生成合二为一的GAN},

         author={苏剑林},

         year={2024},

         month={Jan},

         url={\\url{https://kexue.fm/archives/9969}},

}


分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [GAN](https://kexue.fm/tag/GAN/), [生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/), [对抗](https://kexue.fm/tag/%E5%AF%B9%E6%8A%97/)[22 评论](https://kexue.fm/archives/9969#comments)

< [Transformer升级之路：16、“复盘”长度外推技术](https://kexue.fm/archives/9948 "Transformer升级之路：16、“复盘”长度外推技术") \| [更便捷的Cool Papers打开方式：Chrome重定向扩展](https://kexue.fm/archives/9978 "更便捷的Cool Papers打开方式：Chrome重定向扩展") >

### 你也许还对下面的内容感兴趣

- [生成扩散模型漫谈（三十一）：预测数据而非噪声](https://kexue.fm/archives/11428 "生成扩散模型漫谈（三十一）：预测数据而非噪声")
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328 "DiVeQ：一种非常简洁的VQ训练方案")
- [为什么线性注意力要加Short Conv？](https://kexue.fm/archives/11320 "为什么线性注意力要加Short Conv？")
- [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111 "Transformer升级之路：21、MLA好在哪里?（下）")
- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033 "线性注意力简史：从模仿、创新到反哺")
- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958 "生成扩散模型漫谈（三十）：从瞬时速度到平均速度")
- [Transformer升级之路：20、MLA好在哪里?（上）](https://kexue.fm/archives/10907 "Transformer升级之路：20、MLA好在哪里?（上）")
- [生成扩散模型漫谈（二十九）：用DDPM来离散编码](https://kexue.fm/archives/10711 "生成扩散模型漫谈（二十九）：用DDPM来离散编码")
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667 "细水长flow之TARFLOW：流模型满血归来？")
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633 "生成扩散模型漫谈（二十八）：分步理解一致性模型")

[发表你的看法](https://kexue.fm/archives/9969#comment_form)

[DIYer22](https://github.com/DIYer22)

January 31st, 2024

赞博主的本质分析, IGN 在 openreview 上也遭到了是 GAN 变种的质疑.

近期还有一个搞新生成模型的相似工作 Discrete Distribution Networks (https://discrete-distribution-networks.github.io/) , 求博主也一并分析一下!

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23633#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
January 31st, 2024

阁下似乎就是DDN的作者？欢迎莅临指导！我认真拜读一下～

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23650#respond-post-9969)

[DIYer22](https://github.com/DIYer22) 发表于
January 31st, 2024

哈哈哈哈, 是的, 没想到伪装成路人那么快就被揭穿了. DDN 支持纯粹的判别模型作为引导来做 zero-shot conditional generation (无需梯度和迭代), 让生成模型和判别模型得以进一步融合. 感谢博主关注, 也欢迎交流!

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23653#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
February 3rd, 2024

我昨晚简单阅读了一下DDN，基本结论是：DDN本质上在做跟VQ-VAE类似的事情，试图将图片转换为一系例的离散ID，然后转换为离散ID的生成。不同点在于：

1、DDN通过特定的结构设置，使得输出的L个离散编码具有单向依赖的特点，而VQ-VAE则是双向的；

2、DDN通过特定的训练算法（Split and Prune），使得每个位置的离散编码尽可能均匀，这样在训练出来后，模型自动成为一个自回归生成模型（每一步均匀采样）。

同时因为第2点，我认为论文将DDN定义为单步采样模型是不对的，它应该就是个自回归模型，只不过在原论文的设计之下，每一步递归的计算量不大？

然后，泼个冷水，就是DDN的想法很好，但如果没有进一步的明显优化，我并不看好它的前景，原因有2点：

1、Split and Prune人工雕琢痕迹太严重，很难给人能成为主流的感觉；

2、最重要的是，在DDN论文目前的设计下，熵是严重不足的。其实原论文已经计算过，L长度，每个位置K个值，那么顶多编码L\\log\_2 K个比特的信息，原论文L=128,K=512，然而，参考以往的pixel generation的工作（比如 https://arxiv.org/abs/1904.10509 ），ImageNet 64x64的每个dim的比特数都在3以上，这意味着一个64\*64的ImageNet图像，至少有64\*64\*3\*3=36864个比特（即便celeba可能小一点，也不会小到哪里去），而DDN目前的设置顶天了能编码1152个比特，这是远远不足的，所以DDN无法做到无损编码，而有损的话，因为DDN依赖于MSE，那么生成结果必然模糊。

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23662#respond-post-9969)

[DIYer22](https://github.com/DIYer22) 发表于
February 4th, 2024

感谢博主的评论, 尤其是关于熵不足的论证.

当前的 DDN 论文的目的只是展示一个全新的生成模型及其独特的性质(zero-shot conditional generation 和高度压缩表示), 并做基本的 proof of concept.

关于和 VQ-VAE 的区别, 我认为尽管我们目标有相似性(离散 latent), 但也显著不同(VQ 仍然是二维的 latent, 而 DDN 是序列/层次化的), 且网络架构、latent 构建方案、先验建模和优化方法都不一样, 模型的性质也不同

对于是不是单步模型, DDN 支持参数重用的自回归形式, 也支持 single shot 形式. 而对于 single shot 形式, 从参数复用程度和生成图像的算力上看, DDN 和 GAN 的生成器、VAE 的解码器更相似, 所以我把它归类为了 one-step.

就应用而言, 我也认同纯 DDN 并不适合熵很高的图像生成任务. 但生成模型的应用很广泛, 我想到的 DDN 潜在应用有:

\- DDN 能建模完整分布, 但高频信号差, 能力上正好和 GAN 互补. 所以可以加对抗/感知损失来补上高频信号.

\- 做熵没那么高的任务, 比如 image2image conditional training, latent 生成或者解决某些有歧义性质的判别任务(深度估计, pose).

\- 自然语言的熵很低, 分享一下我正在做的尝试, "把单层 DDN 用在 GPT 上, 直接回归 utf-8 的二进制":

1\. 该方案能去掉 tokenization 步骤, 并根据问题难度在每一次前向中, 自适应调整生成内容的 byte 长度(可以理解为天然支持 speculative sample，能同时节省计算和访存)

2\. 展示一下初步实验生成的句子(由网络自动分词): │The │investigation │is │due to │take place │later │this │summer│ and │it │means │a │team │is gl│abi│lang,│ as well as │the │investigation │is │likely to │take │place │this │summer│. 模型能把 \` as well as \` 这样的 12 个 byte 的词组分为一个 token

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23670#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
February 5th, 2024

因为熵损失太严重，引入对抗或者感知损失只能引导它往另一个方向（更接近人的视角）去有损压缩，距离无损压缩还是差太远，这是它本质瓶颈。

其他观点基本上认同，做低熵任务这个定位我觉得是比较适合的，另外应用到NLP我也稍微思考了一下，但没太深入。我对你最后演示的自动分词效果非常感兴趣，这是DDN+GPT联合训练的？还是先DDN然后GPT？欢迎进一步展开哈哈哈（评论区或者邮件均可）

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23671#respond-post-9969)

[DIYer22](https://github.com/DIYer22) 发表于
February 5th, 2024

简单来讲, 该方案把 GPT 输出层的词表 softmax 换成了一层 Discrete Distribution Layer 输出 K 个长度固定的 patch 候选, 并加一个分词 loss 来预测 patch 应该从哪里分词. 为了处理这个长度不固定的 patch 还有一些较为复杂的设计, 得整理了资料后才好表述清楚, 到时候再与博主交流~

再分享一下自己不成熟的思考, 可能和内容不太相关: 我和很多人交流 DDN 时, 有个很有意思的发现, 做大模型的人都非常看重图像的无损压缩. 按我的理解, 能无损压缩的生成模型只有 AR 和 flow, 而且似乎没有一个实用的图像无损压缩的多模态方案? 所以没能想明白大家看重图像无损压缩背后的缘由. 如果是认为有损压缩无法通向智能, 但图像在成像和预处理的时候就是对物理信号的量化(有损压缩), 所以还有必要追求 bit 层面的无损压缩吗? 我粗浅的理解是无损压缩是绝佳的/客观的评价指标, 但不是智能的必要条件.

[苏剑林](https://kexue.fm/)

February 5th, 2024

[@DIYer22\|comment-23673](https://kexue.fm/archives/9969/comment-page-1#comment-23673)

我新开一层讨论。

首先，GPT+DDN的思路我再简单问一下，就是输入是直接bytes或者更底层？然后输出加了一些处理，所谓自动分词，应该就是让模型能够自动并行预测一部分bytes，这个并行的部分就相当于一个token的概念对吧？感觉很不错，我自行领悟领悟。

然后，关于图像有损的问题。第一，有损无损是一个整体的概念，不局限于bit层面或者某个颗粒度，因为从理论上来说，固有的信息量是跟观察的颗粒度无关的；第二，我同意可以有损，但至少是对于人眼来说或者人脑来说无损，类比LLM的话，LLM per token的熵也不大，并且序列长度也有限，所以按道理人接受到的图像熵应该也只是在这个范围内，而目前的生成模型确实无法做到这一点。

举个最简单的例子，目前各种扩散模型可以生成很逼真的图片了，但你叫它按照指定文字生成一篇纸质版的内容（比如图片上有一封信，信中写了xxxx），应该还没有任何一个模型能够完成，这就是当前生成模型的瓶颈。之所以追求无损，是因为目前尚没有能够描述人类视觉无损的损失可用。

此外，从理论上来说，其实任意高斯分布到目标分布变换的生成模型，都有可能做到无损压缩，比如GAN、flow、扩散模型甚至VAE等，VAE虽然通常模糊，但这是它实践上的问题，并不是理论上的，理论上它靠高斯噪声作为“熵源”，是有足够丰富的熵的。但是DDN不一样，DDN是离散的latent的，它的熵源就是步数L和词表大小K，这只能实现有限的熵。

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23674#respond-post-9969)

[DIYer22](https://github.com/DIYer22) 发表于
February 5th, 2024

对于 DDN+GPT, 我画了一组示意图: https://github.com/Discrete-Distribution-Networks/Discrete-Distribution-Networks.github.io/issues/1

我选择的是把 byte 转换为二进制的 bin 来作为网络的输入和输出. (示意图中没有完全展示针对 patch 长度不固定的相关操作), 有疑问也欢迎继续沟通~

关于无损压缩, 理解了博主倾向无损压缩的背后逻辑, 举出的例子也很赞. 也认同博主关于 DDN 的 “熵源” 不够的说法, 所以, 我把高度压缩的表示算作 DDN 的亮点, 并且也认同 DDN 不适合熵很高的图像生成任务

总之, 感谢博主的耐心解答~

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23675#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
February 6th, 2024

谢谢分享。看上去靠谱，但我看了两遍，没看完全懂这个图，要不我们微信交流一下？（已经邮箱私聊你）

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23684#respond-post-9969)

Chason

February 6th, 2024

苏神最近有考虑写篇关于flow matching的分析文章么？

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23677#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
February 6th, 2024

我记得 flow matching 好像跟 [https://kexue.fm/archives/9379](https://kexue.fm/archives/9379) 的结果差不多的，甚至后者的结果可能更丰富一些。

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23683#respond-post-9969)

[zhb](https://github.com/zhb2000)

February 26th, 2024

IGN 的目标函数里有一项是最大化 L2 loss，最大化 L2 loss 的时候会有梯度消失的问题，效果可能不太好。

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23781#respond-post-9969)

Action

February 26th, 2024

感谢博主分享，我感觉我的理解有点问题，求教：

单看公式3的前半部分\\begin{equation}\\min\_{\\theta} D\_{\\theta}(x) - D\_{\\theta}(G\_{\\varphi'}(z))\\end{equation}却又像是最小化了正负样本的得分差，因为我理解公式1写成\\begin{equation}\\max\_{\\theta}
D\_{\\theta}(x) - D\_{\\theta}(G\_{\\varphi}(z))\\end{equation}也是可以的，这样的话这俩公式的就变成了一个是最小化差异，一个是最大化差异。该怎么理解才对呢？

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23782#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
February 27th, 2024

公式(1)明明是\\max\_{\\theta} D\_{\\theta}(G\_{\\varphi}(z)) - D\_{\\theta}(x)，为什么可以反过来？如果反过来的话，后面也全面需要加上负号（比如公式(2)），所以不大清楚你要表达的点是什么。

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23789#respond-post-9969)

Action

February 27th, 2024

[@苏剑林\|comment-23789](https://kexue.fm/archives/9969/comment-page-1#comment-23789)

是的，我确实没考虑到反过来的话公式（2）应该加负号，谢谢指教

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23792#respond-post-9969)

org\_xin

February 27th, 2024

博主，您好，看你的文章很有启发。有点想法想跟您交流一下，这个IGN的G(x)\\approx x ，能否引入扩散模型中的采样思想，将每步的生成作为下一步G的输入，即G(x\_{i-1})\\approx x\_{i}？请问有将扩散模型中的逐步采样思想引入到GAN的文献工作吗？

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23793#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
February 29th, 2024

不懂就问：都用到扩散了，再加GAN是图什么呢？

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23813#respond-post-9969)

[zhb](https://github.com/zhb2000) 发表于
March 1st, 2024

作者在 reddit 上回复了这个问题，他说由于重构损失的影响，对生成的图像重复应用 IGN 可能会导致图像变模糊。 https://www.reddit.com/r/MachineLearning/comments/17otzfw/comment/k8414qg/

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23833#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
March 2nd, 2024

谢谢提供。但这个本质上是自编码器的问题，不是L2 loss的问题。扩散模型也用L2 loss，但它可以很清晰，而我自己试验了一下IGN，如果使用U-Net的架构做生成模型，没看到任何收敛的迹象，但用DCGAN的自编码器架构就很快收敛了，所以这是一个非常矛盾的地方。

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=23844#respond-post-9969)

Faymek

May 15th, 2024

苏神，可以请您分析下低熵任务和高熵任务吗，比如说语义类编码的熵，控制信息的熵，压缩重建任务的熵。有没有编码器可以同时做低熵任务0.01 bpp和高熵任务 0.1bpp

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=24340#respond-post-9969)

[苏剑林](https://kexue.fm/) 发表于
May 15th, 2024

目前不了解低熵任务和高熵任务的概念，还请你指点一下。

[回复评论](https://kexue.fm/archives/9969/comment-page-1?replyTo=24354#respond-post-9969)

[取消回复](https://kexue.fm/archives/9969#respond-post-9969)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；

2\. 可以通过点击评论楼层编号来引用该楼层；

3\. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[生成对抗](https://kexue.fm/archives/9969#%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97)
[单个损失](https://kexue.fm/archives/9969#%E5%8D%95%E4%B8%AA%E6%8D%9F%E5%A4%B1)
[幂等生成](https://kexue.fm/archives/9969#%E5%B9%82%E7%AD%89%E7%94%9F%E6%88%90)
[个人分析](https://kexue.fm/archives/9969#%E4%B8%AA%E4%BA%BA%E5%88%86%E6%9E%90)
[文章小结](https://kexue.fm/archives/9969#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [电的相对论效应——磁“子虚乌有”？](https://kexue.fm/archives/1987)
- [强大的整数数列网站OEIS](https://kexue.fm/archives/2765)
- [【搜出来的文本】⋅（一）从文本生成到搜索采样](https://kexue.fm/archives/8062)
- [通向最优分布之路：概率空间的最小化](https://kexue.fm/archives/10289)
- [浅谈Transformer的初始化、参数化与标准化](https://kexue.fm/archives/8620)
- [一道自然数的数学题](https://kexue.fm/archives/35)
- [柯西命题：盯着它到显然成立为止！](https://kexue.fm/archives/3272)
- [2012年快乐！](https://kexue.fm/archives/1523)
- [注意力和Softmax的两点有趣发现：鲁棒性和信息量](https://kexue.fm/archives/9593)
- [从动力学角度看优化算法（四）：GAN的第三个阶段](https://kexue.fm/archives/6583)

### 最近评论

- [Bin](https://kexue.fm/archives/1990/comment-page-2#comment-29105): 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院的往届师兄！看到这篇2013年的...
- [Rapture D](https://kexue.fm/archives/11530/comment-page-1#comment-29104): 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。
- [mofheka](https://kexue.fm/archives/11390/comment-page-1#comment-29103): 苏神是还在用jax是么？最近在做基于Google Pathway的理念做一个动态版的MPMD框...
- [长琴](https://kexue.fm/archives/11530/comment-page-1#comment-29102): 看懂这篇博客也不是一件容易的事情。
- [AlexLi](https://kexue.fm/archives/9257/comment-page-4#comment-29101): 苏老师，请教一下(7)式中将 \\mu(x\_t) 传给 p\_o 进行推理的操作。 $x\_...
- [tyler\_zxc](https://kexue.fm/archives/7921/comment-page-2#comment-29100): "Performer的思想是将标准的Attention线性化，所以为什么不干脆直接训练一个线性...
- [我](https://kexue.fm/archives/11494/comment-page-1#comment-29099): 似乎并非mHC提出矩阵的思想？之前hyper connection就是了
- [winter](https://kexue.fm/archives/10847/comment-page-1#comment-29098): 苏神您好，假如对于比较均匀的attention weightP，往往呈现long tail分布...
- [苏剑林](https://kexue.fm/archives/8512/comment-page-2#comment-29097): KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个
- [苏剑林](https://kexue.fm/archives/9119/comment-page-14#comment-29096): 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理成本和推理效果，那么有的方法可以...

### 友情链接

- [Cool Papers](https://papers.cool/)
- [数学研发](https://bbs.emath.ac.cn/)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com/)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

[![署名-非商业用途-保持一致](https://kexue.fm/usr/themes/geekg/images/cc.gif)](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/) 本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。



© 2009-2026 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com/). Powered by [Typecho](http://typecho.org/). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/ "粤ICP备09093259号")。