![MobileSideBar](https://kexue.fm/usr/themes/geekg/images/slide-button.png)

## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [让炼丹更科学一些（五）：基于梯度精...](https://kexue.fm/archives/11530)
- [让炼丹更科学一些（四）：新恒等式，...](https://kexue.fm/archives/11494)
- [为什么DeltaNet要加L2 N...](https://kexue.fm/archives/11486)
- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)

## COMMENTS

- [rynn: 现在推荐中不止有用vq做量化生成id进行自回归生成，也有用vq...](https://kexue.fm/archives/11328/comment-page-1#comment-29106)
- [Bin: 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院...](https://kexue.fm/archives/1990/comment-page-2#comment-29105)
- [Rapture D: 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。](https://kexue.fm/archives/11530/comment-page-1#comment-29104)
- [mofheka: 苏神是还在用jax是么？最近在做基于Google Pathwa...](https://kexue.fm/archives/11390/comment-page-1#comment-29103)
- [长琴: 看懂这篇博客也不是一件容易的事情。](https://kexue.fm/archives/11530/comment-page-1#comment-29102)
- [AlexLi: 苏老师，请教一下(7)式中将 $\\mu(x\_t)$ 传给 $p...](https://kexue.fm/archives/9257/comment-page-4#comment-29101)
- [tyler\_zxc: "Performer的思想是将标准的Attention线性化，...](https://kexue.fm/archives/7921/comment-page-2#comment-29100)
- [我: 似乎并非mHC提出矩阵的思想？之前hyper connecti...](https://kexue.fm/archives/11494/comment-page-1#comment-29099)
- [winter: 苏神您好，假如对于比较均匀的attention weightP...](https://kexue.fm/archives/10847/comment-page-1#comment-29098)
- [苏剑林: KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个](https://kexue.fm/archives/8512/comment-page-2#comment-29097)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm/)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [![](https://kexue.fm/usr/themes/geekg/images/rss.png)\\
\\
欢迎订阅](https://kexue.fm/feed)
- [![](https://kexue.fm/usr/themes/geekg/images/mail.png)\\
\\
个性邮箱](https://kexue.fm/archives/119)
- [![](https://kexue.fm/usr/themes/geekg/images/Saturn.png)\\
\\
天象信息](https://kexue.fm/ac.html)
- [![](https://kexue.fm/usr/themes/geekg/images/iss.png)\\
\\
观测ISS](https://kexue.fm/archives/41)
- [![](https://kexue.fm/usr/themes/geekg/images/pi.png)\\
\\
LaTeX](https://kexue.fm/latex.html)
- [![](https://kexue.fm/usr/themes/geekg/images/mlogo.png)\\
\\
关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm/) [数学研究](https://kexue.fm/category/Mathematics) 让炼丹更科学一些（五）：基于梯度精调学习率

9Jan

# [让炼丹更科学一些（五）：基于梯度精调学习率](https://kexue.fm/archives/11530)

By 苏剑林 \|
2026-01-09 \|
1893位读者 \|

前面四篇文章中，我们探讨了SGD从有界域到无界域、从平均损失到终点损失的一系列收敛结论。或许有读者觉得，说来说去都还是SGD，这恐怕是“上古时代”的结果了吧？还真不是！像第四篇 [《让炼丹更科学一些（四）：新恒等式，新学习率》](https://kexue.fm/archives/11494) 所依赖的核心恒等式，出自不远的2023年；第三篇 [《让炼丹更科学一些（三）：SGD的终点损失收敛》](https://kexue.fm/archives/11480) 的结论稍早一点，亦不过出自2020年。

同样是在第四篇中，我们推出了实践常见的学习率策略“线性衰减”，它表明这系列理论推导并非“纸上谈兵”，而是能对实践产生有效的指导。接下来，我们将讨论基于梯度的更精细的学习率策略，它有助于我们了解学习率调度的原理，同时也是各种自适应学习率优化器的基础。

## 最初起点 [\#](https://kexue.fm/archives/11530\#%E6%9C%80%E5%88%9D%E8%B5%B7%E7%82%B9)

如果仔细重温前面的证明过程，我们会发现，这一系列结论的起点，是一个毫不起眼的恒等式

\\begin{equation}\\begin{aligned}

\\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\varphi}\\Vert^2=&\\, \\Vert\\boldsymbol{\\theta}\_t - \\eta\_t \\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)- \\boldsymbol{\\varphi}\\Vert^2 \\\

=&\\, \\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\varphi}\\Vert^2 - 2\\eta\_t (\\boldsymbol{\\theta}\_t- \\boldsymbol{\\varphi})\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) + \\eta\_t^2\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2

\\end{aligned}\\label{eq:begin}\\end{equation}

之所以说它“毫不起眼”，是因为它太平凡了，任何一个及格的高中生都能理解和证明它，然后就是这么一个简单的恒等式，支撑起了随机优化的一系列结论，不得不让人感慨大道至简、返璞归真。

要理解这个恒等式，我们要注意两点“任意性”。第一，$\\boldsymbol{\\varphi}$是任意的，多数情况下我们会将它取理论最优解$\\boldsymbol{\\theta}^\*$，以得到最有价值的结果，但这不改变$\\boldsymbol{\\varphi}$本身的任意性，我们已经知道 [《让炼丹更科学一些（三）：SGD的终点损失收敛》](https://kexue.fm/archives/11480)、 [《让炼丹更科学一些（四）：新恒等式，新学习率》](https://kexue.fm/archives/11494) 两篇文章推导的关键之一就是代入了$\\boldsymbol{\\varphi}=\\boldsymbol{\\theta}\_{T-k}$和$\\boldsymbol{\\varphi}=\\boldsymbol{\\theta}\_k$。

第二，$\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)$是任意的，这个咋看之下可能有点意外，因为之前的文章都默认$\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)$是损失函数的梯度$\\nabla\_{\\boldsymbol{\\theta}\_t}L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)$，但事实上，将它设为梯度的唯一作用是结合$L$的凸性得到

\\begin{equation}L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{x}\_t,\\boldsymbol{\\varphi}) \\leq (\\boldsymbol{\\theta}\_t- \\boldsymbol{\\varphi})\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\end{equation}

从而让恒等式跟损失函数联系起来，如果我们不需要这一点，或者有别的办法做到这一点，那么它就是非必要的。这个任意性很关键，它允许我们构造更复杂的更新规则，也是后面将结果推广到非SGD优化器的关键。

## 经典结果 [\#](https://kexue.fm/archives/11530\#%E7%BB%8F%E5%85%B8%E7%BB%93%E6%9E%9C)

简单调整一下式$\\eqref{eq:begin}$得

\\begin{equation}2\\eta\_t (\\boldsymbol{\\theta}\_t- \\boldsymbol{\\varphi})\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)= \\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\varphi}\\Vert^2 - \\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\varphi}\\Vert^2 + \\eta\_t^2\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2 \\label{eq:begin-2}\\end{equation}

接下来“老派”的思路是，先将两端除以$2\\eta\_t$，然后对$t$从$1\\sim T$求和，这样好处是左端能够通过凸性直接建立起它跟损失的不等关系，坏处是需要引入有界域和学习率非增的假设，才能比较容易对右端进行放缩。到目前为止，我们只有在第一篇 [《让炼丹更科学一些（一）：SGD的平均损失收敛》](https://kexue.fm/archives/9902) 用到了“老派”方法，最终结果是

\\begin{equation}\\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq \\frac{R^2}{2T\\eta\_T} + \\frac{1}{2T}\\sum\_{t=1}^T\\eta\_t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\\label{leq:old-avg}\\end{equation}

这次我们显式保留了$\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert$，而没有假设$\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert\\leq G$进一步化简。由于假设了学习率非增，所以我们有

\\begin{equation}\\frac{R^2}{2T\\eta\_T} + \\frac{1}{2T}\\sum\_{t=1}^T\\eta\_t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\\geq \\frac{R^2}{2T\\eta\_T} + \\frac{\\eta\_T}{2T}\\sum\_{t=1}^T\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2 \\geq \\frac{R}{T}\\sqrt{\\sum\_{t=1}^T\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2}\\label{leq:old-avg-optimal}\\end{equation}

记$V\_t = \\sum\_{k=1}^t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2$，那么取等号的条件是$\\eta\_1 = \\eta\_2 = \\cdots = \\eta\_T = R/\\sqrt{V\_T}$。也就是说，不等式$\\eqref{leq:old-avg}$右端在常数学习率$R/\\sqrt{V\_T}$取到最小值，这是收敛最快的学习率。然而，这个结果是违反因果律的，在$t$时刻我们无法“预知”后面时刻的梯度模长。将它修改成符合因果律的一种方式是

\\begin{equation}\\eta\_t = \\frac{R}{\\sqrt{V\_t}} = \\frac{R}{\\sqrt{\\sum\_{k=1}^t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_k,\\boldsymbol{\\theta}\_k)\\Vert^2}}\\label{eq:adagrad-mini}\\end{equation}

修改后我们要重新证明一下

\\begin{equation}\\sum\_{t=1}^T\\eta\_t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2 = R\\sum\_{t=1}^T\\frac{V\_t - V\_{t-1}}{\\sqrt{V\_t}}\\leq 2R\\sum\_{t=1}^T\\frac{V\_t - V\_{t-1}}{\\sqrt{V\_t} + \\sqrt{V\_{t-1}}} = 2R\\sum\_{t=1}^T (\\sqrt{V\_t} - \\sqrt{V\_{t-1}}) = 2R\\sqrt{V\_T}\\end{equation}

代回到不等式$\\eqref{leq:old-avg}$得

\\begin{equation}\\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq \\frac{3R}{2T}\\sqrt{\\sum\_{t=1}^T\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2}\\end{equation}

结果只比最理想的$\\eqref{leq:old-avg-optimal}$大50%，已经相当不错了，关键是它不违反因果律，是实践可行的学习率策略。它也是 [AdaGrad](https://jmlr.org/papers/v12/duchi11a.html) 优化器的雏形，将式$\\eqref{eq:adagrad-mini}$的形式Element-wise地应用到每个分量上，我们就得到了标准版的AdaGrad，后面我们还会回来讨论它。

## 小心期望 [\#](https://kexue.fm/archives/11530\#%E5%B0%8F%E5%BF%83%E6%9C%9F%E6%9C%9B)

从第二篇 [《让炼丹更科学一些（二）：将结论推广到无界域》](https://kexue.fm/archives/11469) 开始，我们使用了“新派”的处理手段，它直接对式$\\eqref{eq:begin-2}$两端求和：

\\begin{equation}\\begin{aligned}

\\sum\_{t=1}^T 2\\eta\_t (\\boldsymbol{\\theta}\_t- \\boldsymbol{\\varphi})\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) =&\\, \\Vert\\boldsymbol{\\theta}\_1 - \\boldsymbol{\\varphi}\\Vert^2 - \\Vert\\boldsymbol{\\theta}\_{T+1} - \\boldsymbol{\\varphi}\\Vert^2 + \\sum\_{t=1}^T \\eta\_t^2\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2 \\\

\\leq &\\, \\Vert\\boldsymbol{\\theta}\_1 - \\boldsymbol{\\varphi}\\Vert^2 + \\sum\_{t=1}^T \\eta\_t^2\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2

\\end{aligned}\\end{equation}

很明显，“新派”的好处是不假设学习率的单调性，也不需要假设有界域，右端的$\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\varphi}\\Vert^2$就自然地消去了，代价是左端的求和多了个权重$\\eta\_t$。这个权重对于SGD来说问题不大，但对于自适应学习率优化器来说几乎是致命的，所以纵使新派方法有诸多精妙之处，但几乎都无法推广到自适应学习率优化器，到那时我们还是只能用“老派”方法。

先不扯太远了，还是回到SGD的分析，对上式左端利用凸性得

\\begin{equation}\\sum\_{t=1}^T \\eta\_t \[L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{x}\_t,\\boldsymbol{\\varphi})\]\\leq \\frac{\\Vert\\boldsymbol{\\theta}\_1 - \\boldsymbol{\\varphi}\\Vert^2}{2} + \\frac{1}{2}\\sum\_{t=1}^T \\eta\_t^2\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\\end{equation}

在前三篇文章中，紧接着上式的步骤是对两端取数学期望$\\mathbb{E}$，但这里我们要非常小心！因为取期望是对全体$\\boldsymbol{x}\_1,\\boldsymbol{x}\_2,\\cdots,\\boldsymbol{x}\_T$取的，而在前三篇文章中，我们都假设了学习率$\\eta\_t$与数据无关，那么成立$\\mathbb{E}\[\\eta\_t \[L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{x}\_t,\\boldsymbol{\\varphi})\]\] = \\eta\_t\\mathbb{E} \[L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{x}\_t,\\boldsymbol{\\varphi})\] = \\eta\_t\\mathbb{E} \[L(\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{\\varphi})\]$，从而建立起左端与目标损失的联系。然而，本文是要考虑梯度相关的学习率，$\\eta\_t$无法简单地被分离出来。

一个比较简单的补救办法是假设$\\eta\_t$至多跟$\\boldsymbol{x}\_1,\\boldsymbol{x}\_2,\\cdots,\\boldsymbol{x}\_{t-1}$有关，此时$\\boldsymbol{x}\_t$的期望可以单独求，比如$\\mathbb{E}\[\\eta\_t L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\] = \\mathbb{E}\[\\eta\_t \\mathbb{E}\_{\\boldsymbol{x}\_t}\[L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\]\] = \\mathbb{E}\[\\eta\_t L(\\boldsymbol{\\theta}\_t)\]$，但这未免有点束手束脚了，所以我们干脆还是假设$\\eta\_t$数据无关。这样是否无法实现梯度调节学习率了？并不会，而是我们只能实现基于梯度期望$G\_t = \\sqrt{\\mathbb{E}\[\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\]}$的调节，即

\\begin{equation}\\sum\_{t=1}^T \\eta\_t \\mathbb{E}\[L(\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{\\varphi})\]\\leq \\frac{\\mathbb{E}\[\\Vert\\boldsymbol{\\theta}\_1 - \\boldsymbol{\\varphi}\\Vert^2\]}{2} + \\frac{1}{2}\\sum\_{t=1}^T \\eta\_t^2\\underbrace{\\mathbb{E}\[\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\]}\_{G\_t^2}\\label{leq:E-L}\\end{equation}

## 还是旧的 [\#](https://kexue.fm/archives/11530\#%E8%BF%98%E6%98%AF%E6%97%A7%E7%9A%84)

有了不等式$\\eqref{leq:E-L}$，后续推导就比较平凡了，我们将逐一推广第二、三、四篇文章中的结论，看它们对学习率调节有何新启发。第二篇 [《让炼丹更科学一些（二）：将结论推广到无界域》](https://kexue.fm/archives/11469) 有两个结论，第一个结论假设了学习率的非增性，左端的$\\eta\_t$统一用$\\eta\_T$代替，并代入$\\boldsymbol{\\varphi}=\\boldsymbol{\\theta}^\*$得

\\begin{equation}\\frac{1}{T}\\sum\_{t=1}^T \\mathbb{E}\[L(\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{\\theta}^\*)\] \\leq \\frac{R^2}{2T\\eta\_T} + \\frac{1}{2T\\eta\_T}\\sum\_{t=1}^T \\eta\_t^2 G\_t^2\\end{equation}

这里$R = \\Vert\\boldsymbol{\\theta}\_1 - \\boldsymbol{\\theta}^\*\\Vert$。由于学习率非增，容易证明右端也是在常数学习率下取到最小值，此时

\\begin{equation}\\eta\_t = \\frac{R}{ \\sqrt{\\sum\_{k=1}^T G\_k}}\\end{equation}

当然，这个结果也违反了因果律，所以我们只能将它修改成

\\begin{equation}\\eta\_t = \\frac{R}{\\sqrt{\\sum\_{k=1}^t G\_k^2}} = \\frac{R}{ \\sqrt{\\sum\_{k=1}^t \\mathbb{E}\[\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_k,\\boldsymbol{\\theta}\_k)\\Vert^2\]}}\\end{equation}

但分母中的$\\mathbb{E}$也是不现实的，它意味着我们要重复跑很多次取平均。我们直接去掉$\\mathbb{E}$来作为上式的近似，或者说假设$\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_k,\\boldsymbol{\\theta}\_k)\\Vert^2$的方差非常小，所以单次采样就足够准确，后面的结果我们都默认采取这样的操作。总之，拿掉期望$\\mathbb{E}$后，结果跟$\\eqref{eq:adagrad-mini}$本质一样，暂时没有新的启发。

## 梯度反比 [\#](https://kexue.fm/archives/11530\#%E6%A2%AF%E5%BA%A6%E5%8F%8D%E6%AF%94)

[《让炼丹更科学一些（二）：将结论推广到无界域》](https://kexue.fm/archives/11469) 的第二个结论是加权平均形式的不等式

\\begin{equation}\\frac{\\sum\_{t=1}^T \\eta\_t \\mathbb{E}\[L(\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{\\theta}^\*)\]}{\\sum\_{t=1}^T \\eta\_t}\\leq \\frac{R^2}{2\\sum\_{t=1}^T \\eta\_t} + \\frac{\\sum\_{t=1}^T \\eta\_t^2 G\_t^2}{2\\sum\_{t=1}^T \\eta\_t}\\label{leq:avg-weighted}\\end{equation}

利用柯西不等式得

\\begin{equation}\\sum\_{t=1}^T \\eta\_t^2 G\_t^2 = \\frac{\\sum\_{t=1}^T (\\eta\_t G\_t)^2 \\sum\_{t=1}^T G\_t^{-2}}{\\sum\_{t=1}^T G\_t^{-2}} \\geq \\frac{\\left(\\sum\_{t=1}^T \\eta\_t G\_t G\_t^{-1}\\right)^2}{\\sum\_{t=1}^T G\_t^{-2}} = \\frac{\\left(\\sum\_{t=1}^T \\eta\_t\\right)^2}{\\sum\_{t=1}^T G\_t^{-2}}\\end{equation}

取等号的条件是$\\eta\_t G\_t \\propto G\_t^{-1}$，即$\\eta\_t \\propto G\_t^{-2}$。将上式代入到$\\eqref{leq:avg-weighted}$右端，我们有

\\begin{equation}\\frac{R^2}{2\\sum\_{t=1}^T \\eta\_t} + \\frac{\\sum\_{t=1}^T \\eta\_t^2 G\_t^2}{2\\sum\_{t=1}^T \\eta\_t} \\geq \\frac{R^2}{2\\sum\_{t=1}^T \\eta\_t} + \\frac{\\sum\_{t=1}^T \\eta\_t}{2\\sum\_{t=1}^T G\_t^{-2}}\\geq \\frac{R}{\\sqrt{\\sum\_{t=1}^T G\_t^{-2}}}\\end{equation}

最终取等号的总条件是$\\eta\_t = R G\_t^{-2}/\\sqrt{Q\_T}$，其中$Q\_t = \\sum\_{k=1}^t G\_k^{-2}$。这个结果最特别的地方是，它告诉我们学习率要反比于梯度模长平方，这可以用来解释Warmup的必要性，因为训练初期梯度模长会比较大，而之后梯度模长会降下来，并在相当长时间近似不变。将它修改成符合因果律的形式是

\\begin{equation}\\eta\_t = \\frac{R G\_t^{-2}}{\\sqrt{Q\_t}} = \\frac{R G\_t^{-2}}{\\sqrt{\\sum\_{k=1}^t G\_k^{-2}}}\\end{equation}

修改之后还要重新证明一下：

\\begin{gather}\\sum\_{t=1}^T \\eta\_t = \\sum\_{t=1}^T \\frac{R(Q\_t - Q\_{t-1})}{\\sqrt{Q\_t}} \\geq \\sum\_{t=1}^T \\frac{R(Q\_t - Q\_{t-1})}{\\sqrt{Q\_t} + \\sqrt{Q\_{t-1}}} = \\sum\_{t=1}^T R(\\sqrt{Q\_t} - \\sqrt{Q\_{t-1}}) = R \\sqrt{Q\_T} \\\

\\sum\_{t=1}^T \\eta\_t^2 G\_t^2 = \\sum\_{t=1}^T \\frac{R^2(Q\_t - Q\_{t-1})}{Q\_t} = R^2 + \\sum\_{t=2}^T \\frac{R^2(Q\_t - Q\_{t-1})}{Q\_t} \\leq R^2 + R^2\\sum\_{t=2}^T \\ln \\frac{Q\_t}{Q\_{t-1}}= R^2+ R^2\\ln \\frac{Q\_T}{Q\_1}\\end{gather}

将这两个结果代入$\\eqref{leq:avg-weighted}$得

\\begin{equation}\\frac{\\sum\_{t=1}^T \\eta\_t \\mathbb{E}\[L(\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{\\theta}^\*)\]}{\\sum\_{t=1}^T \\eta\_t}\\leq \\frac{R}{\\sqrt{Q\_T}}\\left(1 + \\frac{1}{2}\\ln \\frac{Q\_T}{Q\_1}\\right)\\end{equation}

跟最优解的核心区别是多了个对数增长的因子$\\ln (Q\_T/Q\_1)$，这是静态学习率改动态学习率的常见现象。

## 关注当下 [\#](https://kexue.fm/archives/11530\#%E5%85%B3%E6%B3%A8%E5%BD%93%E4%B8%8B)

从第三篇 [《让炼丹更科学一些（三）：SGD的终点损失收敛》](https://kexue.fm/archives/11480) 开始，我们的结论开始面向终点损失收敛，将该文章的核心结论推广到动态梯度，结果是

\\begin{equation}\\mathbb{E}\[L(\\boldsymbol{\\theta}\_T) - L(\\boldsymbol{\\theta}^\*)\] \\leq \\frac{R^2}{2T\\eta\_T} + \\frac{1}{2\\eta\_T}\\sum\_{t=1}^{T}\\frac{\\eta\_t^2 G\_t^2}{\\max(1,\\,T-t)}\\label{leq:last-1}\\end{equation}

由于这个结果也是要求学习率非增的，所以容易证明右端最小值是$R\\sqrt{V\_T/T}$，在常数学习率取到：

\\begin{equation}\\eta\_t = \\frac{R}{\\sqrt{T V\_T}},\\qquad V\_t = \\sum\_{k=1}^t\\frac{G\_k^2}{\\max(1,\\,t-k)}\\end{equation}

这个学习率同样也很有意思，它具有跟“迷你版”AdaGrad学习率$\\eqref{eq:adagrad-mini}$相似的分母，$V\_t$都是梯度平方求和的形式，不同的是这里$k$时刻的梯度被加权$1/\\max(1,\\,t-k)$，这意味着更关注当前时刻的梯度，这是从平均损失到终点损失带来的新特性，它跟RMSProp、Adam等通过EMA来更新二阶矩的做法已经非常接近了。

直觉上，因果律版本是$\\eta\_t = R/\\sqrt{t V\_t}$，但这个并不够精准，正确版本应该是$\\eta\_t = R/\\sqrt{T V\_t}$，代入式$\\eqref{leq:last-1}$右端得

\\begin{equation}\\begin{aligned}

\\frac{R^2}{2T\\eta\_T} + \\frac{1}{2\\eta\_T}\\sum\_{t=1}^{T}\\frac{\\eta\_t^2 G\_t^2}{\\max(1,\\,T-t)} =&\\, \\frac{R}{2}\\sqrt{\\frac{V\_T}{T}}\\left(1 + \\sum\_{t=1}^{T}\\frac{G\_t^2/V\_t}{\\max(1,\\,T-t)}\\right) \\\

\\leq&\\, \\frac{R}{2}\\sqrt{\\frac{V\_T}{T}}\\left(1 + \\sum\_{t=1}^{T}\\frac{1}{\\max(1,\\,T-t)}\\right) \\\

\\leq&\\, \\frac{R}{2}\\sqrt{\\frac{V\_T}{T}} (3 + \\ln T)\\\

\\end{aligned}\\end{equation}

这里利用了$G\_t^2\\leq V\_t$。相比最优解，同样多出了一个对数增长的因子$\\ln T$。

## 集大成者 [\#](https://kexue.fm/archives/11530\#%E9%9B%86%E5%A4%A7%E6%88%90%E8%80%85)

在 [《让炼丹更科学一些（四）：新恒等式，新学习率》](https://kexue.fm/archives/11494) 中，我们得到了到目前为止最强的终点损失收敛结果，将它推广到动态梯度，便得到式$\\eqref{leq:avg-weighted}$和式$\\eqref{leq:last-1}$的“集大成者”：

\\begin{equation}\\mathbb{E}\[L(\\boldsymbol{\\theta}\_T) - L(\\boldsymbol{\\theta}^\*)\] \\leq \\frac{R^2}{2\\eta\_{1:T}} + \\frac{1}{2}\\sum\_{t=1}^T\\frac{\\eta\_t^2 G\_t^2}{\\eta\_{\\min(t+1, T):T}}\\label{leq:last-2}\\end{equation}

这个结果看起来简单，实际上很复杂，至少我们没法直观看出右端的最小值在何种学习率模式下取到。不过上一篇文章笔者提供了一个思路，那就是连续化近似后用变分法求解，这里我们依然可以尝试一下：设$S\_t = \\eta\_{\\min(t+1, T):T}$，那么对于$t < T - 1$有$\\eta\_t = S\_{t-1} - S\_t\\approx -\\dot{S}\_t$，统一用$-\\dot{S}\_t$近似$\\eta\_t$、用积分近似求和，那么上式右端近似为（代换$S\_t = W\_t^2$）

\\begin{equation}\\frac{R^2}{2S\_0} + \\frac{1}{2}\\int\_0^T \\frac{\\dot{S}\_t^2 G\_t^2}{S\_t}dt = \\frac{R^2}{2W\_0^2} + 2\\int\_0^T \\dot{W}\_t^2 G\_t^2 dt \\label{eq:int-approx}\\end{equation}

根据定义$W\_T=0$，再固定$W\_0$，那么积分部分就是边界固定的变分问题， [欧拉-拉格朗日方程](https://en.wikipedia.org/wiki/Euler%E2%80%93Lagrange_equation) 给出$\\frac{d}{dt}(\\dot{W}\_t G\_t^2)=0$，即$\\dot{W}\_t \\propto G\_t^{-2}$，两端积分并结合$W\_T=0$得$W\_t = W\_0\\int\_t^T G\_s^{-2} ds/\\int\_0^T G\_s^{-2} ds$，代回$\\eqref{eq:int-approx}$得$R^2/2W\_0^2 + 2 W\_0^2 / \\int\_0^T G\_s^{-2} ds$，最小值在$2W\_0^2 = R(\\int\_0^T G\_s^{-2} ds)^{1/2}$取到。最后，根据近似$\\eta\_t\\approx -\\dot{S}\_t=-2W\_t\\dot{W}\_t$，最终可得

\\begin{equation}\\eta\_t \\approx \\frac{R G\_t^{-2} \\int\_t^T G\_s^{-2}ds}{(\\int\_0^T G\_s^{-2}ds)^{3/2}}\\end{equation}

如果恢复离散化，可以猜测最优学习率大致是

\\begin{equation}\\eta\_t = \\frac{R G\_t^{-2} (Q\_T - Q\_t)}{Q\_T^{3/2}} = \\frac{R G\_t^{-2}}{\\sqrt{Q\_T}} (1 - Q\_t/Q\_T)\\label{eq:last-2-opt-lr}\\end{equation}

的形式，其中$Q\_t$就是前面定义过的$\\sum\_{k=1}^t G\_k^{-2}$。事实上，这个“猜测”就是正确答案！然而，将它代回式$\\eqref{leq:last-2}$验证会非常麻烦，因为式$\\eqref{leq:last-2}$的分母是$\\eta\_{t+1:T}$而不是$\\eta\_{t:T}$，所以无法保证$\\eta\_t / \\eta\_{t+1:T}$有界，放缩起来会特别困难，笔者尝试了一周依然未果。这里我们不打算继续尝试下去，而是等到下一篇文章通过一个更精妙的构造去证明它。

现在我们来赏析一下式$\\eqref{eq:last-2-opt-lr}$。注意到$R G\_t^{-2}/\\sqrt{Q\_T}$正好是$\\eqref{leq:avg-weighted}$的最优学习率，特点是正比于$G\_t^{-2}$，前面说了这可以用来解释Warmup；式$\\eqref{eq:last-2-opt-lr}$在此基础上多乘了一项$1 - Q\_t/Q\_T$，这是单调递减的，在适当假设下它是线性衰减，所以这一项可以用来解释Decay。因此，式$\\eqref{eq:last-2-opt-lr}$正好对应了经典的“Warmup-Decay型”学习率策略。

更有趣的是，上一节$\\eqref{leq:last-1}$的最优学习率告诉我们要更关注当前时刻的梯度，结果式$\\eqref{eq:last-2-opt-lr}$更极端，它只依赖当前时刻和未来时刻的梯度，完全不依赖历史梯度。这无疑是违反因果律的，怎么将它修改成符合因果律呢？$\\sqrt{Q\_T}$可以考虑换成$\\sqrt{Q\_t}$，至于$Q\_t/Q\_T$中的$Q\_T$可以写成$(Q\_T/T)\\times T$，然后考虑将$Q\_T/T$换成$Q\_t/t$，于是得到

\\begin{equation}\\eta\_t = \\frac{R G\_t^{-2}}{\\sqrt{Q\_t}} (1 - t/T)\\end{equation}

看上去很合理，但要想代回式$\\eqref{leq:last-2}$证明它真的有效，也不是一件容易的事情。

## 文章小结 [\#](https://kexue.fm/archives/11530\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

这篇文章开始，我们考虑基于梯度的学习率调度，它有助于我们了解诸如Warmup、Decay等学习率策略的原理，也能为各种自适应学习率优化器提供有益的参考。

_**转载到请包括本文地址：** [https://kexue.fm/archives/11530](https://kexue.fm/archives/11530 "让炼丹更科学一些（五）：基于梯度精调学习率")_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/11530#share)/ [打赏](https://kexue.fm/archives/11530#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。

你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jan. 09, 2026). 《让炼丹更科学一些（五）：基于梯度精调学习率 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/11530](https://kexue.fm/archives/11530)

@online{kexuefm-11530,

         title={让炼丹更科学一些（五）：基于梯度精调学习率},

         author={苏剑林},

         year={2026},

         month={Jan},

         url={\\url{https://kexue.fm/archives/11530}},

}


分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/), [学习率](https://kexue.fm/tag/%E5%AD%A6%E4%B9%A0%E7%8E%87/), [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/), [sgd](https://kexue.fm/tag/sgd/), [炼丹](https://kexue.fm/tag/%E7%82%BC%E4%B8%B9/)[2 评论](https://kexue.fm/archives/11530#comments)

< [让炼丹更科学一些（四）：新恒等式，新学习率](https://kexue.fm/archives/11494 "让炼丹更科学一些（四）：新恒等式，新学习率") \| >

### 你也许还对下面的内容感兴趣

- [让炼丹更科学一些（四）：新恒等式，新学习率](https://kexue.fm/archives/11494 "让炼丹更科学一些（四）：新恒等式，新学习率")
- [让炼丹更科学一些（三）：SGD的终点损失收敛](https://kexue.fm/archives/11480 "让炼丹更科学一些（三）：SGD的终点损失收敛")
- [让炼丹更科学一些（二）：将结论推广到无界域](https://kexue.fm/archives/11469 "让炼丹更科学一些（二）：将结论推广到无界域")
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459 "滑动平均视角下的权重衰减和学习率")
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416 "Muon优化器指南：快速上手与关键细节")
- [AdamW的Weight RMS的渐近估计（下）](https://kexue.fm/archives/11404 "AdamW的Weight RMS的渐近估计（下）")
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388 "流形上的最速下降：5. 对偶梯度下降")
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340 "MuP之上：1. 好模型的三个特征")
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328 "DiVeQ：一种非常简洁的VQ训练方案")
- [AdamW的Weight RMS的渐近估计（上）](https://kexue.fm/archives/11307 "AdamW的Weight RMS的渐近估计（上）")

[发表你的看法](https://kexue.fm/archives/11530#comment_form)

[长琴](https://yam.gift/)

January 9th, 2026

看懂这篇博客也不是一件容易的事情。

[回复评论](https://kexue.fm/archives/11530/comment-page-1?replyTo=29102#respond-post-11530)

Rapture D

January 10th, 2026

我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。

[回复评论](https://kexue.fm/archives/11530/comment-page-1?replyTo=29104#respond-post-11530)

[取消回复](https://kexue.fm/archives/11530#respond-post-11530)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；

2\. 可以通过点击评论楼层编号来引用该楼层；

3\. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[最初起点](https://kexue.fm/archives/11530#%E6%9C%80%E5%88%9D%E8%B5%B7%E7%82%B9)
[经典结果](https://kexue.fm/archives/11530#%E7%BB%8F%E5%85%B8%E7%BB%93%E6%9E%9C)
[小心期望](https://kexue.fm/archives/11530#%E5%B0%8F%E5%BF%83%E6%9C%9F%E6%9C%9B)
[还是旧的](https://kexue.fm/archives/11530#%E8%BF%98%E6%98%AF%E6%97%A7%E7%9A%84)
[梯度反比](https://kexue.fm/archives/11530#%E6%A2%AF%E5%BA%A6%E5%8F%8D%E6%AF%94)
[关注当下](https://kexue.fm/archives/11530#%E5%85%B3%E6%B3%A8%E5%BD%93%E4%B8%8B)
[集大成者](https://kexue.fm/archives/11530#%E9%9B%86%E5%A4%A7%E6%88%90%E8%80%85)
[文章小结](https://kexue.fm/archives/11530#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [从三角不等式到Margin Softmax](https://kexue.fm/archives/8656)
- [外出集训，网站暂停更新...](https://kexue.fm/archives/694)
- [指数函数及其展开式孰大孰小？](https://kexue.fm/archives/1559)
- [祝大家端午节快乐！](https://kexue.fm/archives/681)
- [用热传导方程来指导自监督学习](https://kexue.fm/archives/9359)
- [月全食刚过...](https://kexue.fm/archives/1521)
- [日食当天的天气出来了](https://kexue.fm/archives/17)
- [从对称角度看代数方程](https://kexue.fm/archives/1336)
- [“末日”的快乐！](https://kexue.fm/archives/1840)
- [行星的逆行,顺行和留(计算公式)](https://kexue.fm/archives/608)

### 最近评论

- [rynn](https://kexue.fm/archives/11328/comment-page-1#comment-29106): 现在推荐中不止有用vq做量化生成id进行自回归生成，也有用vq、rq量化物品的多模态嵌入，当做...
- [Bin](https://kexue.fm/archives/1990/comment-page-2#comment-29105): 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院的往届师兄！看到这篇2013年的...
- [Rapture D](https://kexue.fm/archives/11530/comment-page-1#comment-29104): 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。
- [mofheka](https://kexue.fm/archives/11390/comment-page-1#comment-29103): 苏神是还在用jax是么？最近在做基于Google Pathway的理念做一个动态版的MPMD框...
- [长琴](https://kexue.fm/archives/11530/comment-page-1#comment-29102): 看懂这篇博客也不是一件容易的事情。
- [AlexLi](https://kexue.fm/archives/9257/comment-page-4#comment-29101): 苏老师，请教一下(7)式中将 $\\mu(x\_t)$ 传给 $p\_o$ 进行推理的操作。 $x\_...
- [tyler\_zxc](https://kexue.fm/archives/7921/comment-page-2#comment-29100): "Performer的思想是将标准的Attention线性化，所以为什么不干脆直接训练一个线性...
- [我](https://kexue.fm/archives/11494/comment-page-1#comment-29099): 似乎并非mHC提出矩阵的思想？之前hyper connection就是了
- [winter](https://kexue.fm/archives/10847/comment-page-1#comment-29098): 苏神您好，假如对于比较均匀的attention weightP，往往呈现long tail分布...
- [苏剑林](https://kexue.fm/archives/8512/comment-page-2#comment-29097): KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个

### 友情链接

- [Cool Papers](https://papers.cool/)
- [数学研发](https://bbs.emath.ac.cn/)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com/)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

[![署名-非商业用途-保持一致](https://kexue.fm/usr/themes/geekg/images/cc.gif)](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/) 本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。



© 2009-2026 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com/). Powered by [Typecho](http://typecho.org/). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/ "粤ICP备09093259号")。