“闭门造车”之多模态思路浅谈（三）：位置编码 - 科学空间|Scientific Spaces
![MobileSideBar](https://kexue.fm/usr/themes/geekg/images/slide-button.png "MobileSideBar")
## SEARCH
## MENU
* [打赏](https://kexue.fm/reward.html)
* [公式](https://kexue.fm/latex.html)
* [天象](https://kexue.fm/ac.html)
* [链接](https://kexue.fm/links.html)
* [时光](https://kexue.fm/me.html)
* [博览](https://kexue.fm/science.html)
* [归档](https://kexue.fm/content.html)
## CATEGORIES
* [千奇百怪](https://kexue.fm/category/Everything)
* [天文探索](https://kexue.fm/category/Astronomy)
* [数学研究](https://kexue.fm/category/Mathematics)
* [物理化学](https://kexue.fm/category/Phy-chem)
* [信息时代](https://kexue.fm/category/Big-Data)
* [生物自然](https://kexue.fm/category/Biology)
* [图片摄影](https://kexue.fm/category/Photograph)
* [问题百科](https://kexue.fm/category/Questions)
* [生活/情感](https://kexue.fm/category/Life-Feeling)
* [资源共享](https://kexue.fm/category/Resources)
## NEWPOSTS
* [让炼丹更科学一些（四）：新恒等式，...](https://kexue.fm/archives/11494)
* [为什么DeltaNet要加L2 N...](https://kexue.fm/archives/11486)
* [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
* [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
* [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
* [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
* [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
* [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
* [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
* [流形上的最速下降：5. 对偶梯度下降](https://kexue.fm/archives/11388)
## COMMENTS
* [且寻: same。本来想转成二重积分的，但想半天整不出来，搞出来这个半...](https://kexue.fm/archives/11480/comment-page-1#comment-29057)
* [苏剑林: 是梯度均值为零的假设。这个问题不是在“数值模拟”一节讨论过了吗...](https://kexue.fm/archives/11267/comment-page-1#comment-29056)
* [苏剑林: X与单位阵的平均平方误差(mse)，作为它跟单位阵的差距，有什...](https://kexue.fm/archives/7180/comment-page-2#comment-29055)
* [苏剑林: 从公式$(12)$到公式$(15)$，都在推导和解释你说的这个...](https://kexue.fm/archives/9209/comment-page-8#comment-29054)
* [苏剑林: 相对位置编码，似乎没有太多选择了，要不RoPE这种，算是乘性了...](https://kexue.fm/archives/8130/comment-page-7#comment-29053)
* [苏剑林: 学习了一下，感觉这个更多是证明，而不是理解？而且这个证明也没有...](https://kexue.fm/archives/11480/comment-page-1#comment-29052)
* [苏剑林: 那还不如直接softmax attention？](https://kexue.fm/archives/11320/comment-page-1#comment-29051)
* [苏剑林: 可以啊，L1 Norm一定大于等于L2 Norm，所以L1 N...](https://kexue.fm/archives/11486/comment-page-1#comment-29050)
* [苏剑林: 你本来要用数值模拟算两重积分，我现在帮你把一重积分算出来了，你...](https://kexue.fm/archives/9119/comment-page-14#comment-29049)
* [苏剑林: learned, thanks](https://kexue.fm/archives/11158/comment-page-1#comment-29048)
## USERLOGIN
* [登录](https://kexue.fm/admin/login.php)
[科学空间|Scientific Spaces](https://kexue.fm)
* [登录](https://kexue.fm/admin/login.php)
* [打赏](https://kexue.fm/reward.html)
* [公式](https://kexue.fm/latex.html)
* [天象](https://kexue.fm/ac.html)
* [链接](https://kexue.fm/links.html)
* [时光](https://kexue.fm/me.html)
* [博览](https://kexue.fm/science.html)
* [归档](https://kexue.fm/content.html)
渴望成为一个小飞侠* [![](https://kexue.fm/usr/themes/geekg/images/rss.png)
欢迎订阅](https://kexue.fm/feed)
* [![](https://kexue.fm/usr/themes/geekg/images/mail.png)
个性邮箱](https://kexue.fm/archives/119)
* [![](https://kexue.fm/usr/themes/geekg/images/Saturn.png)
天象信息](https://kexue.fm/ac.html)
* [![](https://kexue.fm/usr/themes/geekg/images/iss.png)
观测ISS](https://kexue.fm/archives/41)
* [![](https://kexue.fm/usr/themes/geekg/images/pi.png)
LaTeX](https://kexue.fm/latex.html)
* [![](https://kexue.fm/usr/themes/geekg/images/mlogo.png)
关于博主](https://kexue.fm/me.html)
欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～* [**千奇百怪**Everything](https://kexue.fm/category/Everything)
* [**天文探索**Astronomy](https://kexue.fm/category/Astronomy)
* [**数学研究**Mathematics](https://kexue.fm/category/Mathematics)
* [**物理化学**Phy-chem](https://kexue.fm/category/Phy-chem)
* [**信息时代**Big-Data](https://kexue.fm/category/Big-Data)
* [**生物自然**Biology](https://kexue.fm/category/Biology)
* [**图片摄影**Photograph](https://kexue.fm/category/Photograph)
* [**问题百科**Questions](https://kexue.fm/category/Questions)
* [**生活/情感**Life-Feeling](https://kexue.fm/category/Life-Feeling)
* [**资源共享**Resources](https://kexue.fm/category/Resources)
* [**千奇百怪**](https://kexue.fm/category/Everything)
* [**天文探索**](https://kexue.fm/category/Astronomy)
* [**数学研究**](https://kexue.fm/category/Mathematics)
* [**物理化学**](https://kexue.fm/category/Phy-chem)
* [**信息时代**](https://kexue.fm/category/Big-Data)
* [**生物自然**](https://kexue.fm/category/Biology)
* [**图片摄影**](https://kexue.fm/category/Photograph)
* [**问题百科**](https://kexue.fm/category/Questions)
* [**生活/情感**](https://kexue.fm/category/Life-Feeling)
* [**资源共享**](https://kexue.fm/category/Resources)
[首页](https://kexue.fm)[信息时代](https://kexue.fm/category/Big-Data)“闭门造车”之多模态思路浅谈（三）：位置编码
6Sep
# [“闭门造车”之多模态思路浅谈（三）：位置编码](https://kexue.fm/archives/10352)
By苏剑林|2024-09-06|126249位读者|:
在前面的文章中，我们曾表达过这样的观点：多模态LLM相比纯文本LLM的主要差异在于，前者甚至还没有形成一个公认为标准的方法论。这里的方法论，不仅包括之前讨论的生成和训练策略，还包括一些基础架构的设计，比如本文要谈的“多模态位置编码”。
对于这个主题，我们之前在[《Transformer升级之路：17、多模态位置编码的简单思考》](https://kexue.fm/archives/10040)就已经讨论过一遍，并且提出了一个方案（RoPE-Tie）。然而，当时笔者对这个问题的思考仅处于起步阶段，存在细节考虑不周全、认识不够到位等问题，所以站在现在的角度回看，当时所提的方案与完美答案还有明显的距离。
因此，本文我们将自上而下地再次梳理这个问题，并且给出一个自认为更加理想的结果。## 多模位置[#](#多模位置)
多模态模型居然连位置编码都没有形成共识，这一点可能会让很多读者意外，但事实上确实如此。对于文本LLM，目前主流的位置编码是[RoPE](https://kexue.fm/archives/8265)（RoPE就不展开介绍了，假设读者已经熟知），更准确来说是RoPE-1D，因为原始设计只适用于1D序列。后来我们推导了[RoPE-2D](https://kexue.fm/archives/8397)，这可以用于图像等2D序列，按照RoPE-2D的思路我们可以平行地推广到RoPE-3D，用于视频等3D序列。
然而，以上说的只是单一模态输入，当多种模态混合输入时，困难就出现了：文本是1D序列，所以它的位置只是一个标量$n$；图像是2D的（“宽”和“高”），所以表达它的位置需要一个二维向量$(x,y)$；视频则在图像的基础上新增了一个时间维度（或者说“帧”），所以它的位置是一个三维向量$(x,y,z)$。当我们希望用同一个模型去处理三种模态的数据时，就要想办法糅合这三种不同形式的位置信息。
大家都知道，RoPE在实现上是绝对位置编码，但结合基于内积的Attention来用时，内积之后位置会自动作差，从而实现了相对位置编码的效果。可同一大小的向量可以作差，不同大小的向量怎么作差呢？这就是多模态位置编码的困难所在。
不少工作选择“逃避”这个困难，直接Flatten所有模态然后使用RoPE-1D，这不失为一种解决办法，但终究显得不够优雅。此外，强行Flatten也可能会降低模型性能的天花板，因为[《VisionLLaMA: A Unified LLaMA Backbone for Vision Tasks》](https://papers.cool/arxiv/2403.00522)等工作已经表明，RoPE-2D的引入有助于提升模型效果尤其是变分辨率输入的效果。
## 向后兼容[#](#向后兼容)
所以，我们希望设计一种多模态位置编码，它既可以多模态混合使用，在单模态下又能退化为对应的RoPE-1D/2D/3D，以充分解锁每个模态的能力。
刚才我们说，多模态位置编码的主要困难是不同大小的位置向量无法作差，既要保留完整的位置信息又要允许作差，那么我们就只能统一升维到最高维度。下面我们以图文混合模态为例，由于图像是2D的，所以我们将文本的位置编码也提升到二维，然后统一用RoPE-2D。怎么升维都可以吗？并不是，我们希望它具有向后的**兼容性**，即当输入是纯文本时，它跟RoPE-1D完全等价。
为此，我们对比一下RoPE-1D与RoPE-2D：
$$\\scriptsize{\\begin{array}{c}\\begin{array}{c}\\text{RoPE-1D}\\\\ (\\boldsymbol{\\mathcal{R}}\_n)\\end{array}= \\begin{pmatrix}
\\cos \\bbox[yellow]{n}\\theta\_0 & -\sin& -\sin \\bbox[yellow]{n}\\theta\_0 & 0 & 0& 0 & 0 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
\\sin \\bbox[yellow]{n}\\theta\_0 & \cos & \cos \\bbox[yellow]{n}\\theta\_0 & 0 & 0& 0 & 0 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
0 & 0 & \& 0 & \cos \\bbox[yellow]{n}\\theta\_1 & -\sin& -\sin \\bbox[yellow]{n}\\theta\_1 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
0 & 0 & \& 0 & \sin \\bbox[yellow]{n}\\theta\_1 & \cos & \cos \\bbox[yellow]{n}\\theta\_1 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
\\vdots & \vdot& \vdots & \vdot& \vdots & \vdot& \vdots & \ddot& \ddots & \vdot& \vdots & \vdot& \vdots & \vdot& \vdots & \vdot& \vdots \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & \cos & \cos \\bbox[yellow]{n}\\theta\_{d/2-2} & -\sin& -\sin \\bbox[yellow]{n}\\theta\_{d/2-2} & 0 & 0& 0 & 0 \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & \sin & \sin \\bbox[yellow]{n}\\theta\_{d/2-2} & \cos & \cos \\bbox[yellow]{n}\\theta\_{d/2-2} & 0 & 0& 0 & 0 \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & 0 & 0& 0 & 0 & \cos & \cos \\bbox[yellow]{n}\\theta\_{d/2-1} & -\sin& -\sin \\bbox[yellow]{n}\\theta\_{d/2-1} \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & 0 & 0& 0 & 0 & \sin & \sin \\bbox[yellow]{n}\\theta\_{d/2-1} & \cos & \cos \\bbox[yellow]{n}\\theta\_{d/2-1} \\\\
\\end{pmatrix} \\\\[16pt]
\\begin{array}{c}\\text{RoPE-2D}\\\\ (\\boldsymbol{\\mathcal{R}}\_{x,y})\\end{array}= \\begin{pmatrix}
\\cos \\bbox[yellow]{x}\\theta\_0 & -\sin& -\sin \\bbox[yellow]{x}\\theta\_0 & 0 & 0& 0 & 0 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
\\sin \\bbox[yellow]{x}\\theta\_0 & \cos & \cos \\bbox[yellow]{x}\\theta\_0 & 0 & 0& 0 & 0 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
0 & 0 & \& 0 & \cos \\bbox[yellow]{y}\\theta\_1 & -\sin& -\sin \\bbox[yellow]{y}\\theta\_1 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
0 & 0 & \& 0 & \sin \\bbox[yellow]{y}\\theta\_1 & \cos & \cos \\bbox[yellow]{y}\\theta\_1 & \cdot& \cdots & 0 & 0& 0 & 0 & 0 & 0& 0 & 0 \\\\
\\vdots & \vdot& \vdots & \vdot& \vdots & \vdot& \vdots & \ddot& \ddots & \vdot& \vdots & \vdot& \vdots & \vdot& \vdots & \vdot& \vdots \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & \cos & \cos \\bbox[yellow]{x}\\theta\_{d/2-2} & -\sin& -\sin \\bbox[yellow]{x}\\theta\_{d/2-2} & 0 & 0& 0 & 0 \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & \sin & \sin \\bbox[yellow]{x}\\theta\_{d/2-2} & \cos & \cos \\bbox[yellow]{x}\\theta\_{d/2-2} & 0 & 0& 0 & 0 \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & 0 & 0& 0 & 0 & \cos & \cos \\bbox[yellow]{y}\\theta\_{d/2-1} & -\sin& -\sin \\bbox[yellow]{y}\\theta\_{d/2-1} \\\\
0 & 0 & 0& 0 & 0 & 0 & \& 0 & \cdots & 0 & 0& 0 & 0 & \sin & \sin \\bbox[yellow]{y}\\theta\_{d/2-1} & \cos & \cos \\bbox[yellow]{y}\\theta\_{d/2-1} \\\\
\\end{pmatrix}\\end{array}}$$
发现什么共同点了吗？如果单看这个形式，可以发现其实有$\\boldsymbol{\\mathcal{R}}\_n=\\boldsymbol{\\mathcal{R}}\_{n,n}$，即位置为$n$的RoPE-1D跟位置为$(n,n)$的RoPE-2D其实是等价的，所以要想在图文混合中统一用RoPE-2D，并且对于纯文本能退化为RoPE-1D，那么就要将文本部分的位置坐标取为$(n,n)$的形式。
当然，实际上它们还是有少许不同的，我们知道对于RoPE-1D有$\\theta\_i = b^{-2i/d}$，也就是$\\theta\_{2j}$跟$\\theta\_{2j+1}$是不同的，但对于RoPE-2D来说，为了确保$x,y$的对称性，通常的选择是确保$\\theta\_{2j}=\\theta\_{2j+1}$，这就产生了矛盾之处。对此，我们有两种选择：一是放弃RoPE-2D中$x,y$的对称性，依旧取$\\theta\_i = b^{-2i/d}$；二是取$\\theta\_{2j}=\\theta\_{2j+1}=b^{-4j/d}$，此时纯文本部分的位置编码就跟已有RoPE-1D略有不同。对于$\\theta\_i = b^{-2i/d}$来说，$\\theta\_i$与$\\theta\_{i+1}$差别不大，所以两种方案其实都差不多，选哪一种取决于个人的审美，笔者倾向于选择第一种。
## 等价对称[#](#等价对称)
通过上述分析，我们确定了图文混合模态统一用RoPE-2D的方案，并且由向后兼容性确定了位置$n$的文本Token的二维位置应该取$(n,n)$，从而完成了文本部分的位置编码设计。接下来，我们需要构思的是图像部分的位置编码。
如果输入只有一张$w\\times h$个Patch的图像，那么它的位置坐标自然就是各个Patch本身的坐标，即
\\begin{equation}\\left[\\begin{matrix}
(1,1) & (1,2)& (1,2) & \cdot& \cdots & (1, w& (1, w) \\\\
(2,1) & (2,2)& (2,2) & \cdot& \cdots & (2, w& (2, w) \\\\
\\vdots & \vdot& \vdots & \ddot& \ddots & \vdot& \vdots \\\\
(h,1) & (h,2)& (h,2) & \cdot& \cdots & (h, w& (h, w) \\\\
\\end{matrix}\\right]\\label{eq:rope2d}\\end{equation}
我们这展示的是绝对位置，但实际的效果是相对位置，相对位置的特点是跟位置偏置无关，所以我们可以给每个坐标都加上$(\\beta\_1,\\beta\_2)$而不改变效果；其次，我们可以给每个坐标都乘以$(\\gamma\_1,\\gamma\_2)$，这样允许我们按需调整相邻位置的间隔。将这两点结合起来，我们可以得到图像的一般化二维位置为
\\begin{equation}\\left[\\begin{matrix}
(\\beta\_1 + \\gamma\_1,\\beta\_2 + \\gamma\_2) & (\bet& (\beta\_1 + \\gamma\_1,\\beta\_2 + 2\\gamma\_2) & \cdot& \cdots & (\bet& (\beta\_1 + \\gamma\_1,\\beta\_2 + w\\gamma\_2) \\\\[8pt]
(\\beta\_1 + 2\\gamma\_1,\\beta\_2 + \\gamma\_2) & (\bet& (\beta\_1 + 2\\gamma\_1,\\beta\_2 + 2\\gamma\_2) & \cdot& \cdots & (\bet& (\beta\_1 + 2\\gamma\_1,\\beta\_2 + w\\gamma\_2) \\\\[8pt]
\\vdots & \vdot& \vdots & \ddot& \ddots & \vdot& \vdots \\\\[8pt]
(\\beta\_1 + h\\gamma\_1,\\beta\_2 + \\gamma\_2) & (\bet& (\beta\_1 + h\\gamma\_1,\\beta\_2 + 2\\gamma\_2) & \cdot& \cdots & (\bet& (\beta\_1 + h\\gamma\_1,\\beta\_2 + w\\gamma\_2)
\\end{matrix}\\right]\\end{equation}
现在我们考虑左右两段文本夹着中间一张图像时，$\\beta\_1,\\beta\_2,\\gamma\_1,\\gamma\_2$该怎么选取。
首先，我们假设文本的Token和Patch具有一定的**等价性**：经过合理的[Patchify](https://kexue.fm/archives/10197)后每个Patch的地位跟Token等价（An Image is Worth xxx Tokens），这意味着对于两段文本来说，它们相当于夹着一个$wh$个Token的句子，所以如果左段文本最后一个Token的位置是$(L,L)$，那么右段文本第一个Token的位置就是$(L+wh+1, L + wh + 1)$。
接着，我们还需要引入**对称性**——具体来说，图像的第一个Patch的位置是$(\\beta\_1 + \\gamma\_1,\\beta\_2 + \\gamma\_2)$，最后一个Patch的位置是$(\\beta\_1 + h\\gamma\_1,\\beta\_2 + w\\gamma\_2)$，我们认为【图像第一个Patch】与【左段文本最后一个Token】的位置差，等于【右段文本第一个Token】与【图像最后一个Patch】的位置差，即
\\begin{equation}\\begin{pmatrix}\\beta\_1 + \\gamma\_1 \\\\ \\beta\_2 + \\gamma\_2\\end{pmatrix} - \\begin{pmatrix}L \\\\ L\\end{pmatrix} = \\begin{pmatrix}L+wh+1 \\\\ L+wh+1\\end{pmatrix} - \\begin{pmatrix}\\beta\_1 + h\\gamma\_1 \\\\ \\beta\_2 + w\\gamma\_2\\end{pmatrix}\\label{eq:beta-gamma}\\end{equation}
这里边有四个未知数$\\beta\_1,\\beta\_2,\\gamma\_1,\\gamma\_2$，但只有两个等式，所以有无穷多组解。我们可以简单地取$\\gamma\_1=\\gamma\_2=1$，继而解得
\\begin{equation}\\beta\_1 = L + \\frac{1}{2}(wh - h),\\quad \\beta\_2 = L + \\frac{1}{2}(wh - w)\\end{equation}
这个方案我们暂时可以称之为RoPE-Tie-v2或者RoPE-TV（RoPEforText andVision）吧。
## 优劣分析[#](#优劣分析)
根据这个结果，当句子后面接一张$w\\times h$的图像时，只需要按照上述计算计算出$(\\beta\_1,\\beta\_2)$，然后加到常规的二维RoPE $\\eqref{eq:rope2d}$中去，就得到了图像部分的位置坐标了，如下图所示
[![新版RoPE-TV（RoPE-Tie-v2）示意图](https://kexue.fm/usr/uploads/2024/09/2781465051.png)](https://kexue.fm/usr/uploads/2024/09/2781465051.png)
新版RoPE-TV（RoPE-Tie-v2）示意图
作为对比，我们在[《Transformer升级之路：17、多模态位置编码的简单思考》](https://kexue.fm/archives/10040)提出的旧版RoPE-Tie，其位置坐标如下图所示：
[![旧版RoPE-Tie示意图](https://kexue.fm/usr/uploads/2024/09/2581235844.png)](https://kexue.fm/usr/uploads/2024/09/2581235844.png)
旧版RoPE-Tie示意图
事实上，RoPE-Tie的出发点同样包括**兼容性**和**对称性**，但没有严格遵循**等价性**，并且RoPE-Tie默认了$\\beta\_1=\\beta\_2=L$，以及没有限定$w\\times h$个Patch等价于$wh$个Token，最终推出了一组整数解（如果不要求整数解也可以满足**等价性**）：
\\begin{equation}\\gamma\_1 = w+1,\\quad\\gamma\_2=h+1\\end{equation}
从如今的视角来看，RoPE-Tie的默认设置其实并不是很理想，所以本文重新选择了$\\gamma\_1=\\gamma\_2=1$，并确保**等价性**，然后反推出$\\beta\_1,\\beta\_2$。
那新方案有什么好处呢？首先，RoPE-Tie中图像内的相对位置跟它的大小有关，而新方案中Patch的间隔是固定的$(0,1)$和$(1,0)$，这可以让Patch的尺度更为一致。举个例子，一张128\*128的图像以及该图的上半部份（即128\*64的子图），由于两者高度不一样，所以RoPE-Tie后它们横向的位置间隔并不一样，这意味着同样位置、同样含义的两个Patch在加了RoPE-Tie后的距离（尺度）变得不一致了，这看起来并不合理，而新方案没有这个问题。
其次，RoPE-Tie中图像与左右文本的间隔，跟图像内部Patch的间隔一样都是$(\\gamma\_1,\\gamma\_2)$，而新方案中文本到图像、图像到文本之间会出现一个比较大的间隔$\\frac{1}{2}(wh - h, wh-w)$，然后文本内部、图像内部则都是固定的均匀间隔。直觉上，这种不同模态之间比较大的位置跳跃，可以更好地实现“模态隔离”，让单个模型既能更好地处理单模态内容，又保留了多模态之间的交互，这跟我们通常在左右加[IMG]和[/IMG]两个Special Token来标记出图像具有异曲同工之处。
## 三维困境[#](#三维困境)
在RoPE-Tie的文章中，并没有讨论到“文本-视频”混合模态的位置编码，这一节我们来补充讨论完整。
直观来看，对于视频输入我们可以有两种处理方式。第一种方式就是简单地将视频当成多张图片处理（必要时加个[VIDEO]、[/VIDEO]的标记），这样我们就不需要针对视频提出新的位置编码了，沿用“文本-图像”的混合位置编码结果就行，但这样丧失了同一视频不同帧之间的对齐关系，可能不是太完美，例如“第1帧的第1个Patch”跟“第2帧的第1个Patch”和“第1帧的第2个Patch”，应该有差不多的邻近关系，但展平当多张图片处理就体现不出这一点。
第二种方式则是将“文本-图像”的结果平行地推广到“文本-视频”中。对于一个$w\\times h\\times t$的视频（画面为$w\\times h$，一共$t$帧），它的位置坐标是三维的$(x,y,z)$，根据相同的**兼容性**、**等价性**和**对称性**，我们可以将方程$\\eqref{eq:beta-gamma}$推广成
\\begin{equation}\\begin{pmatrix}\\beta\_1 + \\gamma\_1 \\\\ \\beta\_2 + \\gamma\_2 \\\\ \\beta\_3 + \\gamma\_3\\end{pmatrix} - \\begin{pmatrix}L \\\\ L \\\\ L\\end{pmatrix} = \\begin{pmatrix}L+wht+1 \\\\ L+wht+1 \\\\ L+wht+1\\end{pmatrix} - \\begin{pmatrix}\\beta\_1 + h\\gamma\_1 \\\\ \\beta\_2 + w\\gamma\_2 \\\\ \\beta\_3 + t\\gamma\_3\\end{pmatrix}\\end{equation}
如果还是设$\\gamma\_1=\\gamma\_2=\\gamma\_3=1$，我们得到
\\begin{equation}\\beta\_1 = L + \\frac{1}{2}(wht - h),\\quad \\beta\_2 = L + \\frac{1}{2}(wht - w),\\quad \\beta\_3 = L + \\frac{1}{2}(wht - t)\\end{equation}
这样做完整了保留了视频位置的三维性，看起来会更优雅一些，但笔者认为它仍有一些美中不足之处。这个美中不足源于笔者对视频的时间维度的不同理解：视频的三维，实际上是“2个空间维度+1个时间维度”，跟真实世界的三维立体的“3个空间维度”不一样。按照笔者的观点，视频的时间维度跟两个空间维度是不平权的，时间维度更像是文本从左往右的书写方向，所以笔者想象中的完美多模态LLM，应该能像文本LLM续写文本一样，理论上能够以自回归的方式无限地续作视频，直到出现[EOS]标记。
刚才我们提了两种“文本-视频”混合编码方案，第一种直接当作多张图片处理，这种方案是可以无限自回归生成视频的，但第二种看上去更完美的方案反而不行，因为它的$\\beta\_1,\\beta\_2,\\beta\_3$是依赖于$t$的，这意味着我们需要提前知道生成多少帧的视频，换句话说，第二种方案并不是不能用自回归的方式生成视频，而是需要提前确定帧数，这在笔者看来是不符合时间维度的理想特性的（时间，应该可以无约束地往前推进）。
可能有读者疑问：为什么图像就不介意$\\beta\_1,\\beta\_2$中依赖于$w,h$呢？也就是说为什么图像生成不介意事先知道图像大小呢？这是因为图像有两个方向，就算我们用自回归的方式生成图像，也必须至少知道一个方向的大小，才能告诉模型及时“换行”，以生成一张完整的二维图像。而图像的两个空间维度是平权的，单知其一倒不如全部知道，所以我们能够接受事先确定图像大小。
此外，我们还可以用[《“闭门造车”之多模态思路浅谈（一）：无损输入》](https://kexue.fm/archives/9984)介绍的“AR+Diffusion”做“文本-图像”模型，此时图像生成部分是Diffusion，就必须提前知道目标图像大小了。
## 相关工作[#](#相关工作)
前段时间，阿里开源了名为“Qwen2-VL”的多模态模型，介绍中提到自己提出了一种多模态旋转位置编码（M-ROPE），引起了笔者的兴趣。经过阅读源码（[链接](https://github.com/huggingface/transformers/blob/1759bb9126e59405f58693a17ef9f58040c2008b/src/transformers/models/qwen2_vl/modeling_qwen2_vl.py#L1357)），发现M-RoPE实际上就是沿用了RoPE-Tie的**兼容性**思想，但没有保留**对称性**和**等价性**。
[![M-RoPE的源码注释](https://kexue.fm/usr/uploads/2024/09/1743575360.png)](https://kexue.fm/usr/uploads/2024/09/1743575360.png)
M-RoPE的源码注释
用本文的记号，M-RoPE实际上就是取了$\\beta\_1=\\beta\_2=\\beta\_3=L,\\gamma\_1=\\gamma\_2=\\gamma\_3$（对于“文本-视频”混合模态），然后视频右段的文本的第一个Token的位置，直接取视频最大的位置坐标加1。这样如果还是用自回归的方式生成视频，确实也不用提前确定帧数，但牺牲了**对称性**和**等价性**。
**对称性**和**等价性**有多重要呢？笔者不清楚答案，这需要充分实验来验证。但如果仅仅是头脑风暴的话，笔者猜测可能会影响极端情形的表现，比如对于M-RoPE来说，如果是画面很小但时间很长的视频，它的空间维度的位置坐标相对于左段文本来说是连续的，但相对于右段文本来说则是突变了，直觉上会使得文本和视觉的交互更不友好。
再比如一个$w=h=t=n$的视频，直觉上它等效于$n^3$个Token，但如果按照M-RoPE的规则，如果两段文本夹着这样一个视频，只是等价于夹着一个$n$个Token的文本，换言之在大小为$n$的相对距离内放下了$n^3$个Token，会不会导致信息密度过大而增加模型理解难度了？
当然，对于NoPE都可能Work的Decoder-only LLM来说，这些问题也可能是笔者多虑了。
## 文章小结[#](#文章小结)
本文分享了笔者关于多模态位置编码的后续思考，提出了构建多模态位置编码的三个原则：兼容性、等价性和对称性，改进了之前提出过的RoPE-Tie，最后讨论了“文本-视频”混合模态的位置编码设计和困难，以及Qwen2-VL的M-RoPE与RoPE-Tie的联系等。
***转载到请包括本文地址：** [https://kexue.fm/archives/10352](https://kexue.fm/archives/10352)*
***更详细的转载事宜请参考：*** [《科学空间FAQ》](https://kexue.fm/archives/6508#文章如何转载/引用)
**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**
**如果您觉得本文还不错，欢迎[分享](#share)/[打赏](#pay)本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**
打赏![科学空间](https://kexue.fm/usr/themes/geekg/payment/wx.png)
微信打赏![科学空间](https://kexue.fm/usr/themes/geekg/payment/zfb.png)
支付宝打赏因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。 你还可以[**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ)或在下方评论区留言来告知你的建议或需求。
**如果您需要引用本文，请参考：**
苏剑林. (Sep. 06, 2024). 《“闭门造车”之多模态思路浅谈（三）：位置编码》[Blog post]. Retrieved from[https://kexue.fm/archives/10352](https://kexue.fm/archives/10352)
@online{kexuefm-10352,
title={“闭门造车”之多模态思路浅谈（三）：位置编码},
author={苏剑林},
year={2024},
month={Sep},
url={\\url{https://kexue.fm/archives/10352}},
}
分类：[信息时代](https://kexue.fm/category/Big-Data) 标签：[attention](https://kexue.fm/tag/attention/),[位置编码](https://kexue.fm/tag/位置编码/),[多模态](https://kexue.fm/tag/多模态/)[46 评论](https://kexue.fm/archives/10352#comments)
&lt;[Decoder-only的LLM为什么需要位置编码？](https://kexue.fm/archives/10347)|[低秩近似之路（一）：伪逆](https://kexue.fm/archives/10366)&gt;
### 你也许还对下面的内容感兴趣* [为什么DeltaNet要加L2 Normalize？](https://kexue.fm/archives/11486)
* [低精度Attention可能存在有偏的舍入误差](https://kexue.fm/archives/11371)
* [为什么线性注意力要加Short Conv？](https://kexue.fm/archives/11320)
* [QK-Clip：让Muon在Scaleup之路上更进一步](https://kexue.fm/archives/11126)
* [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111)
* [“对角+低秩”三角阵的高效求逆方法](https://kexue.fm/archives/11072)
* [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
* [Transformer升级之路：20、MLA好在哪里?（上）](https://kexue.fm/archives/10907)
* [Transformer升级之路：19、第二类旋转位置编码](https://kexue.fm/archives/10862)
* [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
[发表你的看法](#comment_form)
1. [&laquo;](https://kexue.fm/archives/10352/comment-page-1#comments)
2. [1](https://kexue.fm/archives/10352/comment-page-1#comments)
3. [2](https://kexue.fm/archives/10352/comment-page-2#comments)
[Qwen2.5-Omni -多模态端到端大模型 R11; chenpaopao](http://139.9.1.231/index.php/2025/03/28/qwen2-5-omni/)
March 28th, 2025
[...]TMRoPE 我们提出了一种音视频时间交错算法（time-interleaving），并引入了新的 位置编码方法——TMRoPE（Time-aligned Multimodal RoPE）。如 图3 所示，TMRoPE 编码了多模态输入的三维位置，采用多模态旋转位置编码（M-RoPE）【ps: Qwen2-VL多模态旋转位置编码 多模位置编码】，并结合绝对时间位置。具体方法是将原始的旋[...]
[回复评论](https://kexue.fm/archives/10352/comment-page-2?replyTo=27259#respond-post-10352)
[Khazzz1c](https://github.com/)
June 11th, 2025
Rope-Tie-v2的那个图 右侧是数学计算写错了还得加上一个L 才是11.5
[回复评论](https://kexue.fm/archives/10352/comment-page-2?replyTo=27853#respond-post-10352)
[苏剑林](https://kexue.fm)发表于 June 13th, 2025
更正过来了，谢谢。[回复评论](https://kexue.fm/archives/10352/comment-page-2?replyTo=27871#respond-post-10352)
Cai Rizhao
November 4th, 2025
an image is worth of 16x16 words (tokens), 但是一个patch的image token跟一个文字的token的信息量本身一定是不同的。所以等价性是不是一定要追求的呢？好似不一定，不知道我这样想对不对
[回复评论](https://kexue.fm/archives/10352/comment-page-2?replyTo=28765#respond-post-10352)
[苏剑林](https://kexue.fm)发表于 November 5th, 2025
这里的等价性只是一个具体例子，如果你认为一个image token等价于0.5个text token，也可以构造另一种等价性形式。但等价性本身，感觉还是要满足比较舒服。
[回复评论](https://kexue.fm/archives/10352/comment-page-2?replyTo=28774#respond-post-10352)
1. [&laquo;](https://kexue.fm/archives/10352/comment-page-1#comments)
2. [1](https://kexue.fm/archives/10352/comment-page-1#comments)
3. [2](https://kexue.fm/archives/10352/comment-page-2#comments)
[取消回复](https://kexue.fm/archives/10352#respond-post-10352)
你的大名电子邮箱个人网站（选填）1. 可以使用LaTeX代码，点击“预览效果”可查看效果；
2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请**不要重复点击提交**。
********************
### 内容速览4. [多模位置](#多模位置)
5. [向后兼容](#向后兼容)
6. [等价对称](#等价对称)
7. [优劣分析](#优劣分析)
8. [三维困境](#三维困境)
9. [相关工作](#相关工作)
10. [文章小结](#文章小结)
********************
### 智能搜索支持整句搜索！网站自动使用[结巴分词](https://github.com/fxsjy/jieba)进行分词，并结合ngrams排序算法给出合理的搜索结果。
********************
### 热门标签[生成模型](https://kexue.fm/tag/生成模型/)[attention](https://kexue.fm/tag/attention/)[优化](https://kexue.fm/tag/优化/)[语言模型](https://kexue.fm/tag/语言模型/)[模型](https://kexue.fm/tag/模型/)[网站](https://kexue.fm/tag/网站/)[梯度](https://kexue.fm/tag/梯度/)[概率](https://kexue.fm/tag/概率/)[矩阵](https://kexue.fm/tag/矩阵/)[优化器](https://kexue.fm/tag/优化器/)[转载](https://kexue.fm/tag/转载/)[微分方程](https://kexue.fm/tag/微分方程/)[分析](https://kexue.fm/tag/分析/)[天象](https://kexue.fm/tag/天象/)[深度学习](https://kexue.fm/tag/深度学习/)[积分](https://kexue.fm/tag/积分/)[python](https://kexue.fm/tag/python/)[扩散](https://kexue.fm/tag/扩散/)[力学](https://kexue.fm/tag/力学/)[无监督](https://kexue.fm/tag/无监督/)[几何](https://kexue.fm/tag/几何/)[节日](https://kexue.fm/tag/节日/)[生活](https://kexue.fm/tag/生活/)[文本生成](https://kexue.fm/tag/文本生成/)[数论](https://kexue.fm/tag/数论/)
********************
********************
### 随机文章* [日食记](https://kexue.fm/archives/7515)
* [【通知转载】国家天文台信息技术类人才招聘](https://kexue.fm/archives/557)
* [又一道川菜！媲美“开水白菜”的瓜燕穗肚](https://kexue.fm/archives/6158)
* [关于交错级数的审敛法则](https://kexue.fm/archives/159)
* [小论文《欧拉数学在数列级数的妙用》](https://kexue.fm/archives/2222)
* [【搜出来的文本】⋅（三）基于BERT的文本采样](https://kexue.fm/archives/8119)
* [第一次使用linux写日志](https://kexue.fm/archives/123)
* [局部余弦相似度大，全局余弦相似度一定也大吗？](https://kexue.fm/archives/9931)
* [关于NBCE方法的一些补充说明和分析](https://kexue.fm/archives/9632)
* [百科翻译：盐酸的历史（氯化氢，HCl）](https://kexue.fm/archives/9)
********************
********************
### 最近评论* [且寻](https://kexue.fm/archives/11480/comment-page-1#comment-29057): same。本来想转成二重积分的，但想半天整不出来，搞出来这个半成品...
* [苏剑林](https://kexue.fm/archives/11267/comment-page-1#comment-29056): 是梯度均值为零的假设。这个问题不是在“数值模拟”一节讨论过了吗？而且最终结果跟实际观测是接近的...
* [苏剑林](https://kexue.fm/archives/7180/comment-page-2#comment-29055): X与单位阵的平均平方误差(mse)，作为它跟单位阵的差距，有什么问题？当然取误差最大值也是一个...
* [苏剑林](https://kexue.fm/archives/9209/comment-page-8#comment-29054): 从公式$(12)$到公式$(15)$，都在推导和解释你说的这个事啊，以$\\mathbb{E}\_...
* [苏剑林](https://kexue.fm/archives/8130/comment-page-7#comment-29053): 相对位置编码，似乎没有太多选择了，要不RoPE这种，算是乘性了，要不Alibi这种加性。你还想...
* [苏剑林](https://kexue.fm/archives/11480/comment-page-1#comment-29052): 学习了一下，感觉这个更多是证明，而不是理解？而且这个证明也没有比原始证明简单。我说的缺乏直观理...
* [苏剑林](https://kexue.fm/archives/11320/comment-page-1#comment-29051): 那还不如直接softmax attention？
* [苏剑林](https://kexue.fm/archives/11486/comment-page-1#comment-29050): 可以啊，L1 Norm一定大于等于L2 Norm，所以L1 Norm归一化后模长小于等于1
* [苏剑林](https://kexue.fm/archives/9119/comment-page-14#comment-29049): 你本来要用数值模拟算两重积分，我现在帮你把一重积分算出来了，你只需要算一重积分了，怎么会更难呢...
* [苏剑林](https://kexue.fm/archives/11158/comment-page-1#comment-29048): learned, thanks
********************
********************
### 友情链接* [Cool Papers](https://papers.cool)
* [数学研发](https://bbs.emath.ac.cn)
* [Seatop](http://www.seatop.com.cn/)
* [Xiaoxia](https://xiaoxia.org/)
* [积分表-网络版](https://kexue.fm/sci/integral/index.html)
* [丝路博傲](http://blog.dvxj.com/)
* [数学之家](http://www.2math.cn/)
* [有趣天文奇观](http://interesting-sky.china-vo.org/)
* [TwistedW](http://www.twistedwg.com/)
* [godweiyang](https://godweiyang.com/)
* [AI柠檬](https://blog.ailemon.net/)
* [王登科-DK博客](https://greatdk.com)
* [ESON](https://blog.eson.org/)
* [枫之羽](https://fzhiy.net/)
* [coding-zuo](https://coding-zuo.github.io/)
* [博科园](https://www.bokeyuan.net/)
* [孔皮皮的博客](https://www.kppkkp.top/)
* [运鹏的博客](https://yunpengtai.top/)
* [jiming.site](https://jiming.site/)
* [OmegaXYZ](https://www.omegaxyz.com/)
* [EAI猩球](https://www.robotech.ink/)
* [文举的博客](https://liwenju0.com/)
* [申请链接](https://kexue.fm/links.html)
********************
[![署名-非商业用途-保持一致](https://kexue.fm/usr/themes/geekg/images/cc.gif)](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“[署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
©2009-2025 Scientific Spaces. All rights reserved. Theme by[laogui](http://www.laogui.com). Powered by[Typecho](http://typecho.org). 备案号:[粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。