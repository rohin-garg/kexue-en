## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [低精度Attention可能存在有...](https://kexue.fm/archives/11371)
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)

## COMMENTS

- [喝一口可乐: 理解了，感谢苏神回复，数学上给出建模分析确实清晰了很多，再次感...](https://kexue.fm/archives/10958/comment-page-3#comment-29030)
- [CuddleSabe1: 感觉普通的 flow matching 可以看成 degrad...](https://kexue.fm/archives/10958/comment-page-1#comment-29029)
- [岁月如书: 受教了，感谢](https://kexue.fm/archives/11126/comment-page-3#comment-29028)
- [苏剑林: 是](https://kexue.fm/archives/11126/comment-page-3#comment-29027)
- [岁月如书: 哦哦，原来是有实验结论，那是我盲目了。多问一句，你说的atte...](https://kexue.fm/archives/11126/comment-page-3#comment-29026)
- [苏剑林: attention sink指的是第一个token的atten...](https://kexue.fm/archives/11126/comment-page-3#comment-29025)
- [苏剑林: 这也许是好事呢？SGD倒是保留了模长，但它就普遍不如不保留模长...](https://kexue.fm/archives/11459/comment-page-1#comment-29024)
- [岁月如书: maxlogit 是attention qk乘积中出现了大值，...](https://kexue.fm/archives/11126/comment-page-3#comment-29023)
- [岁月如书: \[comment=29016\]苏剑林\[/comment\]他通过...](https://kexue.fm/archives/11459/comment-page-1#comment-29022)
- [苏剑林: 我好像也就只有把小的放大然后加噪声的思路](https://kexue.fm/archives/10667/comment-page-1#comment-29021)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 【中文分词系列】 2\. 基于切分的新词发现

18Aug

# [【中文分词系列】 2\. 基于切分的新词发现](https://kexue.fm/archives/3913)

By 苏剑林 \|
2016-08-18 \|
153063位读者\|

上一篇文章讲的是基于词典和AC自动机的快速分词。基于词典的分词有一个明显的优点，就是便于维护，容易适应领域。如果迁移到新的领域，那么只需要添加对应的领域新词，就可以实现较好地分词。当然，好的、适应领域的词典是否容易获得，这还得具体情况具体分析。本文要讨论的就是新词发现这一部分的内容。

这部分内容在去年的文章 [《新词发现的信息熵方法与实现》](https://kexue.fm/archives/3491/) 已经讨论过了，算法是来源于matrix67的文章 [《互联网时代的社会语言学：基于SNS的文本数据挖掘》](http://www.matrix67.com/blog/archives/5044)。在那篇文章中，主要利用了三个指标——频数、凝固度（取对数之后就是我们所说的互信息熵）、自由度（边界熵）——来判断一个片段是否成词。如果真的动手去实现过这个算法的话，那么会发现有一系列的难度。首先，为了得到$n$字词，就需要找出$1\\sim n$字的切片，然后分别做计算，这对于$n$比较大时，是件痛苦的时间；其次，最最痛苦的事情是边界熵的计算，边界熵要对每一个片段就行分组统计，然后再计算，这个工作量的很大的。本文提供了一种方案，可以使得新词发现的计算量大大降低。

### 算法 [\#](https://kexue.fm/kexue.fm\#%E7%AE%97%E6%B3%95)

回顾matrix67的算法做新词发现的过程，应该可以认识到，新词发现做的事情，就是根据语料判断给定片段是不是真的成词了，而所谓成词，就是它相对独立，不可切分。 **那为什么不反过来呢？为什么我们不去找一下哪些片段不能成词呢？根据前面的说法，我们说片段的凝固度大于一定程度时，片段可能成词（接下来要去考虑它的边界熵）。那这不就是说，如果片段的凝固度低于一定程度时，这个片段就不可能成词了吗？那么我们就可以在原来的语料中把它断开了。**

我们可以做适当的简化，如果$a,b$是语料中相邻两字，那么可以统计$(a,b)$成对出现的次数$\\#(a,b)$，继而估计它的频率$P(a,b)$，然后我们分别统计$a,b$出现的次数$\\#a,\\#b$，然后估计它们的频率$P(a),P(b)$，如果
$$\\frac{P(a,b)}{P(a)P(b)} < \\alpha \\quad (\\alpha\\text{是给定的大于1的阈值})$$
那么就应该在原来的语料中把这两个字断开。这个操作本质上就是——我们根据这个指标，对原始语料进行初步的分词！在完成初步分词后，我们就可以统计词频了，然后根据词频来筛选。

**对比matrix67文章中的三个指标，我们现在只用了两个：频数和凝固度，去掉了计算量最大的边界熵，而且，在计算凝固度时，我们只需要计算二字片段的凝固度，省掉了更多字片段的凝固度计算，但是，由于我们是基于切分的方式做的，因此我们少了很多计算量，但理论上却能够得任意长度的词语！**

### 实现 [\#](https://kexue.fm/kexue.fm\#%E5%AE%9E%E7%8E%B0)

看上去很完美——计算量少了，功能更强了。实际效果如何呢？跟matrix67文章中的算法的结果有多少出入？这个还得真的自己试过才能说了算。不过，我用了30万篇微信公众号的文章（约1GB）进行实验，发现效果是可以让人满意的，用时10分钟左右。下面给出实现代码，很短，纯Python，并且不用第三方库的支持，而且内存非常友好，这里的texts可以是一个列表，也可以是一个迭代器（每次返回一篇文章），配合tqdm库，可以方便地显示进度。最后，在统计时，用到了加$\\gamma$平滑法，以缓解出现不合理的词。以前做这些统计计算的时候，不用想就用Pandas了，最近尝试了一下Python原生的一些库，发现也相当好用呢～

```
import pymongo

db = pymongo.MongoClient().baike.items
def texts():
 for a in db.find(no_cursor_timeout=True).limit(1000000):
 yield a['content']

from collections import defaultdict #defaultdict是经过封装的dict，它能够让我们设定默认值
from tqdm import tqdm #tqdm是一个非常易用的用来显示进度的库
from math import log
import re

class Find_Words:
 def __init__(self, min_count=10, min_pmi=0):
 self.min_count = min_count
 self.min_pmi = min_pmi
 self.chars, self.pairs = defaultdict(int), defaultdict(int) #如果键不存在，那么就用int函数
 #初始化一个值，int()的默认结果为0
 self.total = 0.
 def text_filter(self, texts): #预切断句子，以免得到太多无意义（不是中文、英文、数字）的字符串
 for a in tqdm(texts):
 for t in re.split(u'[^\u4e00-\u9fa50-9a-zA-Z]+', a): #这个正则表达式匹配的是任意非中文、
 #非英文、非数字，因此它的意思就是用任
 #意非中文、非英文、非数字的字符断开句子
 if t:
 yield t
 def count(self, texts): #计数函数，计算单字出现频数、相邻两字出现的频数
 for text in self.text_filter(texts):
 self.chars[text[0]] += 1
 for i in range(len(text)-1):
 self.chars[text[i+1]] += 1
 self.pairs[text[i:i+2]] += 1
 self.total += 1
 self.chars = {i:j for i,j in self.chars.items() if j >= self.min_count} #最少频数过滤
 self.pairs = {i:j for i,j in self.pairs.items() if j >= self.min_count} #最少频数过滤
 self.strong_segments = set()
 for i,j in self.pairs.items(): #根据互信息找出比较“密切”的邻字
 _ = log(self.total*j/(self.chars[i[0]]*self.chars[i[1]]))
 if _ >= self.min_pmi:
 self.strong_segments.add(i)
 def find_words(self, texts): #根据前述结果来找词语
 self.words = defaultdict(int)
 for text in self.text_filter(texts):
 s = text[0]
 for i in range(len(text)-1):
 if text[i:i+2] in self.strong_segments: #如果比较“密切”则不断开
 s += text[i+1]
 else:
 self.words[s] += 1 #否则断开，前述片段作为一个词来统计
 s = text[i+1]
 self.words[s] += 1 #最后一个“词”
 self.words = {i:j for i,j in self.words.items() if j >= self.min_count} #最后再次根据频数过滤

fw = Find_Words(16, 1)
fw.count(texts())
fw.find_words(texts())

import pandas as pd
words = pd.Series(fw.words).sort_values(ascending=False)
```

Python流式读取SQL数据的参考代码：

```
from sqlalchemy import *

def sql_data_generator():
 db = create_engine('mysql+pymysql://user:password@123.456.789.123/yourdatabase?charset=utf8')
 result = db.execution_options(stream_results=True).execute(text('select content from articles'))
 for t in result:
 yield t[0]
```

### 分析 [\#](https://kexue.fm/kexue.fm\#%E5%88%86%E6%9E%90)

当然，这个算法不能说完全没有缺点，还是有些问题值得探讨的。一般情况下，为了得到更细粒度的词语（避免分出太多无效的长词），我们可以选择较大的$\\alpha$，比如$\\alpha=10$，但是这带来一个问题：一个词语中相邻两个字的凝固度不一定很大。一个典型的例子是“共和国”，“和”跟“国”都是很频繁的字，“和国”两个字的凝固度并不高（在微信文本中大概为3左右），如果$\\alpha$太大就会导致切错了这个词语（事实上，是“共和”跟“国”的凝固度高），这些例子还有很多，比如“林心如”的“心如”凝固度就不大（当然，如果语料来源于娱乐圈，那又另当别论）。而如果设置$\\alpha=1$，则需要更大的语料库才能使得词库完备起来。这是在使用本算法时需要仔细考虑的。

### 微信词典 [\#](https://kexue.fm/kexue.fm\#%E5%BE%AE%E4%BF%A1%E8%AF%8D%E5%85%B8)

最后分享一份我从最近的30万微信公众号文章（1G左右， 3亿多字）中提取的一份词表，设置了最小凝固度为1，最小频数为100。从表中也可以发现，跟微信具有明显联系的词语都已经被提取出来，并且，这是最新的公众号文章，因此，最近的热点——奥运、王宝强——相关的词语也被提取出来了。

**微信词典： [dict.txt](https://kexue.fm/usr/uploads/2016/08/627400080.txt)**

### 参考链接 [\#](https://kexue.fm/kexue.fm\#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5)

《非主流自然语言处理——遗忘算法系列（二）：大规模语料词库生成》： [http://www.52nlp.cn/forgetnlp2](http://www.52nlp.cn/forgetnlp2)

_**转载到请包括本文地址：** [https://kexue.fm/archives/3913](https://kexue.fm/archives/3913)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Aug. 18, 2016). 《【中文分词系列】 2. 基于切分的新词发现 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/3913](https://kexue.fm/archives/3913)

@online{kexuefm-3913,
        title={【中文分词系列】 2. 基于切分的新词发现},
        author={苏剑林},
        year={2016},
        month={Aug},
        url={\\url{https://kexue.fm/archives/3913}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [分词](https://kexue.fm/tag/%E5%88%86%E8%AF%8D/), [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/), [NLP](https://kexue.fm/tag/NLP/), [新词发现](https://kexue.fm/tag/%E6%96%B0%E8%AF%8D%E5%8F%91%E7%8E%B0/)[23 评论](https://kexue.fm/archives/3913#comments)

< [【中文分词系列】 1\. 基于AC自动机的快速分词](https://kexue.fm/archives/3908) \| [【中文分词系列】 3\. 字标注法与HMM模型](https://kexue.fm/archives/3922) >

### 你也许还对下面的内容感兴趣

- [生成扩散模型漫谈（二十三）：信噪比与大图生成（下）](https://kexue.fm/archives/10055)
- [随机分词再探：从Viterbi Sampling到完美采样算法](https://kexue.fm/archives/9811)
- [随机分词浅探：从Viterbi Decoding到Viterbi Sampling](https://kexue.fm/archives/9768)
- [BytePiece：更纯粹、更高压缩率的Tokenizer](https://kexue.fm/archives/9752)
- [用热传导方程来指导自监督学习](https://kexue.fm/archives/9359)
- [GPLinker：基于GlobalPointer的事件联合抽取](https://kexue.fm/archives/8926)
- [GPLinker：基于GlobalPointer的实体关系联合抽取](https://kexue.fm/archives/8888)
- [Efficient GlobalPointer：少点参数，多点效果](https://kexue.fm/archives/8877)
- [WGAN新方案：通过梯度归一化来实现L约束](https://kexue.fm/archives/8757)
- [曾被嫌弃的预训练任务NSP，做出了优秀的Zero Shot效果](https://kexue.fm/archives/8671)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

1. [«](https://kexue.fm/archives/3913/comment-page-1#comments)
2. [1](https://kexue.fm/archives/3913/comment-page-1#comments)
3. [2](https://kexue.fm/archives/3913/comment-page-2#comments)

三三

October 14th, 2020

代码50行与51行之间应该是少了一行代码哈：self.words\[s\] += 1 用于接收一句话成词以及文章最后一个词。

[回复评论](https://kexue.fm/archives/3913/comment-page-2?replyTo=14565#respond-post-3913)

[苏剑林](https://kexue.fm) 发表于
October 14th, 2020

嗯嗯，可以，我补充上去了。当然，就算不加上去其实也无伤大雅。

[回复评论](https://kexue.fm/archives/3913/comment-page-2?replyTo=14567#respond-post-3913)

[发现新词 \| NLP之无监督方式构建词库(二) R11; 源码巴士](https://code84.com/722266.html)

November 8th, 2022

\[...\]转载于基于切分的新词发现\[...\]

[回复评论](https://kexue.fm/archives/3913/comment-page-2?replyTo=20310#respond-post-3913)

1. [«](https://kexue.fm/archives/3913/comment-page-1#comments)
2. [1](https://kexue.fm/archives/3913/comment-page-1#comments)
3. [2](https://kexue.fm/archives/3913/comment-page-2#comments)

[取消回复](https://kexue.fm/archives/3913#respond-post-3913)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[算法](https://kexue.fm/kexue.fm#%E7%AE%97%E6%B3%95)
[实现](https://kexue.fm/kexue.fm#%E5%AE%9E%E7%8E%B0)
[分析](https://kexue.fm/kexue.fm#%E5%88%86%E6%9E%90)
[微信词典](https://kexue.fm/kexue.fm#%E5%BE%AE%E4%BF%A1%E8%AF%8D%E5%85%B8)
[参考链接](https://kexue.fm/kexue.fm#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [对比学习可以使用梯度累积吗？](https://kexue.fm/archives/8471)
- [科学空间终于恢复访问了！](https://kexue.fm/archives/1658)
- [变分自编码器 = 最小化先验分布 \+ 最大化互信息](https://kexue.fm/archives/6088)
- [为什么梯度裁剪的默认模长是1？](https://kexue.fm/archives/10657)
- [《向量》系列——1.向心力公式证明](https://kexue.fm/archives/701)
- [【NASA每日一图】猎户座与彗星](https://kexue.fm/archives/145)
- [Keras实现两个优化器：Lookahead和LazyOptimizer](https://kexue.fm/archives/6869)
- [当BERT-whitening引入超参数：总有一款适合你](https://kexue.fm/archives/9079)
- [【不可思议的Word2Vec】5. Tensorflow版的Word2Vec](https://kexue.fm/archives/4402)
- [2012诺贝尔奖...](https://kexue.fm/archives/1735)

### 最近评论

- [喝一口可乐](https://kexue.fm/archives/10958/comment-page-3#comment-29030): 理解了，感谢苏神回复，数学上给出建模分析确实清晰了很多，再次感谢苏神回复！
- [CuddleSabe1](https://kexue.fm/archives/10958/comment-page-1#comment-29029): 感觉普通的 flow matching 可以看成 degrade-aware image de...
- [岁月如书](https://kexue.fm/archives/11126/comment-page-3#comment-29028): 受教了，感谢
- [苏剑林](https://kexue.fm/archives/11126/comment-page-3#comment-29027): 是
- [岁月如书](https://kexue.fm/archives/11126/comment-page-3#comment-29026): 哦哦，原来是有实验结论，那是我盲目了。多问一句，你说的attention + output g...
- [苏剑林](https://kexue.fm/archives/11126/comment-page-3#comment-29025): attention sink指的是第一个token的attention普遍不可忽略，不一定是爆...
- [苏剑林](https://kexue.fm/archives/11459/comment-page-1#comment-29024): 这也许是好事呢？SGD倒是保留了模长，但它就普遍不如不保留模长的SignSGD或者Normal...
- [岁月如书](https://kexue.fm/archives/11126/comment-page-3#comment-29023): maxlogit 是attention qk乘积中出现了大值，attention sink等于...
- [岁月如书](https://kexue.fm/archives/11459/comment-page-1#comment-29022): \[comment=29016\]苏剑林\[/comment\]他通过Newton-schulz迭代近...
- [苏剑林](https://kexue.fm/archives/10667/comment-page-1#comment-29021): 我好像也就只有把小的放大然后加噪声的思路

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。