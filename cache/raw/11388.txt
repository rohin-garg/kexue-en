## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [低精度Attention可能存在有...](https://kexue.fm/archives/11371)
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328)
- [为什么线性注意力要加Short C...](https://kexue.fm/archives/11320)

## COMMENTS

- [Xintian Wu: 苏老师您好，我有个疑惑，在进行高分辨率图像训练时，如文中提到的...](https://kexue.fm/archives/11428/comment-page-1#comment-28913)
- [zcj5918: 重想了一下，本质上第一个问题是不是因为：球面均匀分布的情况下和...](https://kexue.fm/archives/7076/comment-page-3#comment-28912)
- [zcj5918: 高维空间下，高维概率这门课的推导的结论来看，确实高维空间两两向...](https://kexue.fm/archives/7076/comment-page-3#comment-28911)
- [yzyyzyhhh: 苏老师我想到一种不需要更多概念的方法：2DROPE相比1D的难...](https://kexue.fm/archives/8397/comment-page-3#comment-28910)
- [苏神小迷弟: https://github.com/UCDvision/si...](https://kexue.fm/archives/7546/comment-page-4#comment-28908)
- [zeurd: 我自己的经验是，在训练low-level模型的时候，对于视频超...](https://kexue.fm/archives/11416/comment-page-1#comment-28907)
- [King.Mr: 感谢](https://kexue.fm/archives/8620/comment-page-4#comment-28906)
- [keyerror: 谢谢苏神～，这个思路对我很有启发。](https://kexue.fm/archives/11428/comment-page-1#comment-28905)
- [vnlee: 苏神似乎在讨论局部本征维度估计？\
https://procee...](https://kexue.fm/archives/11428/comment-page-1#comment-28904)
- [苏剑林: 这里维数实际上是指有效维数，我不大清楚这里怎么严格表达，但理解...](https://kexue.fm/archives/11428/comment-page-1#comment-28903)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) 流形上的最速下降：5\. 对偶梯度下降

3Nov

# [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)

By 苏剑林 \|
2025-11-03 \|
9986位读者\|

前四篇文章我们求解了几个具体的给参数加等式约束的最速下降问题，其中第三、四篇的问题没法找到解析解，所以笔者提出了相应的不动点迭代法。其中的其中，第三篇文章 [《流形上的最速下降：3\. Muon + Stiefel》](https://kexue.fm/archives/11221) 所研究的“Stiefel流形上的Muon”，问题提出自Jeremy Bernstein的 [《Orthogonal manifold》](https://docs.modula.systems/algorithms/manifold/orthogonal/) 一文。

对于这个问题，Jeremy Bernstein最后也给出了一个自己的解法，笔者称之为“对偶梯度下降（Dual Gradient Descent）”，也颇为值得学习一番。

## 基本概念 [\#](https://kexue.fm/kexue.fm\#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)

Jeremy Bernstein的解法，最后发表在Thinking Machines Lab的博客 [《Modular Manifolds》](https://thinkingmachines.ai/blog/modular-manifolds/) 中，是该实验室的第二篇博客，文章中将它称为“对偶上升（Dual Ascent）”，但笔者这里还是结合前四篇的内容，将其称为“对偶梯度下降”。

事实上，对偶梯度下降可以说是拉格朗日乘数法的自然结果，但是拉格朗日乘数法的严格讨论其实是很麻烦的，比如要引入 [Minimax theorem](https://en.wikipedia.org/wiki/Minimax_theorem)，所以在这个系列中，我们为了避免这些麻烦，采用了“待定系数”这样的推导方式，这就使得对偶梯度下降并不是那么自然。但不要紧，我们还是可以沿着我们的思路把它推出来的，只不过可能多费点篇幅。

首先回顾一下各种记号。$\\boldsymbol{W}\\in\\mathbb{R}^{n\\times m}$是一个矩阵参数，不失一般性设$n\\geq m$，$\\boldsymbol{G}\\in\\mathbb{R}^{n\\times m}$是它的梯度。$\\Vert\\boldsymbol{G}\\Vert\_2$是矩阵$\\boldsymbol{G}$的谱范数，等于最大奇异值；$\\Vert\\boldsymbol{G}\\Vert\_\*$是矩阵$\\boldsymbol{G}$的核范数，等于全体奇异值之和。特别地，根据 [《SVD的导数》](https://kexue.fm/archives/10878) 一文的结论，我们有
\\begin{equation}\\nabla\_{\\boldsymbol{G}}\\Vert\\boldsymbol{G}\\Vert\_\* = \\sum\_i \\nabla\_{\\boldsymbol{G}} \\sigma\_i = \\sum\_i \\boldsymbol{u}\_i \\boldsymbol{v}\_i^{\\top} = \\boldsymbol{U}\\boldsymbol{V}^{\\top} = \\newcommand{msign}{\\mathop{\\text{msign}}}\\msign(\\boldsymbol{G}) \\label{eq:nuclear-grad}\\end{equation}
其中$\\boldsymbol{G}=\\sum\_i \\sigma\_i \\boldsymbol{u}\_i \\boldsymbol{v}\_i^{\\top} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\top}$是$\\boldsymbol{G}$的SVD。也就是说，核范数的梯度正好是$\\msign$算子，这是接下来推导的重要基础。

## 问题描述 [\#](https://kexue.fm/kexue.fm\#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0)

我们还是沿着之前的推导思路介绍对偶梯度下降，所以这一节先把问题和已有的结果复述一下。

在 [《流形上的最速下降：3\. Muon + Stiefel》](https://kexue.fm/archives/11221) 中，我们要解决的问题是
\\begin{equation}\\newcommand{tr}{\\mathop{\\text{tr}}}\\max\_{\\boldsymbol{\\Phi}} \\tr(\\boldsymbol{G}^{\\top}\\boldsymbol{\\Phi}) \\qquad \\text{s.t.}\\qquad \\Vert\\boldsymbol{\\Phi}\\Vert\_2 = 1,\\,\\, \\boldsymbol{W}^{\\top}\\boldsymbol{W}=\\boldsymbol{I},\\,\\,\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W} = \\boldsymbol{0} \\label{eq:muon-stiefel}\\end{equation}
解是$\\boldsymbol{\\Phi} = \\msign(\\boldsymbol{G} + \\boldsymbol{W}\\boldsymbol{X})$，其中$\\boldsymbol{X}\\in\\mathbb{R}^{m\\times m}$是待定的对称矩阵，使得$\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W} = \\boldsymbol{0}$。

在 [《流形上的最速下降：4\. Muon + 谱球面》](https://kexue.fm/archives/11241) 中，我们要求解的问题是
\\begin{equation}\\max\_{\\boldsymbol{\\Phi}} \\tr(\\boldsymbol{G}^{\\top}\\boldsymbol{\\Phi}) \\qquad \\text{s.t.}\\qquad \\Vert\\boldsymbol{\\Phi}\\Vert\_2 = 1,\\,\\, \\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})=0 \\label{eq:muon-spectral}\\end{equation}
答案是$\\boldsymbol{\\Phi} = \\msign(\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta})$，其中$\\lambda$是待定系数，使得$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})=0$。

可以看到，我们的最终任务都变成了寻找待定系数，使它满足额外引入的等式约束，这本质上就是非线性方程（组）的求解。而对偶梯度下降，就是将方程的求解转化为某个目标函数的最小化，从而用梯度下降求解。

## 对偶目标 [\#](https://kexue.fm/kexue.fm\#%E5%AF%B9%E5%81%B6%E7%9B%AE%E6%A0%87)

转化的关键就是核范数的梯度等式$\\eqref{eq:nuclear-grad}$。简单起见，我们先看“Muon+谱球面”的问题$\\eqref{eq:muon-spectral}$，待定系数只是一个标量，比较好观察。不难验证
\\begin{equation}\\nabla\_{\\lambda} \\Vert\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta}\\Vert\_\* = \\tr(\\boldsymbol{\\Theta}^{\\top}\\msign(\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta})) = \\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})\\end{equation}
这意味着解方程$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})=0$等价于寻找让$\\Vert\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta}\\Vert\_\*$的梯度等于0的点，这可能是它的（局部）最小/最大值点。由于$\\Vert\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta}\\Vert\_\*$显然没有最大值，所以我们转化为寻找它的最小值点：
\\begin{equation}\\lambda^\* = \\newcommand{argmin}{\\mathop{\\text{argmin}}}\\argmin\_{\\lambda} \\Vert\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta}\\Vert\_\*\\label{eq:muon-spectral-obj}\\end{equation}

我们再来捋一捋这里的步骤：

> 1、我们的目标是解方程$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})=0$，找到任意一个解就行；
>
> 2、$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})$正好是$\\Vert\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta}\\Vert\_\*$关于$\\lambda$的梯度；
>
> 3、这就转化为寻找（局部）最小/最大值点问题，因为此处的梯度往往是0；
>
> 4、可以简单判断没有最大值，所以只能找最小值。

## 梯度下降 [\#](https://kexue.fm/kexue.fm\#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)

确定目标$\\eqref{eq:muon-spectral-obj}$后，我们就可以用梯度下降求解了，其中梯度是现成的，即$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})$，那么梯度下降的格式是
\\begin{equation}\\lambda \\quad \\leftarrow\\quad \\lambda - \\eta \\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})\\end{equation}
当然我们也可以考虑给$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})$加个$\\newcommand{sign}{\\mathop{\\text{sign}}}\\sign$，即SignSGD，这些都可以自由发挥了。从迭代格式上看，对偶梯度下降要比之前我们提的不动点迭代要简单得多，然而，在很多情况下对偶梯度下降所需要的迭代步数也多得多，并且可能需要精调学习率、引入动量机制等，才有可能收敛。

所以，就解方程$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})=0$而言，对偶梯度下降并不算特别理想的方案。但是，我们的最终目标并不是解方程$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})=0$，而是计算$\\boldsymbol{\\Phi}$作为模型的优化方向。模型的优化本就是一个迭代的过程，我们可以将历史的$\\lambda$缓存下来，然后采取$\\lambda$与模型参数同步更新的近似策略
\\begin{equation}\\boldsymbol{\\Phi} = \\msign(\\boldsymbol{G} + \\lambda\\boldsymbol{\\Theta}), \\quad \\boldsymbol{W}\\leftarrow\\boldsymbol{W}- \\eta\_1 \\boldsymbol{\\Phi},\\quad \\lambda \\leftarrow\\lambda - \\eta\_2 \\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})\\end{equation}
这样一来，每一步训练只需要多算一步近乎免费的$\\lambda - \\eta\_2 \\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})$，就得到了原始目标$\\eqref{eq:muon-spectral}$的一个近似实现。从形式上来说，它相当于Muon的一种自适应Weight Decay。

## Stiefel上 [\#](https://kexue.fm/kexue.fm\#Stiefel%E4%B8%8A)

讨论完相对简单的“Muon+谱球面”，我们再来看“Muon+Stiefel”，即目标$\\eqref{eq:muon-stiefel}$。此时待定矩阵$\\boldsymbol{X}$有约束$\\boldsymbol{X}=\\boldsymbol{X}^{\\top}$，我们通过设$\\boldsymbol{X}=\\boldsymbol{\\Lambda}+\\boldsymbol{\\Lambda}^{\\top}$来去掉约束，其中$\\boldsymbol{\\Lambda}\\in\\mathbb{R}^{m\\times m}$是任意矩阵，然后可以发现
\\begin{equation}\\nabla\_{\\boldsymbol{\\Lambda}}\\Vert\\boldsymbol{G} + \\boldsymbol{W}\\boldsymbol{X}\\Vert\_\* = \\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W} \\end{equation}
这里$\\boldsymbol{\\Phi} = \\msign(\\boldsymbol{G} + \\boldsymbol{W}\\boldsymbol{X})$。所以，解方程组$\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W}=\\boldsymbol{0}$同样可以转化为找函数的$\\Vert\\boldsymbol{G} + \\boldsymbol{W}\\boldsymbol{X}\\Vert\_\*$的最小值点，然后用梯度下降解决：
\\begin{equation}\\boldsymbol{\\Lambda} \\quad\\leftarrow\\quad \\boldsymbol{\\Lambda} - \\eta(\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W}) \\end{equation}
由于$\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W}$必然是对称的，所以直接$\\boldsymbol{X} \\leftarrow\\boldsymbol{X} - \\eta(\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W})$也是可取的，将它跟$\\boldsymbol{W}$放一起来同步迭代，我们得到
\\begin{equation}\\boldsymbol{\\Phi} = \\msign(\\boldsymbol{G} + \\boldsymbol{W}\\boldsymbol{X}), \\quad \\boldsymbol{W}\\leftarrow\\boldsymbol{W}- \\eta\_1 \\boldsymbol{\\Phi},\\quad \\boldsymbol{X} \\leftarrow\\boldsymbol{X} - \\eta\_2(\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W})\\end{equation}
这样就实现了目标$\\eqref{eq:muon-stiefel}$的一个近似，每一步多出来的$\\boldsymbol{X} - \\eta\_2(\\boldsymbol{W}^{\\top}\\boldsymbol{\\Phi}+\\boldsymbol{\\Phi}^{\\top}\\boldsymbol{W})$也是近乎免费的。

## 拉氏乘数 [\#](https://kexue.fm/kexue.fm\#%E6%8B%89%E6%B0%8F%E4%B9%98%E6%95%B0)

在这两个例子中，它们所要求解的方程，都刚好等于某个核范数目标的梯度，这是单纯的巧合吗？当然不是，我们在“ [基本概念](https://kexue.fm/kexue.fm#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)”一节就说了，这是拉格朗日乘数法的自然结果，这一节我们对此做一下展开讨论。

为了方便理解，我们还是以相对简单的目标$\\eqref{eq:muon-spectral}$为例，它可以等价地写成
\\begin{equation}\\max\_{\\Vert\\boldsymbol{\\Phi}\\Vert\_2\\leq 1} \\min\_{\\lambda\\in\\mathbb{R}}\\tr(\\boldsymbol{G}^{\\top}\\boldsymbol{\\Phi}) + \\lambda\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})\\end{equation}
要理解这个转换，只需要意识到上式必然有$\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi})=0$，否则$\\min$这一步总可以取到负无穷，那么最后的$\\max$结果也只能是负无穷；至于$\\Vert\\boldsymbol{\\Phi}\\Vert\_2 = 1$改为$\\Vert\\boldsymbol{\\Phi}\\Vert\_2\\leq 1$，并不会改变最大值的结果（因为最大值总是在边界取到），但可以使得$\\boldsymbol{\\Phi}$的可行域变成一个 [凸集](https://en.wikipedia.org/wiki/Convex_set)。

有了这个等价形式，我们就可以利用 [Minimax theorem](https://en.wikipedia.org/wiki/Minimax_theorem) 去交换$\\min$和$\\max$的位置：
\\begin{equation}\\begin{aligned}
&\\,\\max\_{\\Vert\\boldsymbol{\\Phi}\\Vert\_2\\leq 1} \\min\_{\\lambda\\in\\mathbb{R}}\\tr(\\boldsymbol{G}^{\\top}\\boldsymbol{\\Phi}) + \\lambda\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi}) \\\
=&\\, \\min\_{\\lambda\\in\\mathbb{R}}\\max\_{\\Vert\\boldsymbol{\\Phi}\\Vert\_2\\leq 1}\\tr(\\boldsymbol{G}^{\\top}\\boldsymbol{\\Phi}) + \\lambda\\tr(\\boldsymbol{\\Theta}^{\\top} \\boldsymbol{\\Phi}) \\\
=&\\, \\min\_{\\lambda\\in\\mathbb{R}} \\Vert\\boldsymbol{G} + \\lambda \\boldsymbol{\\Theta}\\Vert\_\*
\\end{aligned}\\end{equation}
其中在$\\Vert\\boldsymbol{\\Phi}\\Vert\_2\\leq 1$上取$\\max$这步，是Muon推导的 [基本结果](https://kexue.fm/archives/11215#%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%9C)，所以先求$\\max$并没有困难。这样我们就得到了原问题$\\eqref{eq:muon-spectral}$的对偶目标$\\Vert\\boldsymbol{G} + \\lambda \\boldsymbol{\\Theta}\\Vert\_\*$。

可能有些读者疑问：你这的拉格朗日乘数法，怎么跟我学的好像不一样？因为这里的拉格朗日乘数法推广到了一般凸集，并且严格讨论了$\\min,\\max$的可交换性，以保证最终结果是我们想要的。而我们一般学的拉格朗日乘数法，只是在$\\mathbb{R}^n$中求约束优化问题的一套启发式求解流程，并没有太多去讨论理论保证方面的细节。

## 文章小结 [\#](https://kexue.fm/kexue.fm\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

这篇文章我们介绍了通过对偶梯度下降来寻找流形上的最速下降方向的思路，它也是前段时间Thinking Machines Lab的博客 [《Modular Manifolds》](https://thinkingmachines.ai/blog/modular-manifolds/) 用来求解Stiefel流形上的Muon的方法。

_**转载到请包括本文地址：** [https://kexue.fm/archives/11388](https://kexue.fm/archives/11388)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Nov. 03, 2025). 《流形上的最速下降：5. 对偶梯度下降 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/11388](https://kexue.fm/archives/11388)

@online{kexuefm-11388,
        title={流形上的最速下降：5. 对偶梯度下降},
        author={苏剑林},
        year={2025},
        month={Nov},
        url={\\url{https://kexue.fm/archives/11388}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/), [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/), [muon](https://kexue.fm/tag/muon/), [约束](https://kexue.fm/tag/%E7%BA%A6%E6%9D%9F/), [最速下降](https://kexue.fm/tag/%E6%9C%80%E9%80%9F%E4%B8%8B%E9%99%8D/)[4 评论](https://kexue.fm/archives/11388#comments)

< [低精度Attention可能存在有偏的舍入误差](https://kexue.fm/archives/11371) \| [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390) >

### 你也许还对下面的内容感兴趣

- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的渐近估计（下）](https://kexue.fm/archives/11404)
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [AdamW的Weight RMS的渐近估计（上）](https://kexue.fm/archives/11307)
- [重新思考学习率与Batch Size（四）：EMA](https://kexue.fm/archives/11301)
- [重新思考学习率与Batch Size（三）：Muon](https://kexue.fm/archives/11285)
- [重新思考学习率与Batch Size（二）：平均场](https://kexue.fm/archives/11280)
- [为什么Adam的Update RMS是0.2？](https://kexue.fm/archives/11267)
- [重新思考学习率与Batch Size（一）：现状](https://kexue.fm/archives/11260)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

Namoe

November 3rd, 2025

《Modular Manifolds》里公式(1)到公式(2)是不是写错了，公式(2)应该是 $\\mathrm{trace} A^T(G+W(\\Lambda+\\Lambda^T))$, Jeremy Bernstein写的是 $\\mathrm{trace} A^T(G+\\color{red}{2}W(\\Lambda+\\Lambda^T))$

[回复评论](https://kexue.fm/archives/11388/comment-page-1?replyTo=28764#respond-post-11388)

[苏剑林](https://kexue.fm) 发表于
November 5th, 2025

好像是。你可以去X上@一下Jeremy Bernstein～

[回复评论](https://kexue.fm/archives/11388/comment-page-1?replyTo=28773#respond-post-11388)

Tim

November 6th, 2025

saw this paper, seems quite relevant: https://arxiv.org/abs/2506.15054

[回复评论](https://kexue.fm/archives/11388/comment-page-1?replyTo=28780#respond-post-11388)

[苏剑林](https://kexue.fm) 发表于
November 9th, 2025

似乎是讨论不一样的问题。

[回复评论](https://kexue.fm/archives/11388/comment-page-1?replyTo=28787#respond-post-11388)

[取消回复](https://kexue.fm/archives/11388#respond-post-11388)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[基本概念](https://kexue.fm/kexue.fm#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)
[问题描述](https://kexue.fm/kexue.fm#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0)
[对偶目标](https://kexue.fm/kexue.fm#%E5%AF%B9%E5%81%B6%E7%9B%AE%E6%A0%87)
[梯度下降](https://kexue.fm/kexue.fm#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)
[Stiefel上](https://kexue.fm/kexue.fm#Stiefel%E4%B8%8A)
[拉氏乘数](https://kexue.fm/kexue.fm#%E6%8B%89%E6%B0%8F%E4%B9%98%E6%95%B0)
[文章小结](https://kexue.fm/kexue.fm#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [势能最小问题的探讨](https://kexue.fm/archives/2050)
- [费曼路径积分思想的发展(四)](https://kexue.fm/archives/1850)
- [“十字架”组合计数问题浅试](https://kexue.fm/archives/9291)
- [行星的逆行,顺行和留(计算公式)](https://kexue.fm/archives/608)
- [为什么需要残差？一个来自DeepNet的视角](https://kexue.fm/archives/8994)
- [从费马大定理谈起（十二）：再谈谈切线法](https://kexue.fm/archives/3008)
- [【备忘】电脑远程控制手机的解决方案](https://kexue.fm/archives/3691)
- [在bert4keras中使用混合精度和XLA加速训练](https://kexue.fm/archives/9059)
- [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111)
- [用变分推断统一理解生成模型（VAE、GAN、AAE、ALI）](https://kexue.fm/archives/5716)

### 最近评论

- [Xintian Wu](https://kexue.fm/archives/11428/comment-page-1#comment-28913): 苏老师您好，我有个疑惑，在进行高分辨率图像训练时，如文中提到的512x512，进行patchi...
- [zcj5918](https://kexue.fm/archives/7076/comment-page-3#comment-28912): 重想了一下，本质上第一个问题是不是因为：球面均匀分布的情况下和角度分布均匀的情况下结论是迥然不...
- [zcj5918](https://kexue.fm/archives/7076/comment-page-3#comment-28911): 高维空间下，高维概率这门课的推导的结论来看，确实高维空间两两向量夹角分布的概率随着维度收敛到9...
- [yzyyzyhhh](https://kexue.fm/archives/8397/comment-page-3#comment-28910): 苏老师我想到一种不需要更多概念的方法：2DROPE相比1D的难点在于要搞清楚两个可交换的正交矩...
- [苏神小迷弟](https://kexue.fm/archives/7546/comment-page-4#comment-28908): https://github.com/UCDvision/sima这篇文章用的是l1正则，时间...
- [zeurd](https://kexue.fm/archives/11416/comment-page-1#comment-28907): 我自己的经验是，在训练low-level模型的时候，对于视频超分降噪，muon好像可以降低模型...
- [King.Mr](https://kexue.fm/archives/8620/comment-page-4#comment-28906): 感谢
- [keyerror](https://kexue.fm/archives/11428/comment-page-1#comment-28905): 谢谢苏神～，这个思路对我很有启发。
- [vnlee](https://kexue.fm/archives/11428/comment-page-1#comment-28904): 苏神似乎在讨论局部本征维度估计？
https://proceedings.mlr.press/...
- [苏剑林](https://kexue.fm/archives/11428/comment-page-1#comment-28903): 这里维数实际上是指有效维数，我不大清楚这里怎么严格表达，但理解的话，我们可以类比一下矩阵的有效...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。