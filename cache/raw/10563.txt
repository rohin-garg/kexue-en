## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)

## COMMENTS

- [苏剑林: 刚入门那会的文章，不用深究了。](https://kexue.fm/archives/481/comment-page-1#comment-27835)
- [苏剑林: 目前各方面的实测效果看来不会，我觉得本质上就是因为partia...](https://kexue.fm/archives/10122/comment-page-1#comment-27834)
- [苏剑林: 首先，瞬时速度为什么跟$t$无关？其次，现在reflow和me...](https://kexue.fm/archives/10958/comment-page-1#comment-27833)
- [苏剑林: 对于每一步数据都严格对齐来说，0.01的loss差距不小了，因...](https://kexue.fm/archives/10907/comment-page-2#comment-27832)
- [苏剑林: \[comment=27808\]rpsun\[/comment\]\
...](https://kexue.fm/archives/10699/comment-page-1#comment-27831)
- [苏剑林: 自己都没怎么关注天象了，惭愧](https://kexue.fm/archives/1490/comment-page-1#comment-27830)
- [苏剑林: 原来如此。其实只要预测空间是连续空间，并且任务本质是一对多的输...](https://kexue.fm/archives/10958/comment-page-1#comment-27829)
- [苏剑林: 你可以拿一批语料去eval，看各个expert分别激活了多少次呀。](https://kexue.fm/archives/10945/comment-page-1#comment-27828)
- [苏剑林: 首先这个分布肯定是存在的（贝叶斯公式无关分布），然后它的概率密...](https://kexue.fm/archives/9164/comment-page-4#comment-27827)
- [苏剑林: 这两天看了下FoPE，感觉它的分析有点道理，但它实现的代码跟论...](https://kexue.fm/archives/10907/comment-page-2#comment-27826)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) [信息时代](https://kexue.fm/category/Big-Data) Adam的epsilon如何影响学习率的Scaling Law？

18Nov

# [Adam的epsilon如何影响学习率的Scaling Law？](https://kexue.fm/archives/10563)

By 苏剑林 \|
2024-11-18 \|
24688位读者\|

上一篇文章 [《当Batch Size增大时，学习率该如何随之变化？》](https://kexue.fm/archives/10542) 我们从多个角度讨论了学习率与Batch Size之间的缩放规律，其中对于Adam优化器我们采用了SignSGD近似，这是分析Adam优化器常用的手段。那么一个很自然的问题就是：用SignSGD来近似Adam究竟有多科学呢？

我们知道，Adam优化器的更新量分母会带有一个$\\epsilon$，初衷是预防除零错误，所以其值通常很接近于零，以至于我们做理论分析的时候通常选择忽略掉它。然而，当前LLM的训练尤其是低精度训练，我们往往会选择偏大的$\\epsilon$，这导致在训练的中、后期$\\epsilon$往往已经超过梯度平方大小，所以$\\epsilon$的存在事实上已经不可忽略。

因此，这篇文章我们试图探索$\\epsilon$如何影响Adam的学习率与Batch Size的Scaling Law，为相关问题提供一个参考的计算方案。

## SoftSign [\#](https://kexue.fm/archives/10563\#SoftSign)

由于是接着上一篇文章介绍，所以就不再重复相关背景了。为了探究$\\epsilon$的作用，我们从SignSGD换到SoftSignSGD，即$\\tilde{\\boldsymbol{u}}\_B = \\text{sign}(\\tilde{\\boldsymbol{g}}\_B)$变成$\\tilde{\\boldsymbol{u}}\_B = \\text{softsign}(\\tilde{\\boldsymbol{g}}\_B)$，其中
\\begin{equation}\\text{sign}(x)=\\frac{x}{\\sqrt{x^2}}\\quad\\to\\quad\\text{softsign}(x, \\epsilon)=\\frac{x}{\\sqrt{x^2+\\epsilon^2}}\\end{equation}
这个形式无疑更贴近更贴近Adam。但在此之前，我们需要确认$\\epsilon$是否真的不可忽略，才能确定是否有进一步研究的价值。

在Keras的Adam实现中，$\\epsilon$的默认值是$10^{-7}$，在Torch中则是$10^{-8}$，这时候梯度绝对值小于$\\epsilon$几率还不算大；但在LLM中，$\\epsilon$的普遍取值是$10^{-5}$（比如 [LLAMA2](https://papers.cool/arxiv/2307.09288)），当训练进入“正轨”后，梯度绝对值小于$\\epsilon$的分量将会很普遍了，所以$\\epsilon$的影响是显著的。

这个跟LLM的参数量也有一定关系。一个能稳定训练的模型，不管参数量多大，它的梯度模长大小大致都在同一数量级，这是反向传播的稳定性决定的（参考 [《训练1000层的Transformer究竟有什么困难？》](https://kexue.fm/archives/8978)）。因此，参数量越大的模型，平均下来每个参数的梯度绝度值就相对变小了，从而$\\epsilon$的作用就更突出了。

值得指出的是，$\\epsilon$的引入实际上提供了Adam与SGD之间的一个插值，这是因为当$x\\neq 0$时
\\begin{equation}\\lim\_{\\epsilon\\to \\infty}\\epsilon\\,\\text{softsign}(x, \\epsilon)=\\lim\_{\\epsilon\\to \\infty}\\frac{x \\epsilon}{\\sqrt{x^2+\\epsilon^2}} = x\\end{equation}
所以，$\\epsilon$越大，Adam表现越接近SGD。

（ **注：** 本文SoftSign的概念，源于笔者跟MSR的刘力源老师、董城昱同学的一个ongoing collaboration，经我们商量一致后先把这部分结果分享出来，更多后续结论敬请持续关注。）

## S型近似 [\#](https://kexue.fm/archives/10563\#S%E5%9E%8B%E8%BF%91%E4%BC%BC)

确认了引入$\\epsilon$必要性后，我们着手开始分析。在分析过程中，我们将会反复遇到S型函数，所以还有一个准备工作是探究S型函数的简单近似。

S型函数相比大家已经见怪不怪，上一节引入的$\\text{softsign}$函数本身就是之一，上一篇文章分析过程中的$\\text{erf}$函数也是一例，此外还有$\\tanh$、$\\text{sigmoid}$等。接下来我们处理的是满足如下特性的S型函数$S(x)$：

> 1、全局光滑且单调递增；
>
> 2、奇函数，值域是$\[-1,1\]$；
>
> 3、在原点处斜率为$k > 0$。

对于这类函数，我们考虑两种近似。第一种近似跟$\\text{softsign}$类似：
\\begin{equation}S(x)\\approx \\frac{x}{\\sqrt{x^2 + 1/k^2}}\\end{equation}
它大概是保留$S(x)$如上3点性质的最简单函数了；第二种近似是基于$\\text{clip}$函数：
\\begin{equation}S(x)\\approx \\text{clip}(kx, -1, 1) \\triangleq \\left\\{\\begin{aligned}&1, &kx\\geq 1 \\\
&kx, &-1 < kx < 1\\\
&-1, &kx \\leq -1\\end{aligned}\\right.\\end{equation}
这本质上是一个分段线性函数，放弃了全局光滑的性质，但分段线性会使得积分算起来更容易，我们很快就会看到这一点。

Erf函数与它的两种近似

## 均值估计 [\#](https://kexue.fm/archives/10563\#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1)

事不宜迟，沿着上一篇文章的方法，出发点还是
\\begin{equation}\\mathbb{E}\[\\mathcal{L}(\\boldsymbol{\\theta} - \\eta\\tilde{\\boldsymbol{u}}\_B)\] \\approx \\mathcal{L}(\\boldsymbol{\\theta}) - \\eta\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\]^{\\top}\\boldsymbol{g} + \\frac{1}{2}\\eta^2 \\text{Tr}(\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\\tilde{\\boldsymbol{u}}\_B^{\\top}\]\\boldsymbol{H})\\end{equation}
我们需要做的事情就是估计$\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\]$和$\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\\tilde{\\boldsymbol{u}}\_B^{\\top}\]$。

这一节我们算的是$\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\]$，为此我们需要用$\\text{clip}$函数去近似$\\text{softsign}$函数：
\\begin{equation}\\text{softsign}(x, \\epsilon)\\approx \\text{clip}(x/\\epsilon, -1, 1) = \\left\\{\\begin{aligned}&1, & x/\\epsilon \\geq 1 \\\
& x / \\epsilon, & -1 < x/\\epsilon < 1 \\\
&-1, & x/\\epsilon \\leq -1 \\\
\\end{aligned}\\right.\\end{equation}
然后我们有
\\begin{equation}\\begin{aligned}
\\mathbb{E}\[\\tilde{u}\_B\] =&\\, \\mathbb{E}\[\\text{softsign}(g + \\sigma z/\\sqrt{B}, \\epsilon)\] \\approx \\mathbb{E}\[\\text{clip}(g/\\epsilon + \\sigma z/\\epsilon\\sqrt{B},-1, 1)\] \\\\[5pt\]
=&\\,\\frac{1}{\\sqrt{2\\pi}}\\int\_{-\\infty}^{\\infty} \\text{clip}(g/\\epsilon + \\sigma z/\\epsilon\\sqrt{B},-1, 1) e^{-z^2/2}dz \\\\[5pt\]
=&\\,\\frac{1}{\\sqrt{2\\pi}}\\int\_{-\\infty}^{-(g+\\epsilon)\\sqrt{B}/\\sigma} (-1)\\times e^{-z^2/2}dz + \\frac{1}{\\sqrt{2\\pi}}\\int\_{-(g-\\epsilon)\\sqrt{B}/\\sigma}^{\\infty} 1\\times e^{-z^2/2}dz \\\\[5pt\]
&\\,\\qquad\\qquad + \\frac{1}{\\sqrt{2\\pi}}\\int\_{-(g+\\epsilon)\\sqrt{B}/\\sigma}^{-(g-\\epsilon)\\sqrt{B}/\\sigma} (g/\\epsilon + \\sigma z/\\epsilon\\sqrt{B})\\times e^{-z^2/2}dz
\\end{aligned}\\end{equation}
积分形式很复杂，但用Mathematica算并不难，结果可以用$\\text{erf}$函数表达出来：
\\begin{equation}\\frac{1}{2}\\left\[\\text{erf}\\left(\\frac{a+b}{\\sqrt{2}}\\right)+\\text{erf}\\left(\\frac{a-b}{\\sqrt{2}}\\right)\\right\]+\\frac{a}{2b}\\left\[\\text{erf}\\left(\\frac{a+b}{\\sqrt{2}}\\right)-\\text{erf}\\left(\\frac{a-b}{\\sqrt{2}}\\right)\\right\]+\\frac{e^{-(a+b)^2/2} - e^{-(a-b)^2/2}}{b\\sqrt{2\\pi}}\\end{equation}
其中$a = g\\sqrt{B}/\\sigma, b=\\epsilon \\sqrt{B}/\\sigma$。这个函数看起来比较复杂，但它刚好是$a$的S型函数，值域为$(-1,1)$且在$a=0$处的斜率是$\\text{erf}(b/\\sqrt{2})/b$，所以利用第一种近似形式
\\begin{equation}\\mathbb{E}\[\\tilde{u}\_B\]\\approx\\frac{a}{\\sqrt{a^2 + b^2 / \\text{erf}(b/\\sqrt{2})^2}}\\approx \\frac{a}{\\sqrt{a^2 + b^2 + \\pi / 2}}=\\frac{g/\\sigma}{\\sqrt{(g^2+\\epsilon^2)/\\sigma^2 + \\pi / 2B}}\\label{eq:E-u-approx}\\end{equation}
第二个约等号是利用近似$\\text{erf}(x)\\approx x / \\sqrt{x^2 + \\pi / 4}$来处理分母中的$\\text{erf}(b/\\sqrt{2})$。可以说相当幸运，最终的形式并没有太复杂。接着我们有
\\begin{equation}\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\]\_i \\approx \\frac{g\_i/\\sigma\_i}{\\sqrt{(g\_i^2+\\epsilon^2)/\\sigma\_i^2 + \\pi / 2B}} = \\frac{\\text{softsign}(g\_i, \\epsilon)}{\\sqrt{1 + \\pi \\sigma\_i^2 /(g\_i^2+\\epsilon^2)/2B}}\\approx \\frac{\\text{softsign}(g\_i, \\epsilon)}{\\sqrt{1 + \\pi \\kappa^2/2B}} = u\_i \\beta\\end{equation}
跟上一篇文章一样，最后一个约等号使用了平均场近似，$\\kappa^2$是全体$\\sigma\_i^2 /(g\_i^2+\\epsilon^2)$的某种平均，而$u\_i = \\text{softsign}(g\_i, \\epsilon)$以及$\\beta = (1 + \\pi\\kappa^2 / 2B)^{-1/2}$。

## 方差估计 [\#](https://kexue.fm/archives/10563\#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1)

均值也就是一阶矩解决了，现在轮到二阶矩了
\\begin{equation}\\begin{aligned}
\\mathbb{E}\[\\tilde{u}\_B^2\] =&\\, \\mathbb{E}\[\\text{softsign}(g + \\sigma z/\\sqrt{B}, \\epsilon)^2\] \\approx \\mathbb{E}\[\\text{clip}(g/\\epsilon + \\sigma z/\\epsilon\\sqrt{B},-1, 1)^2\] \\\\[5pt\]
=&\\,\\frac{1}{\\sqrt{2\\pi}}\\int\_{-\\infty}^{\\infty} \\text{clip}(g/\\epsilon + \\sigma z/\\epsilon\\sqrt{B},-1, 1)^2 e^{-z^2/2}dz \\\\[5pt\]
=&\\,\\frac{1}{\\sqrt{2\\pi}}\\int\_{-\\infty}^{-(g+\\epsilon)\\sqrt{B}/\\sigma} (-1)^2\\times e^{-z^2/2}dz + \\frac{1}{\\sqrt{2\\pi}}\\int\_{-(g-\\epsilon)\\sqrt{B}/\\sigma}^{\\infty} 1^2\\times e^{-z^2/2}dz \\\\[5pt\]
&\\,\\qquad\\qquad + \\frac{1}{\\sqrt{2\\pi}}\\int\_{-(g+\\epsilon)\\sqrt{B}/\\sigma}^{-(g-\\epsilon)\\sqrt{B}/\\sigma} (g/\\epsilon + \\sigma z/\\epsilon\\sqrt{B})^2\\times e^{-z^2/2}dz
\\end{aligned}\\end{equation}
结果同样可以用$\\text{erf}$函数表示，但更加冗长，这里就不写出来了，还是那句话，对Mathematica来说这都不是事。视为$a$的函数时，可以发现结果是一条倒钟形的曲线，关于$y$轴对称，上界是$1$，最小值是则在$(0,1)$内。参考$\\mathbb{E}\[\\tilde{u}\_B\]$的近似式$\\eqref{eq:E-u-approx}$，我们选择如下近似
\\begin{equation}\\mathbb{E}\[\\tilde{u}\_B^2\] \\approx 1 - \\frac{b^2}{a^2 + b^2 + \\pi / 2} = 1 - \\frac{\\epsilon^2/(g^2+\\epsilon^2)}{1 + \\pi\\sigma^2/(g^2+\\epsilon^2) / 2B}\\end{equation}
有一说一，这个近似的精度并不高，主要是为了计算的方便，但它已经保留了倒钟形、$y$轴对称、上界为1、$b=0$时结果为1、$b\\to\\infty$结果则为0等关键特性。接下来继续应用平均场近似：
\\begin{equation}\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\\tilde{\\boldsymbol{u}}\_B^{\\top}\]\_{i,i} \\approx 1 - \\frac{\\epsilon^2/(g\_i^2+\\epsilon^2)}{1 + \\pi\\sigma\_i^2/(g\_i^2+\\epsilon^2) / 2B}\\approx 1 - \\frac{\\epsilon^2/(g\_i^2+\\epsilon^2)}{1 + \\pi\\kappa^2 / 2B} = u\_i^2 \\beta^2 + (1 - \\beta^2)\\end{equation}
所以$\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\\tilde{\\boldsymbol{u}}\_B^{\\top}\]\_{i,j}\\approx u\_i u\_j \\beta^2 + \\delta\_{i,j}(1-\\beta^2)$。其中$\\delta\_{i,j}(1-\\beta^2)$这一项就代表了$\\tilde{\\boldsymbol{u}}$的协方差矩阵$(1-\\beta^2)\\boldsymbol{I}$，它是一个对角阵，这是可以预料的，因为我们的假设之一是$\\tilde{\\boldsymbol{u}}$各分量之间的独立性，所以协方差矩阵必然是对角阵。

## 结果初探 [\#](https://kexue.fm/archives/10563\#%E7%BB%93%E6%9E%9C%E5%88%9D%E6%8E%A2)

由此我们得到
\\begin{equation}\\eta^\* \\approx \\frac{\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\]^{\\top}\\boldsymbol{g}}{\\text{Tr}(\\mathbb{E}\[\\tilde{\\boldsymbol{u}}\_B\\tilde{\\boldsymbol{u}}\_B^{\\top}\]\\boldsymbol{H})} \\approx \\frac{\\beta\\sum\_i u\_i g\_i}{\\beta^2\\sum\_{i,j} u\_i u\_j H\_{i,j} + (1-\\beta^2)\\sum\_i H\_{i,i} }\\end{equation}
注意，除了$\\beta$外，剩余的其他符号都不依赖于$B$，所以上式已经给出$\\eta^\*$与$B$的依赖关系。注意为了保证极小值的存在性，我们都会假设$\\boldsymbol{H}$矩阵的正定性，而在此假设之下必然有$\\sum\_{i,j} u\_i u\_j H\_{i,j} > 0$和$\\sum\_i H\_{i,i} > 0$。

上一篇文章我们说Adam最重要的特性是可能会出现“Surge现象”，即$\\eta^\*$关于$B$不再是全局的单调递增函数。接下来我们将会证明，$\\epsilon > 0$的引入会降低Surge现象出现的几率，并且$\\epsilon \\to \\infty$时完全消失。这个证明并不难，很明显Surge现象出现的必要条件是
\\begin{equation}\\sum\_{i,j} u\_i u\_j H\_{i,j} - \\sum\_i H\_{i,i} > 0\\end{equation}
若否，整个$\\eta^\*$关于$\\beta$便是单调递增的，而$\\beta$关于$B$是单调递增的，所以整个$\\eta^\*$关于$B$单调递增，不存在Surge现象。别忘了$u\_i = \\text{softsign}(g\_i, \\epsilon)$是关于$\\epsilon$的单调递减函数，所以当$\\epsilon$增大时$\\sum\_{i,j} u\_i u\_j H\_{i,j}$会更小，从而上述不等式成立的可能性更低，并且$\\epsilon\\to \\infty$时$u\_i$为零，上述不等式不可能再成立，因此Surge现象消失。

进一步，我们可以证明$\\epsilon\\to\\infty$时，结果跟SGD的一致，这只需要留意到
\\begin{equation}\\frac{\\eta^\*}{\\epsilon} \\approx \\frac{\\beta\\sum\_i (\\epsilon u\_i) g\_i}{\\beta^2\\sum\_{i,j} (\\epsilon u\_i)(\\epsilon u\_j) H\_{i,j} + \\epsilon^2(1-\\beta^2)\\sum\_i H\_{i,i} }\\end{equation}
我们有极限
\\begin{equation}\\lim\_{\\epsilon\\to\\infty} \\beta = 1,\\quad\\lim\_{\\epsilon\\to\\infty} \\epsilon u\_i = g\_i, \\quad \\lim\_{\\epsilon\\to\\infty} \\epsilon^2(1-\\beta^2) = \\pi \\sigma^2 / 2B\\end{equation}
这里$\\sigma^2$是全体$\\sigma\_i^2$的某种平均。于是我们得到当$\\epsilon$足够大时有近似
\\begin{equation}\\frac{\\eta^\*}{\\epsilon} \\approx \\frac{\\sum\_i g\_i^2}{\\sum\_{i,j} g\_i g\_j H\_{i,j} + \\left(\\pi \\sigma^2\\sum\_i H\_{i,i}\\right)/2B }\\end{equation}
右端就是假设梯度协方差矩阵为$(\\pi\\sigma^2/2B)\\boldsymbol{I}$时的SGD结果。

## 文章小结 [\#](https://kexue.fm/archives/10563\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文延续了上一篇文章的方法，尝试分析了Adam的$\\epsilon$对学习率与Batch Size之间的Scaling Law的影响，结果是一个介乎SGD与SignSGD之间的形式，当$\\epsilon$越大，结果越接近SGD，“Surge现象”出现的概率就越低。总的来说，计算结果没有特别让人意外之处，但可以作为分析$\\epsilon$作用的一个参考过程。

_**转载到请包括本文地址：** [https://kexue.fm/archives/10563](https://kexue.fm/archives/10563)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/10563#share)/ [打赏](https://kexue.fm/archives/10563#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Nov. 18, 2024). 《Adam的epsilon如何影响学习率的Scaling Law？ 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/10563](https://kexue.fm/archives/10563)

@online{kexuefm-10563,
        title={Adam的epsilon如何影响学习率的Scaling Law？},
        author={苏剑林},
        year={2024},
        month={Nov},
        url={\\url{https://kexue.fm/archives/10563}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics), [信息时代](https://kexue.fm/category/Big-Data)    标签： [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/), [学习率](https://kexue.fm/tag/%E5%AD%A6%E4%B9%A0%E7%8E%87/), [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/), [尺度定律](https://kexue.fm/tag/%E5%B0%BA%E5%BA%A6%E5%AE%9A%E5%BE%8B/)[4 评论](https://kexue.fm/archives/10563#comments)

< [当Batch Size增大时，学习率该如何随之变化？](https://kexue.fm/archives/10542) \| [生成扩散模型漫谈（二十六）：基于恒等式的蒸馏（下）](https://kexue.fm/archives/10567) >

### 你也许还对下面的内容感兴趣

- [msign算子的Newton-Schulz迭代（下）](https://kexue.fm/archives/10996)
- [msign算子的Newton-Schulz迭代（上）](https://kexue.fm/archives/10922)
- [SVD的导数](https://kexue.fm/archives/10878)
- [通过梯度近似寻找Normalization的替代品](https://kexue.fm/archives/10831)
- [MoE环游记：4、难处应当多投入](https://kexue.fm/archives/10815)
- [高阶muP：更简明但更高明的谱条件缩放](https://kexue.fm/archives/10795)
- [初探muP：超参数的跨模型尺度迁移规律](https://kexue.fm/archives/10770)
- [MoE环游记：3、换个思路来分配](https://kexue.fm/archives/10757)
- [Muon续集：为什么我们选择尝试Muon？](https://kexue.fm/archives/10739)
- [MoE环游记：2、不患寡而患不均](https://kexue.fm/archives/10735)

[发表你的看法](https://kexue.fm/archives/10563#comment_form)

王小白

January 8th, 2025

请教苏老师，如果训练过程中梯度变小，接近甚至小于epsilon后，我发现这时候直接降低epsilon，会导致loss先增后降（低于原来水平），猜测loss的增加是因为epsilon降低引起等效“学习率”增加导致，有更好的热切策略能让loss不增加嘛？

[回复评论](https://kexue.fm/archives/10563/comment-page-1?replyTo=26210#respond-post-10563)

[苏剑林](https://kexue.fm) 发表于
January 13th, 2025

采用LAMB optiizer的策略？按weight norm来缩放update。

[回复评论](https://kexue.fm/archives/10563/comment-page-1?replyTo=26250#respond-post-10563)

sam

January 18th, 2025

苏神能解读下这篇文章吗 Scaling Laws for Floating Point Quantization Training

[回复评论](https://kexue.fm/archives/10563/comment-page-1?replyTo=26295#respond-post-10563)

[苏剑林](https://kexue.fm) 发表于
January 20th, 2025

暂不在兴趣范围内

[回复评论](https://kexue.fm/archives/10563/comment-page-1?replyTo=26343#respond-post-10563)

[取消回复](https://kexue.fm/archives/10563#respond-post-10563)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[SoftSign](https://kexue.fm/archives/10563#SoftSign)
[S型近似](https://kexue.fm/archives/10563#S%E5%9E%8B%E8%BF%91%E4%BC%BC)
[均值估计](https://kexue.fm/archives/10563#%E5%9D%87%E5%80%BC%E4%BC%B0%E8%AE%A1)
[方差估计](https://kexue.fm/archives/10563#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A1)
[结果初探](https://kexue.fm/archives/10563#%E7%BB%93%E6%9E%9C%E5%88%9D%E6%8E%A2)
[文章小结](https://kexue.fm/archives/10563#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [几何-算术均值不等式的一般证明](https://kexue.fm/archives/96)
- [《方程与宇宙》：三体问题和它的初积分(六)](https://kexue.fm/archives/1181)
- [当大数据进入厨房：让大数据教你做菜！](https://kexue.fm/archives/3587)
- [当概率遇上复变：随机游走与路径积分](https://kexue.fm/archives/2609)
- [用开源的人工标注数据来增强RoFormer-Sim](https://kexue.fm/archives/8541)
- [“二体+恒力”问题](https://kexue.fm/archives/1358)
- [变分自编码器（三）：这样做为什么能成？](https://kexue.fm/archives/5383)
- [修改了一下公式的显示方式（移动端）](https://kexue.fm/archives/3576)
- [世界各国能否联手应对气候变化？](https://kexue.fm/archives/81)
- [文本情感分类（四）：更好的损失函数](https://kexue.fm/archives/4293)

### 最近评论

- [苏剑林](https://kexue.fm/archives/481/comment-page-1#comment-27835): 刚入门那会的文章，不用深究了。
- [苏剑林](https://kexue.fm/archives/10122/comment-page-1#comment-27834): 目前各方面的实测效果看来不会，我觉得本质上就是因为partial rope的实测效果优于rop...
- [苏剑林](https://kexue.fm/archives/10958/comment-page-1#comment-27833): 首先，瞬时速度为什么跟$t$无关？其次，现在reflow和meanflow的第一、第二目标，不...
- [苏剑林](https://kexue.fm/archives/10907/comment-page-2#comment-27832): 对于每一步数据都严格对齐来说，0.01的loss差距不小了，因为它代表了每一个step的los...
- [苏剑林](https://kexue.fm/archives/10699/comment-page-1#comment-27831): \[comment=27808\]rpsun\[/comment\]
有人这样做了：https://a...
- [苏剑林](https://kexue.fm/archives/1490/comment-page-1#comment-27830): 自己都没怎么关注天象了，惭愧
- [苏剑林](https://kexue.fm/archives/10958/comment-page-1#comment-27829): 原来如此。其实只要预测空间是连续空间，并且任务本质是一对多的输出，那么都有可能关联到Diffu...
- [苏剑林](https://kexue.fm/archives/10945/comment-page-1#comment-27828): 你可以拿一批语料去eval，看各个expert分别激活了多少次呀。
- [苏剑林](https://kexue.fm/archives/9164/comment-page-4#comment-27827): 首先这个分布肯定是存在的（贝叶斯公式无关分布），然后它的概率密度对数是二次函数形式，概率密度的...
- [苏剑林](https://kexue.fm/archives/10907/comment-page-2#comment-27826): 这两天看了下FoPE，感觉它的分析有点道理，但它实现的代码跟论文其实是不一样的。看论文的描述，...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。