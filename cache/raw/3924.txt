![MobileSideBar](https://kexue.fm/usr/themes/geekg/images/slide-button.png)

## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [让炼丹更科学一些（五）：基于梯度精...](https://kexue.fm/archives/11530)
- [让炼丹更科学一些（四）：新恒等式，...](https://kexue.fm/archives/11494)
- [为什么DeltaNet要加L2 N...](https://kexue.fm/archives/11486)
- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)

## COMMENTS

- [Bin: 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院...](https://kexue.fm/archives/1990/comment-page-2#comment-29105)
- [Rapture D: 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。](https://kexue.fm/archives/11530/comment-page-1#comment-29104)
- [mofheka: 苏神是还在用jax是么？最近在做基于Google Pathwa...](https://kexue.fm/archives/11390/comment-page-1#comment-29103)
- [长琴: 看懂这篇博客也不是一件容易的事情。](https://kexue.fm/archives/11530/comment-page-1#comment-29102)
- [AlexLi: 苏老师，请教一下(7)式中将 $\\mu(x\_t)$ 传给 $p...](https://kexue.fm/archives/9257/comment-page-4#comment-29101)
- [tyler\_zxc: "Performer的思想是将标准的Attention线性化，...](https://kexue.fm/archives/7921/comment-page-2#comment-29100)
- [我: 似乎并非mHC提出矩阵的思想？之前hyper connecti...](https://kexue.fm/archives/11494/comment-page-1#comment-29099)
- [winter: 苏神您好，假如对于比较均匀的attention weightP...](https://kexue.fm/archives/10847/comment-page-1#comment-29098)
- [苏剑林: KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个](https://kexue.fm/archives/8512/comment-page-2#comment-29097)
- [苏剑林: 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理...](https://kexue.fm/archives/9119/comment-page-14#comment-29096)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm/)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [![](https://kexue.fm/usr/themes/geekg/images/rss.png)\\
\\
欢迎订阅](https://kexue.fm/feed)
- [![](https://kexue.fm/usr/themes/geekg/images/mail.png)\\
\\
个性邮箱](https://kexue.fm/archives/119)
- [![](https://kexue.fm/usr/themes/geekg/images/Saturn.png)\\
\\
天象信息](https://kexue.fm/ac.html)
- [![](https://kexue.fm/usr/themes/geekg/images/iss.png)\\
\\
观测ISS](https://kexue.fm/archives/41)
- [![](https://kexue.fm/usr/themes/geekg/images/pi.png)\\
\\
LaTeX](https://kexue.fm/latex.html)
- [![](https://kexue.fm/usr/themes/geekg/images/mlogo.png)\\
\\
关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm/) [信息时代](https://kexue.fm/category/Big-Data) 【中文分词系列】 4\. 基于双向LSTM的seq2seq字标注

22Aug

# [【中文分词系列】 4\. 基于双向LSTM的seq2seq字标注](https://kexue.fm/archives/3924)

By 苏剑林 \|
2016-08-22 \|
600706位读者 \|

### 关于字标注法 [\#](https://kexue.fm/archives/3924\#%E5%85%B3%E4%BA%8E%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%95)

上一篇文章谈到了分词的字标注法。要注意字标注法是很有潜力的，要不然它也不会在公开测试中取得最优的成绩了。在我看来，字标注法有效有两个主要的原因，第一个原因是它将分词问题变成了一个序列标注问题，而且这个标注是对齐的，也就是输入的字跟输出的标签是一一对应的，这在序列标注中是一个比较成熟的问题；第二个原因是这个标注法实际上已经是一个总结语义规律的过程，以4tag标注为为例，我们知道，“李”字是常用的姓氏，一半作为多字词（人名）的首字，即标记为b；而“想”由于“理想”之类的词语，也有比较高的比例标记为e，这样一来，要是“李想”两字放在一起时，即便原来词表没有“李想”一词，我们也能正确输出be，也就是识别出“李想”为一个词，也正是因为这个原因，即便是常被视为最不精确的HMM模型也能起到不错的效果。

关于标注，还有一个值得讨论的内容，就是标注的数目。常用的是4tag，事实上还有6tag和2tag，而标记分词结果最简单的方法应该是2tag，即标记“切分/不切分”就够了，但效果不好。为什么反而更多数目的tag效果更好呢？因为更多的tag实际上更全面概括了语义规律。比如，用4tag标注，我们能总结出哪些字单字成词、哪些字经常用作开头、哪些字用作末尾，但仅仅用2tag，就只能总结出哪些字经常用作开头，从归纳的角度来看，是不够全面的。但6tag跟4tag比较呢？我觉得不一定更好，6tag的意思是还要总结出哪些字作第二字、第三字，但这个总结角度是不是对的？我觉得，似乎并没有哪些字固定用于第二字或者第三字的，这个规律的总结性比首字和末字的规律弱多了（不过从新词发现的角度来看，6tag更容易发现长词。）。

### 双向LSTM [\#](https://kexue.fm/archives/3924\#%E5%8F%8C%E5%90%91LSTM)

关于双向LSTM，理解的思路是：双向LSTM是LSTM的改进版，LSTM是RNN的改进版。因此，首先需要理解RNN。

笔者曾在拙作 [《从Boosting学习到神经网络：看山是山？》](https://kexue.fm/archives/3873/) 说到过，模型的输出结果，事实上也是一种特征，也可以作为模型的输入来用，RNN正是这样的网络结构。普通的多层神经网络，是一个输入到输出的单向传播过程。如果涉及到高维输入，也可以这样做，但节点太多，不容易训练，也容易过拟合。比如图像输入是1000x1000的，难以直接处理，这就有了CNN；又或者1000词的句子，每个词用100维的词向量，那么输入维度也不小，这时候，解决这个问题的一个方案是RNN（CNN也可以用，但RNN更适合用于序列问题。）。

[![RNN的过程](https://kexue.fm/usr/uploads/2016/08/2787554479.png)](https://kexue.fm/usr/uploads/2016/08/2787554479.png "点击查看原图")

RNN的过程

**RNN的意思是，为了预测最后的结果，我先用第一个词预测，当然，只用第一个预测的预测结果肯定不精确，我把这个结果作为特征，跟第二词一起，来预测结果；接着，我用这个新的预测结果结合第三词，来作新的预测；然后重复这个过程；直到最后一个词。这样，如果输入有n个词，那么我们事实上对结果作了n次预测，给出了n个预测序列。整个过程中，模型共享一组参数。因此，RNN降低了模型的参数数目，防止了过拟合，同时，它生来就是为处理序列问题而设计的，因此，特别适合处理序列问题。**

LSTM对RNN做了改进，使得能够捕捉更长距离的信息。但是不管是LSTM还是RNN，都有一个问题，它是从左往右推进的，因此后面的词会比前面的词更重要，但是对于分词这个任务来说是不妥的，因为句子各个字应该是平权的。因此出现了双向LSTM，它从左到右做一次LSTM，然后从右到左做一次LSTM，然后把两次结果组合起来。

### 在分词任务中的应用 [\#](https://kexue.fm/archives/3924\#%E5%9C%A8%E5%88%86%E8%AF%8D%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8)

关于深度学习与分词，很早就有人尝试过了，比如下列文章：

[http://blog.csdn.net/itplus/article/details/13616045](http://blog.csdn.net/itplus/article/details/13616045)

[https://github.com/xccds/chinese\_wordseg\_keras](https://github.com/xccds/chinese_wordseg_keras)

[http://www.leiphone.com/news/201608/IWvc75oJglAIsDvJ.html](http://www.leiphone.com/news/201608/IWvc75oJglAIsDvJ.html)

这些文章中，不管是用简单的神经网络还是LSTM，它们的做法都跟传统模型是一样的，都是通过上下文来预测当前字的标签，这里的上下文是固定窗口的，比如用前后5个字加上当前字来预测当前字的标签。这种做法没有什么不妥之处，但仅仅是把以往估计概率的方法，如HMM、ME、CRF等，换为了神经网络而已，整个框架是没变的， **本质上还是n-gram模型**。而有了LSTM，LSTM本身可以做序列到序列（seq2seq）的输出，因此，为什么不直接输出原始句子的序列呢？这样不就真正利用了全文信息了吗？这就是本文的尝试。

LSTM可以根据输入序列输出一个序列，这个序列考虑了上下文的联系，因此，可以给每个输出序列接一个softmax分类器，来预测每个标签的概率。基于这个序列到序列的思路，我们就可以直接预测句子的标签。

### Keras实现 [\#](https://kexue.fm/archives/3924\#Keras%E5%AE%9E%E7%8E%B0)

事不宜迟，动手最重要。词向量维度用了128，句子长度截断为32（抛弃了多于32字的样本，这部分样本很少，事实上，用逗号、句号等天然分隔符分开后，句子很少有多于32字的。）。这次我用了5tag，在原来的4tag的基础上，加上了一个x标签，用来表示不够32字的部分，比如句子是20字的，那么第21～32个标签均为x。

在数据方面，我用了 [Bakeoff 2005](http://sighan.cs.uchicago.edu/bakeoff2005/) 的语料中微软亚洲研究院（Microsoft Research）提供的部分。代码如下，如果有什么不清晰的地方，欢迎留言。

```python

```

我们可以用model.summary()看一下模型的结构。

> >>\> model.summary()
>
> \\_\\_\\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
>
> Layer (type) Output Shape Param # Connected to
>
> =======================================================
>
> input\_2 (InputLayer) (None, 32) 0
>
> \\_\\_\\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
>
> embedding\_2 (Embedding) (None, 32, 128) 660864 input\_2\[0\]\[0\]
>
> \\_\\_\\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
>
> bidirectional\_1 (Bidirectional) (None, 32, 64) 98816 embedding\_2\[0\]\[0\]
>
> \\_\\_\\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
>
> timedistributed\_2 (TimeDistribute) (None, 32, 5) 325 bidirectional\_1\[0\]\[0\]
>
> =======================================================
>
> Total params: 760005
>
> \\_\\_\\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

最终的模型结果如何？我不打算去对比那些评测结果了，现在的模型在测试上达到90%以上的准确率不是什么难事。我关心的是对新词的识别和对歧义的处理。下面是一些测试结果（随便选的）：

> RNN 的 意思 是 ， 为了 预测 最后 的 结果 ， 我 先 用 第一个 词 预测 ， 当然 ， 只 用 第一个 预测 的 预测 结果 肯定 不 精确 ， 我 把 这个 结果 作为 特征 ， 跟 第二词 一起 ， 来 预测 结果 ； 接着 ， 我 用 这个 新 的 预测 结果 结合 第三词 ， 来 作 新 的 预测 ； 然后 重复 这个 过程 。
>
> 结婚 的 和 尚未 结婚 的
>
> 苏剑林 是 科学 空间 的 博主 。
>
> 广东省 云浮市 新兴县
>
> 魏则西 是 一 名 大学生
>
> 这 真是 不堪入目 的 环境
>
> 列夫·托尔斯泰 是 俄罗斯 一 位 著名 的 作家
>
> 保加利亚 首都 索非亚 是 全国 政治 、 经济 、 文化中心 ， 位于 保加利亚 中 西部
>
> 罗斯福 是 第二次世界大战 期间 同 盟国 阵营 的 重要 领导人 之一 。 1941 年 珍珠港 事件发生 后 ， 罗斯 福力 主对 日本 宣战 ， 并 引进 了 价格 管制 和 配给 。 罗斯福 以 租 借 法案 使 美国 转变 为 “ 民主 国家 的 兵工厂 ” ， 使 美国 成为 同 盟国 主要 的 军火 供应商 和 融资 者 ， 也 使得 美国 国内 产业 大幅 扩张 ， 实现 充分 就业 。 二战 后期 同 盟国 逐渐 扭转 形势 后 ， 罗斯福 对 塑造 战后 世界 秩序 发挥 了 关键 作用 ， 其 影响 力 在 雅尔塔 会议 及 联合国 的 成立 中 尤其 明显 。 后来 ， 在 美国 协助 下 ， 盟军 击败 德国 、 意大利 和 日本 。

可以发现，测试结果是很乐观的。不论是人名（中国人名或外国人名）还是地名，识别效果都很好。关于这个模型，目前就说到这里，以后会继续深入的。

### 最后 [\#](https://kexue.fm/archives/3924\#%E6%9C%80%E5%90%8E)

事实上本文是提供了一个框架，能够直接通过双向LSTM对序列进行标注，给出完整的标注序列。这种标注的思路，可以用于很多任务，如词性标注、实体识别，因此，基于双向LSTM的seq2seq标注思路，有很广的应用，值得研究。甚至最近热门的深度学习的机器翻译，都是用这种序列到序列的模型实现的。

[msr\_train.txt.zip](https://kexue.fm/usr/uploads/2016/10/1372394625.zip)

_**转载到请包括本文地址：** [https://kexue.fm/archives/3924](https://kexue.fm/archives/3924 "【中文分词系列】 4. 基于双向LSTM的seq2seq字标注")_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/3924#share)/ [打赏](https://kexue.fm/archives/3924#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。

你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Aug. 22, 2016). 《【中文分词系列】 4. 基于双向LSTM的seq2seq字标注 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/3924](https://kexue.fm/archives/3924)

@online{kexuefm-3924,

         title={【中文分词系列】 4. 基于双向LSTM的seq2seq字标注},

         author={苏剑林},

         year={2016},

         month={Aug},

         url={\\url{https://kexue.fm/archives/3924}},

}


分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/), [python](https://kexue.fm/tag/python/), [分词](https://kexue.fm/tag/%E5%88%86%E8%AF%8D/), [自然语言处理](https://kexue.fm/tag/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/)[139 评论](https://kexue.fm/archives/3924#comments)

< [【中文分词系列】 3\. 字标注法与HMM模型](https://kexue.fm/archives/3922 "【中文分词系列】 3. 字标注法与HMM模型") \| [进驻中山大学南校区，折腾校园网](https://kexue.fm/archives/3936 "进驻中山大学南校区，折腾校园网") >

### 你也许还对下面的内容感兴趣

- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390 "n个正态随机数的最大值的渐近估计")
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902 "一道概率不等式：盯着它到显然成立为止！")
- [Softmax后传：寻找Top-K的光滑近似](https://kexue.fm/archives/10373 "Softmax后传：寻找Top-K的光滑近似")
- [通向最优分布之路：概率空间的最小化](https://kexue.fm/archives/10289 "通向最优分布之路：概率空间的最小化")
- [通向概率分布之路：盘点Softmax及其替代品](https://kexue.fm/archives/10145 "通向概率分布之路：盘点Softmax及其替代品")
- [用傅里叶级数拟合一维概率密度函数](https://kexue.fm/archives/10007 "用傅里叶级数拟合一维概率密度函数")
- [旁门左道之如何让Python的重试代码更加优雅](https://kexue.fm/archives/9938 "旁门左道之如何让Python的重试代码更加优雅")
- [随机分词再探：从Viterbi Sampling到完美采样算法](https://kexue.fm/archives/9811 "随机分词再探：从Viterbi Sampling到完美采样算法")
- [EMO：基于最优传输思想设计的分类损失函数](https://kexue.fm/archives/9797 "EMO：基于最优传输思想设计的分类损失函数")
- [随机分词浅探：从Viterbi Decoding到Viterbi Sampling](https://kexue.fm/archives/9768 "随机分词浅探：从Viterbi Decoding到Viterbi Sampling")

[发表你的看法](https://kexue.fm/archives/3924#comment_form)

1. [«](https://kexue.fm/archives/3924/comment-page-4#comments)
2. [1](https://kexue.fm/archives/3924/comment-page-1#comments)
3. [2](https://kexue.fm/archives/3924/comment-page-2#comments)
4. [3](https://kexue.fm/archives/3924/comment-page-3#comments)
5. [4](https://kexue.fm/archives/3924/comment-page-4#comments)
6. [5](https://kexue.fm/archives/3924/comment-page-5#comments)

hyx

August 3rd, 2018

苏老师，您好。

\[\[9.9845850e-01 1.5413527e-03 2.0018293e-08 1.3571930e-07 4.7176268e-08\]\
\
\[9.9696392e-01 4.4201979e-06 6.0934831e-06 3.0253998e-03 2.1210232e-07\]\
\
\[1.6475507e-05 9.9986351e-01 1.2002354e-04 3.5679773e-10 2.2068347e-09\]\
\
\[9.2972536e-05 1.4892615e-08 1.3250505e-04 9.9977452e-01 2.8691925e-08\]\
\
\[1.6979319e-06 9.9998462e-01 1.3749689e-05 9.7263242e-10 8.7142987e-10\]\
\
\[1.6224482e-04 4.9591140e-04 7.2497368e-01 2.7436778e-01 4.5879750e-07\]\
\
\[2.5113603e-01 1.7205605e-06 9.0925908e-04 7.4795258e-01 4.8560918e-07\]\]

\['我', '是', '一', '个', '中', '国', '人'\]

我看predict的数据是正确的，但是最后预测的结果全部都是单个字？不知道是什么原因？

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=9572#respond-post-3924)

hyx 发表于
August 3rd, 2018

paths\[list(nows.keys())\[k\]\] = list(nows.values())\[k\]

return list(paths.keys())\[np.argmax(paths.values())\]

维特比算法的最后两行加了list类型转换，不知道是不是这里错了？但是没有加list也一直报错，我看python2到python3转换需要增加list

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=9573#respond-post-3924)

[苏剑林](https://kexue.fm/) 发表于
August 3rd, 2018

版本切换的问题我不负责，实在是没空调试，抱歉...

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=9576#respond-post-3924)

hyx 发表于
August 3rd, 2018

嗯，还是谢谢您的解答。我自己再调试一下。

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=9577#respond-post-3924)

liyi 发表于
December 18th, 2018

我用python3调试通过了，python3里面dict.values()和dict.keys()返回的是一个迭代器，而不是一个列表。所以np.argmax(paths.values())也要改成np.argmax(list(paths.values()))，不然np.argmax()会返回一个错误的值。下面是我修改后的viterbi函数：

def viterbi(nodes):

paths = {'b':nodes\[0\]\['b'\], 's':nodes\[0\]\['s'\]}

for l in range(1,len(nodes)):

paths\_ = paths.copy()

paths = {}

for i in nodes\[l\].keys():

nows = {}

for j in paths\_.keys():

if j\[-1\]+i in zy.keys():

nows\[j+i\]= paths\_\[j\]+nodes\[l\]\[i\]+zy\[j\[-1\]+i\]

k = np.argmax(list(nows.values()))

paths\[list(nows.keys())\[k\]\] = list(nows.values())\[k\]

return list(paths.keys())\[np.argmax(list(paths.values()))\]

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=10384#respond-post-3924)

郑娜

August 14th, 2018

请问苏老师，您这个想法有没有发表论文呢？

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=9609#respond-post-3924)

李云

October 3rd, 2018

您好，老师，请问你的代码是在python 哪个版本，哪个环境跑的呢？在引入keras之前的代码，在python2.7的IDE上可以跑通，但后面keras不支持，所以我去了python3，虽然支持了keras，但前面的代码就各种提示错误，是python两个版本对于语法的要求不一样导致的。求有什么好的方法跑通程序吗？

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=9876#respond-post-3924)

[苏剑林](https://kexue.fm/) 发表于
October 4th, 2018

好的方法：学好python基础再看本文及本文的代码。可能有些代码已经过时，需要对照keras官方文档自行调整。

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=9879#respond-post-3924)

lion

December 18th, 2018

学长您好，我想请教一下，您最后用dense(5)将64个单元全连接到5的单元上，在传递中的h(t-1)应该还是64个变量把，还有最后生成结果的方式是不是在每个输出后接softmax函数，维特比在这里的作用是什么呢？谢谢学长。

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=10381#respond-post-3924)

[苏剑林](https://kexue.fm/) 发表于
December 18th, 2018

你前面的理解都没有错，Dense(5)仅仅是对RNN的输出进行运算。

维特比算法仅仅用于解码阶段。

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=10386#respond-post-3924)

zyj

September 24th, 2019

老师您好！想请教一下，simple\_cut函数里面的：

r=model.predict(np.array(\[list(chars\[list(s)\].fillna(0).astype(int))+\[0\]\*(maxlen-len(s))\]), verbose=False)\[0\]\[:len(s)\]

“chars\[list(s)\]”如果要预测的字符不在chars内，就会报错，请问是否只能输入字典里已有的字符？

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=12046#respond-post-3924)

[苏剑林](https://kexue.fm/) 发表于
September 25th, 2019

是，当时写得比较简陋，你可以自行修改。

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=12052#respond-post-3924)

[NLP+词法系列（二）︱中文分词技术简述、深度学习分词实践（CIPS2016、超多案例） - 站壳网](https://www.zhankr.net/9184.html)

November 6th, 2022

\[...\]本节来自于苏剑林，《【中文分词系列】 4.基于双向LSTM的seq2seq字标注》\[...\]

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=20285#respond-post-3924)

[NLP+词法系列（二）︱中文分词技术简述、深度学习分词实践（CIPS2016、超多案例） - SEOOS技术门户](https://www.seoos.net/25298.html)

November 6th, 2022

\[...\]本节来自于苏剑林，《【中文分词系列】 4.基于双向LSTM的seq2seq字标注》\[...\]

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=20287#respond-post-3924)

[简明条件随机场CRF介绍（附带纯Keras实现） R11; 白墨代码网](http://code.bmoook.com/%e7%ae%80%e6%98%8e%e6%9d%a1%e4%bb%b6%e9%9a%8f%e6%9c%ba%e5%9c%bacrf%e4%bb%8b%e7%bb%8d%ef%bc%88%e9%99%84%e5%b8%a6%e7%ba%afkeras%e5%ae%9e%e7%8e%b0%ef%bc%89/)

March 13th, 2023

\[...\]1、【中文分词系列】 4. 基于双向LSTM的seq2seq字标注\[...\]

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=21143#respond-post-3924)

[TensorFlow Bi-LSTM 实现序列标注 \| 珊瑚贝-珊瑚贝](http://www.shanhubei.com/archives/11418.html)

January 8th, 2024

\[...\]基于双向 LSTM 的 seq2seq 字标注\[...\]

[回复评论](https://kexue.fm/archives/3924/comment-page-5?replyTo=23470#respond-post-3924)

1. [«](https://kexue.fm/archives/3924/comment-page-4#comments)
2. [1](https://kexue.fm/archives/3924/comment-page-1#comments)
3. [2](https://kexue.fm/archives/3924/comment-page-2#comments)
4. [3](https://kexue.fm/archives/3924/comment-page-3#comments)
5. [4](https://kexue.fm/archives/3924/comment-page-4#comments)
6. [5](https://kexue.fm/archives/3924/comment-page-5#comments)

[取消回复](https://kexue.fm/archives/3924#respond-post-3924)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；

2\. 可以通过点击评论楼层编号来引用该楼层；

3\. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[关于字标注法](https://kexue.fm/archives/3924#%E5%85%B3%E4%BA%8E%E5%AD%97%E6%A0%87%E6%B3%A8%E6%B3%95)
[双向LSTM](https://kexue.fm/archives/3924#%E5%8F%8C%E5%90%91LSTM)
[在分词任务中的应用](https://kexue.fm/archives/3924#%E5%9C%A8%E5%88%86%E8%AF%8D%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8)
[Keras实现](https://kexue.fm/archives/3924#Keras%E5%AE%9E%E7%8E%B0)
[最后](https://kexue.fm/archives/3924#%E6%9C%80%E5%90%8E)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [一道比较函数大小的题目](https://kexue.fm/archives/1395)
- [趣题：与橡皮绳赛跑的蚂蚁](https://kexue.fm/archives/2520)
- [2^29365451-1不是素数](https://kexue.fm/archives/1969)
- [今日七夕笑牵牛](https://kexue.fm/archives/882)
- [庆祝圆周率(π)节！](https://kexue.fm/archives/524)
- [美国科学家用3000幅照片拼接夜空全景](https://kexue.fm/archives/244)
- [【理解黎曼几何】7\. 高斯-博内公式](https://kexue.fm/archives/4033)
- [温馨\|生活一角](https://kexue.fm/archives/144)
- [今天把Blog升级了](https://kexue.fm/archives/21)
- [科学空间：2010年6月重要天象](https://kexue.fm/archives/656)

### 最近评论

- [Bin](https://kexue.fm/archives/1990/comment-page-2#comment-29105): 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院的往届师兄！看到这篇2013年的...
- [Rapture D](https://kexue.fm/archives/11530/comment-page-1#comment-29104): 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。
- [mofheka](https://kexue.fm/archives/11390/comment-page-1#comment-29103): 苏神是还在用jax是么？最近在做基于Google Pathway的理念做一个动态版的MPMD框...
- [长琴](https://kexue.fm/archives/11530/comment-page-1#comment-29102): 看懂这篇博客也不是一件容易的事情。
- [AlexLi](https://kexue.fm/archives/9257/comment-page-4#comment-29101): 苏老师，请教一下(7)式中将 $\\mu(x\_t)$ 传给 $p\_o$ 进行推理的操作。 $x\_...
- [tyler\_zxc](https://kexue.fm/archives/7921/comment-page-2#comment-29100): "Performer的思想是将标准的Attention线性化，所以为什么不干脆直接训练一个线性...
- [我](https://kexue.fm/archives/11494/comment-page-1#comment-29099): 似乎并非mHC提出矩阵的思想？之前hyper connection就是了
- [winter](https://kexue.fm/archives/10847/comment-page-1#comment-29098): 苏神您好，假如对于比较均匀的attention weightP，往往呈现long tail分布...
- [苏剑林](https://kexue.fm/archives/8512/comment-page-2#comment-29097): KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个
- [苏剑林](https://kexue.fm/archives/9119/comment-page-14#comment-29096): 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理成本和推理效果，那么有的方法可以...

### 友情链接

- [Cool Papers](https://papers.cool/)
- [数学研发](https://bbs.emath.ac.cn/)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com/)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

[![署名-非商业用途-保持一致](https://kexue.fm/usr/themes/geekg/images/cc.gif)](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/) 本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。



© 2009-2026 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com/). Powered by [Typecho](http://typecho.org/). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/ "粤ICP备09093259号")。