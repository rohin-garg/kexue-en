## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [为什么Adam的Update RM...](https://kexue.fm/archives/11267)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11260)
- [Cool Papers更新：简单适...](https://kexue.fm/archives/11250)
- [流形上的最速下降：4\. Muon ...](https://kexue.fm/archives/11241)
- [ReLU/GeLU/Swish的一...](https://kexue.fm/archives/11233)
- [流形上的最速下降：3\. Muon ...](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon ...](https://kexue.fm/archives/11215)
- [基于树莓派Zero2W搭建一个随身旁路由](https://kexue.fm/archives/11206)
- [流形上的最速下降：1\. SGD ...](https://kexue.fm/archives/11196)
- [矩阵r次方根和逆r次方根的高效计算](https://kexue.fm/archives/11175)

## COMMENTS

- [苏剑林: 你是指xml代码？那不是乱码，feed就是xml格式，你要自己...](https://kexue.fm/content.html/comment-page-1#comment-28521)
- [苏剑林: 都是我人工整理的，只要论文集是公开可访问、没有反爬虫的，理论上...](https://kexue.fm/archives/11250/comment-page-1#comment-28520)
- [苏剑林: 按照平均budget来算一个静态scaling factor，...](https://kexue.fm/archives/10945/comment-page-1#comment-28519)
- [苏剑林: 辛苦了，我提供一些参考思路。比如你整理的最后一个\
$$\\lef...](https://kexue.fm/archives/9370/comment-page-1#comment-28518)
- [苏剑林: loss-free属于训练部分，不在K2的开源范围内。但弄懂原...](https://kexue.fm/archives/10815/comment-page-1#comment-28517)
- [苏剑林: 1、GLU想要退化为一层linear更简单了，只要gate那边...](https://kexue.fm/archives/11233/comment-page-1#comment-28516)
- [苏剑林: 很好的想法，这个做法对于压缩maxlogit来说是没有问题的，...](https://kexue.fm/archives/11221/comment-page-1#comment-28515)
- [苏剑林: 1、跟low-rank关系不大，我们也是直接用muon的；\
2...](https://kexue.fm/archives/10592/comment-page-2#comment-28514)
- [苏剑林: 借用Feynman的一句话：what I can not cr...](https://kexue.fm/archives/11033/comment-page-2#comment-28513)
- [苏剑林: 你说的原始问题是啥？公式$(13)$吗？如果是的话，$\\bol...](https://kexue.fm/archives/10407/comment-page-1#comment-28512)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 利用CUR分解加速交互式相似度模型的检索

2Nov

# [利用CUR分解加速交互式相似度模型的检索](https://kexue.fm/archives/9336)

By 苏剑林 \|
2022-11-02 \|
47840位读者\|

文本相似度有“交互式”和“特征式”两种做法，想必很多读者对此已经不陌生，之前笔者也写过一篇文章 [《CoSENT（二）：特征式匹配与交互式匹配有多大差距？》](https://kexue.fm/archives/8860) 来对比两者的效果。总的来说，交互式相似度效果通常会好些，但直接用它来做大规模检索是不现实的，而特征式相似度则有着更快的检索速度，以及稍逊一筹的效果。

因此，如何在保证交互式相似度效果的前提下提高它的检索速度，是学术界一直都有在研究的课题。近日，论文 [《Efficient Nearest Neighbor Search for Cross-Encoder Models using Matrix Factorization》](https://papers.cool/arxiv/2210.12579) 提出了一份新的答卷：CUR分解。

## 问题分析 [\#](https://kexue.fm/kexue.fm\#%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90)

在检索场景下，我们一般有一个数量巨大的待检索集$\\mathcal{K}$，不失一般性，我们可以假设$\\mathcal{K}$是恒定不变的。检索的任务是对于任意的请求$q\\in\\mathcal{Q}$，找出$\\mathcal{K}$中与$q$最相关的若干个结果$k$。交互式相似度模型是直接训练了一个相关性的打分函数$s(q,k)$，理论上我们可以对任意$k\\in\\mathcal{K}$计算$s(q,k)$，然后进行降序排列。但这意味着每次检索的计算量都是$\\mathcal{O}(\|\\mathcal{K}\|)$，而且中间计算结果无法缓存，所以成本是难以接受的。

计算量可以接受的是具有矩阵分解形式的相似度，对于单个样本来说，就是基于内积的相似度及其变体，经典的实现是$q,k$经过编码器$\\boldsymbol{E}$编码为两个向量$\\boldsymbol{E}(q),\\boldsymbol{E}(k)$，然后算内积$\\boldsymbol{E}(q)^{\\top}\\boldsymbol{E}(k)$，这就是特征式相似度。这样的方案有几个特点：1、所有的$\\boldsymbol{E}(k)$可以实现算好并缓存；2、$\\boldsymbol{E}(q)$跟所有的$\\boldsymbol{E}(k)$算内积可以转化为矩阵乘法，可以充分并行快速计算；3、还可以通过Faiss等工具借助近似算法进一步检索速度。

所以，要加速交互式相似度的检索速度的思路，就是将它转化为矩阵分解的形式，比较经典的实现方案就是用一个特征式相似度模型去蒸馏学习交互式相似度的效果。Google这篇论文的精巧之处在于，不引入任何新的模型，直接在原本交互式相似度模型的基础上利用CUR分解来实现加速，该方案被命名为ANNCUR。

## 矩阵分解 [\#](https://kexue.fm/kexue.fm\#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3)

CUR分解是矩阵分解的一种，而说到矩阵分解，很多读者第一反应可能是SVD，但事实上大家对SVD如此敏感的原因，不是SVD有多么通俗易懂，而是SVD被介绍得多。要说到直观易懂，CUR分解明显更胜一筹。

其实，我们也可以用统一的视角去理解SVD和CUR分解：对于一个打分函数$s(q,k)$，我们希望构造如下近似
\\begin{equation}s(q,k) \\approx \\sum\_{u\\in\\mathcal{U},v\\in\\mathcal{V}} f(q, u) g(u, v) h(v, k)\\label{eq:decom}\\end{equation}
一般情况下有限制$\|\\mathcal{U}\|,\|\\mathcal{V}\|\\ll \|\\mathcal{Q}\|,\|\\mathcal{K}\|$，使得它成为一个压缩分解。我们可以将$\\mathcal{U}$看成是$\\mathcal{K}$的一个“代表集”（或者“聚类中心”，反正都只是形象理解，可以随意），相应地$\\mathcal{V}$看成是$\\mathcal{Q}$的一个“代表集”，那么上述分解就会变得很形象：

> $q,k$的打分$s(q,k)$，近似于先将$q$与$\\mathcal{K}$的“代表”$u\\in \\mathcal{U}$算打分$f(q, u)$，然后将$k$与$\\mathcal{Q}$的“代表”$v\\in \\mathcal{V}$算打分$h(v, k)$，然后通过权重$g(u, v)$加权求和。

也就是说，$q$与$k$的直接交互，转化为它们分别与“代表”进行交互，然后再将结果进行加权。这样做的好处很明显，就是当$f,g,h$都确定后，所有的$g(u,v)$、$h(v,k)$都可以事先算好，作为一个矩阵缓存起来，然后每次检索，我们都只需要算$\|\\mathcal{U}\|$次$f(q,u)$，然后再执行一次矩阵乘法（基于内积检索），所以检索的计算量从$\\mathcal{O}(\|\\mathcal{K}\|)$转化为$\\mathcal{O}(\|\\mathcal{U}\|)$（借助Faiss等工具，基于内积的检索可以近似优化到$\\mathcal{O}(1)$，因此可以忽略）。

假设请求集$\\mathcal{Q}$也是有限的，那么所有的$s(q,k)$就构成一个$\|\\mathcal{Q}\|\\times \|\\mathcal{K}\|$的矩阵$\\boldsymbol{S}$，而相应地$f(q, u),g(u, v),h(v, k)$分别对应于$\|\\mathcal{Q}\|\\times \|\\mathcal{U}\|$的矩阵$\\boldsymbol{F}$、$\|\\mathcal{U}\|\\times \|\\mathcal{V}\|$的矩阵$\\boldsymbol{G}$、$\|\\mathcal{V}\|\\times \|\\mathcal{K}\|$的矩阵$\\boldsymbol{H}$，式$\\eqref{eq:decom}$就变成矩阵分解：
\\begin{equation}\\begin{array}{ccccc}
\\boldsymbol{S} & \\approx & \\boldsymbol{F} & \\boldsymbol{G} & \\boldsymbol{H} \\\
\\in\\mathbb{R}^{\|\\mathcal{Q}\|\\times \|\\mathcal{K}\|} & & \\in\\mathbb{R}^{\|\\mathcal{Q}\|\\times \|\\mathcal{U}\|} & \\in\\mathbb{R}^{\|\\mathcal{U}\|\\times \|\\mathcal{V}\|} & \\in\\mathbb{R}^{\|\\mathcal{V}\|\\times \|\\mathcal{K}\|}
\\end{array}\\label{eq:m-decom}\\end{equation}

## CUR分解 [\#](https://kexue.fm/kexue.fm\#CUR%E5%88%86%E8%A7%A3)

如果将$\\boldsymbol{G}$限制为对角矩阵，而$\\boldsymbol{F}$、$\\boldsymbol{H}$不做特殊限制，那么对应的分解就是SVD。SVD相当于虚拟出了若干个“代表”出来，使得最终的拟合效果会比较好，但这样由算法自行构造出来的“代表”，我们很难理解它的具体含义，也就是可解释性差点。

CUR分解则更直观一些，它认为“代表”应该是原来群体之一，也就是从$\\mathcal{Q},\\mathcal{K}$的“代表”应该从它们自身集合挑出来的子集，即$\\mathcal{U}\\subset \\mathcal{K}, \\mathcal{V}\\subset\\mathcal{Q}$。这样一来，$(q,u)$、$(v,k)$就是原来的$(q,k)$之一，因此可以沿用$(q,k)$的打分函数$s$，即
\\begin{equation}s(q,k) \\approx \\sum\_{u\\in\\mathcal{U},v\\in\\mathcal{V}} s(q, u) g(u, v) s(v, k)\\end{equation}
于是，待定的函数就只有$g(u,v)$了。从矩阵分解的角度来看，此时式$\\eqref{eq:m-decom}$中的$\\boldsymbol{F}$就是$\\boldsymbol{S}$的若干列组成的子矩阵，$\\boldsymbol{H}$就是$\\boldsymbol{S}$的若干行组成的子矩阵，要计算的就剩下矩阵$\\boldsymbol{G}$。$\\boldsymbol{G}$的计算也很直观，我们先考虑一个非常特殊的情形，$\\mathcal{U}=\\mathcal{K},\\mathcal{V}=\\mathcal{Q}$且$\|\\mathcal{Q}\|=\|\\mathcal{K}\|$，此时CUR分解为$\\boldsymbol{S}\\approx \\boldsymbol{S}\\boldsymbol{G}\\boldsymbol{S}$，$\\boldsymbol{S}$、$\\boldsymbol{G}$都是方阵。由于此时已经取了$\\mathcal{Q},\\mathcal{K}$全体作为代表，我们自然希望此时是$=$而不是$\\approx$，取$=$的话，可以直接解得$\\boldsymbol{G} = \\boldsymbol{S}^{-1}$。

然而，这意味着$\\boldsymbol{S}$要是可逆的，但一般情况下未必成立。这时候要将矩阵的逆运算进行推广，我们称为“ [伪逆](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse)”，记为$\\boldsymbol{G}=\\boldsymbol{S}^{\\dagger}$。特别地，伪逆对于非方阵也有定义，因此当$\|\\mathcal{Q}\|\\neq\|\\mathcal{K}\|$时，同样可以解得$\\boldsymbol{G}=\\boldsymbol{S}^{\\dagger}$。最后，当$\\mathcal{U}\\neq\\mathcal{K}$或$\\mathcal{V}\\neq\\mathcal{Q}$时，结果也类似的，只不过求伪逆的矩阵换成$\\boldsymbol{F}$与$\\boldsymbol{H}$的交集矩阵$\\boldsymbol{F}\\cap\\boldsymbol{H}$（即$\\boldsymbol{S}$的若干行、若干列交集的元素拼成的$\\mathcal{U}\\times \\mathcal{V}$矩阵）：
\\begin{equation}
\\boldsymbol{S} \\approx \\boldsymbol{F} (\\boldsymbol{F}\\cap \\boldsymbol{H})^{\\dagger}\\boldsymbol{H}\\end{equation}

整个过程如下图所示：

CUR分解示意图

## 加速检索 [\#](https://kexue.fm/kexue.fm\#%E5%8A%A0%E9%80%9F%E6%A3%80%E7%B4%A2)

其实本文也不是第一次涉及CUR分解，去年初的文章 [《Nyströmformer：基于矩阵分解的线性化Attention方案》](https://kexue.fm/archives/8180) 介绍的Nyströmformer，其实也是基于CUR分解思想来设计的，原始论文还花了不少的篇幅来介绍CUR分解。ANNCUR则是利用CUR分解来做检索加速，由此可见CUR的应用也很广泛。

加速的原理刚才已经稍微提及过了，现在再来总结一下。首先，我们分别挑若干个有代表的$q\\in \\mathcal{V}\\subset \\mathcal{Q}$和$k\\in \\mathcal{U}\\subset \\mathcal{K}$，算出它们两两打分构成矩阵$\\boldsymbol{F}\\cap\\boldsymbol{H}$，求伪逆后得到矩阵$\\boldsymbol{G}$，然后提前算好$q\\in \\mathcal{V}$与$k\\in \\mathcal{K}$的打分矩阵$\\boldsymbol{G}$，把$\\boldsymbol{G}\\boldsymbol{H}$存起来。最后，对于每一个需要查询的$q$，与每一个$k\\in \\mathcal{U}$都算打分，得到一个$\|\\mathcal{U}\|$维向量，然后将这个向量与缓存起来的矩阵$\\boldsymbol{G}\\boldsymbol{H}$相乘，就得到了$q$与每一个$k\\in \\mathcal{K}$的打分向量了。

ANNCUR的大致原理就是这样，具体的细节大家可以自行阅读原论文，比如交互式相似度模型换成论文说的 \[EMB\]-CE 版本效果会更好等。可能有读者想问“有代表的$q,k$要怎么选？”，事实上，大多数情况下都是随机选的，这就留下了一些提升空间，比如可以聚类后选最接近聚类中心的那个，这些就看大家自由发挥了。另外要指出的是，CUR分解本身只是一种近似，它肯定有误差，所以该加速方案主要是为检索场景设计的，检索场景的特点是比较在乎topk的召回率，而不是特别要求top1的精确率，我们可以用CUR分解加速来召回若干个结果后，再用精确的$s(q,k)$做一次重排序来提高准确度。

ANNCUR的部分实验结果图

## 文章小结 [\#](https://kexue.fm/kexue.fm\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文回顾了矩阵分解中的CUR分解，并介绍了它在加速交互式相似度检索方面的应用。

_**转载到请包括本文地址：** [https://kexue.fm/archives/9336](https://kexue.fm/archives/9336)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Nov. 02, 2022). 《利用CUR分解加速交互式相似度模型的检索 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/9336](https://kexue.fm/archives/9336)

@online{kexuefm-9336,
        title={利用CUR分解加速交互式相似度模型的检索},
        author={苏剑林},
        year={2022},
        month={Nov},
        url={\\url{https://kexue.fm/archives/9336}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/), [语义](https://kexue.fm/tag/%E8%AF%AD%E4%B9%89/), [语义相似度](https://kexue.fm/tag/%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6/)[11 评论](https://kexue.fm/archives/9336#comments)

< [圆内随机n点在同一个圆心角为θ的扇形的概率](https://kexue.fm/archives/9324) \| [CoSENT（三）：作为交互式相似度的损失函数](https://kexue.fm/archives/9341) >

### 你也许还对下面的内容感兴趣

- [流形上的最速下降：4\. Muon + 谱球面](https://kexue.fm/archives/11241)
- [流形上的最速下降：3\. Muon + Stiefel](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon + 正交](https://kexue.fm/archives/11215)
- [矩阵r次方根和逆r次方根的高效计算](https://kexue.fm/archives/11175)
- [矩阵平方根和逆平方根的高效计算](https://kexue.fm/archives/11158)
- [“对角+低秩”三角阵的高效求逆方法](https://kexue.fm/archives/11072)
- [通过msign来计算奇异值裁剪mclip（下）](https://kexue.fm/archives/11059)
- [矩阵符号函数mcsgn能计算什么？](https://kexue.fm/archives/11056)
- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算奇异值裁剪mclip（上）](https://kexue.fm/archives/11006)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

gefangshun

November 4th, 2022

为什么不可以将K作为矩阵存储起来，这样就可以直接进行矩阵计算加速了

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20270#respond-post-9336)

[苏剑林](https://kexue.fm) 发表于
November 7th, 2022

你怕是对交互式相似度有什么误会？

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20293#respond-post-9336)

[爱坤](https://www.kksyw.cn/)

November 9th, 2022

不错

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20317#respond-post-9336)

daiwk

November 9th, 2022

在线检索是直接q和GH相乘么，当item很多的时候是不是性能也不太行呢。看原文说可以『along with an off-theshelf nearest-neighbor search method for maximum
inner-product search』，不过不太懂具体要怎么应用mips呢

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20322#respond-post-9336)

daiwk 发表于
November 9th, 2022

好像懂了，假设k个种子item，N个候选item，GH就是k\*N，按列来看，就是N个k维向量，相当于N个item向量，扔到annlib里去就行了，而输入的q也是一个k维向量，就可以ann了

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20323#respond-post-9336)

[苏剑林](https://kexue.fm) 发表于
November 10th, 2022

是的

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20344#respond-post-9336)

qyc

November 10th, 2022

F∩H（即S的若干行、若干列交集的元素拼成的矩阵）矩阵的交集该怎么算呢

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20347#respond-post-9336)

[苏剑林](https://kexue.fm) 发表于
November 10th, 2022

本文的“CUR分解示意图”，应该体现得很清楚了吧？$\\boldsymbol{F}$（橙色）与$\\boldsymbol{H}$（黄色）的交集就是紫色部分，很直观呀。

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20354#respond-post-9336)

[CUR矩阵分解\_Johngo学长](https://www.johngo689.com/212370/)

November 26th, 2022

\[...\]利用CUR分解加速交互式相似度模型的检索\[...\]

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=20470#respond-post-9336)

[CUR矩阵分解\_Johngo学长](https://www.johngo689.com/659868/)

June 29th, 2023

\[...\]利用CUR分解加速交互式相似度模型的检索\[...\]

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=22112#respond-post-9336)

[CUR矩阵分解 \| Coding栈](https://www.itcode1024.com/213417/)

September 20th, 2023

\[...\]利用CUR分解加速交互式相似度模型的检索\[...\]

[回复评论](https://kexue.fm/archives/9336/comment-page-1?replyTo=22760#respond-post-9336)

[取消回复](https://kexue.fm/archives/9336#respond-post-9336)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[问题分析](https://kexue.fm/kexue.fm#%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90)
[矩阵分解](https://kexue.fm/kexue.fm#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3)
[CUR分解](https://kexue.fm/kexue.fm#CUR%E5%88%86%E8%A7%A3)
[加速检索](https://kexue.fm/kexue.fm#%E5%8A%A0%E9%80%9F%E6%A3%80%E7%B4%A2)
[文章小结](https://kexue.fm/kexue.fm#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [“Cool Papers + 站内搜索”的一些新尝试](https://kexue.fm/archives/10311)
- [对齐全量微调！这是我看过最精彩的LoRA改进（二）](https://kexue.fm/archives/10266)
- [人不能忘本\|我的数学竞赛题](https://kexue.fm/archives/272)
- [文本情感分类（四）：更好的损失函数](https://kexue.fm/archives/4293)
- [python简单实现gillespie模拟](https://kexue.fm/archives/5607)
- [让研究人员绞尽脑汁的Transformer位置编码](https://kexue.fm/archives/8130)
- [生成扩散模型漫谈（二十三）：信噪比与大图生成（下）](https://kexue.fm/archives/10055)
- [科学空间\|Scientific Spaces 介绍](https://kexue.fm/archives/12)
- [QK-Clip：让Muon在Scaleup之路上更进一步](https://kexue.fm/archives/11126)
- [广州亚运歌曲《重逢》歌词(中英文版)](https://kexue.fm/archives/136)

### 最近评论

- [苏剑林](https://kexue.fm/content.html/comment-page-1#comment-28521): 你是指xml代码？那不是乱码，feed就是xml格式，你要自己找工具订阅。
- [苏剑林](https://kexue.fm/archives/11250/comment-page-1#comment-28520): 都是我人工整理的，只要论文集是公开可访问、没有反爬虫的，理论上都可以，当然实际上行不行，还得看...
- [苏剑林](https://kexue.fm/archives/10945/comment-page-1#comment-28519): 按照平均budget来算一个静态scaling factor，好像也是一个挺合理的事情？
- [苏剑林](https://kexue.fm/archives/9370/comment-page-1#comment-28518): 辛苦了，我提供一些参考思路。比如你整理的最后一个
$$\\left\\Vert \\boldsym...
- [苏剑林](https://kexue.fm/archives/10815/comment-page-1#comment-28517): loss-free属于训练部分，不在K2的开源范围内。但弄懂原理后实现应该不算难。
- [苏剑林](https://kexue.fm/archives/11233/comment-page-1#comment-28516): 1、GLU想要退化为一层linear更简单了，只要gate那边退化为一个常数就行；
2、这个就...
- [苏剑林](https://kexue.fm/archives/11221/comment-page-1#comment-28515): 很好的想法，这个做法对于压缩maxlogit来说是没有问题的，但如果单纯为了压缩maxlogi...
- [苏剑林](https://kexue.fm/archives/10592/comment-page-2#comment-28514): 1、跟low-rank关系不大，我们也是直接用muon的；
2、我们都是用match adam...
- [苏剑林](https://kexue.fm/archives/11033/comment-page-2#comment-28513): 借用Feynman的一句话：what I can not create, I do not u...
- [苏剑林](https://kexue.fm/archives/10407/comment-page-1#comment-28512): 你说的原始问题是啥？公式$(13)$吗？如果是的话，$\\boldsymbol{A},\\bold...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [Zhang's blog](https://armcvai.cn/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。