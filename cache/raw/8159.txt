## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [通过msign来计算奇异值裁剪mc...](https://kexue.fm/archives/11059)
- [矩阵符号函数mcsgn能计算什么？](https://kexue.fm/archives/11056)
- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算奇异值裁剪mc...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)

## COMMENTS

- [abcm: 公式(14)为什么是直接带入，我的理解是0到T积分再换元\
\\b...](https://kexue.fm/archives/10114/comment-page-3#comment-28017)
- [Truenobility303: 苏神好，关于RMS对齐这里有些疑问。1. 如果从 A Spec...](https://kexue.fm/archives/10739/comment-page-2#comment-28016)
- [wolfzdf: 您好，请问cool paper中收集的会议论文，有保存整理文章...](https://kexue.fm/archives/9907/comment-page-4#comment-27987)
- [无敌大铁锤: 嗯嗯笔误了，就是去掉Causal的mask，变成一个纯Self...](https://kexue.fm/archives/11033/comment-page-1#comment-27986)
- [HikaruNight: 苏老师，想请教一下如果把四元数放在三维RoPE里面是不是可行的](https://kexue.fm/archives/8397/comment-page-3#comment-27985)
- [Leco: 请问LoRA的A,B矩阵初始化时，一个高斯随机一个全零还是只能...](https://kexue.fm/archives/9590/comment-page-2#comment-27984)
- [苏剑林: 如果你把你这里提到的数学都学通透了，数学基础基本上可以胜任95...](https://kexue.fm/archives/9119/comment-page-13#comment-27983)
- [苏剑林: 我跑过这个项目，效果是能复现的。“在 CIFAR-10 上效果...](https://kexue.fm/archives/10958/comment-page-2#comment-27982)
- [Henry Zha: 苏神你好，我是一名管理科学与工程专业的博士生，研究方向是结合人...](https://kexue.fm/archives/9119/comment-page-13#comment-27981)
- [SunlightZero: 我根据 https://github.com/haidog-y...](https://kexue.fm/archives/10958/comment-page-2#comment-27980)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) [生物自然](https://kexue.fm/category/Biology) 一个二值化词向量模型，是怎么跟果蝇搭上关系的？

9Feb

# [一个二值化词向量模型，是怎么跟果蝇搭上关系的？](https://kexue.fm/archives/8159)

By 苏剑林 \|
2021-02-09 \|
32160位读者\|

果蝇（图片来自Google搜索）

可能有些读者最近会留意到ICLR 2021的论文 [《Can a Fruit Fly Learn Word Embeddings?》](https://papers.cool/arxiv/2101.06887)，文中写到它是基于仿生思想（仿果蝇的嗅觉回路）做出来的一个二值化词向量模型。其实论文的算法部分并不算难读，可能整篇论文读下来大家的最主要疑惑就是“这东西跟果蝇有什么关系？”、“作者真是从果蝇里边受到启发的？”等等。本文就让我们来追寻一下该算法的来龙去脉，试图回答一下这个词向量模型是怎么跟果蝇搭上关系的。

## BioWord [\#](https://kexue.fm/archives/8159\#BioWord)

原论文并没有给该词向量模型起个名字，为了称呼上的方便，这里笔者就自作主张将其称为“BioWord”了。总的来说，论文内容大体上有三部分：

> 1、给每个n-gram构建了一个词袋表示向量；
>
> 2、对这些n-gram向量执行BioHash算法，得到所谓的（二值化的）静态/动态词向量；
>
> 3、“拼命”讲了一个故事。

其中BioHash我们稍后再介绍，总之就是一个现成的向量二值化算法。从这三点可以看出，其实整个词向量模型本身跟仿生、果蝇并没有明显的关联，就算有关系，也应该是里边的BioHash算法的关系，但这篇论文又不是提出BioHash算法的，因此说过多仿生方面的东西，就显得有点牵强了。下面再来详细解释一下这几点。

首先，给每个n-gram构建一个词袋表示向量，这个做法很朴素，结果是一个$2V$维的二值向量（即0/1向量），其中$V$是词表大小。如下图所示，前$V$维表示上下文部分，1表示上下文出现了这个词；后$V$维就是一个one hot向量，表示中心词。然后，作者对BioHash算法做了一点调整（但没有说清楚为什么这样修改，笔者也看不出如何理解这个修改），BioHash之后，每个n-gram的向量就映射为了一个$K$维的0/1向量，其中每个向量有（固定数目的）$k$个1。

给每个n-gram构建词袋表示

最后，为什么我说作者“拼命”讲了一个故事呢？第一，前面说了，说过多仿生方面的东西显得牵强；第二，作者将BioWord跟Word2Vec、Glove等词向量模型比较，效果基本上都不如它们的；第三，至于作为一种词向量二值化算法，BioWord的效果跟已有的RandExp、LSH等相比也没有什么优势。如果只是这样那还好，但是让人觉得更尴尬的是，作者还强行跟BERT对比来突出自己的“优势”。

作者先是引入了静态/动态词向量的说法，如果词袋向量中前$V$维全是0，那么映射后的$K$维向量就是该词的静态词向量，如果词袋向量中前$V$维是依赖上下文，那么就称映射后的$K$维向量是该词的（类似BERT那样的）动态词向量。但这概念实在是难登大雅之堂，照这样说，哪怕是Word2Vec，求个上下文的平均词向量拼接到中心词向量上，也是一个动态词向量了，但这样无非就是个谈资而已，实验结果也没显示出有什么优势。还有，作为一个词向量模型，作者还跟BERT比训练成本以突出自己的优势，着实是让人尴尬了一把，由此也可见作者为了讲这个故事的“煞费苦心”了。

## BioHash [\#](https://kexue.fm/archives/8159\#BioHash)

BioHash出自论文 [《Bio-Inspired Hashing for Unsupervised Similarity Search》](https://papers.cool/arxiv/2001.04907)，它是一种将向量二值化的方法，跟传统的的LSH不一样的是，它依赖于样本，是为特定数据集“量身定制”的，因此通常能得到效果更好、更稀疏的二值向量。

给定向量集$\\{\\boldsymbol{x}\_i\\}\_{i=1}^N$，BioHash算法大致如下：

> 1、用K-Means将$\\{\\boldsymbol{x}\_i\\}\_{i=1}^N$聚为$K$类，得到$K$个向量中心；
>
> 2、每个$\\boldsymbol{x}\_i$映射为一个$K$维0/1向量，其中与$\\boldsymbol{x}\_i$距离最近的$k$个类对应的位置为1，其余为0。

之所以说“大致”，是因为算法细节上有一些出入。首先，聚类过程中用的距离不是欧式距离，而是归一化内积，即$d(\\boldsymbol{x}, \\boldsymbol{w}) = -\\langle \\boldsymbol{x}, \\boldsymbol{w} / \\Vert\\boldsymbol{w}\\Vert\\rangle$，这个做法我们之前在探究Capsule的时候也用过，读者可以参考 [《再来一顿贺岁宴：从K-Means到Capsule》](https://kexue.fm/archives/5112)；然后，求解聚类中心的时候，用的是SGD而不是常规的EM算法，这一点其实笔者不大理解，虽说SGD可以小批量进行，对内存更友好，但理论上EM算法也可以按批执行，不至于爆内存；最后，笔者完全不理解的一点是，在聚类过程中作者用的距离是归一化内积$-\\langle \\boldsymbol{x}, \\boldsymbol{w} / \\Vert\\boldsymbol{w}\\Vert\\rangle$，但在决定每个样本的归属的时候，又以不归一化的内积$-\\langle \\boldsymbol{x}, \\boldsymbol{w}\\rangle$为距离，实在是莫名其妙。

当然，抛开BioHash的细节不说，BioHash的效果还是很赞的，所以有适当的场景的话，BioHash还是值得借鉴使用的。细心的读者可能会发现，BioWord和BioHash有几位作者是相同的，事实上它们都产自同一个实验室，由此也不难理解BioWord希望传承BioHash的初衷，只不过将BioHash用于词向量构建中，笔者认为无论从动机上还是论文所报告的效果上，都难以称得上漂亮。

## FlyHash [\#](https://kexue.fm/archives/8159\#FlyHash)

说了那么久，我们还没有说到标题的问题：BioWord到底跟果蝇有什么联系？或者说BioHash的哪个地方体现了跟果蝇的相似性？追踪BioHash的参考文献可以发现，BioHash事实上是对一个名为FlyHash的算法的改进，因此要溯源的话，还得找FlyHash。

顾名思义，FlyHash主要是受到果蝇的嗅觉回路启发而构思出来的一种新的向量二值化方法，它相比常规的LSH更高效。对于不了解LSH的读者来说，我们后面再补充介绍一下，这里先直接介绍FlyHash。其实FlyHash跟LSH都是“随机投影 + 二值化”的思路，只不过果蝇启发了一个新的优化方向：高维 \+ 低激活。

具体来说，设原始数据$\\boldsymbol{x}\_i \\in \\mathbb{R}^{D}$，FlyHash选择了一个随机二值矩阵$\\boldsymbol{W}\\in\\{0,1\\}^{D\\times K}$（选好后就固定了），其中一般有$K > D$（高维），经过投影后$\\boldsymbol{x}\_i \\boldsymbol{W}$是一个$K$维向量，然后对它进行一个WTA（Winner Take All，赢者通吃）操作来实现”低激活“——“将$\\boldsymbol{x}\_i \\boldsymbol{W}$最大的$k$个元素置1，其余置0”，这样就得到了一个有$k$个1、$K-k$个0的二值向量了，就将它作为$\\boldsymbol{x}\_i$的Hash向量。

由于激活值只有有限的$k$个，因此就算升维了，存储和检索成本都不会加大，反而效果有所提升，这就是果蝇带来的“高维 + 低激活”思路的好处。FlyHash首先发表在Science的论文 [《A neural algorithm for a fundamental computing problem》](https://science.sciencemag.org/content/358/6364/793)，关于“高维 \+ 低激活”的果蝇嗅觉回路可以仔细参考这篇论文，后来论文 [《Improving Similarity Search with High-dimensional Locality-sensitive Hashing》](https://papers.cool/arxiv/1812.01844) 又进一步完善了理论部分，这两篇论文也是一脉相承的。

所以，现在我们可以回答“怎么跟果蝇搭上关系”了，其实就是在二值化过程中包含了“高维 \+ 低激活”思想的算法，我们都可以说“Inspired by Fly”，由于FlyHash是随机投影来得到最终结果的，所以它必须升到足够多维才能保证效果，而BioHash针对具体数据集进行训练，因此它往往不需要FlyHash那么多维，而且效果还更好，但BioHash也有明显的“赢者通吃”的思想，所以也称“Inspired by Fly”。而BioWord使用了BioHash，因此也自称“Inspired by Fly”了。

## LSH [\#](https://kexue.fm/archives/8159\#LSH)

最后，我们简单介绍一下LSH（Locality Sensitive Hashing），供不了解的读者参考。完整的LSH讲起来又可以长篇大论了，这里主要提一下跟FlyHash比较密切的部分。

简单来说，LSH就是一个将向量二值化的算法，并且二值化之后的向量能近似保持度量不变。常见的一种方案是通过随机投影来（近似）保持cos值的不变性，从之前的文章 [《n维空间下两个随机向量的夹角分布》](https://kexue.fm/archives/7076) 和 [《从几何视角来理解模型参数的初始化策略》](https://kexue.fm/archives/7180) 我们可以知道，高维空间中任意两个高斯随机向量几乎都是正交的，那么从$\\mathcal{N}(0,1/n)$中采样$DK$个随机数来组成一个矩阵$\\boldsymbol{W}\\in\\mathbb{R}^{D\\times K}$，它“几乎”是一个正交矩阵。这样一来，两个原始向量$\\boldsymbol{x}\_i, \\boldsymbol{x}\_j\\in\\mathbb{R}^{D}$被$\\boldsymbol{W}$一乘后，就变成了两个$K$维向量，并且夹角近似不变：
\\begin{equation}\\cos(\\boldsymbol{x}\_i \\boldsymbol{W}, \\boldsymbol{x}\_j \\boldsymbol{W})\\approx \\cos(\\boldsymbol{x}\_i, \\boldsymbol{x}\_j)\\end{equation}
这样一来，如果检索度量是cos值，那么我们可以用投影后的$\\boldsymbol{x} \\boldsymbol{W}$代替原始向量$\\boldsymbol{x}$来做近似检索。更进一步，将结果二值化后基本也能保持cos值不变：
\\begin{equation}\\boldsymbol{x}\\quad\\to\\quad\\text{sgn}(\\boldsymbol{x} \\boldsymbol{W})\\end{equation}
其中$\\text{sgn}$是符号函数，将大于0的改为1，小于等于0的改为-1，这样就将原始向量映射为一个二值向量了。这里的目标维度$K$一般不会比$D$大，并且由于投影的随机性，我们大约可以认为结果之中1和-1都是各一半，这就跟FlyHash的“高维 + 低激活”有明显区别了，因为不管你将1还是将-1视为激活值，数目都差不多，称不上“低激活”。

上面的介绍虽然只是一个启发性的引导，但事实上背后是有严格的概率理论支撑的（在 [《Performer：用随机投影将Attention的复杂度线性化》](https://kexue.fm/archives/7921) 也做过相关的理论分析），因此LSH是一套严谨的可量化的算法，并不是纯粹拍脑袋的近似。对向量二值化之后，我们就可以将它视为一个词袋模型（哪怕原来的是连续型向量），进而可以对它建立索引来加速检索，比如倒排索引，这就是向量二值化的意义了，像Fiass等向量检索库，都包含了LSH算法。

## 文章小结 [\#](https://kexue.fm/archives/8159\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文对一个二值化词向量模型进行了溯源，探究了它究竟是如何联系上果蝇的，从中我们还可以了解到BioHash、FlyHash、LSH等向量二值化方法的思路和关联。本文也是第一次尝试倒叙式写作，希望读者喜欢～

_**转载到请包括本文地址：** [https://kexue.fm/archives/8159](https://kexue.fm/archives/8159)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/8159#share)/ [打赏](https://kexue.fm/archives/8159#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Feb. 09, 2021). 《一个二值化词向量模型，是怎么跟果蝇搭上关系的？ 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/8159](https://kexue.fm/archives/8159)

@online{kexuefm-8159,
        title={一个二值化词向量模型，是怎么跟果蝇搭上关系的？},
        author={苏剑林},
        year={2021},
        month={Feb},
        url={\\url{https://kexue.fm/archives/8159}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data), [生物自然](https://kexue.fm/category/Biology)    标签： [自然语言处理](https://kexue.fm/tag/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/), [词向量](https://kexue.fm/tag/%E8%AF%8D%E5%90%91%E9%87%8F/), [NLP](https://kexue.fm/tag/NLP/)[3 评论](https://kexue.fm/archives/8159#comments)

< [让研究人员绞尽脑汁的Transformer位置编码](https://kexue.fm/archives/8130) \| [Nyströmformer：基于矩阵分解的线性化Attention方案](https://kexue.fm/archives/8180) >

### 你也许还对下面的内容感兴趣

- [GPLinker：基于GlobalPointer的事件联合抽取](https://kexue.fm/archives/8926)
- [GPLinker：基于GlobalPointer的实体关系联合抽取](https://kexue.fm/archives/8888)
- [Efficient GlobalPointer：少点参数，多点效果](https://kexue.fm/archives/8877)
- [关于维度公式“n > 8.33 log N”的可用性分析](https://kexue.fm/archives/8711)
- [曾被嫌弃的预训练任务NSP，做出了优秀的Zero Shot效果](https://kexue.fm/archives/8671)
- [GlobalPointer：用统一的方式处理嵌套和非嵌套NER](https://kexue.fm/archives/8373)
- [P-tuning：自动构建模版，释放语言模型潜能](https://kexue.fm/archives/8295)
- [必须要GPT3吗？不，BERT的MLM模型也能小样本学习](https://kexue.fm/archives/7764)
- [最小熵原理（六）：词向量的维度应该怎么选择？](https://kexue.fm/archives/7695)
- [现在可以用Keras玩中文GPT2了（GPT2\_ML）](https://kexue.fm/archives/7292)

[发表你的看法](https://kexue.fm/archives/8159#comment_form)

GDY

March 8th, 2021

大神，bert可以得到动态化的中文词向量吗？我看了一些网站，用bert直接生成“词向量”感觉这种做法得到的向量并不能准确表达这个词的语意信息（或者说包含了这个词的全部语意？所以计算词之间的相似度会很高，即便是两个词义上完全不同的词语相似度都能达到80%以上）。
通过bert文件下的extract\_features.py，是否可以提取出特定句子下，当前词的单一词义，通过拼接字向量，得到代表当前词义的词向量。

[回复评论](https://kexue.fm/archives/8159/comment-page-1?replyTo=15701#respond-post-8159)

[苏剑林](https://kexue.fm) 发表于
March 9th, 2021

BERT编码出来的结果，你可以认为就是动态词向量。至于所谓的两两之间相似度高，为什么不能高呢？高犯法了吗？相似度本身就只有相对值的意义，没有绝对值的意义（A与B的相似度大与A与C的相似度，说明A与B更相似，至于A与B的相似度为0.9还是0.99，不能说明A与B很相似）。

[回复评论](https://kexue.fm/archives/8159/comment-page-1?replyTo=15702#respond-post-8159)

GDY 发表于
March 9th, 2021

谢谢您的回复，不知道bert做动词聚类（我尝试计算相似度后比较排序，筛选出更相似的放到一块儿）理论上是否会好，实验结果目前是部分聚类效果差
（生锈 0.964843686305325
放风 0.9620670817693009
生变 0.9614261891932692
补亏 0.9596749132617699
解闷 0.9589171143252767
强身 0.9575194929705564
破网 0.9575100226416652
洞穿 0.9569771280179669）

部分效果还可以（出任 0.9544409972585935
赴任 0.9544287250910719
调任 0.9528044723798709
录用 0.9512114554968791
升任 0.9491209451635789
改任 0.9438771892628215
获任 0.9431596466120113
应邀 0.942756069368584
聘任 0.9397173259676643
留任 0.9374595917218109）
后面的数值，是各个词与中心词的相似度，结果是按大小排序取的，您对bert在这块儿的工作怎样的评价和认识那？

[回复评论](https://kexue.fm/archives/8159/comment-page-1?replyTo=15704#respond-post-8159)

[取消回复](https://kexue.fm/archives/8159#respond-post-8159)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[BioWord](https://kexue.fm/archives/8159#BioWord)
[BioHash](https://kexue.fm/archives/8159#BioHash)
[FlyHash](https://kexue.fm/archives/8159#FlyHash)
[LSH](https://kexue.fm/archives/8159#LSH)
[文章小结](https://kexue.fm/archives/8159#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [《积分公式大全》网络版本](https://kexue.fm/archives/976)
- [又是Dropout两次！这次它做到了有监督任务的SOTA](https://kexue.fm/archives/8496)
- [海伦公式的一个别致的物理推导](https://kexue.fm/archives/3252)
- [2009年中秋手机拍摄月亮](https://kexue.fm/archives/157)
- [《Attention is All You Need》浅读（简介+代码）](https://kexue.fm/archives/4765)
- [科学空间：2010年9月重要天象](https://kexue.fm/archives/909)
- [让炼丹更科学一些（一）：SGD的平均损失收敛](https://kexue.fm/archives/9902)
- [生成扩散模型漫谈（十四）：构建ODE的一般步骤（上）](https://kexue.fm/archives/9370)
- [漫话模型\|模型与选芒果](https://kexue.fm/archives/3390)
- [伽马函数的傅里叶变换之路](https://kexue.fm/archives/3108)

### 最近评论

- [abcm](https://kexue.fm/archives/10114/comment-page-3#comment-28017): 公式(14)为什么是直接带入，我的理解是0到T积分再换元
\\begin{align}
\\int...
- [Truenobility303](https://kexue.fm/archives/10739/comment-page-2#comment-28016): 苏神好，关于RMS对齐这里有些疑问。1. 如果从 A Spectral Condition f...
- [wolfzdf](https://kexue.fm/archives/9907/comment-page-4#comment-27987): 您好，请问cool paper中收集的会议论文，有保存整理文章（通讯）作者的邮箱吗？
现在计算...
- [无敌大铁锤](https://kexue.fm/archives/11033/comment-page-1#comment-27986): 嗯嗯笔误了，就是去掉Causal的mask，变成一个纯Self-Attention的形式,然后...
- [HikaruNight](https://kexue.fm/archives/8397/comment-page-3#comment-27985): 苏老师，想请教一下如果把四元数放在三维RoPE里面是不是可行的
- [Leco](https://kexue.fm/archives/9590/comment-page-2#comment-27984): 请问LoRA的A,B矩阵初始化时，一个高斯随机一个全零还是只能A高斯，B全零呢？
- [苏剑林](https://kexue.fm/archives/9119/comment-page-13#comment-27983): 如果你把你这里提到的数学都学通透了，数学基础基本上可以胜任95%以上的场景了吧？至于“直觉”这...
- [苏剑林](https://kexue.fm/archives/10958/comment-page-2#comment-27982): 我跑过这个项目，效果是能复现的。“在 CIFAR-10 上效果非常差，生成的图片都是模糊的”是...
- [Henry Zha](https://kexue.fm/archives/9119/comment-page-13#comment-27981): 苏神你好，我是一名管理科学与工程专业的博士生，研究方向是结合人工智能模型建模用户行为之类的管理...
- [SunlightZero](https://kexue.fm/archives/10958/comment-page-2#comment-27980): 我根据 https://github.com/haidog-yaqub/MeanFlow 尝试...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。