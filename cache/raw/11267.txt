## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [为什么Adam的Update RM...](https://kexue.fm/archives/11267)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11260)
- [Cool Papers更新：简单适...](https://kexue.fm/archives/11250)
- [流形上的最速下降：4\. Muon ...](https://kexue.fm/archives/11241)
- [ReLU/GeLU/Swish的一...](https://kexue.fm/archives/11233)
- [流形上的最速下降：3\. Muon ...](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon ...](https://kexue.fm/archives/11215)
- [基于树莓派Zero2W搭建一个随身旁路由](https://kexue.fm/archives/11206)
- [流形上的最速下降：1\. SGD ...](https://kexue.fm/archives/11196)
- [矩阵r次方根和逆r次方根的高效计算](https://kexue.fm/archives/11175)

## COMMENTS

- [gapeng: kimi k2形式上推导了一个公式，最后数值模拟在0.23左右...](https://kexue.fm/archives/11267/comment-page-1#comment-28531)
- [Evan1024: 太牛了！](https://kexue.fm/archives/11267/comment-page-1#comment-28530)
- [ameowcat: 苏神您好，有个问题想请教一下，最近扩散模型的推理优化有一篇文章...](https://kexue.fm/archives/10958/comment-page-3#comment-28529)
- [Eliot: 2 实现loss-free with budget应当是在当前...](https://kexue.fm/archives/10815/comment-page-1#comment-28528)
- [Eliot: 继续阅读这2份代码后，大概结论如下\
1 megatron-lm...](https://kexue.fm/archives/10815/comment-page-1#comment-28527)
- [lzyyzl: 帮忙解惑一下\
1 文中提到本文主题是求O=msign(M)的导...](https://kexue.fm/archives/11025/comment-page-1#comment-28525)
- [z: 牛](https://kexue.fm/archives/11267/comment-page-1#comment-28524)
- [Gusto: 按照个人理解将weight decay理解为损失函数中的惩罚项...](https://kexue.fm/archives/10739/comment-page-2#comment-28523)
- [hazdzz: 非常感谢您提到 pbSGD，这启发了我的毕业论文！](https://kexue.fm/archives/11196/comment-page-1#comment-28522)
- [苏剑林: 你是指xml代码？那不是乱码，feed就是xml格式，你要自己...](https://kexue.fm/content.html/comment-page-1#comment-28521)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) 为什么Adam的Update RMS是0.2？

2Sep

# [为什么Adam的Update RMS是0.2？](https://kexue.fm/archives/11267)

By 苏剑林 \|
2025-09-02 \|
7924位读者\|

众所周知，我们很早就开始尝试将Muon用于大规模LLM的训练。特别地，在 [《Muon续集：为什么我们选择尝试Muon？》](https://kexue.fm/archives/10739) 中，我们提出了“Match Adam Update RMS”的技巧，以便快速从Adam迁移到Muon上，这个技巧同样用到了Kimi K2的训练中。该技巧是指将Muon的Update RMS统一成0.2，这使得我们复用Adam的学习率和权重衰减率。

这一技巧的背后，是我们观察到Adam的Update RMS约等于0.2，并且这一现象是稳定且可复现的。这便引发了一个有趣的问题：为什么Adam的Update RMS是0.2？我们可以从理论上解释它吗？

## 问题引入 [\#](https://kexue.fm/kexue.fm\#%E9%97%AE%E9%A2%98%E5%BC%95%E5%85%A5)

首先描述一下现象：从实验中我们观察到，大致上在Warmup结束、模型进入正式训练后，Adam的Update RMS几乎都保持在0.2～0.3之间，并且不同尺寸的模型也呈现出相似的规律。这些模型的共同点是都用Adam训练，参数是$\\beta\_1=0.9,\\beta\_2=0.95$。由于共性很明显，所以这大概率不是巧合，因此笔者尝试分析背后的原理。

然后我们回顾一下Adam优化器的形式：
\\begin{equation}\\text{Adam}\\color{skyblue}{\\text{W}}:=\\left\\{\\begin{aligned}
&\\boldsymbol{m}\_t = \\beta\_1 \\boldsymbol{m}\_{t-1} + \\left(1 - \\beta\_1\\right) \\boldsymbol{g}\_t\\\
&\\boldsymbol{v}\_t = \\beta\_2 \\boldsymbol{v}\_{t-1} + \\left(1 - \\beta\_2\\right) \\boldsymbol{g}\_t^2\\\
&\\hat{\\boldsymbol{m}}\_t = \\boldsymbol{m}\_t\\left/\\left(1 - \\beta\_1^t\\right)\\right.\\\
&\\hat{\\boldsymbol{v}}\_t = \\boldsymbol{v}\_t\\left/\\left(1 - \\beta\_2^t\\right)\\right.\\\
&\\boldsymbol{u}\_t =\\hat{\\boldsymbol{m}}\_t\\left/\\left(\\sqrt{\\hat{\\boldsymbol{v}}\_t} + \\epsilon\\right)\\right.\\\
&\\boldsymbol{\\theta}\_t = \\boldsymbol{\\theta}\_{t-1} - \\eta\_t (\\boldsymbol{u}\_t \\color{skyblue}{ + \\lambda\_t \\boldsymbol{\\theta}\_{t-1}})
\\end{aligned}\\right.\\end{equation}
注意：本文所有向量的乘除法，包括平方，默认都是指Hadamard积/商，即Element-wise的乘/除。

我们要做的事情，就是证明$\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}\\approx 0.2$，至少在$\\beta\_1=0.9,\\beta\_2=0.95$这组设置下如此。由于我们关心的是稳定训练后的情形，因此可以认为$t$足够大，以至于$\\beta\_1^t,\\beta\_2^t$都足够接近于0，那么就不用区分$\\boldsymbol{m}\_t$和$\\hat{\\boldsymbol{m}}\_t$、$\\boldsymbol{v}\_t$和$\\hat{\\boldsymbol{v}}\_t$。同时，我们假设$\\epsilon$足够小，也可以忽略，于是有$\\boldsymbol{u}\_t =\\boldsymbol{m}\_t/\\sqrt{\\boldsymbol{v}\_t}$。

对于$\\boldsymbol{m}\_t,\\boldsymbol{v}\_t$，我们可以得到展开式
\\begin{equation}\\boldsymbol{m}\_t = (1 - \\beta\_1)\\sum\_{i=1}^t \\beta\_1^{t-i}\\boldsymbol{g}\_i,\\qquad \\boldsymbol{v}\_t = (1 - \\beta\_2)\\sum\_{i=1}^t \\beta\_2^{t-i}\\boldsymbol{g}\_i^2\\end{equation}

## 数值模拟 [\#](https://kexue.fm/kexue.fm\#%E6%95%B0%E5%80%BC%E6%A8%A1%E6%8B%9F)

如果我们假设$\\boldsymbol{g}\_1,\\boldsymbol{g}\_2,\\cdots,\\boldsymbol{g}\_t$都是从同一个分布采样出来的，那么我们就可以直接用数值模拟的方法估计$\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}$。事不宜迟，让我们从最简单的标准正态分布$\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})$进行尝试，参考代码如下：

```
import numpy as np

N, T = 10000, 2000
beta1, beta2 = 0.9, 0.95
m, v = 0, 0
for i in range(T):
 g = np.random.randn(N)
 m = beta1 * m + (1 - beta1) * g
 v = beta2 * v + (1 - beta2) * g**2

u = m / v**0.5
rms = (u**2).mean()**0.5
print(rms)
```

大家猜猜结果是多少？答案大概是0.225，居然跟实验结果惊人地相似！这反过来表明我们的模拟假设跟实际情况还是很吻合的。可能有读者觉得不对，$\\boldsymbol{g}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})$不是纯噪声了吗，这还能吻合？实际训练当然不可能是纯噪声，只能说单次梯度的信噪比小得可怜，因此可以用纯噪声来模拟。

读者可以自行折腾一下上述参考代码，观察Update RMS的影响变量，大体结论是：Update RMS跟$\\beta\_1$正相关，跟$\\beta\_2$似乎关系不大，如果$\\boldsymbol{g}$的分布具有非零均值（相当于增大梯度的信噪比），那么Update RMS也会变大。

## 平均近似 [\#](https://kexue.fm/kexue.fm\#%E5%B9%B3%E5%9D%87%E8%BF%91%E4%BC%BC)

这一节笔者尝试从理论方面推导上述模拟结果的一个近似解析解。首先，我们从RMS的定义可知，要求$\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}$，需要先求$\\boldsymbol{u}\_t^2 = \\boldsymbol{m}\_t^2/\\boldsymbol{v}\_t$。笔者的想法是，用$\\boldsymbol{u}\_t^2$的期望作为它的近似，并进一步转化为平均场近似：
\\begin{equation}\\mathbb{E}\[\\boldsymbol{u}\_t^2\] = \\mathbb{E}\\left\[\\frac{\\boldsymbol{m}\_t^2}{\\boldsymbol{v}\_t}\\right\] \\approx \\frac{\\mathbb{E}\[\\boldsymbol{m}\_t^2\]}{\\mathbb{E}\[\\boldsymbol{v}\_t\]}\\end{equation}
可能会有读者质疑最后一步近似的合理性。笔者的建议是，先不管这些细枝末节，就好比上一节假设$\\boldsymbol{g}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})$一样，先算了再说，如果结果合理那么过程必然一定程度上也是合理的。现在我们分别算分子、分母，这次我们一般地设$\\mathbb{E}\[\\boldsymbol{g}\]=\\boldsymbol{\\mu},\\mathbb{E}\[\\boldsymbol{g}^2\]=\\boldsymbol{\\mu}^2 + \\boldsymbol{\\sigma}^2 $，其中分母比较简单
\\begin{equation}\\begin{aligned}
\\mathbb{E}\[\\boldsymbol{v}\_t\] =&\\, (1 - \\beta\_2)\\sum\_{i=1}^t \\beta\_2^{t-i}\\mathbb{E}\[\\boldsymbol{g}\_i^2\] \\\
=&\\, (1 - \\beta\_2)\\sum\_{i=1}^t \\beta\_2^{t-i}(\\boldsymbol{\\mu}^2 + \\boldsymbol{\\sigma}^2) \\\\[6pt\]
=&\\, (1 - \\beta\_2^t)(\\boldsymbol{\\mu}^2 + \\boldsymbol{\\sigma}^2) \\\\[8pt\]
=&\\, \\boldsymbol{\\mu}^2 + \\boldsymbol{\\sigma}^2\\qquad (t\\to\\infty)
\\end{aligned}\\end{equation}
至于分子，可以直接展开平方计算，也可以稍微偷懒一下：我们要求的是$\\boldsymbol{m}\_t$的二阶矩$\\mathbb{E}\[\\boldsymbol{m}\_t^2\]$，它又等于$\\mathbb{E}\[\\boldsymbol{m}\_t\]^2 + \\mathbb{V}ar\[\\boldsymbol{m}\_t\]$，由于$\\boldsymbol{m}\_t$是$\\boldsymbol{g}\_i$的加权平均，所以必然有$\\mathbb{E}\[\\boldsymbol{m}\_t\]=\\mathbb{E}\[\\boldsymbol{g}\_i\]=\\boldsymbol{\\mu}$；至于方差，它具有平方可加性，因此
\\begin{equation}\\mathbb{V}ar\[\\boldsymbol{m}\_t\] = (1 - \\beta\_1)^2\\sum\_{i=1}^t \\beta\_1^{2(t-i)}\\boldsymbol{\\sigma}^2 = \\frac{(1 - \\beta\_1)^2 (1 - \\beta\_1^{2t})}{1 - \\beta\_1^2}\\boldsymbol{\\sigma}^2= \\frac{1 - \\beta\_1}{1 + \\beta\_1}\\boldsymbol{\\sigma}^2\\qquad (t\\to\\infty)\\end{equation}
所以
\\begin{equation}\\mathbb{E}\[\\boldsymbol{u}\_t^2\]\\approx \\frac{\\boldsymbol{\\mu}^2 + \\frac{1 - \\beta\_1}{1 + \\beta\_1}\\boldsymbol{\\sigma}^2}{\\boldsymbol{\\mu}^2 + \\boldsymbol{\\sigma}^2}\\end{equation}

## 结果分析 [\#](https://kexue.fm/kexue.fm\#%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90)

由于$\\mathbb{E}\[\\boldsymbol{u}\_t^2\]$已经是平方后的向量，所以为了估计$\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}$，我们只需要对各个分量求平均然后开平方。求平均这一步，我们不妨再来一次平均场近似（分子分母分别求平均），最终将得到
\\begin{equation}\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS} \\approx \\sqrt{\\frac{\\Vert\\boldsymbol{\\mu}\\Vert^2 + \\frac{1 - \\beta\_1}{1 + \\beta\_1}\\Vert\\boldsymbol{\\sigma}\\Vert^2}{\\Vert\\boldsymbol{\\mu}\\Vert^2 + \\Vert\\boldsymbol{\\sigma}\\Vert^2}} = \\sqrt{\\frac{\\Vert\\boldsymbol{\\mu}\\Vert^2/\\Vert\\boldsymbol{\\sigma}\\Vert^2 + \\frac{1 - \\beta\_1}{1 + \\beta\_1}}{\\Vert\\boldsymbol{\\mu}\\Vert^2/\\Vert\\boldsymbol{\\sigma}\\Vert^2 + 1}}\\label{eq:mean-field}\\end{equation}
它有两个影响因子：一是$\\Vert\\boldsymbol{\\mu}\\Vert^2/\\Vert\\boldsymbol{\\sigma}\\Vert^2$，这可以看成是梯度的信噪比（SNR）；二是$\\beta\_1$，这是Adam的超参数之一。特别地，结果不依赖于$\\beta\_2$，这跟前面的模拟结果吻合。那么这个式子究竟近似得好不好呢？我们不妨考虑最简单的特例$\\boldsymbol{\\mu}=\\boldsymbol{0}$，此时
\\begin{equation}\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS} \\approx \\sqrt{\\frac{1 - \\beta\_1}{1 + \\beta\_1}}\\end{equation}
代入$\\beta\_1=0.9$，结果是$0.2294\\cdots$，跟模拟结果和实践表现居然都很吻合！进一步地，它跟模拟结果的多个对比如下：

模拟结果与平均场近似（不同beta1、beta2）

应该说，近似程度还是不错的，特别是$\\beta\_2 \\geq 0.9$之后，结果几乎跟平均场近似重合了。至于考虑SNR的比较结果如下：

模拟结果与平均场近似（不同beta1、SNR）

当信噪比增大时，平均场近似的误差开始变大，不过仍旧能预测一个整体趋势。事实上，实际训练中梯度的信噪比很少机会能有接近1这么大，因此依然可以认为平均场是一个良好近似。

## 反向预测 [\#](https://kexue.fm/kexue.fm\#%E5%8F%8D%E5%90%91%E9%A2%84%E6%B5%8B)

如果我们已经接受平均场近似$\\eqref{eq:mean-field}$，那么可以反过来用它估算梯度的信噪比：
\\begin{equation}\\frac{\\Vert\\boldsymbol{\\mu}\\Vert^2}{\\Vert\\boldsymbol{\\sigma}\\Vert^2} \\approx \\frac{\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}^2 - \\frac{1 - \\beta\_1}{1 + \\beta\_1}}{1 - \\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}^2}\\end{equation}
在实际训练中，$\\beta\_1$是给定的，$\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}$（也就是Adam的Update RMS）也是可以直接估算的，所以上式是可计算的。当然，这个式子只对Adam适用，有没有更一般的估计思路呢？还真有！别忘了前面我们估计得到
\\begin{equation}\\mathbb{E}\[\\boldsymbol{m}\_t^2\]\\approx \\boldsymbol{\\mu}^2 + \\frac{1 - \\beta\_1}{1 + \\beta\_1}\\boldsymbol{\\sigma}^2\\end{equation}
那么对它的分量求和然后开平方，我们认为它会是$\\Vert\\boldsymbol{m}\_t\\Vert$的一个近似：
\\begin{equation}\\Vert\\boldsymbol{m}\_t\\Vert\\approx \\sqrt{\\Vert\\boldsymbol{\\mu}\\Vert^2 + \\frac{1 - \\beta\_1}{1 + \\beta\_1}\\Vert\\boldsymbol{\\sigma}\\Vert^2}\\end{equation}
至于二阶矩是$\\mathbb{E}\[\\boldsymbol{v}\_t\]\\approx \\boldsymbol{\\mu}^2 + \\boldsymbol{\\sigma}^2$，而像Muon之类的优化器并没有二阶矩可用，但是我们留意到二阶矩的结果是跟$\\beta\_2$无关的，所以我们不妨考虑一个最简单的特例——$\\beta\_2=0$——此时$\\boldsymbol{v}\_t=\\boldsymbol{g}\_t^2$。当然这可能有点勉强，但估算嘛肯定是怎么方便怎么来。这个“近似”意味着成立$\\Vert\\boldsymbol{g}\_t\\Vert^2\\approx \\Vert\\boldsymbol{\\mu}\\Vert^2 + \\Vert\\boldsymbol{\\sigma}\\Vert^2$，于是我们有
\\begin{equation}\\frac{\\Vert\\boldsymbol{m}\_t\\Vert}{\\Vert\\boldsymbol{g}\_t\\Vert}\\approx \\sqrt{\\frac{\\Vert\\boldsymbol{\\mu}\\Vert^2 + \\frac{1 - \\beta\_1}{1 + \\beta\_1}\\Vert\\boldsymbol{\\sigma}\\Vert^2}{\\Vert\\boldsymbol{\\mu}\\Vert^2 + \\Vert\\boldsymbol{\\sigma}\\Vert^2}}\\end{equation}
右端的形式跟式$\\eqref{eq:mean-field}$如出一辙，所以我们可以写出
\\begin{equation}\\frac{\\Vert\\boldsymbol{\\mu}\\Vert^2}{\\Vert\\boldsymbol{\\sigma}\\Vert^2} \\approx \\frac{\\Vert\\boldsymbol{m}\_t\\Vert^2/\\Vert\\boldsymbol{g}\_t\\Vert^2 - \\frac{1 - \\beta\_1}{1 + \\beta\_1}}{1 - \\Vert\\boldsymbol{m}\_t\\Vert^2/\\Vert\\boldsymbol{g}\_t\\Vert^2}\\end{equation}
也就是用$\\Vert\\boldsymbol{m}\_t\\Vert/\\Vert\\boldsymbol{g}\_t\\Vert$替代$\\Vert\\boldsymbol{u}\_t\\Vert\_{RMS}$，这就给出了一种带动量优化器通用的估计$\\Vert\\boldsymbol{\\mu}\\Vert^2/\\Vert\\boldsymbol{\\sigma}\\Vert^2$的思路。可能还有读者想问动量都没有咋办？这就真没有办法了，因为这里的$\\Vert\\boldsymbol{\\mu}\\Vert^2/\\Vert\\boldsymbol{\\sigma}\\Vert^2$属于跨优化轨迹的统计量，我们总得有些跨轨迹的统计信息，才有可能去估计它。

## 文章小结 [\#](https://kexue.fm/kexue.fm\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文主要从模拟实验和理论近似两个角度探讨了Adam的Update RMS，它可以作为我们在Muon优化器中将Update RMS对齐到0.2的理论依据之一。

_**转载到请包括本文地址：** [https://kexue.fm/archives/11267](https://kexue.fm/archives/11267)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Sep. 02, 2025). 《为什么Adam的Update RMS是0.2？ 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/11267](https://kexue.fm/archives/11267)

@online{kexuefm-11267,
        title={为什么Adam的Update RMS是0.2？},
        author={苏剑林},
        year={2025},
        month={Sep},
        url={\\url{https://kexue.fm/archives/11267}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/), [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/), [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/), [平均场](https://kexue.fm/tag/%E5%B9%B3%E5%9D%87%E5%9C%BA/)[4 评论](https://kexue.fm/archives/11267#comments)

< [重新思考学习率与Batch Size的关系（一）：现状](https://kexue.fm/archives/11260) \| >

### 你也许还对下面的内容感兴趣

- [重新思考学习率与Batch Size的关系（一）：现状](https://kexue.fm/archives/11260)
- [流形上的最速下降：4\. Muon + 谱球面](https://kexue.fm/archives/11241)
- [ReLU/GeLU/Swish的一个恒等式](https://kexue.fm/archives/11233)
- [流形上的最速下降：3\. Muon + Stiefel](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon + 正交](https://kexue.fm/archives/11215)
- [流形上的最速下降：1\. SGD + 超球面](https://kexue.fm/archives/11196)
- [QK-Clip：让Muon在Scaleup之路上更进一步](https://kexue.fm/archives/11126)
- [msign的导数](https://kexue.fm/archives/11025)
- [msign算子的Newton-Schulz迭代（下）](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

[长琴](https://yam.gift)

September 2nd, 2025

神奇

[回复评论](https://kexue.fm/archives/11267/comment-page-1?replyTo=28495#respond-post-11267)

z

September 5th, 2025

牛

[回复评论](https://kexue.fm/archives/11267/comment-page-1?replyTo=28524#respond-post-11267)

[Evan1024](https://nanoai.run/)

September 7th, 2025

太牛了！

[回复评论](https://kexue.fm/archives/11267/comment-page-1?replyTo=28530#respond-post-11267)

gapeng

September 7th, 2025

kimi k2形式上推导了一个公式，最后数值模拟在0.23左右。偏离$\\beta\_1=0.9, \\beta\_2=0.95$比较大时误差也会变大。

[回复评论](https://kexue.fm/archives/11267/comment-page-1?replyTo=28531#respond-post-11267)

[取消回复](https://kexue.fm/archives/11267#respond-post-11267)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[问题引入](https://kexue.fm/kexue.fm#%E9%97%AE%E9%A2%98%E5%BC%95%E5%85%A5)
[数值模拟](https://kexue.fm/kexue.fm#%E6%95%B0%E5%80%BC%E6%A8%A1%E6%8B%9F)
[平均近似](https://kexue.fm/kexue.fm#%E5%B9%B3%E5%9D%87%E8%BF%91%E4%BC%BC)
[结果分析](https://kexue.fm/kexue.fm#%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90)
[反向预测](https://kexue.fm/kexue.fm#%E5%8F%8D%E5%90%91%E9%A2%84%E6%B5%8B)
[文章小结](https://kexue.fm/kexue.fm#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [必须要GPT3吗？不，BERT的MLM模型也能小样本学习](https://kexue.fm/archives/7764)
- [大词表语言模型在续写任务上的一个问题及对策](https://kexue.fm/archives/9762)
- [科学空间：2010年12月重要天象](https://kexue.fm/archives/1085)
- [小数的二进制表示](https://kexue.fm/archives/1907)
- [10月国际空间站过境时间](https://kexue.fm/archives/131)
- [高中数学联赛题目和答案](https://kexue.fm/archives/1382)
- [圆内随机n点在同一个圆心角为θ的扇形的概率](https://kexue.fm/archives/9324)
- [科学空间：2011年6月重要天象](https://kexue.fm/archives/1370)
- [《向量》系列——1.向心力公式证明](https://kexue.fm/archives/701)
- [端到端的腾讯验证码识别（46%正确率）](https://kexue.fm/archives/4138)

### 最近评论

- [gapeng](https://kexue.fm/archives/11267/comment-page-1#comment-28531): kimi k2形式上推导了一个公式，最后数值模拟在0.23左右。偏离$\\beta\_1=0.9,...
- [Evan1024](https://kexue.fm/archives/11267/comment-page-1#comment-28530): 太牛了！
- [ameowcat](https://kexue.fm/archives/10958/comment-page-3#comment-28529): 苏神您好，有个问题想请教一下，最近扩散模型的推理优化有一篇文章也是使用ode：https://...
- [Eliot](https://kexue.fm/archives/10815/comment-page-1#comment-28528): 2 实现loss-free with budget应当是在当前Megatron-LM基础上应当...
- [Eliot](https://kexue.fm/archives/10815/comment-page-1#comment-28527): 继续阅读这2份代码后，大概结论如下
1 megatron-lm应当只实现了经典的loss-fr...
- [lzyyzl](https://kexue.fm/archives/11025/comment-page-1#comment-28525): 帮忙解惑一下
1 文中提到本文主题是求O=msign(M)的导数。将∇ML表示为∇OL的函数也...
- [z](https://kexue.fm/archives/11267/comment-page-1#comment-28524): 牛
- [Gusto](https://kexue.fm/archives/10739/comment-page-2#comment-28523): 按照个人理解将weight decay理解为损失函数中的惩罚项的话，为什么weight dec...
- [hazdzz](https://kexue.fm/archives/11196/comment-page-1#comment-28522): 非常感谢您提到 pbSGD，这启发了我的毕业论文！
- [苏剑林](https://kexue.fm/content.html/comment-page-1#comment-28521): 你是指xml代码？那不是乱码，feed就是xml格式，你要自己找工具订阅。

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [Zhang's blog](https://armcvai.cn/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。