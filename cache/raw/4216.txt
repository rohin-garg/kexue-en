## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)

## COMMENTS

- [苏剑林: 我的测试结果是mha-128跟mla-192大致上持平。要说潜...](https://kexue.fm/archives/10907/comment-page-1#comment-27869)
- [xumingyu: 不好意思...我刚刚把csgn和msign看岔了.](https://kexue.fm/archives/11025/comment-page-1#comment-27868)
- [Kai Liu: 此外，由于目标函数是1，所以$f^∗\_t(x）$在 $x$ 处...](https://kexue.fm/archives/10996/comment-page-1#comment-27866)
- [xumingyu: (21)式是怎么推出来的呀？或许这里可以给个链接以帮助阅读](https://kexue.fm/archives/11025/comment-page-1#comment-27865)
- [tesslqy: 数学系机器学习从业人员有这个心学学物理还研究了不少算不错了，要...](https://kexue.fm/archives/3638/comment-page-1#comment-27863)
- [陈荣子: 文中“6至7周岁后，幼狐开始断奶。”是不是多了一个“岁”？](https://kexue.fm/archives/4/comment-page-1#comment-27862)
- [Zanwei Zhou: 感谢苏神的回复！我理解您的意思，Meanflow确实给出了一个...](https://kexue.fm/archives/10958/comment-page-1#comment-27861)
- [个个君: 捉虫“按照分布轨迹xt=(1−t)x0+tx1，将x1变到x1...](https://kexue.fm/archives/10958/comment-page-1#comment-27860)
- [Phoenix8215: 苏神QT-ViT: Improving Linear Atte...](https://kexue.fm/archives/8601/comment-page-1#comment-27858)
- [Khazzz1c: Rope-Tie-v2的那个图 右侧是数学计算写错了 还得加上...](https://kexue.fm/archives/10352/comment-page-2#comment-27853)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) SVD分解(二)：为什么SVD意味着聚类？

26Jan

# [SVD分解(二)：为什么SVD意味着聚类？](https://kexue.fm/archives/4216)

By 苏剑林 \|
2017-01-26 \|
90259位读者\|

**提前祝各位读者新年快乐，2017行好运～**

这篇文章主要想回答两个“为什么”的问题：1、为啥我就对SVD感兴趣了？；2、为啥我说SVD是一个聚类过程？回答的内容纯粹个人思辨结果，暂无参考文献。

## 为什么要研究SVD？ [\#](https://kexue.fm/archives/4216\#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%A0%94%E7%A9%B6SVD%EF%BC%9F)

从2015年接触深度学习到现在，已经研究了快两年的深度学习了，现在深度学习、数据科学等概念也遍地开花。为什么在深度学习火起来的时候，我反而要回去研究“古老”的SVD分解呢？我觉得，SVD作为一个矩阵分解算法，它的价值不仅仅体现在它广泛的应用，它背后还有更加深刻的内涵，即它的可解释性。在深度学习流行的今天，不少人还是觉得深度学习（神经网络）就是一个有效的“黑箱”模型。但是，仅用“黑箱”二字来解释深度学习的有效性显然不能让人满意。前面已经说过，SVD分解本质上与不带激活函数的三层自编码机等价，理解SVD分解，能够为神经网络模型寻求一个合理的概率解释。

近来，我尝试做一些较为复杂的模型，比如问答系统、聊天机器人，我越来越感觉到，刚开始上手的时候，最近大放异彩的seq2seq之类的深度学习模型基本没法用。我基本上是 **从最基本的概率模型$P(A\|Q)$出发，逐步简化，最后得到一个复杂度可以接受的模型。这样得到的模型意义清晰、可控性强。** 但是其中的一部分是基于统计来做的，纯粹的统计没法得到真正“智能”的结果，而前面说过，SVD分解可以在统计结果的基础上带来初步的智能。这给我强烈的感觉，一个是模型的可解释性尤其是概率解释是很重要的，另外一个是更好理解了SVD之后，对神经网络模型的意义和应用都更有感觉了。

## SVD分解是怎么聚类的？ [\#](https://kexue.fm/archives/4216\#SVD%E5%88%86%E8%A7%A3%E6%98%AF%E6%80%8E%E4%B9%88%E8%81%9A%E7%B1%BB%E7%9A%84%EF%BC%9F)

为什么SVD分解是聚类？其实这里边是一个很简单的概率模型。

给定矩阵$M\_{m\\times n}$，不失一般性，假设它每个元素都是非负数，这样我们就可以对每一行做归一化，这样，得到的矩阵可以表示一个转移概率
$$P(B\|A)=\\begin{pmatrix}p(b\_1\|a\_1) & p(b\_2\|a\_1) & \\dots & p(b\_n\|a\_1)\\\
p(b\_1\|a\_2) & p(b\_2\|a\_2) & \\dots & p(b\_n\|a\_2)\\\
\\vdots & \\vdots & \\ddots & \\vdots\\\
p(b\_1\|a\_m) & p(b\_2\|a\_m) & \\dots & p(b\_n\|a\_m)\\end{pmatrix}$$
归一化条件是
$$\\sum\_{j=1}^n p(b\_j\|a\_i)=1, \\quad i=1,2,\\dots,m$$
所谓$p(b\_j\|a\_i)$，即$a\_i$后接$b\_j$的概率，这种概率模型是很常见的，比如二元语言模型。

现在我们假设各个$a\_i$可以聚为$l$个类，分别为$c\_1,c\_2,\\dots,c\_l$；而各$b\_i$可以聚为$k$个类，分别为$d\_1,d\_2,\\dots,d\_k$；我们要研究$a\_i$后接$b\_j$的规律，事实上可以简化为类别之间的规律（一个典型的小案例就是：我们将词语分为动词、名词、形容词等，然后发现动词后面可以接名词构成短语，“动词＋名词”就是我们大脑发现的聚类规律了）。这就是SVD分解的唯一假设了。更清晰地，假设包括：

> 1、$a\_i$和$b\_i$都可以聚为若干个类；
> 2、$a\_i$和$b\_i$之间的连接规律可以简化为两者所属的类的连接规律。

这时候根据概率公式，就得到
$$p(b\_j\|a\_i) = \\sum\_{k,l}p(b\_j\|d\_k)p(d\_k\|c\_l)p(c\_l\|a\_i)$$

每一项都有非常清晰的概率意义：

> $p(c\_l\|a\_i)$是$a\_i$表现为类别$c\_l$的概率；
>
> $p(d\_k\|c\_l)$是类别$c\_l$后接类别$d\_k$概率；
>
> $p(b\_j\|d\_k)$是已知类别$d\_k$时，元素为$b\_j$的概率。

这样自然有$p(b\_j\|a\_i) = \\sum\_{k,l}p(b\_j\|d\_k)p(d\_k\|c\_l)p(c\_l\|a\_i)$，也就是说，只要假设成立，那么这个公式是精确成立的。而这个运算，正好是三个矩阵的乘法：
$$P(B\|A)=P(B\|D)\\times P(D\|C)\\times P(C\|A)$$
也就是说，一个矩阵分解为三个维度更低的矩阵相乘，这不就是SVD分解吗？当然，细致上的区别是，如果是概率分解，则需要有归一化要求，这部分内容属于主题模型中pLSA模型的内容，而SVD分解本身不需要归一化约束，但这不影响本质思想，即矩阵分解蕴含了聚类的意义在里边。

这样，我们就通过矩阵分解，来对行与列进行了聚类。我们不需要告诉计算机聚成哪些类（比如，不需要告诉计算机要将词语分为名词、动词、形容词等），而是直接矩阵分解来完成（试想一下，只要用“大声公”喊一声“集合啦，要聚类啦”，大家自动分好类，不用我们告诉它怎么做。）。或者反过来说，我们通过概率模型，为SVD分解赋予了聚类意义。

## 新年快乐 [\#](https://kexue.fm/archives/4216\#%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%90)

额...本来感觉一两句话可以讲清楚的事情，又扯了那么多文字，希望读者不要觉得我哆嗦^\_^

再次祝大家新年快乐啦，年年都是那句：希望大家多多捧场！

_**转载到请包括本文地址：** [https://kexue.fm/archives/4216](https://kexue.fm/archives/4216)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/4216#share)/ [打赏](https://kexue.fm/archives/4216#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jan. 26, 2017). 《SVD分解(二)：为什么SVD意味着聚类？ 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/4216](https://kexue.fm/archives/4216)

@online{kexuefm-4216,
        title={SVD分解(二)：为什么SVD意味着聚类？},
        author={苏剑林},
        year={2017},
        month={Jan},
        url={\\url{https://kexue.fm/archives/4216}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [聚类](https://kexue.fm/tag/%E8%81%9A%E7%B1%BB/), [SVD](https://kexue.fm/tag/SVD/)[16 评论](https://kexue.fm/archives/4216#comments)

< [SVD分解(一)：自编码器与人工智能](https://kexue.fm/archives/4208) \| [除夕试拍星空星轨～](https://kexue.fm/archives/4222) >

### 你也许还对下面的内容感兴趣

- [通过msign来计算mclip（奇异值裁剪）](https://kexue.fm/archives/11006)
- [SVD的导数](https://kexue.fm/archives/10878)
- [低秩近似之路（二）：SVD](https://kexue.fm/archives/10407)
- [最小熵原理（五）：“层层递进”之社区发现与聚类](https://kexue.fm/archives/7006)
- [最小熵原理（四）：“物以类聚”之从图书馆到词向量](https://kexue.fm/archives/6191)
- [变分自编码器（四）：一步到位的聚类方案](https://kexue.fm/archives/5887)
- [从最大似然到EM算法：一致的理解方式](https://kexue.fm/archives/5239)
- [三味Capsule：矩阵Capsule与EM路由](https://kexue.fm/archives/5155)
- [再来一顿贺岁宴：从K-Means到Capsule](https://kexue.fm/archives/5112)
- [揭开迷雾，来一顿美味的Capsule盛宴](https://kexue.fm/archives/4819)

[发表你的看法](https://kexue.fm/archives/4216#comment_form)

xufeng

December 25th, 2017

解释的真不错呀

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=8496#respond-post-4216)

马套

May 9th, 2019

写得很有启发性，但是我还是有点疑问：
\\*\\*\\*
正好是三个矩阵的乘法：
P(B\|A)=P(B\|D)×P(D\|C)×P(C\|A)
\\*\\*\\*
关于上面这一段，svd的sigema矩阵是对角矩阵，而P(D\|C)不是对角矩阵
这么解释好像存在一定的问题

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=11130#respond-post-4216)

[苏剑林](https://kexue.fm) 发表于
May 10th, 2019

其实我当初理解的SVD是优化角度的，即对于矩阵$\\boldsymbol{A}$，找到矩阵$\\boldsymbol{B},\\boldsymbol{C},\\boldsymbol{D}$，使得$\\Vert \\boldsymbol{A} - \\boldsymbol{B}\\boldsymbol{C}\\boldsymbol{D}\\Vert\_F$最小化。这样一来$\\boldsymbol{C}$就未必是对角形式了～

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=11133#respond-post-4216)

zp1008611 发表于
May 26th, 2025

感觉这种优化理解应该说是低秩分解的角度理解，SVD是低秩分解的特例.

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=27671#respond-post-4216)

diamria 发表于
February 27th, 2020

这对svd 一种聚类方向的解释吧，确实能够解释为什么选每一行最大值所在列作为数据的类别这个问题。
不过svd本质还是线性变换吧，n为空间到m 维空间的变换，本质还是纯数学的吧，这样更加严谨。

我们老师讲svd说了svd 可以聚类，但是就说这样就可以，不知道为什么，博主给了一个解释，挺有启发的。

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=12918#respond-post-4216)

cc

July 11th, 2019

挺有意思的，苏神是否可以讲讲 SVD对二分图进行聚类，找到k类具有紧密关系结构的子图

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=11585#respond-post-4216)

123

September 26th, 2019

感谢分享，文中“近来，我尝试做一些较为复杂的模型，比如问答系统、聊天机器人，我越来越感觉到，刚开始上手的时候，最近大放异彩的seq2seq之类的深度学习模型基本没法用。” 想问下苏神，为什么seq2seq之类的模型不能胜任QA、chatbot之类的复杂任务？还有类似这些复杂的任务一般用什么模型来做呢？

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=12060#respond-post-4216)

[苏剑林](https://kexue.fm) 发表于
September 26th, 2019

seq2seq可控性很差。当然这是当年的评价了，现在已经有长足的进步了。

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=12067#respond-post-4216)

king

October 7th, 2019

p(bj\|ai)=∑k,lp(bj\|dk)p(dk\|cl)p(cl\|ai) 这个公式是怎么推到出来的呢？

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=12118#respond-post-4216)

[苏剑林](https://kexue.fm) 发表于
October 7th, 2019

这个公式就是两个假设的等价写法，不是推导出来的。

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=12135#respond-post-4216)

zbh

July 19th, 2020

“对每一行做归一行”应该是“归一化”。

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=13869#respond-post-4216)

[苏剑林](https://kexue.fm) 发表于
July 19th, 2020

done. thanks.

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=13870#respond-post-4216)

Eva

November 15th, 2021

很受启发！

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=17803#respond-post-4216)

ZqY

December 27th, 2021

想请问下 p(bj\|ai)=∑k,lp(bj\|dk)p(dk\|cl)p(cl\|ai) 这里可以这么用吗，是否需要bj与cl, ai无关的假设呢？

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=18103#respond-post-4216)

[苏剑林](https://kexue.fm) 发表于
December 29th, 2021

严格来说是需要声明。但这里很明显，只是解决转移概率的类比来为矩阵乘法赋予一个形象的意义，从而为SVD赋予一个形象的意义，所以get到思想就行了，不必要纠结细节，因为本来就不是什么严格的证明。

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=18115#respond-post-4216)

ZqY 发表于
December 29th, 2021

好的，谢谢您~

[回复评论](https://kexue.fm/archives/4216/comment-page-1?replyTo=18123#respond-post-4216)

[取消回复](https://kexue.fm/archives/4216#respond-post-4216)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[为什么要研究SVD？](https://kexue.fm/archives/4216#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%A0%94%E7%A9%B6SVD%EF%BC%9F)
[SVD分解是怎么聚类的？](https://kexue.fm/archives/4216#SVD%E5%88%86%E8%A7%A3%E6%98%AF%E6%80%8E%E4%B9%88%E8%81%9A%E7%B1%BB%E7%9A%84%EF%BC%9F)
[新年快乐](https://kexue.fm/archives/4216#%E6%96%B0%E5%B9%B4%E5%BF%AB%E4%B9%90)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [【NASA每日一图】NGC 6559 的恒星,尘埃和星云](https://kexue.fm/archives/51)
- [从Knotsevich在黑板上写的级数题目谈起](https://kexue.fm/archives/3229)
- [【理解黎曼几何】3\. 测地线](https://kexue.fm/archives/3977)
- [关于光的传播定律](https://kexue.fm/archives/29)
- [意犹未尽——继续光学曲线](https://kexue.fm/archives/1058)
- [平面曲线的曲率的复数表示](https://kexue.fm/archives/2403)
- [带点电荷的均匀杆](https://kexue.fm/archives/2362)
- [CoSENT（二）：特征式匹配与交互式匹配有多大差距？](https://kexue.fm/archives/8860)
- [泰迪杯赛前培训之数据挖掘与建模“慢谈”](https://kexue.fm/archives/4271)
- [数学魔术——漂亮的近似](https://kexue.fm/archives/654)

### 最近评论

- [苏剑林](https://kexue.fm/archives/10907/comment-page-1#comment-27869): 我的测试结果是mha-128跟mla-192大致上持平。要说潜力可能是mha-128高点，但m...
- [xumingyu](https://kexue.fm/archives/11025/comment-page-1#comment-27868): 不好意思...我刚刚把csgn和msign看岔了.
- [Kai Liu](https://kexue.fm/archives/10996/comment-page-1#comment-27866): 此外，由于目标函数是1，所以$f^∗\_t(x）$在 $x$ 处的斜率大于零，所以$l\_t$ 只...
- [xumingyu](https://kexue.fm/archives/11025/comment-page-1#comment-27865): (21)式是怎么推出来的呀？或许这里可以给个链接以帮助阅读
- [tesslqy](https://kexue.fm/archives/3638/comment-page-1#comment-27863): 数学系机器学习从业人员有这个心学学物理还研究了不少算不错了，要是数学系的都把物理学的和物理系的...
- [陈荣子](https://kexue.fm/archives/4/comment-page-1#comment-27862): 文中“6至7周岁后，幼狐开始断奶。”是不是多了一个“岁”？
- [Zanwei Zhou](https://kexue.fm/archives/10958/comment-page-1#comment-27861): 感谢苏神的回复！我理解您的意思，Meanflow确实给出了一个清晰明确的优化目标。CTM构造l...
- [个个君](https://kexue.fm/archives/10958/comment-page-1#comment-27860): 捉虫“按照分布轨迹xt=(1−t)x0+tx1，将x1变到x1的ODE形式解是”应该是x1到x...
- [Phoenix8215](https://kexue.fm/archives/8601/comment-page-1#comment-27858): 苏神QT-ViT: Improving Linear Attention in ViT wit...
- [Khazzz1c](https://kexue.fm/archives/10352/comment-page-2#comment-27853): Rope-Tie-v2的那个图 右侧是数学计算写错了 还得加上一个L 才是11.5

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。