## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [为什么DeltaNet要加L2 N...](https://kexue.fm/archives/11486)
- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [低精度Attention可能存在有...](https://kexue.fm/archives/11371)

## COMMENTS

- [kaiyuan: 看了“Linear Transformers Are Secr...](https://kexue.fm/archives/11486/comment-page-1#comment-29036)
- [sog: 好的，符号相同，搞混了呃](https://kexue.fm/archives/11469/comment-page-1#comment-29035)
- [kerry: 还没有通读完后面的系列，提出一些拙见。\
降低方差这一节把原本的...](https://kexue.fm/archives/9119/comment-page-14#comment-29034)
- [Kevin Yin: I wrote https://research.novela...](https://kexue.fm/archives/11158/comment-page-1#comment-29033)
- [罗: 公式(6)显示出来是不是有点小问题？](https://kexue.fm/archives/11480/comment-page-1#comment-29032)
- [cmlin: 本人对这方面不太熟悉，想了解这三个条件的意义及动机，且希望这系...](https://kexue.fm/archives/11340/comment-page-1#comment-29031)
- [喝一口可乐: 理解了，感谢苏神回复，数学上给出建模分析确实清晰了很多，再次感...](https://kexue.fm/archives/10958/comment-page-3#comment-29030)
- [CuddleSabe1: 感觉普通的 flow matching 可以看成 degrad...](https://kexue.fm/archives/10958/comment-page-1#comment-29029)
- [岁月如书: 受教了，感谢](https://kexue.fm/archives/11126/comment-page-3#comment-29028)
- [苏剑林: 是](https://kexue.fm/archives/11126/comment-page-3#comment-29027)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) RoFormerV2：自然语言理解的极限探索

21Mar

# [RoFormerV2：自然语言理解的极限探索](https://kexue.fm/archives/8998)

By 苏剑林 \|
2022-03-21 \|
92204位读者\|

大概在1年前，我们提出了 [旋转位置编码（RoPE）](https://kexue.fm/archives/8265)，并发布了对应的预训练模型 [RoFormer](https://github.com/ZhuiyiTechnology/roformer)。随着时间的推移，RoFormer非常幸运地得到了越来越多的关注和认可，比如EleutherAI新发布的 [60亿](https://github.com/kingoflolz/mesh-transformer-jax/#gpt-j-6b) 和 [200亿](https://blog.eleuther.ai/announcing-20b/) 参数的GPT模型中就用上了RoPE位置编码，Google新提出的 [FLASH](https://kexue.fm/archives/8934) 模型论文中则明确指出了RoPE对Transformer效果有明显的提升作用。

与此同时，我们也一直在尝试继续加强RoFormer模型，试图让RoFormer的性能“更上一层楼”。经过近半年的努力，我们自认为取得了还不错的成果，因此将其作为“RoFormerV2”正式发布：

> **Github： [https://github.com/ZhuiyiTechnology/roformer-v2](https://github.com/ZhuiyiTechnology/roformer-v2)**

## 极限探索 [\#](https://kexue.fm/kexue.fm\#%E6%9E%81%E9%99%90%E6%8E%A2%E7%B4%A2)

在预训练模型兴起之后，不少研究人员都对一个问题相当感兴趣：预训练模型的极限在哪里？当然，“极限”这个词含义很丰富，以GPT3为代表的一系列工作试图探索的是参数量、数据量的极限，而微软近来提出的 [DeepNet](https://kexue.fm/archives/8978) 则探究的是深度的极限。对于我们来说，我们更想知道同一参数量下的性能极限，试图最充分地“压榨”预训练模型的性能，RoFormerV2正是这一理念的产物。

简单来说，RoFormerV2先在RoFormer的基础上对模型结构做了适当的简化，从而获得了一定的速度提升。训练方面，除了进行常规的无监督MLM预训练外，我们还收集了20多G的标注数据，进行了有监督的多任务预训练。在有监督式训练之下，模型效果获得了长足的提升，基本上实现了同一参数量下速度和效果的最优解。

特别地，3亿参数量的RoFormer large，在 [CLUE榜单](https://www.cluebenchmarks.com/rank.html) 上超过了若干10亿+参数量的模型，做到了第5名，它也是榜上前5名中参数量最少的模型：

RoFormerV2 large在CLUE上的“成绩单”

## 模型介绍 [\#](https://kexue.fm/kexue.fm\#%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D)

相比RoFormer，RoFormerV2的主要改动是简化模型结构、增加训练数据以及加入有监督训练，这些改动能让RoFormerV2最终取得了速度和效果的“双赢”。

### 结构的简化 [\#](https://kexue.fm/kexue.fm\#%E7%BB%93%E6%9E%84%E7%9A%84%E7%AE%80%E5%8C%96)

在结构上，RoFormerV2主要去掉了模型的所有Bias项，以及Layer Norm换成了简单的RMS Norm，并且去掉了RMS Norm的gamma参数。这些改动的灵感主要来自Google的 [T5](https://papers.cool/arxiv/1910.10683) 模型。

大家的潜意识里可能会觉得Bias项以及Layer Norm的beta和gamma参数计算量都很小，至少对速度来说是无关痛痒的。但事实出乎我们的意料：去掉这些看似“无关痛痒”的参数外，RoFormerV2的训练速度获得了明显的提升！

一些参考数据如下（RoFormer和RoBERTa速度接近，就不列出来了，base版的测试显卡为3090，large版的测试显卡为A100）：
\\begin{array}{c\|cc\|cc}
\\hline
& \\text{序列长度} & \\text{训练速度} & \\text{序列长度} & \\text{训练速度} \\\
\\hline
\\text{RoBERTa base} & 128 & 1.0\\text{x} & 512 & 1.0\\text{x} \\\
\\text{RoFormerV2 base} & 128 & 1.3\\text{x} & 512 & 1.2\\text{x}\\\
\\hline
\\text{RoBERTa large} & 128 & 1.0\\text{x} & 512 & 1.0\\text{x} \\\
\\text{RoFormerV2 large} & 128 & 1.3\\text{x} & 512 & 1.2\\text{x} \\\
\\hline
\\end{array}

### 无监督训练 [\#](https://kexue.fm/kexue.fm\#%E6%97%A0%E7%9B%91%E7%9D%A3%E8%AE%AD%E7%BB%83)

同RoFormer一样，RoFormerV2也是先通过MLM任务进行无监督预训练，不同的地方主要有两点：

> 1、RoFormer是在RoBERTa权重基础上进行训练，RoFormerV2是从零训练；
>
> 2、RoFormer的无监督训练只有30多G数据，RoFormerV2则用到了280G数据。

从零训练相比于在已有权重基础上继续训练会更加困难，主要体现在Post Norm结构更难收敛。为此，我们提出了一种新的训练技术：将残差设计为
\\begin{equation}\\boldsymbol{x}\_{t+1} = \\text{Norm}(\\boldsymbol{x}\_t + \\alpha F(\\boldsymbol{x}\_t)) \\end{equation}
其中$\\alpha$初始化为0并线性地缓慢增加到1，相关讨论还可以参考 [《浅谈Transformer的初始化、参数化与标准化》](https://kexue.fm/archives/8620)。该方案跟ReZero相似，不同的是ReZero中$\\alpha$是可训练参数且去掉$\\text{Norm}$操作，而实验显示我们的改动相比ReZero的最终效果更好，几乎是DeepNet之前的最优解。

### 多任务训练 [\#](https://kexue.fm/kexue.fm\#%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%AE%AD%E7%BB%83)

前面提到RoFormerV2的结构有所简化以获得速度的提升，但由于“没有免费的午餐”，同样的训练设置之下RoFormerV2相比RoBERTa、RoFormer的效果会有轻微下降。为了弥补回这部分下降的效果，更有效地挖掘模型潜力，我们补充了有监督式的多任务预训练。

具体来说，我们收集了77个共计20G的标注数据集，构建了92个任务进行多任务训练，这些数据集涵盖文本分类、文本匹配、阅读理解、信息抽取、指代消解等常见自然语言理解任务，以求模型能获得比较全面的自然语言理解能力。为了完成训练，我们在bert4keras基础上进一步开发了一个多任务训练框架，灵活支持不同格式的任务进行混合训练，并整合了梯度归一化等技术（参考 [《多任务学习漫谈（二）：行梯度之事》](https://kexue.fm/archives/8896)）来确保每个任务都达到尽可能优的效果。

RoFormerV2并不是第一个尝试多任务预训练的模型，在它之前有 [MT-DNN](https://papers.cool/arxiv/1901.11504)、 [T5](https://papers.cool/arxiv/1910.10683) 以及前段时间的 [ZeroPrompt](https://papers.cool/arxiv/2201.06910) 都已经肯定过多任务预训练的价值，而我们主要是在中文上进行了充分的验证并首先进行了开源。

## 实验结果 [\#](https://kexue.fm/kexue.fm\#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C)

我们主要在CLUE榜单上对比效果：
$$\\small{\\begin{array}{c\|ccccccccccc}
\\hline
& \\text{iflytek} & \\text{tnews} & \\text{afqmc} & \\text{cmnli} & \\text{ocnli} & \\text{wsc} & \\text{csl} & \\text{cmrc2018} & \\text{c3} & \\text{chid} & \\text{cluener}\\\
\\hline
\\text{BERT base} & 61.19 & 56.29 & 73.37 & 79.37 & 71.73 & 73.85 & 84.03 & 72.10 & 61.33 & 85.13 & 78.68\\\
\\hline
\\text{RoBERTa base} & 61.12 & 58.35 & 73.61 & 80.81 & 74.27 & 82.28 & \\textbf{85.33} & 75.40 & 67.11 & 86.04 & 79.38\\\
\\text{RoBERTa large} & 60.58 & 55.51 & 75.14 & \\textbf{82.16} & 75.47 & 81.97 & 85.07 & 78.85 & 76.74 & \\textbf{88.65} & \\textbf{80.19}\\\
\\hline
\\text{RoFormer base} & 61.08 & 56.74 & 73.82 & 80.97 & 73.10 & 80.57 & 84.93 & 73.50 & 66.29 & 86.30 & 79.69\\\
\\hline
\\text{RoFormerV2 small} & 60.46 & 51.46 & 72.39 & 76.93 & 67.70 & 69.11 & 83.00 & 71.80 & 64.49 & 77.35 & 78.20\\\
\\text{RoFormerV2 base} & 62.50 & \\textbf{58.74} & 75.63 & 80.62 & 74.23 & 82.71 & 84.17 & 77.00 & 75.57 & 85.95 & 79.87\\\
\\text{RoFormerV2 large} & \\textbf{62.65} & 58.06 & \\textbf{76.95} & 81.20 & \\textbf{75.83} & \\textbf{88.03} & 84.97 & \\textbf{80.50} & \\textbf{78.34} & 87.68 & \\textbf{80.17}\\\
\\hline
\\end{array}}$$

可以看到，多任务训练的提升是相当可观的，在大多数任务上RoFormerV2不仅“追回”了结构简化带来的效果差距，还有一定的提升，平均来说算得上达到了同级模型的最优效果。另外，CMNLI和CHID两个任务上，RoFormerV2都不如RoBERTa，这是因为这两个任务都训练数据都非常多（数十万级别），当训练数据量足够大时，模型的效果主要取决于模型的容量，多任务训练带来的提升比较小。

所以，总的来说就是：如果你的任务类型比较常规，数据量不是特别大，那么RoFormerV2往往是一个不错的选择；如果你希望加快一点训练速度，那么也可以选择RoFormerV2；但如果你的任务数据量特别大，那么RoFormerV2通常不会有优势。

## 本文小结 [\#](https://kexue.fm/kexue.fm\#%E6%9C%AC%E6%96%87%E5%B0%8F%E7%BB%93)

本文主要对我们新发布的RoFormerV2模型做了基本的介绍，它主要通过结构的简化来提升速度，并通过无监督预训练和有监督预训练的结合来提升效果，从而达到了速度与效果的“双赢”。

_**转载到请包括本文地址：** [https://kexue.fm/archives/8998](https://kexue.fm/archives/8998)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Mar. 21, 2022). 《RoFormerV2：自然语言理解的极限探索 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/8998](https://kexue.fm/archives/8998)

@online{kexuefm-8998,
        title={RoFormerV2：自然语言理解的极限探索},
        author={苏剑林},
        year={2022},
        month={Mar},
        url={\\url{https://kexue.fm/archives/8998}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/), [预训练](https://kexue.fm/tag/%E9%A2%84%E8%AE%AD%E7%BB%83/)[25 评论](https://kexue.fm/archives/8998#comments)

< [为什么需要残差？一个来自DeepNet的视角](https://kexue.fm/archives/8994) \| [为什么Pre Norm的效果不如Post Norm？](https://kexue.fm/archives/9009) >

### 你也许还对下面的内容感兴趣

- [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111)
- [Transformer升级之路：20、MLA好在哪里?（上）](https://kexue.fm/archives/10907)
- [Transformer升级之路：19、第二类旋转位置编码](https://kexue.fm/archives/10862)
- [Decoder-only的LLM为什么需要位置编码？](https://kexue.fm/archives/10347)
- [Monarch矩阵：计算高效的稀疏型矩阵分解](https://kexue.fm/archives/10249)
- [缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA](https://kexue.fm/archives/10091)
- [时空之章：将Attention视为平方复杂度的RNN](https://kexue.fm/archives/10017)
- [我在Performer中发现了Transformer-VQ的踪迹](https://kexue.fm/archives/9862)
- [预训练一下，Transformer的长序列成绩还能涨不少！](https://kexue.fm/archives/9787)
- [脑洞大开：非线性RNN居然也可以并行计算？](https://kexue.fm/archives/9783)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

1. [«](https://kexue.fm/archives/8998/comment-page-1#comments)
2. [1](https://kexue.fm/archives/8998/comment-page-1#comments)
3. [2](https://kexue.fm/archives/8998/comment-page-2#comments)

MECH

September 28th, 2023

问下苏神RoFormerV2从零训练的速度和使用资源怎么样？花了多久时间训练一个epoch呢？

[回复评论](https://kexue.fm/archives/8998/comment-page-2?replyTo=22816#respond-post-8998)

[苏剑林](https://kexue.fm) 发表于
September 28th, 2023

好像Large版用两张80G的A100大概训练了两个月吧，不大记得了，Base版好像是一个月左右，具体训练配置Github上有。

[回复评论](https://kexue.fm/archives/8998/comment-page-2?replyTo=22827#respond-post-8998)

NoelYin

May 14th, 2024

问下苏神，我正在做一些大模型在中文语料上的训练工作，您这边方便提供一下文中提到的数据集吗

[回复评论](https://kexue.fm/archives/8998/comment-page-2?replyTo=24333#respond-post-8998)

[苏剑林](https://kexue.fm) 发表于
May 15th, 2024

不能，这是我前公司的数据，我没有权限分享。

[回复评论](https://kexue.fm/archives/8998/comment-page-2?replyTo=24349#respond-post-8998)

NoelYin 发表于
May 20th, 2024

了解，感谢回复！

[回复评论](https://kexue.fm/archives/8998/comment-page-2?replyTo=24374#respond-post-8998)

pass\_lin

March 29th, 2025

roformerV2的苏神版本只支持keras2.3.1+tf1.15-tf2.2的组合，在现在看来太老旧了，不适合新朋友使用。

如果大家在2025后想继续使用roformerV2，建议使用keras3的新实现。你可以在keras\_hub>0.20版本后使用（截至这条消息的2025.3.29这个版本还未发布，但是很快了，敬请期待）。

权重下载链接：

https://www.modelscope.cn/models/q935499957/roformerV2\_small\_zh-Keras
https://www.modelscope.cn/models/q935499957/roformerV2\_base\_zh-Keras
https://www.modelscope.cn/models/q935499957/roformerV2\_large\_zh-Keras

[回复评论](https://kexue.fm/archives/8998/comment-page-2?replyTo=27263#respond-post-8998)

[苏剑林](https://kexue.fm) 发表于
March 30th, 2025

感谢

[回复评论](https://kexue.fm/archives/8998/comment-page-2?replyTo=27286#respond-post-8998)

1. [«](https://kexue.fm/archives/8998/comment-page-1#comments)
2. [1](https://kexue.fm/archives/8998/comment-page-1#comments)
3. [2](https://kexue.fm/archives/8998/comment-page-2#comments)

[取消回复](https://kexue.fm/archives/8998#respond-post-8998)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[极限探索](https://kexue.fm/kexue.fm#%E6%9E%81%E9%99%90%E6%8E%A2%E7%B4%A2)
[模型介绍](https://kexue.fm/kexue.fm#%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D)
[结构的简化](https://kexue.fm/kexue.fm#%E7%BB%93%E6%9E%84%E7%9A%84%E7%AE%80%E5%8C%96)
[无监督训练](https://kexue.fm/kexue.fm#%E6%97%A0%E7%9B%91%E7%9D%A3%E8%AE%AD%E7%BB%83)
[多任务训练](https://kexue.fm/kexue.fm#%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%AE%AD%E7%BB%83)
[实验结果](https://kexue.fm/kexue.fm#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C)
[本文小结](https://kexue.fm/kexue.fm#%E6%9C%AC%E6%96%87%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [NASA & 国际空间站 直播频道](https://kexue.fm/archives/20)
- [生成扩散模型漫谈（三十一）：预测数据而非噪声](https://kexue.fm/archives/11428)
- [三个相切圆的公切圆:补充](https://kexue.fm/archives/2333)
- [TeaForN：让Teacher Forcing更有“远见”一些](https://kexue.fm/archives/7818)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [费曼积分法——积分符号内取微分(4)](https://kexue.fm/archives/1637)
- [关于维度公式“n > 8.33 log N”的可用性分析](https://kexue.fm/archives/8711)
- [多标签“Softmax+交叉熵”的软标签版本](https://kexue.fm/archives/9064)
- [为什么梯度裁剪能加速训练过程？一个简明的分析](https://kexue.fm/archives/7469)
- [费曼路径积分思想的发展(一)](https://kexue.fm/archives/1844)

### 最近评论

- [kaiyuan](https://kexue.fm/archives/11486/comment-page-1#comment-29036): 看了“Linear Transformers Are Secretly Fast Weight...
- [sog](https://kexue.fm/archives/11469/comment-page-1#comment-29035): 好的，符号相同，搞混了呃
- [kerry](https://kexue.fm/archives/9119/comment-page-14#comment-29034): 还没有通读完后面的系列，提出一些拙见。
降低方差这一节把原本的目标“预测单步的noise”变成...
- [Kevin Yin](https://kexue.fm/archives/11158/comment-page-1#comment-29033): I wrote https://research.novelai.net/muonscale/...
- [罗](https://kexue.fm/archives/11480/comment-page-1#comment-29032): 公式(6)显示出来是不是有点小问题？
- [cmlin](https://kexue.fm/archives/11340/comment-page-1#comment-29031): 本人对这方面不太熟悉，想了解这三个条件的意义及动机，且希望这系列可以继续写下去。以下想发表一些...
- [喝一口可乐](https://kexue.fm/archives/10958/comment-page-3#comment-29030): 理解了，感谢苏神回复，数学上给出建模分析确实清晰了很多，再次感谢苏神回复！
- [CuddleSabe1](https://kexue.fm/archives/10958/comment-page-1#comment-29029): 感觉普通的 flow matching 可以看成 degrade-aware image de...
- [岁月如书](https://kexue.fm/archives/11126/comment-page-3#comment-29028): 受教了，感谢
- [苏剑林](https://kexue.fm/archives/11126/comment-page-3#comment-29027): 是

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。