μ(xt)

![MobileSideBar](https://kexue.fm/usr/themes/geekg/images/slide-button.png)

## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [让炼丹更科学一些（五）：基于梯度精...](https://kexue.fm/archives/11530)
- [让炼丹更科学一些（四）：新恒等式，...](https://kexue.fm/archives/11494)
- [为什么DeltaNet要加L2 N...](https://kexue.fm/archives/11486)
- [让炼丹更科学一些（三）：SGD的终...](https://kexue.fm/archives/11480)
- [让炼丹更科学一些（二）：将结论推广...](https://kexue.fm/archives/11469)
- [滑动平均视角下的权重衰减和学习率](https://kexue.fm/archives/11459)
- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)

## COMMENTS

- [Bin: 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院...](https://kexue.fm/archives/1990/comment-page-2#comment-29105)
- [Rapture D: 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。](https://kexue.fm/archives/11530/comment-page-1#comment-29104)
- [mofheka: 苏神是还在用jax是么？最近在做基于Google Pathwa...](https://kexue.fm/archives/11390/comment-page-1#comment-29103)
- [长琴: 看懂这篇博客也不是一件容易的事情。](https://kexue.fm/archives/11530/comment-page-1#comment-29102)
- [AlexLi: 苏老师，请教一下(7)式中将 μ(xt) 传给 $p...](https://kexue.fm/archives/9257/comment-page-4#comment-29101)
- [tyler\_zxc: "Performer的思想是将标准的Attention线性化，...](https://kexue.fm/archives/7921/comment-page-2#comment-29100)
- [我: 似乎并非mHC提出矩阵的思想？之前hyper connecti...](https://kexue.fm/archives/11494/comment-page-1#comment-29099)
- [winter: 苏神您好，假如对于比较均匀的attention weightP...](https://kexue.fm/archives/10847/comment-page-1#comment-29098)
- [苏剑林: KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个](https://kexue.fm/archives/8512/comment-page-2#comment-29097)
- [苏剑林: 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理...](https://kexue.fm/archives/9119/comment-page-14#comment-29096)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm/)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [![](https://kexue.fm/usr/themes/geekg/images/rss.png)\\
\\
欢迎订阅](https://kexue.fm/feed)
- [![](https://kexue.fm/usr/themes/geekg/images/mail.png)\\
\\
个性邮箱](https://kexue.fm/archives/119)
- [![](https://kexue.fm/usr/themes/geekg/images/Saturn.png)\\
\\
天象信息](https://kexue.fm/ac.html)
- [![](https://kexue.fm/usr/themes/geekg/images/iss.png)\\
\\
观测ISS](https://kexue.fm/archives/41)
- [![](https://kexue.fm/usr/themes/geekg/images/pi.png)\\
\\
LaTeX](https://kexue.fm/latex.html)
- [![](https://kexue.fm/usr/themes/geekg/images/mlogo.png)\\
\\
关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm/) [信息时代](https://kexue.fm/category/Big-Data) 变分自编码器（六）：从几何视角来理解VAE的尝试

10Sep

# [变分自编码器（六）：从几何视角来理解VAE的尝试](https://kexue.fm/archives/7725)

By 苏剑林 \|
2020-09-10 \|
108797位读者 \|

前段时间公司组织技术分享，轮到笔者时，大家希望我讲讲VAE。鉴于之前笔者也写过 [变分自编码器系列](https://kexue.fm/search/%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/)，所以对笔者来说应该也不是特别难的事情，因此就答应了下来，后来仔细一想才觉得犯难：怎么讲才好呢？

对于VAE来说，之前笔者有两篇比较系统的介绍： [《变分自编码器（一）：原来是这么一回事》](https://kexue.fm/archives/5253) 和 [《变分自编码器（二）：从贝叶斯观点出发》](https://kexue.fm/archives/5343)。后者是纯概率推导，对于不做理论研究的人来说其实没什么意义，也不一定能看得懂；前者虽然显浅一点，但也不妥，因为它是从生成模型的角度来讲的，并没有说清楚“为什么需要VAE”（说白了，VAE可以带来生成模型，但是VAE并不一定就为了生成模型），整体风格也不是特别友好。

笔者想了想，对于大多数不了解但是想用VAE的读者来说，他们应该只希望大概了解VAE的形式，然后想要知道“VAE有什么作用”、“VAE相比AE有什么区别”、“什么场景下需要VAE”等问题的答案，对于这种需求，上面两篇文章都无法很好地满足。于是笔者尝试构思了VAE的一种几何图景，试图从几何角度来描绘VAE的关键特性，在此也跟大家分享一下。

## 自编码器 [\#](https://kexue.fm/archives/7725\#%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8)

我们从自编码器（AutoEncoder，AE）出发。自编码器的初衷是为了数据降维，假设原始特征xx维度过高，那么我们希望通过编码器EE将其编码成低维特征向量z=E(x)z=E(x)，编码的原则是尽可能保留原始信息，因此我们再训练一个解码器DD，希望能通过zz重构原始信息，即x≈D(E(x))x≈D(E(x))，其优化目标一般是

E,D=argminE,DEx∼D\[‖x−D(E(x))‖2\]

对应的示意图如下：

[![自编码器示意图](https://kexue.fm/usr/uploads/2020/09/2808850132.png)](https://kexue.fm/usr/uploads/2020/09/2808850132.png "点击查看原图")

自编码器示意图

## 编码空间 [\#](https://kexue.fm/archives/7725\#%E7%BC%96%E7%A0%81%E7%A9%BA%E9%97%B4)

假如每个样本都可以重构得很好，那么我们可以将z当作是x的等价表示，也就是说把z研究好了就相当于把x研究好了。现在我们将每个x都编码出对应的特征向量z，然后我们关心一个问题：这些z覆盖的空间“长什么样”？

[![经过自编码器后，原始样本对应编码空间中的一个点](https://kexue.fm/usr/uploads/2020/09/3960764387.png)](https://kexue.fm/usr/uploads/2020/09/3960764387.png "点击查看原图")

经过自编码器后，原始样本对应编码空间中的一个点

为什么要关心这个问题呢？因为我们可以有很多不同的编码方式，不同编码方式得到的特征向量也有好坏之分，从“编码空间长什么样”我们可以大致地看出特征向量的好坏。比如下面四个不同的编码向量的分布形状模拟图：

[![四种不同的编码空间形状模拟图，分别代表无规律、线形、环形、圆形](https://kexue.fm/usr/uploads/2020/09/2840260916.png)](https://kexue.fm/usr/uploads/2020/09/2840260916.png "点击查看原图")

四种不同的编码空间形状模拟图，分别代表无规律、线形、环形、圆形

第一个图的向量分布没什么特别的形状，比较散乱，说明编码空间并不是特别规整；第二个图的向量集中在一条线上，说明其实编码向量的维度之间存在冗余；第三个图是一个环形，说明其圆心附近并没有对应的真实样本；第四个图是一个圆形，表明它比较规整地覆盖了一块连续空间。就四个图来看，我们认为最后一个图所描绘的向量分布形状是最理想的：规整、无冗余、连续，这意味着我们从中学习了一部分样本，就很容易泛化到未知的新样本上去，因为我们知道编码空间是规整连续的，所以我们知道训练样本的编码向量之间的“缝隙”（图中的两个点之间的空白部分），实际上也对应着未知的真实样本，因此把已知的搞好了，很可能未知的也搞好了。

## 从点到面 [\#](https://kexue.fm/archives/7725\#%E4%BB%8E%E7%82%B9%E5%88%B0%E9%9D%A2)

总的来说，大体上我们关心编码空间的如下问题：

> 1、所有编码向量覆盖一个怎样的区域？
>
> 2、是否有未知的真实样本对应空白之处的向量？
>
> 3、有没有“脱离群众”的向量？
>
> 4、有没有办法让编码空间更规整一些？

常规的自编码器由于没有特别的约束，因此很难回答上述问题。于是，变分自编码器出来了，从编码角度来看，它的目的是： **1、让编码空间更规整一些；2、让编码向量更紧凑一些。** 为了达到这个目的，变分自编码器先引入了后验分布p(z\|x)。

对于不想深究概率语言的读者来说，该怎么理解后验分布p(z\|x)呢？直观来看，我们可以将后验分布理解为一个“椭圆”，原来每个样本对应着一个编码向量，也就是编码空间中的一个点，引入后验分布之后，相对于说现在每个样本x都对应一个“椭圆”。刚才我们说希望编码向量更“紧凑”一些，但理论上来讲，再多的“点”也没有办法把一个“面”覆盖完，但要是用“面”来覆盖“面”，那么就容易把目标覆盖住了。这就是变分自编码器做出的主要改动之一。

[![每个样本的编码从一个点变成了一个面（椭圆），于是原本由点覆盖的编码空间变成了由面覆盖](https://kexue.fm/usr/uploads/2020/09/2603393496.png)](https://kexue.fm/usr/uploads/2020/09/2603393496.png "点击查看原图")

每个样本的编码从一个点变成了一个面（椭圆），于是原本由点覆盖的编码空间变成了由面覆盖

读者可能会问，为什么非得要椭圆呢？矩形或者其他形状可以吗？回到概率语言上，椭圆对应着“假设p(z\|x)各分量独立的高斯分布”，从概率的角度来看，高斯分布是比较容易处理的一类概率分布，所以我们用高斯分布，也就对应着椭圆，其他形状也就对应这其他分布，比如矩形可以跟均匀分布对应，但后面再算KL散度的时候会比较麻烦，因此一般不使用。

## 采样重构 [\#](https://kexue.fm/archives/7725\#%E9%87%87%E6%A0%B7%E9%87%8D%E6%9E%84)

现在每个样本x都对应一个“椭圆”，而确定一个“椭圆”需要两个信息：椭圆中心、椭圆轴长，它们各自构成一个向量，并且这个向量依赖于样本x，我们将其记为μ(x),σ(x)。既然整个椭圆都对应着样本x，我们要求椭圆内任意一点都可以重构x，所以训练目标为：

μ,σ,D=argminμ,σ,DEx∼D\[‖x−D(μ(x)+ε⊗σ(x))‖2\],ε∼N(0,1)

其中D是训练数据，N(0,1)为标准正态分布，我们可以将它理解为一个单位圆，也就是说，我们先从单位圆内采样ε，然后通过平移缩放变换μ(x)+ε⊗σ(x)将其变为“中心为μ(x)、轴长为σ(x)”的椭圆内的点，这个过程就是所谓的“重参数（Reparameterization）”。

这里的μ(x)其实就对应于自编码器中的编码器E(x)，σ(x)相当于它能泛化的范围。

## 空间正则 [\#](https://kexue.fm/archives/7725\#%E7%A9%BA%E9%97%B4%E6%AD%A3%E5%88%99)

最后，“椭圆”可以“让编码向量更紧凑”，但还不能“让编码空间更规整”。现在我们希望编码向量满足标准正态分布（可以将它理解为一个单位圆），即所有的椭圆覆盖的空间组成一个单位圆。

为此，我们希望每个椭圆都能向单位圆靠近，单位圆的中心为0，半径为1，所以一个基本想法是引入正则项：

Ex∼D\[‖μ(x)−0‖2+‖σ(x)−1‖2\]

事实上，这前面两项loss结合起来，就已经非常接近标准的变分自编码器了。标准的变分自编码器用了一个复杂一些、功能类似的正则项：

Ex∼D\[d∑i=112(μ2i(x)+σ2i(x)−logσ2i(x)−1)\]

这个正则项来源于两个高斯分布的KL散度，所以通常也叫“KL散度项”。

[![变分自编码器示意图](https://kexue.fm/usr/uploads/2020/09/783775597.png)](https://kexue.fm/usr/uploads/2020/09/783775597.png "点击查看原图")

变分自编码器示意图

将两项目标组合起来，就得到最终的变分自编码器了：

‖x−D(μ(x)+ε⊗σ(x))‖2+d∑i=112(μ2i(x)+σ2i(x)−logσ2i(x)−1),ε∼N(0,1)

## 文章总结 [\#](https://kexue.fm/archives/7725\#%E6%96%87%E7%AB%A0%E6%80%BB%E7%BB%93)

本文从几何类比的角度介绍了对变分自编码器（VAE）的理解，在此视角下，变分自编码器的目标是让编码向量更加紧凑，并规范了编码分布为标准正态分布（单位圆）。

这样一来，VAE能达到两个效果：1、从标准高斯分布（单位圆）随机采样一个向量，就可以由解码器得到真实样本，即实现了生成模型；2、由于编码空间的紧凑形以及训练时对编码向量所加入的噪声，使得编码向量的各个分量能做到一定程度的解耦，并赋予编码向量一定的线性运算性质。

几何视角能让我们快速地把握变分自编码器的关键特性，降低入门难度，但也有一定的不严谨之处。如有不妥当的地方，还请读者理解并指出。

_**转载到请包括本文地址：** [https://kexue.fm/archives/7725](https://kexue.fm/archives/7725 "变分自编码器（六）：从几何视角来理解VAE的尝试")_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8 "《科学空间FAQ》")

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/7725#share)/ [打赏](https://kexue.fm/archives/7725#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/wx.png)

微信打赏

![科学空间](https://kexue.fm/usr/themes/geekg/payment/zfb.png)

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。

你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Sep. 10, 2020). 《变分自编码器（六）：从几何视角来理解VAE的尝试 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/7725](https://kexue.fm/archives/7725)

@online{kexuefm-7725,

         title={变分自编码器（六）：从几何视角来理解VAE的尝试},

         author={苏剑林},

         year={2020},

         month={Sep},

         url={\\url{https://kexue.fm/archives/7725}},

}


分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [变分](https://kexue.fm/tag/%E5%8F%98%E5%88%86/), [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/), [vae](https://kexue.fm/tag/vae/), [生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/)[26 评论](https://kexue.fm/archives/7725#comments)

< [动手做个DialoGPT：基于LM的生成式多轮对话模型](https://kexue.fm/archives/7718 "动手做个DialoGPT：基于LM的生成式多轮对话模型") \| [殊途同归的策略梯度与零阶优化](https://kexue.fm/archives/7737 "殊途同归的策略梯度与零阶优化") >

### 你也许还对下面的内容感兴趣

- [生成扩散模型漫谈（三十一）：预测数据而非噪声](https://kexue.fm/archives/11428 "生成扩散模型漫谈（三十一）：预测数据而非噪声")
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328 "DiVeQ：一种非常简洁的VQ训练方案")
- [为什么线性注意力要加Short Conv？](https://kexue.fm/archives/11320 "为什么线性注意力要加Short Conv？")
- [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111 "Transformer升级之路：21、MLA好在哪里?（下）")
- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033 "线性注意力简史：从模仿、创新到反哺")
- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958 "生成扩散模型漫谈（三十）：从瞬时速度到平均速度")
- [Transformer升级之路：20、MLA好在哪里?（上）](https://kexue.fm/archives/10907 "Transformer升级之路：20、MLA好在哪里?（上）")
- [生成扩散模型漫谈（二十九）：用DDPM来离散编码](https://kexue.fm/archives/10711 "生成扩散模型漫谈（二十九）：用DDPM来离散编码")
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667 "细水长flow之TARFLOW：流模型满血归来？")
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633 "生成扩散模型漫谈（二十八）：分步理解一致性模型")

[发表你的看法](https://kexue.fm/archives/7725#comment_form)

peakzeng

September 11th, 2020

一言蔽之，VAE 就是 AE 的贝叶斯化。把Z 的『点估计』 变成 Z 的概率分布P(z)的推断。对应你文中的『点』变成「椭圆」。就像以前经典的统计学习喜欢求解模型的最优解w, 而贝叶斯理论偏好求解模型参数w 的概率分布P(w)。所以VAE 更好的名字或许是 BAE（Bayesian auto encoder) :)

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=14298#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
September 11th, 2020

很正确的理解，其实就是估计点的同时估计它的不确定性。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=14304#respond-post-7725)

hdn

September 30th, 2020

这个系列太赞了！第一次理解了VAE。我自己是按，5716->二->一->三->四->六，看的；但是似乎（六）很适合标记为（零）啊。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=14483#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
September 30th, 2020

谢谢。

本篇的定位确实是“零”，不过编排是按照撰写时间顺序的，不调整了。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=14484#respond-post-7725)

[Allen](https://www.linkedin.com/in/allenyllee/)

October 7th, 2020

博主好，最近看到LeCun 出了一篇 Implicit Rank-Minimizing Autoencoder

https://arxiv.org/abs/2010.00679

方法非常簡單，而且效果似乎比VAE 還好，

博主有空可以研究一下~

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=14502#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
October 9th, 2020

谢谢推荐，前几天已经收藏了，还没空看，到时候看看再说。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=14513#respond-post-7725)

qazasdedc

December 21st, 2020

博主好，读博主的文章受益匪浅~

我有个小小的问题，请问博主对“每个椭圆都能向单位圆靠近”与“所有的椭圆覆盖的空间组成一个单位圆”之间的联系有什么看法呢。

我看大部分有关VAE的文章都或多或少提及使整个编码分布服从标准正态分布，但损耗函数看上去是让每个具体的编码各自服从标准正态分布。这个差别是由损耗函数由变分下界推导来造成的吗，还是这两者是等价的呢？

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=15054#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
December 21st, 2020

请看本系列第二篇关于VAE的定量公式描述。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=15058#respond-post-7725)

z2007c

January 31st, 2021

相比CSDN上的，博主的文章要严谨的多。受益匪浅，感谢！

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=15427#respond-post-7725)

xxxxL

April 26th, 2021

太妙了，苏神这个VAE系列建议反过来看。。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=16219#respond-post-7725)

宇航员

August 30th, 2021

深入浅出，反复琢磨。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=17226#respond-post-7725)

Jsooo

September 24th, 2021

您好！请问在“空间正则”中的“现在我们希望编码向量满足标准正态分布（可以将它理解为一个单位圆），即所有的椭圆覆盖的空间组成一个单位圆。”这句话，是应该按哪个思路理解：

1\. 对于样本{X1, ..., Xn}，每个样本对应的μ、σ，训练时在正态分布和标准正态分布之间对抗；

2\. 对于样本{X1, ..., Xn}，分别在单位圆采样、经过平移缩放变换得到{Z1, ..., Zn}，让整个

{Z1, ..., Zn}服从标准正态分布；

也就是说，是将每个小椭圆趋向于单位圆，还是所有小椭圆组成的空间趋向于单位圆？

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=17433#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
September 24th, 2021

后者。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=17434#respond-post-7725)

Jsooo 发表于
September 24th, 2021

好的谢谢！

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=17435#respond-post-7725)

Lily 发表于
October 17th, 2022

请问这个第二点是怎么体现的呢？在损失函数里看上去是让每个p(z\|x)都向标准正态分布靠拢呀，感觉更像是第一点，如果是第二点该怎么结合公式进行理解呢？

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=20115#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
October 17th, 2022

人人都向雷锋学习，难道就一定可以让人人都跟雷锋一模一样么？

你要理解，就只看第二篇，优化联合分布的KL散度，就得到了连同重构项和KL散度项的一个整体loss，这个loss是整体，不能分割。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=20116#respond-post-7725)

Lily 发表于
October 17th, 2022

谢谢您的回答！

楼主的后者“ 对于样本{X1, ..., Xn}，分别在单位圆采样、经过平移缩放变换得到{Z1, ..., Zn}，让整个{Z1, ..., Zn}服从标准正态分布”，我不太理解这个后者中“所有小椭圆组成的空间趋向于单位圆”的含义以及如何表示。从正文看，您还提到了“希望每个椭圆都能向单位圆靠近”，这不是前者的含义吗？在第二篇里loss的第二项，是x不变将z视为变量得到的KL散度，这应该也对应着“希望每个椭圆都能向单位圆靠近”而不是“整个{Z1, ..., Zn}服从标准正态分布”吧，“整个{Z1, ..., Zn}服从标准正态分布”它们各自是一个高斯分布，怎么让这整个服从标准正态分布呢？

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=20119#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
October 21st, 2022

我说了，希望“人人向雷锋学习”，并不能保证“人人都跟雷锋一样”，只能实现“社会（人的总体）像雷锋一样（的风气）”。

重构项妨碍了每个椭圆像单位圆看齐，就好比每个人的个性妨碍了每个人跟雷锋一模一样。

Albert2X 发表于
October 10th, 2024

[@Lily\|comment-20119](https://kexue.fm/archives/7725/comment-page-1#comment-20119) 博主提到：希望“人人向雷锋学习”，并不能保证“人人都跟雷锋一样”，只能实现“社会（人的总体）像雷锋一样（的风气）”。

我自己理解的，反过来的几何化一点的表达是：让每个椭球都靠近标准圆，但是重构损失不允许椭球完全变成标准圆且要求椭球尽可能地不重叠。从解码器角度来看，进行了分布的叠加（即椭球的叠加）的“平均作用”后，它看到的样本极有可能就是等价来自于标准圆了。

多啰嗦一点，椭球的说明方式也能解释为什么VAE生成的图像模糊：椭球和椭球之间总会存在重叠的区域，当随机地从标准圆中采样得到的样本点处于这个重叠区域，那最后经过解码器解码出来的图像就会包含原来不同椭球所表示的图像的某些特征，也就是说解码出来的图像可以看做是多张图像的叠加效果，自然地图像就变得模糊了。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=25407#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
October 11th, 2024

重叠这个角度可能不是很本质，因为如果在VAE的decoder端加上GAN Loss的话，是可能让重构和采样结果变得清晰的。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=25475#respond-post-7725)

Albert2X 发表于
October 11th, 2024

加GAN Loss为什么会使得结果图像变得清晰呢，博主可以讲一下吗，就是解码器是怎么使得处于重叠区域的采样点变得清晰的？我能想到的是，虽然有多张图像对应同一个编码z，GAN Loss会强迫解码器输出某种单一偏好的图像。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=25490#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
October 14th, 2024

因为GAN学出来的判别器更符合我们对视觉相似的认知，弱化了L2距离带来的假设（逐像素对应），此外加Perceptual Loss也通常能提高清晰度，目前的Vision Tokenizer（如VQGAN）都是这样训的。早期GAN出来没多久那会，也有很多VAE+GAN的组合工作，来提高VAE的清晰度。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=25505#respond-post-7725)

Raven

January 11th, 2024

怎么这么像3d gaussian...

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=23498#respond-post-7725)

puz3d 发表于
March 14th, 2024

公式（2）稍微有一点点类似。 每个样本是高斯球中心。 公式（3）就和3d高斯无关了。是为了采样方便把整体样本映射到一个标准高斯球。VAEloss结合了（2）和（3）一起算。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=23926#respond-post-7725)

[milter](http://www.liwenju0.com/)

November 15th, 2024

高斯混合模型背后的假设是：数据来自K个高斯分布。

苏神的VAE博客看下来，VAE背后的假设似乎可以理解为，数据来自无穷个高斯分布，每个数据背后都对应一个高斯分布.

不知道这么理解是不是正确？

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=25780#respond-post-7725)

[苏剑林](https://kexue.fm/) 发表于
November 19th, 2024

对的。VAE、GAN这类生成模型，可以理解为无限个高斯分布的叠加。

[回复评论](https://kexue.fm/archives/7725/comment-page-1?replyTo=25797#respond-post-7725)

[取消回复](https://kexue.fm/archives/7725#respond-post-7725)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；

2\. 可以通过点击评论楼层编号来引用该楼层；

3\. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[自编码器](https://kexue.fm/archives/7725#%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8)
[编码空间](https://kexue.fm/archives/7725#%E7%BC%96%E7%A0%81%E7%A9%BA%E9%97%B4)
[从点到面](https://kexue.fm/archives/7725#%E4%BB%8E%E7%82%B9%E5%88%B0%E9%9D%A2)
[采样重构](https://kexue.fm/archives/7725#%E9%87%87%E6%A0%B7%E9%87%8D%E6%9E%84)
[空间正则](https://kexue.fm/archives/7725#%E7%A9%BA%E9%97%B4%E6%AD%A3%E5%88%99)
[文章总结](https://kexue.fm/archives/7725#%E6%96%87%E7%AB%A0%E6%80%BB%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [记IOAA之旅](https://kexue.fm/archives/931)
- [词向量与Embedding究竟是怎么回事？](https://kexue.fm/archives/4122)
- [恒等式 det(exp(A)) = exp(Tr(A)) 赏析](https://kexue.fm/archives/6377)
- [漫谈几何量子化](https://kexue.fm/archives/2348)
- [写在2009年终结之际...](https://kexue.fm/archives/333)
- [关于“平衡态公理”的更正与思考](https://kexue.fm/archives/1902)
- [那个屠榜的T5模型，现在可以在中文上玩玩了](https://kexue.fm/archives/7867)
- [【理解黎曼几何】7\. 高斯-博内公式](https://kexue.fm/archives/4033)
- [分享：孟岩的《理解矩阵》一文](https://kexue.fm/archives/1754)
- [【不可思议的Word2Vec】5. Tensorflow版的Word2Vec](https://kexue.fm/archives/4402)

### 最近评论

- [Bin](https://kexue.fm/archives/1990/comment-page-2#comment-29105): 今天偶然从某个论坛看到有人推荐您的博客，定睛一看竟然是华师同院的往届师兄！看到这篇2013年的...
- [Rapture D](https://kexue.fm/archives/11530/comment-page-1#comment-29104): 我有一个问题，为什么不考虑亥姆霍兹定理和斯托克斯公式。
- [mofheka](https://kexue.fm/archives/11390/comment-page-1#comment-29103): 苏神是还在用jax是么？最近在做基于Google Pathway的理念做一个动态版的MPMD框...
- [长琴](https://kexue.fm/archives/11530/comment-page-1#comment-29102): 看懂这篇博客也不是一件容易的事情。
- [AlexLi](https://kexue.fm/archives/9257/comment-page-4#comment-29101): 苏老师，请教一下(7)式中将 μ(xt) 传给 po 进行推理的操作。 $x\_...
- [tyler\_zxc](https://kexue.fm/archives/7921/comment-page-2#comment-29100): "Performer的思想是将标准的Attention线性化，所以为什么不干脆直接训练一个线性...
- [我](https://kexue.fm/archives/11494/comment-page-1#comment-29099): 似乎并非mHC提出矩阵的思想？之前hyper connection就是了
- [winter](https://kexue.fm/archives/10847/comment-page-1#comment-29098): 苏神您好，假如对于比较均匀的attention weightP，往往呈现long tail分布...
- [苏剑林](https://kexue.fm/archives/8512/comment-page-2#comment-29097): KL散度、JS散度、W距离啥的，都行啊，看你喜欢哪个
- [苏剑林](https://kexue.fm/archives/9119/comment-page-14#comment-29096): 没有绝对公平的对比方法，主要看你关心什么。比如，如果只关心推理成本和推理效果，那么有的方法可以...

### 友情链接

- [Cool Papers](https://papers.cool/)
- [数学研发](https://bbs.emath.ac.cn/)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com/)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

[![署名-非商业用途-保持一致](https://kexue.fm/usr/themes/geekg/images/cc.gif)](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/) 本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。



© 2009-2026 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com/). Powered by [Typecho](http://typecho.org/). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/ "粤ICP备09093259号")。