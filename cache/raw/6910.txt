## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)

## COMMENTS

- [石子131: 也许可以尝试把热水管的回水管的开关阀做成用户的手动阀，在热水管...](https://kexue.fm/archives/9405/comment-page-2#comment-27955)
- [Kuo: 我的理解，这是一个迭代过程，注意下标K是指condition还...](https://kexue.fm/archives/10795/comment-page-1#comment-27954)
- [musicfish1973: 好的设计都是相似的,haha](https://kexue.fm/archives/8009/comment-page-1#comment-27953)
- [忍者猫: 这优化器的作者真的应该给你打钱](https://kexue.fm/archives/10592/comment-page-2#comment-27952)
- [Chaofa Yuan: 写得太好了](https://kexue.fm/archives/11033/comment-page-1#comment-27951)
- [Skyler Lin: respect苏神！](https://kexue.fm/archives/11033/comment-page-1#comment-27949)
- [宋佳铭: 对，个人感觉mean flow就是continuous tim...](https://kexue.fm/archives/10958/comment-page-1#comment-27947)
- [宋佳铭: 的确，对sg这个事情我感觉如果是用‘归纳’法做是不太能避免的，...](https://kexue.fm/archives/10958/comment-page-1#comment-27946)
- [MoFHeka: 苏老师您好，请问一下这套结论在稀疏参数上应该如何应用？比如大规...](https://kexue.fm/archives/10542/comment-page-1#comment-27945)
- [苏剑林: Temp LoRA倒是有印象，其实思想是一样的，如果我单独开一...](https://kexue.fm/archives/11033/comment-page-1#comment-27944)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) HSIC简介：一个有意思的判断相关性的思路

26Aug

# [HSIC简介：一个有意思的判断相关性的思路](https://kexue.fm/archives/6910)

By 苏剑林 \|
2019-08-26 \|
122496位读者\|

前几天，在机器之心看到这样的一个推送 [《彻底解决梯度爆炸问题，新方法不用反向传播也能训练ResNet》](https://mp.weixin.qq.com/s/jT6WU-XlcvP-n428oWyHQQ)，当然，媒体的标题党作风我们暂且无视，主要看内容即可。机器之心的这篇文章，介绍的是论文 [《The HSIC Bottleneck: Deep Learning without Back-Propagation》](https://papers.cool/arxiv/1908.01580) 的成果，里边提出了一种通过HSIC Bottleneck来训练神经网络的算法。

坦白说，这篇论文笔者还没有看明白，因为对笔者来说里边的新概念有点多了。不过论文中的“HSIC”这个概念引起了笔者的兴趣。经过学习，终于基本地理解了这个HSIC的含义和来龙去脉，于是就有了本文，试图给出HSIC的一个尽可能通俗（但可能不严谨）的理解。

## 背景 [\#](https://kexue.fm/archives/6910\#%E8%83%8C%E6%99%AF)

HSIC全称“Hilbert-Schmidt independence criterion”，中文可以叫做“希尔伯特-施密特独立性指标”吧，跟互信息一样，它也可以用来衡量两个变量之间的独立性。

### 度量相关 [\#](https://kexue.fm/archives/6910\#%E5%BA%A6%E9%87%8F%E7%9B%B8%E5%85%B3)

我们知道，互信息的基本形式是
$$\\begin{equation}I(X,Y)=\\iint p(x,y)\\log \\frac{p(x, y)}{p(x)p(y)}dxdy\\label{eq:i}\\end{equation}$$
如果$I(X,Y)=0$那么就说明$p(x, y)\\equiv p(x)p(y)$，也就是两个变量是相互独立的，否则是相关的。但$\\log \\frac{p(x, y)}{p(x)p(y)}$这一项意味着我们要用某种方式对概率密度进行估计。

HSIC的作用跟互信息类似，但是跟互信息不一样的是，它不需要估计两个变量的概率密度，而是直接转化为采样的形式。

长期关注本博客的读者都知道，“互信息”是本博客经常出现的概念，我们可以用互信息做新词发现（比如 [《基于切分的新词发现》](https://kexue.fm/archives/3913)），也可以用互信息做无监督学习（比如 [《深度学习的互信息：无监督提取特征》](https://kexue.fm/archives/6024)），互信息的重要性可见一斑。如果说有一个指标可以取代互信息、比互信息还方便，那肯定是笔者必须去学习的对象了。

### 问题定义 [\#](https://kexue.fm/archives/6910\#%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89)

一般来说，我们将问题定义为：

> 有数据$(x\_1, y\_1),(x\_2, y\_2),\\dots,(x\_n,y\_n)\\sim p(x, y)$，判断$p(x, y)$是否恒等于$p(x), p(y)$，即$x,y$是否独立。

严格来讲，如果是对于连续变量，这里的“恒等于”指的是“几乎处处等于”，但我们这里不严格声明这一点。

为了描述的规范，这里设$x\\in X, y\\in Y$，而$f(x),g(y)\\in \\mathbb{R}$。注意$x,y$可能是两个含义完全不一样的变量，比如$x$可能是“星期一”，$y$可能是“上班”，$p(x,y)$就是“今天是星期一，且今天要上班”的概率。鉴于此，$X,Y$可能是两个完全不一样的域。

基本的思路是去计算互信息$\\eqref{eq:i}$，但很多问题中我们都无法很好地估计概率或概率密度。一种可能的方案是转化为对偶问题，用类似对抗的思路去学习互信息（ [infomax](https://kexue.fm/archives/6024) 的思路），但这种方法可能会不稳定，而且受到采样方案的影响。最好的方案就是能有一个类似“相关系数”的指标，让我们可以显式地计算和优化这个指标。

HSIC就是冲着这个目标而来的～

## HSIC [\#](https://kexue.fm/archives/6910\#HSIC)

这里我们尽可能清晰地引入HSIC的概念。然而，“尽可能清晰”不等价于篇幅尽可能短，事实上，下面的篇幅依然会比较长，而且有不少数学公式，但是相对于标准教程里边一上来就引入希尔伯特空间、再生核、各种算子等做法，这里的介绍应该算是对很多不了解相关概念的读者来说都是友好的了。

### 基本思想 [\#](https://kexue.fm/archives/6910\#%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3)

HSIC留意到：

> $p(x, y)\\equiv p(x)p(y)$当且仅当对于任意的$f,g$，式
> $$\\begin{equation}\\begin{aligned}C\[f,g\]=&\\iint p(x,y)f(x)g(y)dxdy - \\iint p(x)p(y)f(x)g(y)dxdy\\\
> =&\\mathbb{E}\_{(x,y)\\sim p(x,y)}\[f(x)g(y)\]-\\mathbb{E}\_{x\\sim p(x)}\[f(x)\]\\mathbb{E}\_{y\\sim p(y)}\[g(y)\]\\end{aligned}\\end{equation}$$
> 都等于0。

这个结论显然不难理解。有意思的是，第二个等号右边是采样的形式，也就是说我们将这个指标转化为了采样的形式，避免了直接估算概率密度。

这样一来，我们就有一个判断独立性的方法：选取“足够多”的$f,g$，然后计算
$$\\begin{equation}L\_H=\\sum\_{f,g} \\big(C\[f,g\]\\big)^2\\label{eq:l0}\\end{equation}$$
看$L\_H$与0的接近程度；反过来，如果在优化问题中，我们希望特征$x,y$尽可能相互独立，那么我们就可以将$L\_H$加入到损失函数中。

### 抽丝剥茧 [\#](https://kexue.fm/archives/6910\#%E6%8A%BD%E4%B8%9D%E5%89%A5%E8%8C%A7)

其实$L\_H$的形式已经很好地体现了HSIC的判别思想。下面我们就沿着这个思路，继续抽丝剥茧，逐步地走向HSIC最终的形式。

首先我们把$\\big(C\[f,g\]\\big)^2$算一算：
$$\\begin{equation}\\begin{aligned}\\big(C\[f,g\]\\big)^2=&\\big(\\mathbb{E}\_{(x,y)\\sim p(x,y)}\[f(x)g(y)\]\\big)^2 + \\big(\\mathbb{E}\_{x\\sim p(x)}\[f(x)\]\\big)^2 \\big(\\mathbb{E}\_{y\\sim p(y)}\[g(y)\]\\big)^2\\\
& \- 2\\big(\\mathbb{E}\_{(x,y)\\sim p(x,y)}\[f(x)g(y)\]\\big)\\big(\\mathbb{E}\_{x\\sim p(x)}\[f(x)\]\\big)\\big(\\mathbb{E}\_{y\\sim p(y)}\[g(y)\]\\big)\\end{aligned}\\end{equation}$$

然后我们用一个技巧：我们知道$\\mathbb{E}\_{x\\sim p(x)}\[f(x)\]=\\mathbb{E}\_{x'\\sim p(x')}\[f(x')\]$，说明了这个期望值的结果跟随机变量的记号没啥关系。所以我们有
$$\\begin{equation}\\begin{aligned}\\big(\\mathbb{E}\_{x\\sim p(x)}\[f(x)\]\\big)^2=&\\big(\\mathbb{E}\_{x\_1\\sim p(x)}\[f(x\_1)\]\\big)\\big(\\mathbb{E}\_{x\_2\\sim p(x)}\[f(x\_2)\]\\big)\\\
=&\\mathbb{E}\_{x\_1\\sim p(x),x\_2\\sim p(x)}\[f(x\_1)f(x\_2)\]\\end{aligned}\\end{equation}$$

把其余的项都这样变换，最终我们就可以得到
$$\\begin{equation}\\begin{aligned}\\big(C\[f,g\]\\big)^2=&\\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),(x\_2,y\_2)\\sim p(x,y)}\[f(x\_1)f(x\_2)g(y\_1)g(y\_2)\] \\\
& \+ \\mathbb{E}\_{x\_1\\sim p(x),x\_2\\sim p(x),y\_1\\sim p(y),y\_2\\sim p(y)}\[f(x\_1)f(x\_2)g(y\_1)g(y\_2)\]\\\
& \- 2 \\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),x\_2\\sim p(x),y\_2\\sim p(y)}\[f(x\_1)f(x\_2)g(y\_1)g(y\_2)\]\\end{aligned}\\end{equation}\\label{eq:c}$$
这样一来，每一项都是$f(x\_1)f(x\_2)g(x\_1)g(x\_2)$的期望，只不过变量的采样分布不一样。

### 特征函数 [\#](https://kexue.fm/archives/6910\#%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0)

现在的问题是：要选择哪些$f,g$呢？怎样才算“足够多”呢？

类比向量空间的知识，所有可能的$f(x)$能组成一个向量空间$\\mathcal{F}$，所有的$g(y)$也一样组成一个向量空间$\\mathcal{G}$。如果能把这两个空间的所有“基底”都遍历一遍，那肯定就够了。那问题就是：如何找到所有的基底呢？

这时候“核函数”就登场了。所谓核函数，那就是——呃，其实说起来很复杂，我也不大懂。简单来说，核函数是类似于线性代数中“正定矩阵”的存在，就是一个定义在$X\\times X$的二元对称函数$K(x\_1, x\_2)=K(x\_2, x\_1)$，然后我们把一元函数$f(x)$类比为一个向量，那么
$$\\begin{equation}\\int K(x\_1,x\_2) f(x\_2)dx\_2\\end{equation}$$
就相当于一个矩阵乘以向量的矩阵运算。跟矩阵的特征值和特征向量一样，核函数也能定义特征值和特征函数，满足下述恒等式的一元函数$\\psi$就称为这个核函数的特征函数：
$$\\begin{equation}\\int K(x\_1,x\_2) \\psi(x\_2)dx\_2=\\alpha \\psi(x\_1)\\end{equation}$$

上面的内容都是铺垫的，其严格定义则是属于“再生核希尔伯特空间“范畴。后面我们用到的，实际上是两点性质：

> 1、核函数的所有特征函数$\\psi\_1,\\psi\_2,\\dots$，构成该空间的一组正交基；
>
> 2、核函数的所有特征值$\\alpha\_1,\\alpha\_2,\\dots$都是正的，且满足
> $$\\begin{equation}K(x\_1,x\_2)=\\sum\_i \\alpha\_i \\psi\_i(x\_1)\\psi\_i(x\_2)\\end{equation}\\label{eq:k}$$

### HSIC登场 [\#](https://kexue.fm/archives/6910\#HSIC%E7%99%BB%E5%9C%BA)

经过上述铺垫，HSIC基本上就可以登场了～

首先，假如我们已经有定义在$X\\times X$的核函数$K\_X(x\_1,x\_2)$，那么我们就可以算出$K\_X(x\_1,x\_2)$对应的特征值$\\alpha\_1,\\alpha\_2,\\dots$和特征函数$\\psi\_1,\\psi\_2,\\dots$；同样地，有了定义在$Y\\times Y$的核函数$K\_Y(y\_1,y\_2)$后，也可以算出$K\_Y(y\_1,y\_2)$对应的特征值$\\beta\_1,\\beta\_2,\\dots$和特征函数$\\phi\_1,\\phi\_2,\\dots$。

然后，因为特征函数构成了基底，所以在$\\eqref{eq:l0}$中，我们可以把$f,g$换成对应特征函数$\\psi\_i,\\phi\_j$
$$\\begin{equation}L\_H=\\sum\_{i,j}\\big(C\[\\psi\_i, \\phi\_j\]\\big)^2\\end{equation}$$
因为所有的特征值都是正的，所以我们还可以用特征值为权重进行加权求和，而不改变$L\_H$的作用：
$$\\begin{equation}L\_H=\\sum\_{i,j}\\alpha\_i \\beta\_j\\cdot\\big(C\[\\psi\_i, \\phi\_j\]\\big)^2\\end{equation}$$
现在我们把$\\eqref{eq:c}$代入到上面去，就得到
$$\\begin{equation}\\begin{aligned}L\_H=&\\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),(x\_2,y\_2)\\sim p(x,y)}\\left\[\\sum\_{i,j}\\alpha\_i \\beta\_j\\psi\_i(x\_1)\\psi\_i(x\_2)\\phi\_j(y\_1)\\phi\_j(y\_2)\\right\] \\\
& \+ \\mathbb{E}\_{x\_1\\sim p(x),x\_2\\sim p(x),y\_1\\sim p(y),y\_2\\sim p(y)}\\left\[\\sum\_{i,j}\\alpha\_i \\beta\_j\\psi\_i(x\_1)\\psi\_i(x\_2)\\phi\_j(y\_1)\\phi\_j(y\_2)\\right\]\\\
& \- 2 \\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),x\_2\\sim p(x),y\_2\\sim p(y)}\\left\[\\sum\_{i,j}\\alpha\_i \\beta\_j\\psi\_i(x\_1)\\psi\_i(x\_2)\\phi\_j(y\_1)\\phi\_j(y\_2)\\right\]
\\end{aligned}\\end{equation}$$

最后，再利用等式$\\eqref{eq:k}$，方括号里边的实际上就是$K\_X(x\_1,x\_2)K\_Y(y\_1,y\_2)$，于是，HSIC就登场了：
$$\\begin{equation}\\begin{aligned}HSIC(X,Y)=&\\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),(x\_2,y\_2)\\sim p(x,y)}\\left\[K\_X(x\_1,x\_2)K\_Y(y\_1,y\_2)\\right\] \\\
& \+ \\mathbb{E}\_{x\_1\\sim p(x),x\_2\\sim p(x),y\_1\\sim p(y),y\_2\\sim p(y)}\\left\[K\_X(x\_1,x\_2)K\_Y(y\_1,y\_2)\\right\]\\\
& \- 2 \\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),x\_2\\sim p(x),y\_2\\sim p(y)}\\left\[K\_X(x\_1,x\_2)K\_Y(y\_1,y\_2)\\right\]\\end{aligned}\\end{equation}\\label{eq:hsic}$$
这就是我们最重要寻找的度量相关性的指标，它纯粹是采样的形式，而且$K\_X,K\_Y$都是事先给定的、通常是可微的，因此这就是一个可以明确采样计算、可以直接优化的指标！

在实际计算中，我们可选的核函数有很多，比较常用的是
$$\\begin{equation}K(x\_1, x\_2) = \\exp\\left(-\\frac{\\Vert x\_1 - x\_2\\Vert\_2^2}{\\sigma^2}\\right)\\end{equation}\\label{eq:gk}$$
其中$\\sigma > 0$是一个常数，本文开头提到的论文 [《The HSIC Bottleneck: Deep Learning without Back-Propagation》](https://papers.cool/arxiv/1908.01580) 也是用这个核函数。不同的核函数效果有点不一样，但是都能保证$HSIC(X,Y)=0 \\Leftrightarrow p(x,y)\\equiv p(x)p(y)$。

### 矩阵形式 [\#](https://kexue.fm/archives/6910\#%E7%9F%A9%E9%98%B5%E5%BD%A2%E5%BC%8F)

最后，我们来推导一下$\\eqref{eq:hsic}$在有限样本下的矩阵形式。

按照采样求期望的思想，$\\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y)}$实际上就是对所有的样本对$(x\_i,y\_i)$的结果求平均，而$\\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),(x\_2,y\_2)\\sim p(x,y)}$其实就是将这个平均操作做两次，所以
$$\\begin{equation}\\mathbb{E}\_{(x\_1,y\_1)\\sim p(x,y),(x\_2,y\_2)\\sim p(x,y)}\\left\[K\_X(x\_1,x\_2)K\_Y(y\_1,y\_2)\\right\]=\\frac{1}{n^2}\\sum\_{i=1}^n \\sum\_{j=1}^n \\left\[K\_X(x\_i,x\_j)K\_Y(y\_i,y\_j)\\right\]\\end{equation}$$
其中$K\_X(x\_i,x\_j),K\_Y(y\_i,y\_j)$实际上都是$n\\times n$的对称矩阵，分别记为$K\_X,\_y$，那么上述运算可以写成矩阵乘法$\\frac{1}{n^2}\\text{Tr}(K\_X K\_Y)$，其中$\\text{Tr}$表示矩阵的迹。基于同样的思想，第二项实际上就是“$K\_X$所有元素的平均乘以$K\_Y$所有元素的平均”，如果非要写成矩阵形式的话，那就是$\\frac{1}{n^4}\\text{Tr}(K\_X \\boldsymbol{1}K\_Y \\boldsymbol{1})$，其中加粗的$\\boldsymbol{1}$表示大小为$n\\times n$的全1矩阵。相应地，最后一项是“$K\_X K\_Y$所有元素平均值的$1/n$的两倍”，即$\\frac{2}{n^3}\\text{Tr}(K\_X K\_Y \\boldsymbol{1})$。

所以，如果用矩阵形式表示HSIC，那就是
$$\\begin{equation}\\begin{aligned}HSIC(X,Y)=&\\frac{1}{n^2}\\text{Tr}(K\_X K\_Y)+\\frac{1}{n^4}\\text{Tr}(K\_X \\boldsymbol{1}K\_Y \\boldsymbol{1})-\\frac{2}{n^3}\\text{Tr}(K\_X K\_Y \\boldsymbol{1})\\\
=&\\frac{1}{n^2}\\text{Tr}(K\_X J K\_Y J)
\\end{aligned}\\end{equation}$$
这里的$J = \\boldsymbol{I}-\\boldsymbol{1}/n$，而$\\boldsymbol{I}$是$n$阶单位矩阵。跟 [《简述无偏估计和有偏估计》](https://kexue.fm/archives/6747) 一文讨论的类似，这其实是一个有偏估计，而将前面的$1/n$换成$1/(n-1)$，就得到无偏估计：
$$\\begin{equation}HSIC(X,Y)=\\frac{1}{(n-1)^2}\\text{Tr}(K\_X J K\_Y J)\\end{equation}\\label{eq:hsic-m}$$
这就是最终的矩阵形式的HSIC公式（注意$J$里边的$1/n$不用换成$1/(n-1)$）。

## 其它 [\#](https://kexue.fm/archives/6910\#%E5%85%B6%E5%AE%83)

这里先给出一个参考实现，并做一个简单的实验，来验证HSIC的有效性，然后在后一节中，我们思考一下HSIC可能存在的问题。

### 参考实现 [\#](https://kexue.fm/archives/6910\#%E5%8F%82%E8%80%83%E5%AE%9E%E7%8E%B0)

假如已知核矩阵$K\_X,K\_Y$的情况下，HSIC的计算实现参考如下：

```
import numpy as np

def hsic(Kx, Ky):
 Kxy = np.dot(Kx, Ky)
 n = Kxy.shape[0]
 h = np.trace(Kxy) / n**2 + np.mean(Kx) * np.mean(Ky) - 2 * np.mean(Kxy) / n
 return h * n**2 / (n - 1)**2
```

注意这里的实现是根据$\\eqref{eq:hsic}$每一项的含义来的，并非根据矩阵形式$\\eqref{eq:hsic-m}$，事实上矩阵形式$\\eqref{eq:hsic-m}$效率并不高（涉及到三次矩阵乘法）。

下面做一个简单的实验，验证HSIC的有效性：

```
# 产生两组独立无关的随机变量
x = np.random.randn(1000)
y = np.random.randn(1000)

Kx = np.expand_dims(x, 0) - np.expand_dims(x, 1)
Kx = np.exp(- Kx**2) # 计算核矩阵

Ky = np.expand_dims(y, 0) - np.expand_dims(y, 1)
Ky = np.exp(- Ky**2) # 计算核矩阵

print(hsic(Kx, Ky)) # 计算HSIC
```

输出结果大概是0.0002左右，如果将$x,y$改为

```
x = np.random.randn(1000)
y = x + 0.1 * np.random.randn(1000)

```

这意味着$x,y$有比较强的相关性，而HSIC的结果也表明了这一点，约等于0.096，比0.0002大了两个数量级以上，这表明了HSIC确实是有效的。（注意，HSIC的输出值一般只有相对比较的意义，其绝对值没有明显含义。）

### 个人思考 [\#](https://kexue.fm/archives/6910\#%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83)

显然，由$\\eqref{eq:hsic}$给出的HSIC的计算结果取决于核函数的选择。不管用哪个核函数，理论上都可以保证
$$\\begin{equation}HSIC(X,Y)=0 \\Leftrightarrow p(x,y)\\equiv p(x)p(y)\\end{equation}$$
但问题是，当$HSIC(X,Y) > 0$时，$X,Y$究竟有多相关呢？

这就相当依赖核函数选择和原始问题的背景了。从常用核函数$\\eqref{eq:gk}$的形式我们大概可以感知到，核函数相当于两个样本之间的相似度，问题是什么样的相似度定义才是真正符合问题背景的，这并没有标准答案，而且通常都是很困难的问题。

举个例子，假如$x\_1,x\_2,x\_3$分别代表三张图片，我们知道$\\Vert x\_1 - x\_2\\Vert\_2 = 0$的话意味着$x\_1,x\_2$这两张图片完全一样，但是当$\\Vert x\_1 - x\_2\\Vert\_2,\\Vert x\_1 - x\_3\\Vert\_2$都不等于0时，我们不能因为$\\Vert x\_1 - x\_2\\Vert\_2 < \\Vert x\_1 - x\_3\\Vert\_2$就说图片$x\_2$一定比图片$x\_3$“看起来”更像$x\_1$，因为范数$\\Vert\\cdot\\Vert\_2$不是我们视觉的一个完美的度量。

其实笔者认为这是所有核方法的通病，即核方法只能保证当某个指标等于0时就是我们的理想追求，但是当这个指标不等于0时，这个指标无法很好地度量我们跟理想的差距。良好的度量是要根据具体问题精心设计的，或者根据数据集通过类似GAN的方法自动把这个度量学习出来。

当然，也不能就此说HSIC就没有价值了，HSIC的价值在于它可以作为辅助目标来优化，就好比我们要训练一个图片自编码器，就算我们用GAN的思想，我们也通常会把原图片和重构图片的MSE作为辅助loss来使用。

## 文末 [\#](https://kexue.fm/archives/6910\#%E6%96%87%E6%9C%AB)

总的来说，本文以一种较为通俗直白的方法介绍了HSIC这个概念，介绍过程中涉及到了一些数学内容，但省去了严格的数学定义和论述，尽量只保持了比较核心的部分，私以为这种处理会使得读者更容易接受一些。对于追求严谨的读者，请多多包涵～

_**转载到请包括本文地址：** [https://kexue.fm/archives/6910](https://kexue.fm/archives/6910)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/6910#share)/ [打赏](https://kexue.fm/archives/6910#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Aug. 26, 2019). 《HSIC简介：一个有意思的判断相关性的思路 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/6910](https://kexue.fm/archives/6910)

@online{kexuefm-6910,
        title={HSIC简介：一个有意思的判断相关性的思路},
        author={苏剑林},
        year={2019},
        month={Aug},
        url={\\url{https://kexue.fm/archives/6910}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/), [互信息](https://kexue.fm/tag/%E4%BA%92%E4%BF%A1%E6%81%AF/), [核方法](https://kexue.fm/tag/%E6%A0%B8%E6%96%B9%E6%B3%95/)[32 评论](https://kexue.fm/archives/6910#comments)

< [开源一版DGCNN阅读理解问答模型（Keras版）](https://kexue.fm/archives/6906) \| [自己实现了一个bert4keras](https://kexue.fm/archives/6915) >

### 你也许还对下面的内容感兴趣

- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [Softmax后传：寻找Top-K的光滑近似](https://kexue.fm/archives/10373)
- [通向最优分布之路：概率空间的最小化](https://kexue.fm/archives/10289)
- [通向概率分布之路：盘点Softmax及其替代品](https://kexue.fm/archives/10145)
- [用傅里叶级数拟合一维概率密度函数](https://kexue.fm/archives/10007)
- [随机分词再探：从Viterbi Sampling到完美采样算法](https://kexue.fm/archives/9811)
- [EMO：基于最优传输思想设计的分类损失函数](https://kexue.fm/archives/9797)
- [随机分词浅探：从Viterbi Decoding到Viterbi Sampling](https://kexue.fm/archives/9768)
- [大词表语言模型在续写任务上的一个问题及对策](https://kexue.fm/archives/9762)
- [如何度量数据的稀疏程度？](https://kexue.fm/archives/9595)

[发表你的看法](https://kexue.fm/archives/6910#comment_form)

1. [«](https://kexue.fm/archives/6910/comment-page-1#comments)
2. [1](https://kexue.fm/archives/6910/comment-page-1#comments)
3. [2](https://kexue.fm/archives/6910/comment-page-2#comments)

大菈

December 2nd, 2021

非常好的文章。想问问笔者我在实际上用HSIC的时候，发现HSIC的值有时候是负的，请问这是正确的吗？理论上好像HSIC的值是有可能是负的吧，具体它有什么含义呢？感谢！

[回复评论](https://kexue.fm/archives/6910/comment-page-2?replyTo=17944#respond-post-6910)

[苏剑林](https://kexue.fm) 发表于
December 2nd, 2021

感觉上应该是采样不充分导致的估计偏差问题。

[回复评论](https://kexue.fm/archives/6910/comment-page-2?replyTo=17955#respond-post-6910)

MUJINO

March 13th, 2025

感觉推导可能有不严谨的地方. 关键是领会到HSIC中的$f\\in \\mathcal{F}$和$g\\in \\mathcal{G}$是一个高维映射，不是一开始所说的$f:\\mathcal{X} \\rightarrow \\mathbb{R}$，用$\\varphi$和$\\psi$更好. 以下是HSIC一个例子，将随机变量$f(X)=X^2$，$g(Y)=Y^2$，这样若$X^2+Y^2=1$，则$f(X)$和$g(Y)$之间用协方差$\\mathbb{E}\[f(X) g(Y)\] - \\mathbb{E}\[f(X)\] \\mathbb{E}\[g(Y)\]$就能得到非$0$结果，否则直接用皮尔逊相关系数，结果为$0$，但$X$和$Y$明显相关. 因此，式(5)最后一等号，能不能成立似乎不太清楚.
一个严谨推导是：$\\text{MMD}^2(P\_{XY}, P\_{X}P\_{Y})=\\Vert \\mathbb{E}\_{XY}\[\\varphi(X)\\otimes \\psi(Y)\] - \\mathbb{E}\_{X} \[\\varphi(X)\] \\otimes \\mathbb{E}\_{Y} \[\\psi(Y)\] \\Vert\_{\\text{HS}\_{(\\mathcal{F}, \\mathcal{G})}}$，内积定义模展开，利用张量积的内积运算可得sirius发布的式子.
HSIC其实是联合概率分布和边缘概率分布乘积在Hilbert Space里的距离，即MMD.

[回复评论](https://kexue.fm/archives/6910/comment-page-2?replyTo=27111#respond-post-6910)

[苏剑林](https://kexue.fm) 发表于
March 14th, 2025

感谢指正，确实我对HSIC并不了解，只是尽自己所能来分享一些理解，加上科普文章所限，做不到十分严谨。

[回复评论](https://kexue.fm/archives/6910/comment-page-2?replyTo=27117#respond-post-6910)

bearcat

April 20th, 2025

学了一天没懂，之后又去学RKHS空间，又发现泛函也没学过。睡了一觉再研究，仔细读完理解了。发现还是苏建林老师写的好，没学泛函也能明白。

[回复评论](https://kexue.fm/archives/6910/comment-page-2?replyTo=27428#respond-post-6910)

1. [«](https://kexue.fm/archives/6910/comment-page-1#comments)
2. [1](https://kexue.fm/archives/6910/comment-page-1#comments)
3. [2](https://kexue.fm/archives/6910/comment-page-2#comments)

[取消回复](https://kexue.fm/archives/6910#respond-post-6910)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[背景](https://kexue.fm/archives/6910#%E8%83%8C%E6%99%AF)
[度量相关](https://kexue.fm/archives/6910#%E5%BA%A6%E9%87%8F%E7%9B%B8%E5%85%B3)
[问题定义](https://kexue.fm/archives/6910#%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89)
[HSIC](https://kexue.fm/archives/6910#HSIC)
[基本思想](https://kexue.fm/archives/6910#%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3)
[抽丝剥茧](https://kexue.fm/archives/6910#%E6%8A%BD%E4%B8%9D%E5%89%A5%E8%8C%A7)
[特征函数](https://kexue.fm/archives/6910#%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0)
[HSIC登场](https://kexue.fm/archives/6910#HSIC%E7%99%BB%E5%9C%BA)
[矩阵形式](https://kexue.fm/archives/6910#%E7%9F%A9%E9%98%B5%E5%BD%A2%E5%BC%8F)
[其它](https://kexue.fm/archives/6910#%E5%85%B6%E5%AE%83)
[参考实现](https://kexue.fm/archives/6910#%E5%8F%82%E8%80%83%E5%AE%9E%E7%8E%B0)
[个人思考](https://kexue.fm/archives/6910#%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83)
[文末](https://kexue.fm/archives/6910#%E6%96%87%E6%9C%AB)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [数学基本技艺之23、24（下）](https://kexue.fm/archives/2096)
- [进驻中山大学南校区，折腾校园网](https://kexue.fm/archives/3936)
- [11月03日美国“发现号”航天飞机“绝唱”](https://kexue.fm/archives/1034)
- [寒假结束，今天上学了](https://kexue.fm/archives/470)
- [科学空间：2010年10月重要天象](https://kexue.fm/archives/951)
- [网站统计总结\|来访信息综合](https://kexue.fm/archives/91)
- [2^29365451-1不是素数](https://kexue.fm/archives/1969)
- [【NASA每日一图】月夜流星](https://kexue.fm/archives/76)
- [有限素域上的乘法群是循环群](https://kexue.fm/archives/3200)
- [从牛顿力学角度研究宇宙学](https://kexue.fm/archives/684)

### 最近评论

- [石子131](https://kexue.fm/archives/9405/comment-page-2#comment-27955): 也许可以尝试把热水管的回水管的开关阀做成用户的手动阀，在热水管临近回水管、手动阀靠近热水管侧加...
- [Kuo](https://kexue.fm/archives/10795/comment-page-1#comment-27954): 我的理解，这是一个迭代过程，注意下标K是指condition还是desideratum
- [musicfish1973](https://kexue.fm/archives/8009/comment-page-1#comment-27953): 好的设计都是相似的,haha
- [忍者猫](https://kexue.fm/archives/10592/comment-page-2#comment-27952): 这优化器的作者真的应该给你打钱
- [Chaofa Yuan](https://kexue.fm/archives/11033/comment-page-1#comment-27951): 写得太好了
- [Skyler Lin](https://kexue.fm/archives/11033/comment-page-1#comment-27949): respect苏神！
- [宋佳铭](https://kexue.fm/archives/10958/comment-page-1#comment-27947): 对，个人感觉mean flow就是continuous time CTM
- [宋佳铭](https://kexue.fm/archives/10958/comment-page-1#comment-27946): 的确，对sg这个事情我感觉如果是用‘归纳’法做是不太能避免的，因为毕竟是用步长短的模型去约束步...
- [MoFHeka](https://kexue.fm/archives/10542/comment-page-1#comment-27945): 苏老师您好，请问一下这套结论在稀疏参数上应该如何应用？比如大规模稀疏Embedding，每个B...
- [苏剑林](https://kexue.fm/archives/11033/comment-page-1#comment-27944): Temp LoRA倒是有印象，其实思想是一样的，如果我单独开一篇文章介绍TTT的话，应该会提到...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。