## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)

## COMMENTS

- [石子131: 也许可以尝试把热水管的回水管的开关阀做成用户的手动阀，在热水管...](https://kexue.fm/archives/9405/comment-page-2#comment-27955)
- [Kuo: 我的理解，这是一个迭代过程，注意下标K是指condition还...](https://kexue.fm/archives/10795/comment-page-1#comment-27954)
- [musicfish1973: 好的设计都是相似的,haha](https://kexue.fm/archives/8009/comment-page-1#comment-27953)
- [忍者猫: 这优化器的作者真的应该给你打钱](https://kexue.fm/archives/10592/comment-page-2#comment-27952)
- [Chaofa Yuan: 写得太好了](https://kexue.fm/archives/11033/comment-page-1#comment-27951)
- [Skyler Lin: respect苏神！](https://kexue.fm/archives/11033/comment-page-1#comment-27949)
- [宋佳铭: 对，个人感觉mean flow就是continuous tim...](https://kexue.fm/archives/10958/comment-page-1#comment-27947)
- [宋佳铭: 的确，对sg这个事情我感觉如果是用‘归纳’法做是不太能避免的，...](https://kexue.fm/archives/10958/comment-page-1#comment-27946)
- [MoFHeka: 苏老师您好，请问一下这套结论在稀疏参数上应该如何应用？比如大规...](https://kexue.fm/archives/10542/comment-page-1#comment-27945)
- [苏剑林: Temp LoRA倒是有印象，其实思想是一样的，如果我单独开一...](https://kexue.fm/archives/11033/comment-page-1#comment-27944)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 细水长flow之TARFLOW：流模型满血归来？

17Jan

# [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)

By 苏剑林 \|
2025-01-17 \|
44282位读者\|

不知道还有没有读者对这个系列有印象？这个系列取名“细水长flow”，主要介绍flow模型的相关工作，起因是当年（2018年）OpenAI发布了一个新的流模型 [Glow](https://kexue.fm/archives/5807)，在以GAN为主流的当时来说着实让人惊艳了一番。但惊艳归惊艳，事实上在相当长的时间内，Glow及后期的一些改进在生成效果方面都是比不上GAN的，更不用说现在主流的扩散模型了。

不过局面可能要改变了，上个月的论文 [《Normalizing Flows are Capable Generative Models》](https://papers.cool/arxiv/2412.06329) 提出了新的流模型TARFLOW，它在几乎在所有的生成任务效果上都逼近了当前SOTA，可谓是流模型的“满血”回归。

## 写在前面 [\#](https://kexue.fm/archives/10667\#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2)

这里的流模型，特指Normalizing Flow，是指模型架构具有可逆特点、以最大似然为训练目标、能实现一步生成的相关工作，当前扩散模型的分支Flow Matching不归入此列。

自从Glow闪耀登场之后，流模型的后续进展可谓“乏善可陈”，简单来说就是让它生成没有明显瑕疵的CelebA人脸都难，更不用说更复杂的ImageNet了，所以“细水长flow”系列也止步于2019年的 [《细水长flow之可逆ResNet：极致的暴力美学》](https://kexue.fm/archives/6482)。不过，TARFLOW的出现，证明了流模型“尚能一战”，这一次它的生成画风是这样的：

TARFLOW的生成效果

相比之下，此前Glow的生成画风是这样的：

Glow的生成效果

Glow演示的还只是相对简单的人脸生成，但瑕疵已经很明显了，更不用说更复杂的自然图像生成了，由此可见TARFLOW的进步并不只是一星半点。从数据上看，它的表现也逼近模型模型的最佳表现，超过了GAN的SOTA代表BigGAN：

TARFLOW与其他模型的定量对比

要知道，流模型天然就是一步生成模型，并且不像GAN那样对抗训练，它也是单个损失函数训练到底，某种程度上它的训练比扩散模型还简单。所以，TARFLOW把流模型的效果提升了上来，意味着它同时具备了GAN和扩散模型的优点，同时还有自己独特的优势（可逆、可以用来估计对数似然等）。

## 模型回顾 [\#](https://kexue.fm/archives/10667\#%E6%A8%A1%E5%9E%8B%E5%9B%9E%E9%A1%BE)

言归正传，我们来看看TARFLOW用了什么“灵丹妙药”来让流模型重新焕发活力。不过在此之前，我们简要回顾一下流模型的理论基础，更详细的历史溯源，可以参考 [《细水长flow之NICE：流模型的基本概念与实现》](https://kexue.fm/archives/5776) 和 [《细水长flow之RealNVP与Glow：流模型的传承与升华》](https://kexue.fm/archives/5807)。

从最终目标来看，流模型和GAN都是希望得到一个确定性函数$\\boldsymbol{x}=\\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z})$，将随机噪声$\\boldsymbol{z}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})$映射到目标分布的图片$\\boldsymbol{x}$，用概率分布的语言说，就是用如下形式的分布来建模目标分布：
\\begin{equation}q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) = \\int \\delta(\\boldsymbol{x} - \\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z}))q(\\boldsymbol{z})d\\boldsymbol{z}\\label{eq:q-int}\\end{equation}
其中$q(\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})$，$\\delta()$是 [狄拉克δ函数](https://en.wikipedia.org/wiki/Dirac_delta_function)。训练概率模型的理想目标是最大似然，即以$-\\log q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$为损失函数。但目前的$q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$带有积分，只有形式意义，无法用于训练。

此时流模型和GAN就“分道扬镳”了：GAN大致上是用另外一个模型（判别器）去近似$-\\log q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$，这导致了交替训练；流模型则通过设计适当的$\\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z})$，让积分$\\eqref{eq:q-int}$可以直接算出来。把积分$\\eqref{eq:q-int}$算出来需要什么条件呢？设$\\boldsymbol{y} = \\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z})$，其逆函数为$\\boldsymbol{z} = \\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{y})$，那么
\\begin{equation}d\\boldsymbol{z} = \\left\|\\det \\frac{\\partial \\boldsymbol{z}}{\\partial \\boldsymbol{y}}\\right\|d\\boldsymbol{y} = \\left\|\\det \\frac{\\partial \\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{y})}{\\partial \\boldsymbol{y}}\\right\|d\\boldsymbol{y}\\end{equation}
以及
\\begin{equation}\\begin{aligned}
q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) =&\\, \\int \\delta(\\boldsymbol{x} - \\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z}))q(\\boldsymbol{z})d\\boldsymbol{z} \\\
=&\\, \\int \\delta(\\boldsymbol{x} - \\boldsymbol{y})q(\\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{y}))\\left\|\\det \\frac{\\partial \\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{y})}{\\partial \\boldsymbol{y}}\\right\|d\\boldsymbol{y} \\\
=&\\, q(\\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}))\\left\|\\det \\frac{\\partial \\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}\\right\|
\\end{aligned}\\end{equation}
因此
\\begin{equation}-\\log q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) = -\\log q(\\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})) - \\log \\left\|\\det \\frac{\\partial \\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}\\right\|\\end{equation}
这表明，将积分$\\eqref{eq:q-int}$算出来需要两个条件：一、需要知道$\\boldsymbol{x} = \\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z})$的逆函数$\\boldsymbol{z} = \\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$；二、需要计算雅可比矩阵$\\frac{\\partial \\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})}{\\partial \\boldsymbol{x}}$的行列式。

## 仿射耦合 [\#](https://kexue.fm/archives/10667\#%E4%BB%BF%E5%B0%84%E8%80%A6%E5%90%88)

为此，流模型提出了一个关键设计——“仿射耦合层”：
\\begin{equation}\\begin{aligned}&\\boldsymbol{h}\_1 = \\boldsymbol{x}\_1\\\
&\\boldsymbol{h}\_2 = \\exp(\\boldsymbol{\\gamma}(\\boldsymbol{x}\_1))\\otimes\\boldsymbol{x}\_2 + \\boldsymbol{\\beta}(\\boldsymbol{x}\_1)\\end{aligned}\\label{eq:couple}\\end{equation}
其中$\\boldsymbol{x} = \[\\boldsymbol{x}\_1,\\boldsymbol{x}\_2\]$，$\\boldsymbol{\\gamma}(\\boldsymbol{x}\_1)$、$\\boldsymbol{\\beta}(\\boldsymbol{x}\_1)$是以$\\boldsymbol{x}\_1$为输入、输出形状跟$\\boldsymbol{x}\_2$一致的模型，$\\otimes$是Hadamard积。上式说的是，将$\\boldsymbol{x}$分成两部份，分法随意，也不要求等分，将其中一份原封不动输出，另一边按照指定规则运算输出。注意仿射耦合层是可逆的，其逆为
\\begin{equation}\\begin{aligned}&\\boldsymbol{x}\_1 = \\boldsymbol{h}\_1\\\
&\\boldsymbol{x}\_2 = \\exp(-\\boldsymbol{\\gamma}(\\boldsymbol{h}\_1))\\otimes(\\boldsymbol{h}\_2 - \\boldsymbol{\\beta}(\\boldsymbol{h}\_1))\\end{aligned}\\end{equation}
这就满足了第一个条件可逆性。另一方面，仿射耦合层的雅可比矩阵是一个下三角阵：
\\begin{equation}\\frac{\\partial \\boldsymbol{h}}{\\partial \\boldsymbol{x}} = \\begin{pmatrix}\\frac{\\partial \\boldsymbol{h}\_1}{\\partial \\boldsymbol{x}\_1} & \\frac{\\partial \\boldsymbol{h}\_1}{\\partial \\boldsymbol{x}\_2} \\\ \\frac{\\partial \\boldsymbol{h}\_2}{\\partial \\boldsymbol{x}\_1} & \\frac{\\partial \\boldsymbol{h}\_2}{\\partial \\boldsymbol{x}\_2}\\end{pmatrix}=\\begin{pmatrix}\\boldsymbol{I} & \\boldsymbol{O} \\\
\\frac{\\partial (\\exp(\\boldsymbol{\\gamma}(\\boldsymbol{x}\_1))\\otimes\\boldsymbol{x}\_2 + \\boldsymbol{\\beta}(\\boldsymbol{x}\_1))}{\\partial \\boldsymbol{x}\_1} & \\text{diag}(\\exp(\\boldsymbol{\\gamma}(\\boldsymbol{x}\_1)))\\end{pmatrix}\\end{equation}
三角矩阵的行列式，等于对角线元素之积，所以
\\begin{equation}\\log\\left\|\\det\\frac{\\partial \\boldsymbol{h}}{\\partial \\boldsymbol{x}}\\right\| = \\sum\_i \\boldsymbol{\\gamma}\_i(\\boldsymbol{x}\_1)\\end{equation}
即雅可比矩阵行列式的绝对值对数等于$\\boldsymbol{\\gamma}(\\boldsymbol{x}\_1)$的各分量之和，这就满足了第二个条件雅可比矩阵行列式的可计算性。

仿射耦合层首次提出自 [RealNVP](https://papers.cool/arxiv/1605.08803)，NVP的含义是“Non-Volume Preserving”，也就是“不保体积”，这个名字对标的是$\\boldsymbol{\\gamma}(\\boldsymbol{x}\_1)$恒等于零时的特殊情形，此时称为“加性耦合层”，提出自 [NICE](https://papers.cool/arxiv/1410.8516)，特点是其雅可比行列式等于1，即加性耦合层是“保体积”的（行列式的几何意义是体积）。

注意，如果直接堆叠多个仿射耦合层，那么$\\boldsymbol{x}\_1$将一直保持不变，这并不是我们想要的，我们想要做的是将整个$\\boldsymbol{x}$映射到标准正态分布。为了解决这个问题，我们每次应用仿射耦合层前，都要输入的分量以某种方式“打乱”，这样就不至于出现始终不变的分量。“打乱”运算对应于置换矩阵变换，行列式绝对值始终为1。

## 核心改进 [\#](https://kexue.fm/archives/10667\#%E6%A0%B8%E5%BF%83%E6%94%B9%E8%BF%9B)

到目前为止，这些内容都还只是流模型的基础内容，接下来才正式进入到TARFLOW的贡献点。

首先，TARFLOW留意到仿射耦合层$\\eqref{eq:couple}$可以推广到多块划分，即将$\\boldsymbol{x}$分成更多份$\[\\boldsymbol{x}\_1,\\boldsymbol{x}\_2,\\cdots,\\boldsymbol{x}\_n\]$，然后按照类似的规则运算
\\begin{equation}\\begin{aligned}&\\boldsymbol{h}\_1 = \\boldsymbol{x}\_1\\\
&\\boldsymbol{h}\_k = \\exp(\\boldsymbol{\\gamma}\_k(\\boldsymbol{x}\_{< k}))\\otimes\\boldsymbol{x}\_k + \\boldsymbol{\\beta}\_k(\\boldsymbol{x}\_{< k})\\end{aligned}\\label{eq:couple-2}\\end{equation}
其中$k > 1$，$\\boldsymbol{x}\_{< k}=\[\\boldsymbol{x}\_1,\\boldsymbol{x}\_2,\\cdots,\\boldsymbol{x}\_{k-1}\]$，其逆运算为
\\begin{equation}\\begin{aligned}&\\boldsymbol{x}\_1 = \\boldsymbol{h}\_1\\\
&\\boldsymbol{x}\_k = \\exp(-\\boldsymbol{\\gamma}\_k(\\boldsymbol{x}\_{< k}))\\otimes(\\boldsymbol{h}\_k - \\boldsymbol{\\beta}\_k(\\boldsymbol{x}\_{< k}))\\end{aligned}\\label{eq:couple-2-inv}\\end{equation}
类似地，推广版本的仿射耦合层的雅可比行列式绝对值对数为$\\boldsymbol{\\gamma}\_2(\\boldsymbol{x}\_{< 2}),\\cdots,\\boldsymbol{\\gamma}\_n(\\boldsymbol{x}\_{< n})$所有分量之和，所以流模型要求的两个条件都能满足。这个推广的雏形最早在2016年的 [IAF](https://papers.cool/arxiv/1606.04934) 就提出了，比Glow还早。

可为什么后来的工作鲜往这个方向深入呢？这大体是历史原因。早年CV模型的主要架构是CNN，用CNN的前提是特征满足局部相关性，这就导致了将$\\boldsymbol{x}$分块时，往往只考虑在通道（channel）维度划分。因为每一层还有一个必要的打乱运算，一旦选择在长、宽两个空间维度划分，那么随机打乱后特征就失去了局部相关性了，从而没法用CNN。而如果在通道维度划分多份，那么多个通道特征图比较难高效地交互。

然而，到了Transformer时代，情况截然不同了。Transformer的输入本质上是一个无序的向量集合，换言之不依赖局部相关性，因此以Transformer为主架构，我们就可以选择在空间维度划分，这就是Patchify。此外，式$\\eqref{eq:couple-2}$中$\\boldsymbol{h}\_{k} = \\cdots(\\boldsymbol{x}\_{< k})$形式，意味着这是一个Causal模型，这也正好可以用Transformer高效实现。

除了形式上的契合外，在空间维度划分有什么本质好处呢？这就要回到流模型的目标了：$\\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z})$将噪声变成图片，逆模型$\\boldsymbol{f}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$则将图片变成噪声，噪声的特点是随机，说白了就是乱，图片的显著特点是局部相关性，所以图片变噪声的关键之一就是要打乱这种局部相关性，直接在空间维度Patchify配合耦合层自带的打乱操作，无疑是最高效的选择。

所以，式$\\eqref{eq:couple-2}$跟Transformer可谓是“一拍即合”、“相得益彰”，这就是TARFLOW前三个字母TAR的含义（Transformer AutoRegressive Flow），也是它的核心改进。

## 加噪去噪 [\#](https://kexue.fm/archives/10667\#%E5%8A%A0%E5%99%AA%E5%8E%BB%E5%99%AA)

流模型常用的一个训练技巧是加噪，也就是往图片加入微量噪声后再送入模型进行训练。虽然我们将图片视为连续向量，但它实际是以离散的格式存储的，加噪可以进一步平滑这种不连续性，使得图片更接近连续向量。噪声的加入还可以防止模型过度依赖训练数据中的特定细节，从而减少过拟合的风险。

加噪是流模型的基本操作，并不是TARFLOW首先提出的，TARFLOW提出的是去噪。理论上来说，图片加噪后训练出来的流模型，生成结果也是带有噪声的，只不过以往的流模型生成效果也没多好，所以这点噪声也无所谓了。但TARFLOW把流模型的能力提上去后，去噪就“势在必行”了，不然噪声就称为影响效果的主要因素了。

怎么去噪呢？另外训练一个去噪模型？没这个必要。我们在 [《从去噪自编码器到生成模型》](https://kexue.fm/archives/7038) 已经证明了，如果$q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$是加噪$\\mathcal{N}(\\boldsymbol{0},\\sigma^2 \\boldsymbol{I})$训练后的概率密度函数，那么
\\begin{equation}\\boldsymbol{r}(\\boldsymbol{x}) = \\boldsymbol{x} + \\sigma^2 \\nabla\_{\\boldsymbol{x}} \\log q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})\\end{equation}
就是去噪模型的理论最优解。所以有了$q\_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$后，我们就不用另外训练去噪模型了，直接按照上式计算就可以去噪，这也是流模型的优势之一。而正因为加入了去噪步骤，所以TARFLOW的输入的噪声改为高斯分布，并适当增大了噪声的方差，这也是它性能更好的原因之一。

综上所述，TARFLOW完整的采样流程是
\\begin{equation}\\boldsymbol{z}\\sim \\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I}) ,\\quad \\boldsymbol{y} =\\boldsymbol{g}\_{\\boldsymbol{\\theta}}(\\boldsymbol{z}),\\quad\\boldsymbol{x} = \\boldsymbol{y} + \\sigma^2 \\nabla\_{\\boldsymbol{y}} \\log q\_{\\boldsymbol{\\theta}}(\\boldsymbol{y})
\\end{equation}

## 延伸思考 [\#](https://kexue.fm/archives/10667\#%E5%BB%B6%E4%BC%B8%E6%80%9D%E8%80%83)

至此，TARFLOW相比以往流模型的一些关键变化已经介绍完毕，剩下的一些模型细节，大家自行读原论文就好，如果还有不懂的也可以参考官方开源的代码。

> **Github： [https://github.com/apple/ml-tarflow](https://github.com/apple/ml-tarflow)**

下面主要谈谈笔者对TARFLOW的一些思考。

首先，需要指出的是，TARFLOW虽然效果上达到了SOTA，但它采样速度实际上不如我们期望，原论文附录提到，在A100上采样32张ImageNet64图片大概需要2分钟。为什么会这么慢呢？我们仔细观察耦合层的逆$\\eqref{eq:couple-2-inv}$就会发现，它实际上是一个非线性RNN！非线性RNN只能串行计算，这就是它慢的根本原因。

换句话说，TARFLOW实际上是一个训练快、采样慢的模型，当然如果我们愿意也可以改为训练慢、采样快，总之正向和逆向不可避免会有一侧慢，这是分多块的仿射耦合层的缺点，也是TARFLOW想要进一步推广的主要改进方向。

其次，TARFLOW中的AR一词，容易让人联想到现在主流的自回归式LLM，那么它们俩是否可以整合在一起做多模态生成？说实话很难。因为TARFLOW的AR纯粹是仿射耦合层的要求，而耦合层之前还要打乱，所以它并非一个真正的Causal模型，反而是彻头彻尾的Bi-Directional模型，所以它并不好跟文本的AR强行整合在一起。

总的来说，如果TARFLOW进一步将采样速度也提上去，那么它将会是一个非常有竞争力的纯视觉生成模型。因为除了训练简单和效果优异，流模型的可逆性还有另外一个优点，就是 [《The Reversible Residual Network: Backpropagation Without Storing Activations》](https://papers.cool/arxiv/1707.04585) 所提的反向传播可以完全不用存激活值，并且重计算的成本比普通模型低得多。

至于它有没有可能成为多模态LLM的统一架构，只能说现在还不大明朗。

## 文艺复兴 [\#](https://kexue.fm/archives/10667\#%E6%96%87%E8%89%BA%E5%A4%8D%E5%85%B4)

最后，谈谈深度学习模型的“文艺复兴”。

近年来，已经有不少工作尝试结合当前最新的认知，来反思和改进一些看起来已经落后的模型，并得到了一些新的结果。除了TARFLOW试图让流模型重新焕发活力外，最近还有 [《The GAN is dead; long live the GAN! A Modern GAN Baseline》](https://papers.cool/arxiv/2501.05441) 对GAN的各种排列组合去芜存菁，得到了同样有竞争力的结果。

更早一些，还有 [《Improved Residual Networks for Image and Video Recognition》](https://papers.cool/arxiv/2004.04989)、 [《Revisiting ResNets: Improved Training and Scaling Strategies》](https://papers.cool/arxiv/2103.07579) 等工作让ResNet更上一层楼，甚至还有 [《RepVGG: Making VGG-style ConvNets Great Again》](https://papers.cool/arxiv/2101.03697) 让VGG经典再现。当然，SSM、线性Attention等工作也不能不提，它们代表着RNN的“文艺复兴”。

期待这种百花齐放的“复兴”潮能更热烈一些，它能让我们获得对模型更全面和准确的认知。

_**转载到请包括本文地址：** [https://kexue.fm/archives/10667](https://kexue.fm/archives/10667)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/10667#share)/ [打赏](https://kexue.fm/archives/10667#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Jan. 17, 2025). 《细水长flow之TARFLOW：流模型满血归来？ 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/10667](https://kexue.fm/archives/10667)

@online{kexuefm-10667,
        title={细水长flow之TARFLOW：流模型满血归来？},
        author={苏剑林},
        year={2025},
        month={Jan},
        url={\\url{https://kexue.fm/archives/10667}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [流模型](https://kexue.fm/tag/%E6%B5%81%E6%A8%A1%E5%9E%8B/), [flow](https://kexue.fm/tag/flow/), [生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/), [attention](https://kexue.fm/tag/attention/)[17 评论](https://kexue.fm/archives/10667#comments)

< [低秩近似之路（五）：CUR](https://kexue.fm/archives/10662) \| [三个球的交点坐标（三球交会定位）](https://kexue.fm/archives/10684) >

### 你也许还对下面的内容感兴趣

- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958)
- [Transformer升级之路：20、MLA究竟好在哪里？](https://kexue.fm/archives/10907)
- [Transformer升级之路：19、第二类旋转位置编码](https://kexue.fm/archives/10862)
- [生成扩散模型漫谈（二十九）：用DDPM来离散编码](https://kexue.fm/archives/10711)
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633)
- [生成扩散模型漫谈（二十七）：将步长作为条件输入](https://kexue.fm/archives/10617)
- [生成扩散模型漫谈（二十六）：基于恒等式的蒸馏（下）](https://kexue.fm/archives/10567)
- [VQ的又一技巧：给编码表加一个线性变换](https://kexue.fm/archives/10519)
- [VQ的旋转技巧：梯度直通估计的一般推广](https://kexue.fm/archives/10489)

[发表你的看法](https://kexue.fm/archives/10667#comment_form)

More

January 17th, 2025

请问如何实现文中提到的训练慢采样快

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26291#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
January 20th, 2025

就反过来用啊，式$\\eqref{eq:couple-2-inv}$做encoder，式$\\eqref{eq:couple-2}$做生成。

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26340#respond-post-10667)

MoreMore

January 17th, 2025

看了下效果，似然分比较高，FID也超过了GAN，但还是不如diffusion方法。尤其是和他有联系的flow-matching。但可以作为一次意义的尝试。

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26293#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
January 20th, 2025

其实这点FID很小了，稍微调调估计有办法追上。另外，其实我不认为flow matching跟normalizing flow有什么实在联系，除了都用了flow这个词作为名字外～

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26341#respond-post-10667)

[Sunbread](http://sunbread.dev) 发表于
January 31st, 2025

还有都可逆吧，都可以建模一个正态样本和一个目标分布样本之间的可逆对应关系（

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26402#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
February 9th, 2025

嗯，大家的相同点是可逆，都可以做一些可逆模型能做的事情，这是flow模型的特色，但当我们具体指到flow matching和normalizing flow时，其实本意上已经指向它们各自不同的地方了。

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26525#respond-post-10667)

Haonan

January 24th, 2025

不知道苏哥有没有关注过一系列名为神经算子的研究，譬如Fourier Neural Operator，DeepONet等。它们的陈述，都是试图以某种方式试图学会如何“解PDE”。觉得以苏哥对数学和AI的理解，能产生一些很有意思的见解，很期待谈谈这方面的分享呀！

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26372#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
January 29th, 2025

听说过，没关注，感觉不够机器学习本身有意思。

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26393#respond-post-10667)

卉卉酱

January 26th, 2025

大佬去kimi了？离开追一了吗

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26377#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
January 29th, 2025

嗯

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26395#respond-post-10667)

姚兆汝

March 2nd, 2025

博主，我一直有个疑问：Transformer AutoRegressive FLow 如何实现条件控制呢？使用Cross attention吗？条件输入tokens可以从一些预训练vit模型提取出来，但想生成不同尺寸图片，好像就很难做到了，因为官方没有去实现vit动态输入，而且 支持 动态尺寸输入的预训练vit模型似乎难以找到。博主有什么想法吗？困扰了好长时间。

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26901#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
March 5th, 2025

直接将条件作为$\\boldsymbol{\\beta}\_k(\\boldsymbol{x}\_{< k})$和$\\boldsymbol{\\gamma}\_k(\\boldsymbol{x}\_{< k})$的额外输入就行了啊。没看懂你这段话的前后关联，为什么又提到生成不同尺寸图片了？原则上flow模型不支持同时生成多分辨率结果。

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=26983#respond-post-10667)

li6626

April 19th, 2025

苏老师，TARFLOW里面对原始图像做patchify时用的PatchSize相较于ViT使用的16\*16而言非常小，作者也没有解释原因。可以谈谈您的理解吗？

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=27427#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
April 21st, 2025

越小越细颗粒度，理论上越好？大patch按道理都是为了节省计算量～

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=27450#respond-post-10667)

li6626

June 14th, 2025

苏老师，Normalizing Flow有了新进展，论文链接:https://arxiv.org/pdf/2506.06276v1, 直接在flow模型外面接一个AE。这是否过于粗暴？想请苏老师解惑~

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=27893#respond-post-10667)

li6626 发表于
June 20th, 2025

是接了一个VAE，我上次的表达有误。但同样不太理解，之前看您的文章了解到VAE优化的是一个更强的上界，因此它是一个近似模型。而流模型直接计算积分，更加精确。作者论文中对deep-shallow结构做了消融，发现VAE和deep-shallow都能帮助降低FID。为什么加了VAE反而提点了呢？想了解一下苏老师的想法~

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=27928#respond-post-10667)

[苏剑林](https://kexue.fm) 发表于
June 20th, 2025

看了一下，STARFlow的VAE其实是LDM的VAE，虽然叫做VAE，但实际上更多是一个AE，用来压缩输入大小，降低训练难度的，这种VAE能实现人眼近乎不失真的压缩效果。通过这种VAE转化为latent空间的生成，是生成模型一贯以来的做法。

参考我之前的回复：https://www.zhihu.com/question/649097976/answer/3621069894

STARFlow真正的创新是deep-shallow设计，因为TARFlow采样不可并行，所以干脆把主要计算量压在单个block内，以提高生成速度。

[回复评论](https://kexue.fm/archives/10667/comment-page-1?replyTo=27930#respond-post-10667)

[取消回复](https://kexue.fm/archives/10667#respond-post-10667)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[写在前面](https://kexue.fm/archives/10667#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2)
[模型回顾](https://kexue.fm/archives/10667#%E6%A8%A1%E5%9E%8B%E5%9B%9E%E9%A1%BE)
[仿射耦合](https://kexue.fm/archives/10667#%E4%BB%BF%E5%B0%84%E8%80%A6%E5%90%88)
[核心改进](https://kexue.fm/archives/10667#%E6%A0%B8%E5%BF%83%E6%94%B9%E8%BF%9B)
[加噪去噪](https://kexue.fm/archives/10667#%E5%8A%A0%E5%99%AA%E5%8E%BB%E5%99%AA)
[延伸思考](https://kexue.fm/archives/10667#%E5%BB%B6%E4%BC%B8%E6%80%9D%E8%80%83)
[文艺复兴](https://kexue.fm/archives/10667#%E6%96%87%E8%89%BA%E5%A4%8D%E5%85%B4)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [一个神秘而糟糕的图形](https://kexue.fm/archives/853)
- [《为什么现在的LLM都是Decoder-only的架构？》FAQ](https://kexue.fm/archives/9547)
- [也来扯几句“全国青少年科技创新大赛”](https://kexue.fm/archives/7611)
- [排除万难，就会有奇迹出现](https://kexue.fm/archives/82)
- [生活拾零...](https://kexue.fm/archives/139)
- [【外微分浅谈】7\. 有力的计算](https://kexue.fm/archives/4076)
- [第1000篇文章](https://kexue.fm/archives/7782)
- [这样的世界之最你见过没有？](https://kexue.fm/archives/36)
- [\[问题解答\]双曲线上的最短距离](https://kexue.fm/archives/1904)
- [微积分学习（一）：极限](https://kexue.fm/archives/75)

### 最近评论

- [石子131](https://kexue.fm/archives/9405/comment-page-2#comment-27955): 也许可以尝试把热水管的回水管的开关阀做成用户的手动阀，在热水管临近回水管、手动阀靠近热水管侧加...
- [Kuo](https://kexue.fm/archives/10795/comment-page-1#comment-27954): 我的理解，这是一个迭代过程，注意下标K是指condition还是desideratum
- [musicfish1973](https://kexue.fm/archives/8009/comment-page-1#comment-27953): 好的设计都是相似的,haha
- [忍者猫](https://kexue.fm/archives/10592/comment-page-2#comment-27952): 这优化器的作者真的应该给你打钱
- [Chaofa Yuan](https://kexue.fm/archives/11033/comment-page-1#comment-27951): 写得太好了
- [Skyler Lin](https://kexue.fm/archives/11033/comment-page-1#comment-27949): respect苏神！
- [宋佳铭](https://kexue.fm/archives/10958/comment-page-1#comment-27947): 对，个人感觉mean flow就是continuous time CTM
- [宋佳铭](https://kexue.fm/archives/10958/comment-page-1#comment-27946): 的确，对sg这个事情我感觉如果是用‘归纳’法做是不太能避免的，因为毕竟是用步长短的模型去约束步...
- [MoFHeka](https://kexue.fm/archives/10542/comment-page-1#comment-27945): 苏老师您好，请问一下这套结论在稀疏参数上应该如何应用？比如大规模稀疏Embedding，每个B...
- [苏剑林](https://kexue.fm/archives/11033/comment-page-1#comment-27944): Temp LoRA倒是有印象，其实思想是一样的，如果我单独开一篇文章介绍TTT的话，应该会提到...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。