## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [为什么Adam的Update RM...](https://kexue.fm/archives/11267)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11260)
- [Cool Papers更新：简单适...](https://kexue.fm/archives/11250)
- [流形上的最速下降：4\. Muon ...](https://kexue.fm/archives/11241)
- [ReLU/GeLU/Swish的一...](https://kexue.fm/archives/11233)
- [流形上的最速下降：3\. Muon ...](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon ...](https://kexue.fm/archives/11215)
- [基于树莓派Zero2W搭建一个随身旁路由](https://kexue.fm/archives/11206)
- [流形上的最速下降：1\. SGD ...](https://kexue.fm/archives/11196)
- [矩阵r次方根和逆r次方根的高效计算](https://kexue.fm/archives/11175)

## COMMENTS

- [gapeng: kimi k2形式上推导了一个公式，最后数值模拟在0.23左右...](https://kexue.fm/archives/11267/comment-page-1#comment-28531)
- [Evan1024: 太牛了！](https://kexue.fm/archives/11267/comment-page-1#comment-28530)
- [ameowcat: 苏神您好，有个问题想请教一下，最近扩散模型的推理优化有一篇文章...](https://kexue.fm/archives/10958/comment-page-3#comment-28529)
- [Eliot: 2 实现loss-free with budget应当是在当前...](https://kexue.fm/archives/10815/comment-page-1#comment-28528)
- [Eliot: 继续阅读这2份代码后，大概结论如下\
1 megatron-lm...](https://kexue.fm/archives/10815/comment-page-1#comment-28527)
- [lzyyzl: 帮忙解惑一下\
1 文中提到本文主题是求O=msign(M)的导...](https://kexue.fm/archives/11025/comment-page-1#comment-28525)
- [z: 牛](https://kexue.fm/archives/11267/comment-page-1#comment-28524)
- [Gusto: 按照个人理解将weight decay理解为损失函数中的惩罚项...](https://kexue.fm/archives/10739/comment-page-2#comment-28523)
- [hazdzz: 非常感谢您提到 pbSGD，这启发了我的毕业论文！](https://kexue.fm/archives/11196/comment-page-1#comment-28522)
- [苏剑林: 你是指xml代码？那不是乱码，feed就是xml格式，你要自己...](https://kexue.fm/content.html/comment-page-1#comment-28521)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) [信息时代](https://kexue.fm/category/Big-Data) 生成扩散模型漫谈（十二）：“硬刚”扩散ODE

28Sep

# [生成扩散模型漫谈（十二）：“硬刚”扩散ODE](https://kexue.fm/archives/9280)

By 苏剑林 \|
2022-09-28 \|
123406位读者\|

在 [《生成扩散模型漫谈（五）：一般框架之SDE篇》](https://kexue.fm/archives/9209) 中，我们从SDE的角度理解了生成扩散模型，然后在 [《生成扩散模型漫谈（六）：一般框架之ODE篇》](https://kexue.fm/archives/9228) 中，我们知道SDE对应的扩散模型中，实际上隐含了一个ODE模型。无独有偶，在 [《生成扩散模型漫谈（四）：DDIM = 高观点DDPM》](https://kexue.fm/archives/9181) 中我们也知道原本随机采样的DDPM模型中，也隐含了一个确定性的采样过程DDIM，它的连续极限也是一个ODE。

细想上述过程，可以发现不管是“DDPM→DDIM”还是“SDE→ODE”，都是从随机采样模型过渡到确定性模型，而如果我们一开始的目标就是ODE，那么该过程未免显得有点“迂回”了。在本文中，笔者尝试给出ODE扩散模型的直接推导，并揭示了它与雅可比行列式、热传导方程等内容的联系。

## 微分方程 [\#](https://kexue.fm/kexue.fm\#%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B)

像GAN这样的生成模型，它本质上是希望找到一个确定性变换，能将从简单分布（如标准正态分布）采样出来的随机变量，变换为特定数据分布的样本。flow模型也是生成模型之一，它的思路是反过来，先找到一个能将数据分布变换简单分布的可逆变换，再求解相应的逆变换来得到一个生成模型。

传统的flow模型是通过设计精巧的耦合层（参考“ [细水长flow](https://kexue.fm/search/%E7%BB%86%E6%B0%B4%E9%95%BFflow)”系列）来实现这个可逆变换，但后来大家就意识到，其实通过微分方程也能实现这个变换，并且理论上还很优雅。基于“神经网络 \+ 微分方程”做生成模型等一系列研究，构成了被称为“神经ODE”的一个子领域。

考虑$\\boldsymbol{x}\_t\\in\\mathbb{R}^d$上的一阶（常）微分方程（组）
\\begin{equation}\\frac{d\\boldsymbol{x}\_t}{dt}=\\boldsymbol{f}\_t(\\boldsymbol{x}\_t)\\label{eq:ode}\\end{equation}
假设$t\\in\[0, T\]$，那么给定$\\boldsymbol{x}\_0$，（在比较容易实现的条件下）我们可以确定地求解出$\\boldsymbol{x}\_T$，也就是说该微分方程描述了从$\\boldsymbol{x}\_0$到$\\boldsymbol{x}\_T$的一个变换。特别地，该变换还是可逆的，即可以逆向求解该微分方程，得到从$\\boldsymbol{x}\_T$到$\\boldsymbol{x}\_0$的变换。所以说，微分方程本身就是构建可逆变换的一个理论优雅的方案。

## 雅可比行列式 [\#](https://kexue.fm/kexue.fm\#%E9%9B%85%E5%8F%AF%E6%AF%94%E8%A1%8C%E5%88%97%E5%BC%8F)

跟之前的扩散模型一样，在这篇文章中，我们将$\\boldsymbol{x}\_0$视为一个数据样本，而将$\\boldsymbol{x}\_T$视为简单分布的样本，我们希望通过微分方程，来实现从数据分布到简单分布的变换。

首先，我们从离散化的角度来理解微分方程$\\eqref{eq:ode}$：
\\begin{equation}\\boldsymbol{x}\_{t+\\Delta t} - \\boldsymbol{x}\_t = \\boldsymbol{f}\_t(\\boldsymbol{x}\_t)\\Delta t\\label{eq:ode-diff}\\end{equation}
由于是确定性变换，所以我们有
\\begin{equation}p\_t(\\boldsymbol{x}\_t) d\\boldsymbol{x}\_t = p\_{t+\\Delta t}(\\boldsymbol{x}\_{t+\\Delta t}) d\\boldsymbol{x}\_{t+\\Delta t} = p\_{t+\\Delta t}(\\boldsymbol{x}\_{t+\\Delta t}) \\left\| \\frac{\\partial \\boldsymbol{x}\_{t+\\Delta t}}{\\partial \\boldsymbol{x}\_t} \\right\| d\\boldsymbol{x}\_t\\end{equation}
这里的$\\frac{\\partial \\boldsymbol{x}\_{t+\\Delta t}}{\\partial \\boldsymbol{x}\_t}$表示变换的雅可比矩阵，$\|\\cdot\|$代表行列式的绝对值。直接对式$\\eqref{eq:ode-diff}$两边求偏导，我们就得到
\\begin{equation}\\frac{\\partial \\boldsymbol{x}\_{t+\\Delta t}}{\\partial \\boldsymbol{x}\_t} = \\boldsymbol{I} + \\frac{\\partial \\boldsymbol{f}\_t(\\boldsymbol{x}\_t)}{\\partial \\boldsymbol{x}\_t}\\Delta t\\end{equation}
根据 [《行列式的导数》](https://kexue.fm/archives/2383) 一文，我们就有
\\begin{equation}\\left\|\\frac{\\partial \\boldsymbol{x}\_{t+\\Delta t}}{\\partial \\boldsymbol{x}\_t}\\right\| \\approx 1 + \\text{Tr}\\,\\frac{\\partial \\boldsymbol{f}\_t(\\boldsymbol{x}\_t)}{\\partial \\boldsymbol{x}\_t}\\Delta t = 1 + \\nabla\_{\\boldsymbol{x}\_t}\\cdot \\boldsymbol{f}\_t(\\boldsymbol{x}\_t) \\Delta t\\approx e^{\\nabla\_{\\boldsymbol{x}\_t}\\cdot \\boldsymbol{f}\_t(\\boldsymbol{x}\_t) \\Delta t}\\end{equation}
于是我们可以写出
\\begin{equation}\\log p\_{t+\\Delta t}(\\boldsymbol{x}\_{t+\\Delta t}) - \\log p\_t(\\boldsymbol{x}\_t) \\approx -\\nabla\_{\\boldsymbol{x}\_t}\\cdot \\boldsymbol{f}\_t(\\boldsymbol{x}\_t) \\Delta t\\label{eq:approx-ode}\\end{equation}

## 泰勒近似 [\#](https://kexue.fm/kexue.fm\#%E6%B3%B0%E5%8B%92%E8%BF%91%E4%BC%BC)

假设$p\_t(\\boldsymbol{x}\_t)$是一簇随着参数$t$连续变化的分布的概率密度函数，其中$p\_0(\\boldsymbol{x}\_0)$是数据分布，$p\_T(\\boldsymbol{x}\_T)$则是简单分布，当$\\Delta t$和$\\boldsymbol{x}\_{t+\\Delta t} - \\boldsymbol{x}\_t$都较小时，我们有一阶泰勒近似
\\begin{equation}\\log p\_{t+\\Delta t}(\\boldsymbol{x}\_{t+\\Delta t}) - \\log p\_t(\\boldsymbol{x}\_t) \\approx (\\boldsymbol{x}\_{t+\\Delta t} - \\boldsymbol{x}\_t)\\cdot \\nabla\_{\\boldsymbol{x}\_t}\\log p\_t(\\boldsymbol{x}\_t) + \\Delta t\\frac{\\partial}{\\partial t}\\log p\_t(\\boldsymbol{x}\_t)\\end{equation}
代入式$\\eqref{eq:ode-diff}$的$\\boldsymbol{x}\_{t+\\Delta t} - \\boldsymbol{x}\_t$，然后对照式$\\eqref{eq:approx-ode}$，可以得到$\\boldsymbol{f}\_t(\\boldsymbol{x}\_t)$所满足的方程
\\begin{equation}-\\nabla\_{\\boldsymbol{x}\_t}\\cdot \\boldsymbol{f}\_t(\\boldsymbol{x}\_t) = \\boldsymbol{f}\_t(\\boldsymbol{x}\_t)\\cdot \\nabla\_{\\boldsymbol{x}\_t}\\log p\_t(\\boldsymbol{x}\_t) + \\frac{\\partial}{\\partial t}\\log p\_t(\\boldsymbol{x}\_t)\\label{eq:ode-f-eq}\\end{equation}
换句话说，满足该方程的任意$\\boldsymbol{f}\_t(\\boldsymbol{x}\_t)$，都可以用来构造一个微分方程$\\eqref{eq:ode}$，通过求解它来实现数据分布和简单分布之间的变换。我们也可以将它整理得
\\begin{equation}\\frac{\\partial}{\\partial t} p\_t(\\boldsymbol{x}\_t) = - \\nabla\_{\\boldsymbol{x}\_t}\\cdot\\Big(\\boldsymbol{f}\_t(\\boldsymbol{x}\_t) p\_t(\\boldsymbol{x}\_t)\\Big)\\label{eq:ode-f-eq-fp}\\end{equation}
它其实就是 [《生成扩散模型漫谈（六）：一般框架之ODE篇》](https://kexue.fm/archives/9228#F-P%E6%96%B9%E7%A8%8B) 介绍的“Fokker-Planck方程”在$g\_t=0$时的特例。

## 热传导方程 [\#](https://kexue.fm/kexue.fm\#%E7%83%AD%E4%BC%A0%E5%AF%BC%E6%96%B9%E7%A8%8B)

我们考虑如下格式的解
\\begin{equation}\\boldsymbol{f}\_t(\\boldsymbol{x}\_t) = - \\boldsymbol{D}\_t(\\boldsymbol{x}\_t)\\,\\nabla\_{\\boldsymbol{x}\_t}\\log p\_t(\\boldsymbol{x}\_t)\\label{eq:ode-f-grad}\\end{equation}
其中$\\boldsymbol{D}\_t(\\boldsymbol{x}\_t)$可以是一个矩阵，也可能是一个标量，视具体考虑的复杂度而定。为什么要考虑这种形式的解？说实话，笔者一开始就是往DDIM格式去凑的，后来就是发现一般化后能跟下面的扩散方程联系起来，所以就直接设为式$\\eqref{eq:ode-f-grad}$了。事后来看，如果假设$\\boldsymbol{D}\_t(\\boldsymbol{x}\_t)$是非负标量函数，那么将它代入式$\\eqref{eq:ode-diff}$后，就会发现其格式跟梯度下降有点相似，即从$\\boldsymbol{x}\_0$到$\\boldsymbol{x}\_T$是逐渐寻找低概率区域，反之从$\\boldsymbol{x}\_T$到$\\boldsymbol{x}\_0$就是逐渐寻找高概率区域，跟直觉相符，这也算是式$\\eqref{eq:ode-f-grad}$的一个启发式引导吧。

将式$\\eqref{eq:ode-f-grad}$代入方程$\\eqref{eq:ode-f-eq-fp}$后，我们可以得到
\\begin{equation}\\frac{\\partial}{\\partial t}p\_t(\\boldsymbol{x}\_t) = \\nabla\_{\\boldsymbol{x}\_t}\\cdot\\Big(\\boldsymbol{D}\_t(\\boldsymbol{x}\_t)\\,\\nabla\_{\\boldsymbol{x}\_t} p\_t(\\boldsymbol{x}\_t)\\Big)\\end{equation}
这就是偏微分方程中的“ [扩散方程](https://en.wikipedia.org/wiki/Diffusion_equation)”。这里我们只考虑一个极简单的情形——$\\boldsymbol{D}\_t(\\boldsymbol{x}\_t)$是跟$\\boldsymbol{x}\_t$无关的标量函数$D\_t$，此时扩散方程简化为
\\begin{equation}\\frac{\\partial}{\\partial t}p\_t(\\boldsymbol{x}\_t) = D\_t \\nabla\_{\\boldsymbol{x}\_t}^2 p\_t(\\boldsymbol{x}\_t)\\label{eq:heat}\\end{equation}
这就是“ [热传导方程](https://en.wikipedia.org/wiki/Heat_equation)”，是我们接下来要重点求解和分析的对象。

## 求解分布 [\#](https://kexue.fm/kexue.fm\#%E6%B1%82%E8%A7%A3%E5%88%86%E5%B8%83)

利用傅里叶变换，可以将热传导方程转为常微分方程，继而完成分布$p\_t(\\boldsymbol{x}\_t)$的求解，结果是：
\\begin{equation}\\begin{aligned}
p\_t(\\boldsymbol{x}\_t) =&\\, \\int \\frac{1}{(2\\pi\\sigma\_t^2)^{d/2}}\\exp\\left(-\\frac{\\Vert \\boldsymbol{x}\_t - \\boldsymbol{x}\_0\\Vert^2}{2\\sigma\_t^2}\\right)p\_0(\\boldsymbol{x}\_0) d \\boldsymbol{x}\_0 \\\
=&\\, \\int \\mathcal{N}(\\boldsymbol{x}\_t; \\boldsymbol{x}\_0, \\sigma\_t^2 \\boldsymbol{I})\\, p\_0(\\boldsymbol{x}\_0) d \\boldsymbol{x}\_0
\\end{aligned}\\label{eq:heat-sol}\\end{equation}
其中$\\sigma\_t^2 = 2\\int\_0^t D\_s ds$，或者$D\_t = \\dot{\\sigma}\_t \\sigma\_t$（其中$\\sigma\_0=0$）。可以看到，热传导方程的解正好是以$p\_0(\\boldsymbol{x}\_0)$为初始分布的高斯混合模型。

> **过程：** 这里简单介绍一下热传导方程的求解思路。对于不关心求解过程的读者，或者已经熟悉热传导方程的读者，可以跳过这部分内容。
>
> 用傅里叶变换求热传导方程$\\eqref{eq:heat}$其实很简单，对两边的$\\boldsymbol{x}\_t$变量做傅里叶变换，根据$\\nabla\_{\\boldsymbol{x}\_t}\\to i\\boldsymbol{\\omega}$的原则，结果是
> \\begin{equation}\\frac{\\partial}{\\partial t}\\mathcal{F}\_t(\\boldsymbol{\\omega}) = -D\_t \\boldsymbol{\\omega}^2 \\mathcal{F}\_t(\\boldsymbol{\\boldsymbol{\\omega}})\\end{equation}
> 这只是关于$t$的常微分方程，可以解得
> \\begin{equation}\\mathcal{F}\_t(\\boldsymbol{\\omega}) = \\mathcal{F}\_0(\\boldsymbol{\\omega}) \\exp\\left(-\\frac{1}{2}\\sigma\_t^2 \\boldsymbol{\\omega}^2\\right)\\end{equation}
> 其中$\\sigma\_t^2 = 2\\int\_0^t D\_s ds$，而$\\mathcal{F}\_0(\\boldsymbol{\\omega})$则是$p\_0(\\boldsymbol{x}\_0)$的傅里叶变换。现在对两边做傅里叶逆变换，$\\mathcal{F}\_t(\\boldsymbol{\\omega})$自然变回$p\_t(\\boldsymbol{x}\_t)$，$\\mathcal{F}\_0(\\boldsymbol{\\omega})$变回$p\_0(\\boldsymbol{x}\_0)$，$\\exp\\left(-\\frac{1}{2}\\sigma\_t^2 \\boldsymbol{\\omega}^2\\right)$则对应正态分布$\\mathcal{N}(\\boldsymbol{x}\_t; \\boldsymbol{0}, \\sigma\_t^2 \\boldsymbol{I})$，最后利用傅里叶变换的卷积性质，就得到解$\\eqref{eq:heat-sol}$。

## 完成设计 [\#](https://kexue.fm/kexue.fm\#%E5%AE%8C%E6%88%90%E8%AE%BE%E8%AE%A1)

现在我们汇总一下我们的结果：通过求解热传导方程，我们确定了
\\begin{equation}p\_t(\\boldsymbol{x}\_t) = \\int \\mathcal{N}(\\boldsymbol{x}\_t; \\boldsymbol{x}\_0, \\sigma\_t^2 \\boldsymbol{I})\\, p\_0(\\boldsymbol{x}\_0) d \\boldsymbol{x}\_0 \\label{eq:heat-sol-2}\\end{equation}
此时对应的微分方程
\\begin{equation}\\frac{d\\boldsymbol{x}\_t}{dt}=-\\dot{\\sigma}\_t \\sigma\_t \\nabla\_{\\boldsymbol{x}\_t}\\log p\_t(\\boldsymbol{x}\_t)\\end{equation}
给出了从$p\_0(\\boldsymbol{x}\_0)$到$p\_T(\\boldsymbol{x}\_T)$的一个确定性变换。如果$p\_T(\\boldsymbol{x}\_T)$易于采样，并且$\\nabla\_{\\boldsymbol{x}\_t}\\log p\_t(\\boldsymbol{x}\_t)$已知，那么我们就可以随机采样$\\boldsymbol{x}\_T\\sim p\_T(\\boldsymbol{x}\_T)$，然后逆向求解该微分方程，来生成$\\boldsymbol{x}\_0\\sim p\_0(\\boldsymbol{x}\_0)$的样本。

第一个问题，什么时候$p\_T(\\boldsymbol{x}\_T)$是易于采样的？根据结果$\\eqref{eq:heat-sol-2}$，我们知道
\\begin{equation}\\boldsymbol{x}\_T\\sim p\_T(\\boldsymbol{x}\_T) \\quad\\Leftrightarrow\\quad \\boldsymbol{x}\_T = \\boldsymbol{x}\_0 + \\sigma\_T \\boldsymbol{\\varepsilon},\\,\\,\\, \\boldsymbol{x}\_0\\sim p\_0(\\boldsymbol{x}\_0),\\,\\boldsymbol{\\varepsilon}\\sim \\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})\\end{equation}
当$\\sigma\_T$足够大时，$\\boldsymbol{x}\_0$对$\\boldsymbol{x}\_T$的影响就很微弱了，此时可以认为
\\begin{equation}\\boldsymbol{x}\_T\\sim p\_T(\\boldsymbol{x}\_T) \\quad\\Leftrightarrow\\quad \\boldsymbol{x}\_T = \\sigma\_T \\boldsymbol{\\varepsilon},\\,\\,\\,\\boldsymbol{\\varepsilon}\\sim \\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})\\end{equation}
这就实现了$p\_T(\\boldsymbol{x}\_T)$易于采样的目的。因此，选择$\\sigma\_t$的一般要求是：满足$\\sigma\_0 = 0$和$\\sigma\_T \\gg 1$的光滑单调递增函数。

第二个问题，就是如何计算$\\nabla\_{\\boldsymbol{x}\_t}\\log p\_t(\\boldsymbol{x}\_t)$？这其实跟 [《生成扩散模型漫谈（五）：一般框架之SDE篇》](https://kexue.fm/archives/9209#%E5%BE%97%E5%88%86%E5%8C%B9%E9%85%8D) 中的“得分匹配”一节是一样的，我们用一个神经网络$\\boldsymbol{s}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)$去拟合它，训练目标是
\\begin{equation}\\mathbb{E}\_{\\boldsymbol{x}\_0,\\boldsymbol{x}\_t \\sim \\mathcal{N}(\\boldsymbol{x}\_t; \\boldsymbol{x}\_0, \\sigma\_t^2 \\boldsymbol{I})p\_0(\\boldsymbol{x}\_0)}\\left\[\\left\\Vert \\boldsymbol{s}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t) - \\nabla\_{\\boldsymbol{x}\_t} \\log \\mathcal{N}(\\boldsymbol{x}\_t; \\boldsymbol{x}\_0, \\sigma\_t^2 \\boldsymbol{I})\\right\\Vert^2\\right\]
\\end{equation}
这叫做“条件得分匹配”，其推导我们在SDE篇已经给出了，这里就不重复了。

## 文章小结 [\#](https://kexue.fm/kexue.fm\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

在这篇文章中，我们对ODE式扩散模型做了一个“自上而下”的推导：首先从ODE出发，结合雅可比行列式得到了概率变化的一阶近似，然后对比直接泰勒展开的一阶近似，得到了ODE应该要满足的方程，继而转化为扩散方程、热传导方程来求解。相对来说，整个过程比较一步到位，不需要通过SDE、FP方程等结果来做过渡。

_**转载到请包括本文地址：** [https://kexue.fm/archives/9280](https://kexue.fm/archives/9280)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Sep. 28, 2022). 《生成扩散模型漫谈（十二）：“硬刚”扩散ODE 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/9280](https://kexue.fm/archives/9280)

@online{kexuefm-9280,
        title={生成扩散模型漫谈（十二）：“硬刚”扩散ODE},
        author={苏剑林},
        year={2022},
        month={Sep},
        url={\\url{https://kexue.fm/archives/9280}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics), [信息时代](https://kexue.fm/category/Big-Data)    标签： [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/), [生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/), [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/)[44 评论](https://kexue.fm/archives/9280#comments)

< [生成扩散模型漫谈（十一）：统一扩散模型（应用篇）](https://kexue.fm/archives/9271) \| [“十字架”组合计数问题浅试](https://kexue.fm/archives/9291) >

### 你也许还对下面的内容感兴趣

- [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111)
- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958)
- [Transformer升级之路：20、MLA好在哪里?（上）](https://kexue.fm/archives/10907)
- [生成扩散模型漫谈（二十九）：用DDPM来离散编码](https://kexue.fm/archives/10711)
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633)
- [生成扩散模型漫谈（二十七）：将步长作为条件输入](https://kexue.fm/archives/10617)
- [生成扩散模型漫谈（二十六）：基于恒等式的蒸馏（下）](https://kexue.fm/archives/10567)
- [VQ的又一技巧：给编码表加一个线性变换](https://kexue.fm/archives/10519)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

1. [«](https://kexue.fm/archives/9280/comment-page-1#comments)
2. [1](https://kexue.fm/archives/9280/comment-page-1#comments)
3. [2](https://kexue.fm/archives/9280/comment-page-2#comments)

0r0k

July 26th, 2023

请问式(8)到式(9)是怎么推导的? 对数是怎么消掉的?

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=22348#respond-post-9280)

[苏剑林](https://kexue.fm) 发表于
July 27th, 2023

直接链式法则计算

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=22359#respond-post-9280)

Ran

September 3rd, 2023

方程(9)形式有点像物理学中的流守恒方程。那么是不是可以借助物理中的“特殊流”，然后写出ODE方程，根据ODE写出离散的采样形式，构建扩散模型。

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=22631#respond-post-9280)

Ran 发表于
September 3rd, 2023

好像了解了，这里的守恒流是概率$p\_t(x\_t)$，由于ODE是连续的，因此随着时间演化，概率演化满足连续性方程。

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=22632#respond-post-9280)

[苏剑林](https://kexue.fm) 发表于
September 6th, 2023

就是守恒流（连续性方程）/不过这里的目的就是推导这个方程跟ODE的对应关系，而不是直接利用连续性方恒。

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=22644#respond-post-9280)

[生成扩散模型漫谈（二十一）：中值定理加速ODE采样 R11; AI 資訊](https://news.aitime.space/2023/12/74497/)

December 7th, 2023

\[...\]本文我们聚焦于ODE。在本系列的（六）、（十二）、（十四）、（十五）、（十七）等博客中，我们已经推导过ODE与扩散模型的联系，本文则对扩散ODE的采样加速做简单介绍，并重点介绍一种巧妙地利用“中值定理”思想的新颖采样加速方案“AMED”。\[...\]

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=23225#respond-post-9280)

n n n

December 9th, 2023

苏神，想请教一下式（3）的第一个等号为什么成立

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=23243#respond-post-9280)

Collins Hu 发表于
March 19th, 2025

$x\_t$到$x\_{t+\\mathrm{d}t}$是确定性变换，所以$t$时刻在$x\_t$处的概率$p\_t(x\_t)\\mathrm{d}x\_t$会完整转移到$t+\\mathrm{d}t$时刻在$x\_{t+\\mathrm{d}t}$处的概率$p\_{t+\\mathrm{d}t}(x\_{t+\\mathrm{d}t})\\mathrm{d}x\_{t+\\mathrm{d}t}$，然后$\\mathrm{d}x\_t$和$\\mathrm{d}x\_{t+\\mathrm{d}t}$之间会有一个“尺度”变化，用变换的雅可比行列式来表示这种变化

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=27167#respond-post-9280)

yellow006

May 26th, 2024

苏老师您好，我拜读了您的几篇博客，但我水平有限还是看得一知半解，关于公式(17)，我的理解是在前向扩散/反向生成过程中都隐含了这个常微分方程，这个常微分方程揭示了前向/反向过程中的每一步是怎么变化的，这样的理解正确吗？
而且当这篇文章的内容和DDIM联系起来的时候我有一些困惑，对于DDIM这种$\\sigma\_t=0$的反向过程，同样也满足公式(17)吗？

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=24437#respond-post-9280)

yellow006 发表于
May 29th, 2024

我好像明白了，本文的前向过程和DDPM/DDIM的前向过程表述有一些区别，本文采用的是VE-SDE，而DDIM/DDPM采用的是VP-SDE，本质上它们是等价的，本文指代的$\\sigma\_t$实质上在DDIM的视角看是一个关于$\\overline{\\alpha\_t}$的函数，和DDIM中的$\\sigma\_t$没有关系

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=24449#respond-post-9280)

[苏剑林](https://kexue.fm) 发表于
May 29th, 2024

DDIM是采样方差为0，这里的$\\sigma\_t^2$不是采样方差，是$p(\\boldsymbol{x}\_t\|\\boldsymbol{x}\_0)$的方差。

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=24453#respond-post-9280)

月夜

July 9th, 2024

（5）式里等式左边是1加上雅可比行列式的迹，是个标量，而右边是函数的导数，那是个向量吧？

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=24727#respond-post-9280)

[苏剑林](https://kexue.fm) 发表于
July 9th, 2024

你说$\\nabla\_{\\boldsymbol{x}\_t}\\cdot \\boldsymbol{f}\_t(\\boldsymbol{x}\_t)$？这个的意思是梯度算子跟函数向量做内积，结果是一个标量。比如
$$\\left(\\frac{\\partial}{\\partial x}, \\frac{\\partial}{\\partial y}\\right)\\cdot\\left(f\_1, f\_2\\right) = \\frac{\\partial f\_1}{\\partial x} + \\frac{\\partial f\_2}{\\partial y}$$

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=24745#respond-post-9280)

月夜 发表于
July 9th, 2024

原来如此，理解了，一直以来都一知半解的。

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=24753#respond-post-9280)

冬瓜大王

July 2nd, 2025

老师您好，我想请教一个关于SDE和ODE的问题：
1）SDE和PF-ODE是一一对应的吗？或者是一对多或者多对一的方式呢？
2）DPM-Solver里面主要是对指数积分项进行一种数学技术上的处理，但是flow matching的ODE没有这种指数积分项。那有没有可能把flow matching的ODE变回SDE，然后从SDE再变到一个带指数积分的ODE，然后就可以使用DPM-Solver的数学手段处理，或者DPM-Solver v3里面的Rosenbrock的指数积分的处理方法。（我觉得这样做是比直接用euler方法要好的，因为指不定能导出一些线性项，这样误差更小了。）

从老师您的推导中我感觉到好像不是唯一的，因为老师您在SDE $\\rightarrow$ ODE是直接假定$\\sigma\_t$，在本节，老师您又是直接构造出一个解$f(x)$

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=28028#respond-post-9280)

[苏剑林](https://kexue.fm) 发表于
July 2nd, 2025

1、本文似乎没有涉及到SDE$\\to$ODE的过程？所以不大理解你关于SDE$\\to$ODE的疑问点。

2、从理论上来说，即便给定每一处$t$的边缘分布$p\_t(\\boldsymbol{x}\_t)$，对应的ODE也未必是唯一的；

3、DPM-Solver我理解是相当于常数变易法？它是把能积分的部分先积分出来，这个只能具体ODE具体分析了我感觉。

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=28041#respond-post-9280)

香蕉大王 发表于
July 3rd, 2025

谢谢老师回复。明白老师您说的了。

我再想请问一个小小的问题：既然ODE未必是唯一的，有没有人尝试去寻找一个比较容易求解的ODE训练模型呢？ODE种类这么多，总一些已经被研究的很透的，比如对于flow matching，有没有可能通过$\\frac{d x\_t}{dt} = v\_\\theta(x\_t, t)$这个找到另外一个更适合求解的ODE呢？（比如把$\\frac{d x\_t}{dt} = v\_\\theta(x\_t, t)$还原回SDE，再通过SDE找一个比较好计算ODE?）不知道这样是不是可行的？或者老师您是否有这方面的文章看过呢？

谢谢老师，打扰老师了

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=28047#respond-post-9280)

香蕉大王 发表于
July 3rd, 2025

还是刚刚flow matching的例子$\\frac{d x\_t}{dt} = v\_\\theta(x\_t, t)$，ODE虽然是足够简单了，但如果真的要用求解器求解，我们需要对右边的整个部分进行积分估计，但如果说能适当的拆分出一部分可精确估计的项，那似乎误差就会少很多。所以如果说能找到一个，在数学上非常适合某种ODE求解器求解的ODE，那这样会不会更好？

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=28048#respond-post-9280)

[苏剑林](https://kexue.fm) 发表于
July 11th, 2025

某种程度上说，reflow ( [https://kexue.fm/archives/9497](https://kexue.fm/archives/9497) ) 给出的ode已经接近最简解，因为它符合最优传输的原则。$\\boldsymbol{v}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t,t)$的复杂度本质上取决于初始分布和目标分布的差异程度。至于你说的将$\\boldsymbol{v}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t,t)$分离出部分可以解析求解的项，这是有机会的，这篇文章 https://arxiv.org/abs/2506.15864 提供了一些通用思路，但更一般的我认为只能具体ode具体分析。

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=28070#respond-post-9280)

榴莲大王 发表于
July 23rd, 2025

谢谢老师回复，看明白了，感谢感谢

[回复评论](https://kexue.fm/archives/9280/comment-page-2?replyTo=28232#respond-post-9280)

1. [«](https://kexue.fm/archives/9280/comment-page-1#comments)
2. [1](https://kexue.fm/archives/9280/comment-page-1#comments)
3. [2](https://kexue.fm/archives/9280/comment-page-2#comments)

[取消回复](https://kexue.fm/archives/9280#respond-post-9280)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[微分方程](https://kexue.fm/kexue.fm#%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B)
[雅可比行列式](https://kexue.fm/kexue.fm#%E9%9B%85%E5%8F%AF%E6%AF%94%E8%A1%8C%E5%88%97%E5%BC%8F)
[泰勒近似](https://kexue.fm/kexue.fm#%E6%B3%B0%E5%8B%92%E8%BF%91%E4%BC%BC)
[热传导方程](https://kexue.fm/kexue.fm#%E7%83%AD%E4%BC%A0%E5%AF%BC%E6%96%B9%E7%A8%8B)
[求解分布](https://kexue.fm/kexue.fm#%E6%B1%82%E8%A7%A3%E5%88%86%E5%B8%83)
[完成设计](https://kexue.fm/kexue.fm#%E5%AE%8C%E6%88%90%E8%AE%BE%E8%AE%A1)
[文章小结](https://kexue.fm/kexue.fm#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [HSIC简介：一个有意思的判断相关性的思路](https://kexue.fm/archives/6910)
- [当BERT-whitening引入超参数：总有一款适合你](https://kexue.fm/archives/9079)
- [第四波：2^29360741-1不是素数！](https://kexue.fm/archives/1970)
- [祝大家新春愉快！虎年飞跃！](https://kexue.fm/archives/436)
- [Linux下的误删大坑与简单的恢复技巧](https://kexue.fm/archives/4491)
- [为什么梯度裁剪能加速训练过程？一个简明的分析](https://kexue.fm/archives/7469)
- [Tiger：一个“抠”到极致的优化器](https://kexue.fm/archives/9512)
- [2019年全年天象](https://kexue.fm/archives/6257)
- [那个屠榜的T5模型，现在可以在中文上玩玩了](https://kexue.fm/archives/7867)
- [从语言模型到Seq2Seq：Transformer如戏，全靠Mask](https://kexue.fm/archives/6933)

### 最近评论

- [gapeng](https://kexue.fm/archives/11267/comment-page-1#comment-28531): kimi k2形式上推导了一个公式，最后数值模拟在0.23左右。偏离$\\beta\_1=0.9,...
- [Evan1024](https://kexue.fm/archives/11267/comment-page-1#comment-28530): 太牛了！
- [ameowcat](https://kexue.fm/archives/10958/comment-page-3#comment-28529): 苏神您好，有个问题想请教一下，最近扩散模型的推理优化有一篇文章也是使用ode：https://...
- [Eliot](https://kexue.fm/archives/10815/comment-page-1#comment-28528): 2 实现loss-free with budget应当是在当前Megatron-LM基础上应当...
- [Eliot](https://kexue.fm/archives/10815/comment-page-1#comment-28527): 继续阅读这2份代码后，大概结论如下
1 megatron-lm应当只实现了经典的loss-fr...
- [lzyyzl](https://kexue.fm/archives/11025/comment-page-1#comment-28525): 帮忙解惑一下
1 文中提到本文主题是求O=msign(M)的导数。将∇ML表示为∇OL的函数也...
- [z](https://kexue.fm/archives/11267/comment-page-1#comment-28524): 牛
- [Gusto](https://kexue.fm/archives/10739/comment-page-2#comment-28523): 按照个人理解将weight decay理解为损失函数中的惩罚项的话，为什么weight dec...
- [hazdzz](https://kexue.fm/archives/11196/comment-page-1#comment-28522): 非常感谢您提到 pbSGD，这启发了我的毕业论文！
- [苏剑林](https://kexue.fm/content.html/comment-page-1#comment-28521): 你是指xml代码？那不是乱码，feed就是xml格式，你要自己找工具订阅。

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [Zhang's blog](https://armcvai.cn/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。