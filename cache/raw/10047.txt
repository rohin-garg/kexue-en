## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [从无穷范数求导到等值振荡定理](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)
- [Transformer升级之路：1...](https://kexue.fm/archives/10862)
- [矩阵的有效秩（Effective ...](https://kexue.fm/archives/10847)

## COMMENTS

- [OceanYU: 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）...](https://kexue.fm/archives/9164/comment-page-4#comment-27801)
- [jorjiang: 训练和prefill这个compute-bound阶段不做矩阵...](https://kexue.fm/archives/10907/comment-page-2#comment-27800)
- [amy: 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工...](https://kexue.fm/archives/10907/comment-page-2#comment-27799)
- [jiurizz: 在2\*shared experts + 160\*routed ...](https://kexue.fm/archives/10945/comment-page-1#comment-27798)
- [开水: 感谢苏老师回复，论文appendix里面写了实验是load b...](https://kexue.fm/archives/10945/comment-page-1#comment-27797)
- [苏剑林: 欢迎作者，这篇文章确实在收藏夹了，结果还没来得及看，抱歉哈，马...](https://kexue.fm/archives/10958/comment-page-1#comment-27796)
- [苏剑林: “将存储kv cache改为存储降维后的Embedding X...](https://kexue.fm/archives/10907/comment-page-2#comment-27795)
- [苏剑林: 呃，是这样的，Moonlight-16B-A3B实际上对应的是...](https://kexue.fm/archives/10945/comment-page-1#comment-27794)
- [Jiaming Song: 推销一下我们前一段时间的工作，这个其实已经达到了你说的三个标准...](https://kexue.fm/archives/10958/comment-page-1#comment-27793)
- [ZhouTimeMachine: 感谢您的回复！这么一看，我才注意到能从 $p(x\_0)$ 变换...](https://kexue.fm/archives/9497/comment-page-2#comment-27792)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 生成扩散模型漫谈（二十二）：信噪比与大图生成（上）

8Apr

# [生成扩散模型漫谈（二十二）：信噪比与大图生成（上）](https://kexue.fm/archives/10047)

By 苏剑林 \|
2024-04-08 \|
66068位读者\|

盘点主流的图像扩散模型作品，我们会发现一个特点：当前多数做高分辨率图像生成（下面简称“大图生成”）的工作，都是先通过Encoder变换到Latent空间进行的（即LDM， [Latent Diffusion Model](https://papers.cool/arxiv/2112.10752)），直接在原始Pixel空间训练的扩散模型，大多数分辨率都不超过64\*64，而恰好，LDM通过AutoEncoder变换后的Latent，大小通常也不超过64\*64。这就自然引出了一系列问题：扩散模型是不是对于高分辨率生成存在固有困难？能否在Pixel空间直接生成高分辨率图像？

论文 [《Simple diffusion: End-to-end diffusion for high resolution images》](https://papers.cool/arxiv/2301.11093) 尝试回答了这个问题，它通过“信噪比”分析了大图生成的困难，并以此来优化noise schdule，同时提出只需在最低分辨率feature上对架构进行scale up、多尺度Loss等技巧来保证训练效率和效果，这些改动使得原论文成功在Pixel空间上训练了分辨率高达1024\*1024的图像扩散模型。

## LDM回顾 [\#](https://kexue.fm/archives/10047\#LDM%E5%9B%9E%E9%A1%BE)

在进入正题之前，我们不妨先反过来想一想：为什么LDM能成功成为主流的扩散模型做法？笔者认为，主要原始是两方面：

> 1、不管是应用还是学术，用LDM的主要原因想必是效率：当前主流的工作都直接重用了LDM论文所开源的训练好的AutoEncoder，它的Encoder部分会将512\*512的图像变成了64\*64的Latent，相当于说只用到64\*64分辨率这个级别的算力和时间，就可以生成512\*512的图像，这个效率显然是非常吸引人的；
>
> 2、LDM契合了FID这个指标，这让它看起来是效果无损的：FID全称是“Fréchet Inception Distance”，其中Inception是指用ImageNet预训练的InceptionV3模型作为Encoder编码图片，然后假设编码特征服从高斯分布来算$\\mathcal{W}$距离，而LDM也是先Encoder编码，两个Encoder虽然不完全相同，但也有一定共性，因此在FID上表现为几乎无损。

我们还可以稍微展开一下。LDM的AutoEncoder在训练阶段组合了很多内容——它的重构Loss并不只有常规的MAE或者MSE，还包括对抗Loss和Perceptual Loss，对抗Loss用来保证重构结果的清晰度，而Perceptual Loss用来保证重构结果的语义和风格的相似性。 [Perceptual Loss](https://papers.cool/arxiv/1603.08155) 跟FID很相似，都是用ImageNet模型的特征计算的相似性指标，只不过用的不是InceptionV3而是VGG-16，由于训练任务的相似性，可以猜测两者特征有很多共性，因此Perceptual Loss的加入变相地保证了FID的损失尽可能少。

此外，LDM的Encoder对原始图像来说是降维的，比如原始图像大小为512\*512\*3，直接patchify的话结果是64\*64\*192，但LDM的Encoder出来的特征是64\*64\*4，降低到了1/48，同时为了进一步降低编码特征的方差，避免模型“死记硬背”，LDM还对Encoder出来的特征加了相应的正则项，可选的有 [VAE](https://kexue.fm/archives/5253) 的KL散度项或 [VQ-VAE](https://kexue.fm/archives/6760) 的VQ正则化。降维和正则的设计，都会压缩特征的多样性，提高特征的泛化能力，但也会导致重构难度增加，最终导致了有损的重构结果。

到这里，LDM能成功的原因其实就“豁然开朗”了：“降维 + 正则”的组合，降低了Latent的信息量，从而降低了在Latent空间学习扩散模型的难度，同时Perceptual Loss的存在，保证了重构虽然有损但FID几乎无损（Perceptual Loss的Encoder跟FID一样都用InceptionV3理论上更好）。这样一来，对于FID这个指标来说，LDM几乎就是免费午餐了，因此不管是学术和工程都乐意沿用它。

## 信噪之比 [\#](https://kexue.fm/archives/10047\#%E4%BF%A1%E5%99%AA%E4%B9%8B%E6%AF%94)

尽管LDM简单高效，但它毕竟是有损的，其Latent只能保持宏观上的语义，局部细节可能会严重缺失。而在之前的文章 [《“闭门造车”之多模态思路浅谈（一）：无损输入》](https://kexue.fm/archives/9984) 中，笔者表达过一个观点：当作为输入时，图像最好的表示方式就是原始Pixel数组。基于这个观点，笔者最近都比较关注直接在Pixel空间上训练的扩散模型。

然而，将低分辨率（比如64\*64）图像的扩散模型配置直接应用于高分辨率（比如512\*512）的大图生成时，会存在算力消耗过大、收敛速度太慢等问题，而且效果上也比不上LDM（至少FID指标如此），Simple diffusion逐一分析了这些问题并提出了相应的解决方案。其中，笔者认为利用“信噪比（Signal-to-Noise Ratio，SNR）”的概念来分析高分辨率扩散模型的学习效率低问题最为精彩。

具体来说，Simple diffusion观察到，如果我们给高分辨率图像加上某个方差的noise，那么相对于加上同样方差的noise的低分辨率图像来说，它的信噪比其实更高，原论文的Figure 3非常直观地演示了这一点，如下图所示。第一行图片，是由512\*512的图片加了特定方差的noise后再降采样（平均Pooling）到64\*64的，而第二行则是直接在64\*64的图片加上同样方差的noise，很明显第一行的图片更加清晰，也就是相对信噪比更高了。

同一noise不同分辨率的信噪比

所谓“信噪比”，顾名思义即“信号与噪声的强度之比”，信噪比更高（即噪声的占比更低）意味着去噪更容易，换言之训练阶段Denoiser面对的更多是简单样本，但实际上大图生成的难度显然更高，也就是说我们的目标是一个更难的模型，但却给了更简单的样本，因此导致了学习效率的低下。

## 向低看齐 [\#](https://kexue.fm/archives/10047\#%E5%90%91%E4%BD%8E%E7%9C%8B%E9%BD%90)

我们也可以从数学上描述这一点。沿用本系列的记号，通过加噪来构造$\\boldsymbol{x}\_t$的运算可以表示为
\\begin{equation}\\boldsymbol{x}\_t = \\bar{\\alpha}\_t \\boldsymbol{x}\_0 + \\bar{\\beta}\_t \\boldsymbol{\\varepsilon},\\quad \\boldsymbol{\\varepsilon}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})\\end{equation}
其中$\\bar{\\alpha}\_t,\\bar{\\beta}\_t$就称为noise schedule，满足$\\bar{\\alpha}\_0=\\bar{\\beta}\_T=1, \\bar{\\alpha}\_T=\\bar{\\beta}\_0=0$，此外一般来说它们还有额外的约束，比如在DDPM中通常是$\\bar{\\alpha}\_t^2 + \\bar{\\beta}\_t^2=1$，本文将沿用这个约束。

对于一个随机变量来说，信噪比是均值平方与方差之比。给定$\\boldsymbol{x}\_0$，$\\boldsymbol{x}\_t$的均值显然是$\\bar{\\alpha}\_t \\mathbb{E}\[\\boldsymbol{x}\_0\]$，方差则是$\\bar{\\beta}\_t^2$，于是信噪比为$\\frac{\\bar{\\alpha}\_t^2}{\\bar{\\beta}\_t^2}\\mathbb{E}\[\\boldsymbol{x}\_0\]^2$，由于我们总是在给定$\\boldsymbol{x}\_0$下讨论，因此我们也可以简单地说信噪比就是$SNR(t) = \\frac{\\bar{\\alpha}\_t^2}{\\bar{\\beta}\_t^2}$

当我们对$\\boldsymbol{x}\_t$使用$s\\times s$大小的平均Pooling时，每个$s\\times s$的patch通过取平均变成了一个标量，即
\\begin{equation}\\frac{1}{s^2}\\sum\_{i=1}^s \\sum\_{j=1}^s\\boldsymbol{x}\_t^{(i,j)} = \\bar{\\alpha}\_t\\left(\\frac{1}{s^2}\\sum\_{i=1}^s \\sum\_{j=1}^s \\boldsymbol{x}\_0^{(i,j)}\\right) + \\bar{\\beta}\_t\\left(\\frac{1}{s^2}\\sum\_{i=1}^s \\sum\_{j=1}^s \\boldsymbol{\\varepsilon}^{(i,j)}\\right) ,\\quad \\boldsymbol{\\varepsilon}^{(i,j)}\\sim\\mathcal{N}(0, 1)\\end{equation}
平均Pooling不改变均值，但会降低方差，从而提高信噪比，这是因为正态分布的可加性得出
\\begin{equation}\\frac{1}{s^2}\\sum\_{i=1}^s \\sum\_{j=1}^s \\boldsymbol{\\varepsilon}^{(i,j)}\\sim\\mathcal{N}(0, 1/s^2)\\end{equation}
所以在同一noise schedule下，如果我们将高分辨率图像通过平均Pooling来对齐低分辨率，那么就会发现信噪比更高，是原来的$s^2$倍：
\\begin{equation}SNR^{w\\times h\\to w/s\\times h/s}(t) = SNR^{w/s\\times h/s}(t) \\times s^2 \\end{equation}
反过来想，如果我们已经有一个在低分辨率图像上调好了的noise schedule $\\bar{\\alpha}\_t^{w/s\\times h/s},\\bar{\\beta}\_t^{w/s\\times h/s}$，那么当我们想要scale up到更高分辨率时，应该要调整noise schedule为$\\bar{\\alpha}\_t^{w\\times h},\\bar{\\beta}\_t^{w\\times h}$，使得它降采样到低分辨率后，其信噪比能够跟已经调好的低分辨率的noise schedule对齐，这样才能最大程度上“传承”已经低分辨率扩散模型的学习效率，即
\\begin{equation} \\frac{(\\bar{\\alpha}\_t^{w\\times h})^2}{(\\bar{\\beta}\_t^{w\\times h})^2} \\times s^2 = \\frac{(\\bar{\\alpha}\_t^{w/s\\times h/s})^2}{(\\bar{\\beta}\_t^{w/s\\times h/s})^2} \\end{equation}
如果加上约束$\\bar{\\alpha}\_t^2 + \\bar{\\beta}\_t^2=1$，那么就可以从$\\bar{\\alpha}\_t^{w/s\\times h/s},\\bar{\\beta}\_t^{w/s\\times h/s}$中唯一地解出$\\bar{\\alpha}\_t^{w\\times h},\\bar{\\beta}\_t^{w\\times h}$。这就解决了高分辨率扩散的noise schedule设置问题。

## 架构拓展 [\#](https://kexue.fm/archives/10047\#%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95)

为了做好大图的扩散生成，除了要调整noise schedule之外，我们还需要把架构也scale up上去，因为前面我们也已经说了，大图生成是一个更难的问题，因此理应需要更加重量级的架构。

扩散模型常用的就是 [U-Net](https://papers.cool/arxiv/1505.04597) 或者 [U-Vit](https://papers.cool/arxiv/2209.12152)，两者都是先逐渐降采样然后逐渐上采样，比如512\*512的输入，一般先进行一个block的运算，然后降采样到256\*256，接着进行新一个block的运算，在降采样到128\*128，依此类推，降采样到一个最低的分辨率16\*16，接下来再次重复这个过程，但将降采样改为上采样，直到分辨率恢复512\*512。默认设置下，我们会将参数平均分到每一个block中，但这样一来靠近输入和输出的block由于输入尺寸都很大，因此计算量会急剧增加，导致模型训练效率低下甚至不可行。

Simple diffusion提出了两个应对方案。第一，它提出可以直接在第一层（而不是第一个block，每个block有多个层）之后就降采样，并且考虑一步到位低降到128\*128甚至64\*64，最后输出的时候，也是在最后一层之前才从64\*64或者128\*128直接上采样到512\*512，这样模型的大部分block所处理的分辨率都降低了，从而降低了整体计算量；第二，它提出将模型所scale up的层都放到最低分辨率（即16\*16）之后，而不是平摊到每一个分辨率的block，即新增的层处理的都是16\*16的输入，包括Dropout也都只加入到低分辨率的层中，这样一来分辨率增加带来的计算压力就明显减少了。

此外，为了进一步稳定训练，论文提出了“多尺度Loss”的训练目标。默认情况下，扩散模型的Loss等价于MSE损失
\\begin{equation}\\mathcal{L}=\\frac{1}{wh}\\Vert \\boldsymbol{\\varepsilon} - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\bar{\\alpha}\_t \\boldsymbol{x}\_0 + \\bar{\\beta}\_t \\boldsymbol{\\varepsilon}, t)\\Vert^2\\end{equation}
Simple diffusion将它泛化为
\\begin{equation}\\mathcal{L}\_{s\\times s} = \\frac{1}{(w/s)(h/s)}\\big\\Vert \\mathcal{D}\_{w/s\\times h/s}\[\\boldsymbol{\\varepsilon}\] - \\mathcal{D}\_{w/s\\times h/s}\[\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\bar{\\alpha}\_t \\boldsymbol{x}\_0 + \\bar{\\beta}\_t \\boldsymbol{\\varepsilon}, t)\]\\big\\Vert^2\\end{equation}
其中$\\mathcal{D}\_{w/s\\times h/s}\[\\cdot\]$是通过平均Pooling将输入变换到$w/s\\times h/s$的下采样算子，原论文取了多个$s$对应的Loss进行平均，作为最终的训练目标。这个多尺度Loss的目标也很明显，跟通过信噪比对齐来调整noise schedule一样，都是保证训练出来的高分辨率扩散模型至少不差于直接训练的低分辨率模型。

至于实验部分，大家自行看原论文就好。Simple diffusion实验的最大分辨率是1024\*1024（在附录中提到），效果都尚可，并且对比实验表明上述提出的一些技巧都是有提升的，最终直接在Pixel空间中训练出来的扩撒模型，相比LDM也取得了有竞争力的效果。

## 文章小结 [\#](https://kexue.fm/archives/10047\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

在这篇文章中，我们介绍了Simple diffusion，这是一篇探索如何直接在Pixel空间中端到端地训练图像扩散模型的工作，利用了信噪比的概念介绍了高分辨率扩散模型的训练效率低问题，并由此来指标调整新的noise schedule，以及探索了如何尽可能节约算力成本地scale up模型架构。

_**转载到请包括本文地址：** [https://kexue.fm/archives/10047](https://kexue.fm/archives/10047)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/10047#share)/ [打赏](https://kexue.fm/archives/10047#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Apr. 08, 2024). 《生成扩散模型漫谈（二十二）：信噪比与大图生成（上） 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/10047](https://kexue.fm/archives/10047)

@online{kexuefm-10047,
        title={生成扩散模型漫谈（二十二）：信噪比与大图生成（上）},
        author={苏剑林},
        year={2024},
        month={Apr},
        url={\\url{https://kexue.fm/archives/10047}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [损失函数](https://kexue.fm/tag/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/), [生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/), [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/), [信噪比](https://kexue.fm/tag/%E4%BF%A1%E5%99%AA%E6%AF%94/)[33 评论](https://kexue.fm/archives/10047#comments)

< [Transformer升级之路：17、多模态位置编码的简单思考](https://kexue.fm/archives/10040) \| [生成扩散模型漫谈（二十三）：信噪比与大图生成（下）](https://kexue.fm/archives/10055) >

### 你也许还对下面的内容感兴趣

- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958)
- [Transformer升级之路：20、MLA究竟好在哪里？](https://kexue.fm/archives/10907)
- [MoE环游记：3、换个思路来分配](https://kexue.fm/archives/10757)
- [MoE环游记：2、不患寡而患不均](https://kexue.fm/archives/10735)
- [生成扩散模型漫谈（二十九）：用DDPM来离散编码](https://kexue.fm/archives/10711)
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633)
- [生成扩散模型漫谈（二十七）：将步长作为条件输入](https://kexue.fm/archives/10617)
- [生成扩散模型漫谈（二十六）：基于恒等式的蒸馏（下）](https://kexue.fm/archives/10567)
- [VQ的又一技巧：给编码表加一个线性变换](https://kexue.fm/archives/10519)

[发表你的看法](https://kexue.fm/archives/10047#comment_form)

李

April 8th, 2024

最近看到一个改进LDM的工作，好像实现了无条件的2048\*1024的图片生成.效果看着还不错，苏神怎么看。 https://arxiv.org/abs/2403.12915

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24091#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 9th, 2024

看上去是通过架构上的优化来实现的，金字塔特征的做法也算比较常规了，个人暂时不大关注架构细节上的调优。

另外跟本篇方法并不矛盾。因为LDM往上做的话，即便encoder之后的特征图，也可能会有512\*512这个级别。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24104#respond-post-10047)

Muon

April 8th, 2024

苏神,对于flow模型来说，是不是就不存在scheduler的问题，理论上各种分辨率都能统一

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24092#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 9th, 2024

flow模型本身就没有noise schedule，所以不存在这个问题，但normalizing flow模型目前属于效果最差的生成模型之一。。。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24105#respond-post-10047)

Muon 发表于
April 12th, 2024

continuous normalizing flow效果很好的，SD3就用了rectified flow

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24121#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 13th, 2024

rectified flow不算normalizing flow吧？要不然扩散模型也算是normalizing flow了。

我理解的normalizing flow，是构建一个可逆模型，算出它的雅可比行列式，然后利用最大似然作为目标函数去训练的，并不是只要可逆就算normalizing flow了。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24133#respond-post-10047)

suco 发表于
April 15th, 2024

那么rectified flow会不会有这个问题呢？

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24143#respond-post-10047)

suco 发表于
April 15th, 2024

推了一下公式，好像降采样到低分辨率后信噪比依旧是变成原本的$s^2$倍

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24144#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 18th, 2024

本文的设定是$\\boldsymbol{x}\_t = \\bar{\\alpha}\_t \\boldsymbol{x}\_0 + \\bar{\\beta}\_t \\boldsymbol{\\varepsilon},\\quad \\boldsymbol{\\varepsilon}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})$，reflow也是这个形式，自然也有这个问题

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24168#respond-post-10047)

Pango 发表于
May 21st, 2024

苏神，请问高分辨率SNR对齐低分辨率，输入给网络的$t$是不变的，只改变$\\alpha\_t$和$\\beta\_t$吗？

[苏剑林](https://kexue.fm) 发表于
May 24th, 2024

是的

[王磊](https://wangleiphy.github.io/) 发表于
April 27th, 2024

如果把模型架构和训练方式分开考虑的话，rectified flow是一种特定的训练continuous normalizing flow的方式。它抛弃了最大似然估计，而利用（从扩散模型和得分匹配那里学来的）flow matching的方式训练flow。

所以，在我心目中只要可逆就算flow，扩散模型也算flow的一种。当然，它们更广义的定义也许是基于输运（transportation）的生成模型。这样一来，当下好用的生成模型就两类：基于输运的和基于自回归的。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24213#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
May 1st, 2024

如果GAN的生成器取输入输出维度一致呢？虽然没有理论保证用这样用GAN训练出来的生成器可逆，但从数值计算的概率来讲，数学上严格不可逆的概率几乎为0（比如对于线性变换，不可逆意味着行列式为0，而行列式精确等于0的概率显然是非常小的）

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24234#respond-post-10047)

ftg3257

April 11th, 2024

苏神，之前有论文提出了HDiT架构，能直接在1024×1024的Pixel Space训练。https://arxiv.org/abs/2401.11605

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24116#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 12th, 2024

感谢分享，我读了之后再来交流。

确实，本文所介绍的论文已经是去年初的工作了，对于瞬息万变的AI领域来说算是很老了，只不过感觉里边的分析还是很有借鉴意义的，所以拿来学习一下。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24130#respond-post-10047)

Andy27

April 12th, 2024

苏神你好，我本人也很关注pixel space的diffusion。结合你上篇文章我觉得你说的很对 latent这种方式局限很多，需要一个task specific的metric来指导压缩。个人也觉得长期以来不可取。而且本身这种架构对于一些应用就很局限。
关于你提到的高分辨率生成，还有一篇on the importance of noise scheduling for diffusion models里面也提到了noise schedule的问题，表达的意思是一样的，但他的处理稍微有点不一样。希望听听你的想法。另外 他提到了RIN这个结构，感觉没多少人follow 但我也觉得挺有意思的，可以在forward过程中使用一个固定长度token的数量来减少计算量。因为作者认为分辨率虽然大了 但信息量可以仍然是一定的。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24120#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 12th, 2024

谢谢认可和推荐。

on the importance of noise scheduling for diffusion models 感觉偏向于实验了，不过结论应该差不多；RIN我稍微扫了一下，感觉它能节省计算量的本质原因是训练阶段强行截断了递归的梯度（没细看，如果错误请指正），这样设计痕迹太严重，并且让人怀疑它是否scaleable～

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24132#respond-post-10047)

qwe021575566

April 13th, 2024

苏神好，感謝您的分享。
想請問LDM關於KL-reg和VQ-reg，原論文在附錄G.中提到:
(ii) For a VQ-regularized latent space, we extract z before the quantization layer
and absorb the quantization operation into the decoder, i.e. it can be interpreted as the first layer of D.
VQ-reg使用Encode後量化前的特徵，相比於KL-reg的特征分佈，VQ-reg的特徵分佈似乎不是"接近正态分布"，這樣LDM的訓練還行得通嗎? 是否能多分享些有關LDM的細節，感謝。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24136#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 18th, 2024

KL-reg和VQ-reg都是对特征的正则项，目的都是让特征的信息有所损失（信息瓶颈），从而导致有损的重构。在信息瓶颈下迫使模型完成重构，则会让模型学习到更有泛化能力的特征。

关于VQ-reg对特征的有损性，我们可以参考 [https://kexue.fm/archives/9984](https://kexue.fm/archives/9984) 一文对VQ的熵分析。简单来说，对序列严重缩短的特征进行VQ之后，信息会有非常明显的损失，而使用VQ前的特征则好一些，但由于学习过程中VQ前的特征会尽量向VQ后的特征靠齐，所以依然有正则化作用。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24163#respond-post-10047)

dongraemon

April 18th, 2024

sd3(https://arxiv.org/pdf/2403.03206v1.pdf)也给出了类似的观点，即对于高分辨率图需要添加更强的noise。不过他们针对的是多尺度训练的问题

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24158#respond-post-10047)

dongraemon 发表于
April 19th, 2024

实际上sd3似乎是从另一个角度解释了低分辨率训练模型直接生成高分辨率图像存在的gap。根据sd3的观点，是不是《Upsample Guidance: Scale Up Diffusion Models without Training》中高分辨率细节项ϵθ(xt,t)在使用时，也可以对t做一个重新映射

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24181#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
April 25th, 2024

看了看，sd3对$t$所做的调整，貌似都是训练阶段就必须引入的，而不是推理阶段才做的免训练改动？

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24200#respond-post-10047)

JimmySue

April 28th, 2024

苏神，信噪比章节的对比方式感觉不严谨。

高斯分布样本的均值的分布方差是原来的 1/n, 均值 pooling 之后 实际上等效于对于下采样的图片加入 $\\frac{1}{n}\\sigma^2$ n 是pooling 窗口的pixel 个数 的噪声，感觉文章将二者认为同样的噪声水平不妥

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24215#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
May 1st, 2024

没看懂你这里想表达什么。你想表达Pooling之后等效于对低分辨率图加入$\\frac{1}{n}\\sigma^2$方差的噪声？然后呢？哪里不妥？

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24236#respond-post-10047)

JimmySue 发表于
May 6th, 2024

原文论点是：
\> 如果我们给高分辨率图像加上某个方差的noise，那么相对于加上同样方差的noise的低分辨率图像来说，它的信噪比其实更高

而对比的是高分辨率加噪再下采样的结果， 不能说明 高分辨率加噪 和 低分辨率 加噪的信噪比的差异。 毕竟下采样带低通效果，也就是附带了去噪过程。 等效噪声是 1/n 。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24254#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
May 7th, 2024

你的个别字眼我始终没理解想要表达什么（比如最后一句突然出现的“等效噪声是 1/n”）...

总的来说，博客中想要表达的意思是【对于不同分辨率的同一幅图像，如果加上同样强度的高斯噪声，那么高分辨率图像远远看起来会更加清晰】。我不是很理解，你想要强调的是原文的表达不大严谨，还是想要否定这个结论...

如果是前者，可能确实有点不严谨，因为高分辨率图像加上同样噪声模糊的是高分辨率细节，不论一概而论说信噪比更高了，但就本文的主题来说，这样表达也似乎不会引起歧义。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24266#respond-post-10047)

Liam

June 30th, 2024

苏神你好，我想问一下，这个预训练好了的autoencoder可以直接拿来用于其他领域任务吗，比如医学领域，还是说得用医学数据再重新训练比较好？

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24634#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
July 2nd, 2024

一般垂直领域都要微调一下比较好

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24654#respond-post-10047)

Animation

August 6th, 2024

假如使用DDPM T=1000步来训练的话，t=1000时的$\\bar\\alpha\_t$并非0，也就导致信噪比仍然存在。那这时是不是就会导致inference和training的不一致呢？
另外信噪比是不是还可以和预测原图loss及预测噪声loss来建立关系哈

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24956#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
August 7th, 2024

从数值精度的视角来看，其实$\\bar{\\alpha}\_T$跟0没有实质差别了。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24975#respond-post-10047)

Animation 发表于
August 8th, 2024

不过Stable Diffusion里设置的数值还是有差别的，snr在T步并不小，感觉这个还是会有些影响大

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=24988#respond-post-10047)

[苏剑林](https://kexue.fm) 发表于
August 14th, 2024

其实我们也可以认为存在一个绝对等于零的$\\bar{\\alpha}\_t$，只不过既然绝对等于零，也就是没有任何有效输入，那么训练起来就没有意义了，干脆就不训了。这不会影响后面关于采样过程包括相关加速采样方法的推导。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=25016#respond-post-10047)

August 发表于
October 5th, 2024

\\* inference与training是否一致的关键是: P(x\_T)的分布是否是高斯
\\* x\_T\|x\_0信噪比存在 => x\_T/x\_0不是纯噪音 => P(x\_T\|x\_0)不是高斯 ≠> P(x\_T)不是高斯
\\* LDM中,P(x\_0)本身就高斯分布,P(x\_T) = ∫P(x\_T\|x\_0)P(x\_0)d(x\_0)基本上就是纯高斯了。

[回复评论](https://kexue.fm/archives/10047/comment-page-1?replyTo=25377#respond-post-10047)

[取消回复](https://kexue.fm/archives/10047#respond-post-10047)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请不要重复点击提交。

### 内容速览

[LDM回顾](https://kexue.fm/archives/10047#LDM%E5%9B%9E%E9%A1%BE)
[信噪之比](https://kexue.fm/archives/10047#%E4%BF%A1%E5%99%AA%E4%B9%8B%E6%AF%94)
[向低看齐](https://kexue.fm/archives/10047#%E5%90%91%E4%BD%8E%E7%9C%8B%E9%BD%90)
[架构拓展](https://kexue.fm/archives/10047#%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95)
[文章小结](https://kexue.fm/archives/10047#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [奔向固原，追逐梦想...](https://kexue.fm/archives/650)
- [【NASA每日一图】本星系群远后方的星系](https://kexue.fm/archives/127)
- [OCR技术浅探：2. 背景与假设](https://kexue.fm/archives/3781)
- [谷歌搜索退出中国内地](https://kexue.fm/archives/556)
- [【备忘】电脑远程控制手机的解决方案](https://kexue.fm/archives/3691)
- [【备忘】在自己的电脑上搭建服务器](https://kexue.fm/archives/1665)
- [【NASA每日一图】木星的新疤痕](https://kexue.fm/archives/45)
- [重新拥抱国家天文台！](https://kexue.fm/archives/146)
- [旋转的弹簧将如何伸长(2)？](https://kexue.fm/archives/826)
- [脑洞大开：非线性RNN居然也可以并行计算？](https://kexue.fm/archives/9783)

### 最近评论

- [OceanYU](https://kexue.fm/archives/9164/comment-page-4#comment-27801): 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）只能保证关于x\_t-1是二次函数...
- [jorjiang](https://kexue.fm/archives/10907/comment-page-2#comment-27800): 训练和prefill这个compute-bound阶段不做矩阵吸收，这个用我这个解释更好理解了...
- [amy](https://kexue.fm/archives/10907/comment-page-2#comment-27799): 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工作的看法是什么，这篇工作可以wo...
- [jiurizz](https://kexue.fm/archives/10945/comment-page-1#comment-27798): 在2\*shared experts + 160\*routed expert + top6的配置...
- [开水](https://kexue.fm/archives/10945/comment-page-1#comment-27797): 感谢苏老师回复，论文appendix里面写了实验是load balance loss，正交lo...
- [苏剑林](https://kexue.fm/archives/10958/comment-page-1#comment-27796): 欢迎作者，这篇文章确实在收藏夹了，结果还没来得及看，抱歉哈，马上学习。
- [苏剑林](https://kexue.fm/archives/10907/comment-page-2#comment-27795): “将存储kv cache改为存储降维后的Embedding X”这句话没错，但是按照我的理解，...
- [苏剑林](https://kexue.fm/archives/10945/comment-page-1#comment-27794): 呃，是这样的，Moonlight-16B-A3B实际上对应的是 scaling\_factor(...
- [Jiaming Song](https://kexue.fm/archives/10958/comment-page-1#comment-27793): 推销一下我们前一段时间的工作，这个其实已经达到了你说的三个标准，并且不需要stop\_grad或...
- [ZhouTimeMachine](https://kexue.fm/archives/9497/comment-page-2#comment-27792): 感谢您的回复！这么一看，我才注意到能从 $p(x\_0)$ 变换到 $p(x\_1)$ 实际上是每...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。