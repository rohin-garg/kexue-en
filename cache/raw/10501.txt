## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)

## COMMENTS

- [1: 1\[comment=14986\]Daniel Cheng\[/c...](https://kexue.fm/reward.html/comment-page-1#comment-27905)
- [1: 1\[comment=14986\]Daniel Cheng\[/c...](https://kexue.fm/reward.html/comment-page-1#comment-27904)
- [1: 1\[comment=25585\]Evan-wyl\[/comme...](https://kexue.fm/links.html/comment-page-6#comment-27903)
- [1: 1\[comment=25585\]Evan-wyl\[/comme...](https://kexue.fm/links.html/comment-page-6#comment-27902)
- [tll1945tll1937: 真心实意的向大家请教问题：看了文章“对齐全量微调！这是我看过最...](https://kexue.fm/archives/10266/comment-page-1#comment-27901)
- [oYo\_logan: \[comment=27017\]苏剑林\[/comment\]苏神，...](https://kexue.fm/archives/10757/comment-page-1#comment-27897)
- [z123: 在参数矩阵较多的CNN小模型上，Muon会明显慢于Adam，这...](https://kexue.fm/archives/10592/comment-page-1#comment-27896)
- [dry: 苏神好，一直有个疑问，ReFlow构建的ODE是$dx\_t/d...](https://kexue.fm/archives/10958/comment-page-2#comment-27895)
- [tyj: 感觉和之前的一篇文章很像，应该算是concurrent wor...](https://kexue.fm/archives/10958/comment-page-2#comment-27894)
- [li6626: 苏老师，Normalizing Flow有了新进展，论文链接:...](https://kexue.fm/archives/10667/comment-page-1#comment-27893)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) 低秩近似之路（四）：ID

30Oct

# [低秩近似之路（四）：ID](https://kexue.fm/archives/10501)

By 苏剑林 \|
2024-10-30 \|
26099位读者\|

这篇文章的主角是ID（Interpolative Decomposition），中文可以称之为“插值分解”，它同样可以理解为是一种具有特定结构的低秩分解，其中的一侧是该矩阵的若干列（当然如果你偏好于行，那么选择行也没什么问题），换句话说，ID试图从一个矩阵中找出若干关键列作为“骨架”（通常也称作“草图”）来逼近原始矩阵。

可能很多读者都未曾听说过ID，即便维基百科也只有几句语焉不详的介绍（ [链接](https://en.wikipedia.org/wiki/Interpolative_decomposition)），但事实上，ID跟SVD一样早已内置在SciPy之中（参考 [scipy.linalg.interpolative](https://docs.scipy.org/doc/scipy/reference/linalg.interpolative.html)），这侧面印证了ID的实用价值。

## 基本定义 [\#](https://kexue.fm/archives/10501\#%E5%9F%BA%E6%9C%AC%E5%AE%9A%E4%B9%89)

前三篇文章我们分别介绍了 [伪逆](https://kexue.fm/archives/10366)、 [SVD](https://kexue.fm/archives/10407)、 [CR近似](https://kexue.fm/archives/10427)，它们都可以视为寻找特定结构的低秩近似：
\\begin{equation}\\mathop{\\text{argmin}}\_{\\text{rank}(\\tilde{\\boldsymbol{M}})\\leq r}\\Vert \\tilde{\\boldsymbol{M}} - \\boldsymbol{M}\\Vert\_F^2\\end{equation}
其中$\\boldsymbol{M}\\in\\mathbb{R}^{n\\times m}$。当不再添加其他约束时，最优解由SVD给出；当约定$\\tilde{\\boldsymbol{M}}=\\boldsymbol{A}\\boldsymbol{B}$并且$\\boldsymbol{A},\\boldsymbol{B}$之一已经给出求另一半的最优解时，最优解可以通过伪逆来给出；如果约定$\\boldsymbol{M}=\\boldsymbol{X}\\boldsymbol{Y}$且$\\tilde{\\boldsymbol{M}}=\\boldsymbol{X}\_{\[:, S\]}\\boldsymbol{Y}\_{\[S,:\]}$，那么就是CR近似关心的问题。

CR近似通过选择原本矩阵的行/列来构建低秩近似，这使得近似结果更具解释性，同时也适用于一些非线性场景，但CR近似的前提是矩阵$\\boldsymbol{M}$本身是由两个矩阵相乘而来，它的初衷是降低矩阵计算量，而对于直接给出矩阵$\\boldsymbol{M}$的场景，类似的低秩近似则由ID给出。

具体来说，在ID中有$\\tilde{\\boldsymbol{M}}=\\boldsymbol{C}\\boldsymbol{Z}$，其中$\\boldsymbol{C}=\\boldsymbol{M}\_{\[:,S\]}$是$\\boldsymbol{M}$的若干列，$\\boldsymbol{Z}$是任意的，即以$\\boldsymbol{M}$若干列为骨架来逼近它自己：
\\begin{equation}\\mathop{\\text{argmin}}\_{S,\\boldsymbol{Z}}\\Vert \\underbrace{\\boldsymbol{M}\_{\[:,S\]}}\_{\\boldsymbol{C}}\\boldsymbol{Z} - \\boldsymbol{M}\\Vert\_F^2\\quad\\text{s.t.}\\quad S\\subset\\{0,1,\\cdots,m-1\\},\|S\|=r,\\boldsymbol{Z}\\in\\mathbb{R}^{r\\times m}\\end{equation}
根据 [《低秩近似之路（一）：伪逆》](https://kexue.fm/archives/10366) 的结果，如果$\\boldsymbol{C}$已经确定，那么$\\boldsymbol{Z}$的最优解就是$\\boldsymbol{C}^{\\dagger} \\boldsymbol{M}$，所以ID的实际难度只有$S$的优化，即列的选取，这是一个组合优化问题，精确求解是NP-Hard的，所以主要目前是寻找效率和精度都适当的近似算法。

## 几何意义 [\#](https://kexue.fm/archives/10501\#%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89)

在试图求解之前，我们先来进一步了解一下ID的几何意义，这有助于我们更好地理解它的应用场景和求解思路。我们先将$\\boldsymbol{C}$表示为列向量形式$\\boldsymbol{C}=(\\boldsymbol{c}\_1,\\boldsymbol{c}\_2,\\cdots,\\boldsymbol{c}\_r)$，那么对于任意列向量$\\boldsymbol{z}=(z\_1,z\_2,\\cdots,z\_r)^{\\top}$，我们有
\\begin{equation}\\boldsymbol{C}\\boldsymbol{z} = \\begin{pmatrix}\\boldsymbol{c}\_1 & \\boldsymbol{c}\_2 & \\cdots & \\boldsymbol{c}\_r\\end{pmatrix}\\begin{pmatrix}z\_1 \\\ z\_2 \\\ \\vdots \\\ z\_r\\end{pmatrix} = \\sum\_{i=1}^r z\_i \\boldsymbol{c}\_i\\end{equation}
所以$\\boldsymbol{C}\\boldsymbol{z}$的几何意义是$\\boldsymbol{C}$的列向量的线性组合。注意$\\boldsymbol{c}\_1,\\boldsymbol{c}\_2,\\cdots,\\boldsymbol{c}\_r$选自$\\boldsymbol{M}=(\\boldsymbol{m}\_1,\\boldsymbol{m}\_2,\\cdots,\\boldsymbol{m}\_m)$，所以ID就是说选择若干列作为（近似的）基向量，将剩下的列都表示为这些基的线性组合，这就是ID中的“I（Interpolative，插值）”的含义。

我们知道，“Interpolative”更准确的含义是“内插”，为了更好地突出“内插”这一特性，有些文献会给ID的定义加上$\|z\_{i,j}\| \\leq 1$的条件（$z\_{i,j}$是矩阵$\\boldsymbol{Z}$的任意元素）。当然这个条件实际上也比较苛刻，保证它严格成立的难度可能也是NP-Hard的，所以很多文献会将其放宽为$\|z\_{i,j}\| \\leq 2$，大多数近似算法的实际表现都能让这个界成立，如果没有其他需求，只考虑逼近误差的最优，那么也可以去掉这个限制。

## QR分解 [\#](https://kexue.fm/archives/10501\#QR%E5%88%86%E8%A7%A3)

ID的求解算法分为确定性算法和随机算法两大类，其中确定性算法的计算量更大但近似程度往往更优，反之随机算法计算效率更高但精度稍次。注意它们都只是实际表现尚可的近似算法，并且都不排除有完全失效的极端例子的可能性。

第一个被视为标准的近似算法是基于QR分解的，更准确地说是Column-Pivoting的QR分解，中文常译作“列主元QR分解”（不过笔者感觉还不如干脆意译为“列驱QR分解”），它是一个确定性算法。为什么ID会跟QR分解联系在一起呢？我们可以从$\\boldsymbol{Z}$的求法出发来理解。

前面提到，如果$\\boldsymbol{C}$已经给定，那么$\\boldsymbol{Z}$的最优解就是$\\boldsymbol{C}^{\\dagger}\\boldsymbol{M}$，这个答案当然是对的，但不够直观。不失一般性，假设$\\boldsymbol{c}\_1,\\boldsymbol{c}\_2,\\cdots,\\boldsymbol{c}\_r$线性无关，那么从几何的角度看，求$\\boldsymbol{C}\\boldsymbol{Z}$形式的最优近似实际上就是将$\\boldsymbol{M}$的每个列向量都投影到$\\boldsymbol{c}\_1,\\boldsymbol{c}\_2,\\cdots,\\boldsymbol{c}\_r$构成的$r$维子空间中，而为了求出这个投影结果，我们可以先将$\\boldsymbol{c}\_1,\\boldsymbol{c}\_2,\\cdots,\\boldsymbol{c}\_r$执行Gram-Schmidt正交化，使其变为一组标准正交基，然后在标准正交基上投影就简单多了，而正交化的过程，自然就对应QR分解了。

Gram-Schmidt正交化是递归执行如下步骤：
\\begin{equation}\\boldsymbol{q}\_1 = \\frac{\\boldsymbol{c}\_1}{\\Vert\\boldsymbol{c}\_1\\Vert},\\quad \\boldsymbol{q}\_k = \\frac{\\hat{\\boldsymbol{q}}\_k}{\\Vert\\hat{\\boldsymbol{q}}\_k\\Vert},\\quad\\hat{\\boldsymbol{q}}\_k = \\boldsymbol{c}\_k - \\sum\_{i=1}^{k-1} (\\boldsymbol{c}\_k^{\\top} \\boldsymbol{q}\_i)\\boldsymbol{q}\_i,\\quad k = 2,3,\\cdots,r\\end{equation}
其结果将$\\boldsymbol{C}$表示成：
\\begin{equation}\\boldsymbol{C} = \\underbrace{\\begin{pmatrix}\\boldsymbol{q}\_1 & \\boldsymbol{q}\_2 & \\cdots & \\boldsymbol{q}\_r\\end{pmatrix}}\_{\\boldsymbol{Q}}\\underbrace{\\begin{pmatrix}R\_{1,1} & R\_{1,2} & \\cdots & R\_{1,r} \\\
0 & R\_{2,2} & \\cdots & R\_{2,r} \\\
\\vdots & \\vdots & \\ddots & \\vdots \\\
0 & 0 & \\cdots & R\_{r,r} \\\
\\end{pmatrix}}\_{\\boldsymbol{R}}\\end{equation}
有了$\\boldsymbol{q}\_1,\\boldsymbol{q}\_2,\\cdots,\\boldsymbol{q}\_r$，那么矩阵$\\boldsymbol{M}$的第$k$列$\\boldsymbol{m}\_k$在$\\boldsymbol{C}$上的最优逼近和误差就分别是
\\begin{equation}\\sum\_{i=1}^r (\\boldsymbol{m}\_k^{\\top} \\boldsymbol{q}\_i)\\boldsymbol{q}\_i\\qquad\\text{和}\\qquad \\left\\Vert\\boldsymbol{m}\_k - \\sum\_{i=1}^r (\\boldsymbol{m}\_k^{\\top} \\boldsymbol{q}\_i)\\boldsymbol{q}\_i\\right\\Vert^2\\end{equation}

## 列驱QR [\#](https://kexue.fm/archives/10501\#%E5%88%97%E9%A9%B1QR)

当然，上述结果是在已知$\\boldsymbol{C}$的前提下得到的，那怎么从$\\boldsymbol{M}$中挑出比较优的$r$列构成$\\boldsymbol{C}$呢？列驱QR分解给出了一个参考答案。

一般来说，如果我们要对$\\boldsymbol{m}\_1,\\boldsymbol{m}\_2,\\cdots,\\boldsymbol{m}\_m$做Gram-Schmidt正交化的话，都是按照顺序来的，即从$\\boldsymbol{m}\_1$出发，接下来是$\\boldsymbol{m}\_2,\\boldsymbol{m}\_3,\\cdots$，而列驱QR分解则根据模长来修改了正交化顺序，写成公式是
\\begin{equation}\\begin{gathered}
\\boldsymbol{q}\_1 = \\frac{\\boldsymbol{m}\_{\\rho\_1}}{\\Vert\\boldsymbol{m}\_{\\rho\_1}\\Vert},\\quad
\\boldsymbol{q}\_k = \\frac{\\hat{\\boldsymbol{q}}\_k}{\\Vert\\hat{\\boldsymbol{q}}\_k\\Vert},\\quad\\hat{\\boldsymbol{q}}\_k = \\boldsymbol{m}\_{\\rho\_k} - \\sum\_{i=1}^{k-1} (\\boldsymbol{m}\_{\\rho\_k}^{\\top} \\boldsymbol{q}\_i)\\boldsymbol{q}\_i \\\
\\rho\_1 = \\mathop{\\text{argmax}}\_{i\\in\\{1,2,\\cdots,m\\}} \\Vert \\boldsymbol{m}\_i\\Vert,\\quad \\rho\_k = \\mathop{\\text{argmax}}\_{i\\in\\{1,2,\\cdots,m\\}\\backslash\\{\\rho\_1,\\rho\_2,\\cdots,\\rho\_{k-1}\\}} \\left\\Vert \\boldsymbol{m}\_i - \\sum\_{j=1}^{k-1} (\\boldsymbol{m}\_i^{\\top} \\boldsymbol{q}\_j)\\boldsymbol{q}\_j\\right\\Vert
\\end{gathered}\\end{equation}
说白了，列驱QR分解就是每一步都选择剩下的误差最大的列来执行正交归一化。除了执行顺序有所变化外，列驱QR分解跟普通QR分解的计算并无其他不同之处，所以列驱QR分解的最终形式可以表示为
\\begin{equation}\\boldsymbol{M}\\boldsymbol{\\Pi} = \\underbrace{\\begin{pmatrix}\\boldsymbol{q}\_1 & \\boldsymbol{q}\_2 & \\cdots & \\boldsymbol{q}\_m\\end{pmatrix}}\_{\\boldsymbol{Q}}\\underbrace{\\begin{pmatrix}R\_{1,1} & R\_{1,2} & \\cdots & R\_{1,m} \\\
0 & R\_{2,2} & \\cdots & R\_{2,m} \\\
\\vdots & \\vdots & \\ddots & \\vdots \\\
0 & 0 & \\cdots & R\_{m,m} \\\
\\end{pmatrix}}\_{\\boldsymbol{R}}\\end{equation}
其中$\\boldsymbol{\\Pi}$是列置换矩阵。根据每一步都选择误差（模长）最大列的操作，我们可以得到对于任意$k$，子矩阵$\\boldsymbol{R}\_{\[k-1:,k-1:\]}$的第一列模长是最大的，它不小于剩余任意一列的模长，即
\\begin{equation}R\_{k,k}^2 \\geq \\sum\_{i=k}^j R\_{i,j}^2,\\quad \\forall j = k,k+1,\\cdots,m\\end{equation}
由此还可以推得$\|R\_{1,1}\|\\geq \|R\_{2,2}\| \\geq \\cdots\\geq \|R\_{m,m}\|$。这些性质让我们相信，如果想要$\\boldsymbol{M}\\boldsymbol{\\Pi}$的一个$r$秩近似，只保留$\\boldsymbol{R}$的前$r$行应该是一个不错的选择，即
\\begin{equation}\\boldsymbol{M}\\boldsymbol{\\Pi} = \\boldsymbol{Q}\\boldsymbol{R} \\approx \\boldsymbol{Q}\_{\[:,:r\]}\\boldsymbol{R}\_{\[:r,:\]}=\\boldsymbol{Q}\_{\[:,:r\]}\\big\[\\boldsymbol{R}\_{\[:r,:r\]},\\boldsymbol{R}\_{\[:r,r:\]}\\big\]=\\boldsymbol{Q}\_{\[:,:r\]}\\boldsymbol{R}\_{\[:r,:r\]}\\big\[\\boldsymbol{I}\_r,\\boldsymbol{R}\_{\[:r,:r\]}^{-1}\\boldsymbol{R}\_{\[:r,r:\]}\\big\]\\end{equation}
注意我们之前约定过切片的优先级高于求逆，所以这里$\\boldsymbol{R}\_{\[:r,:r\]}^{-1}$的含义是$(\\boldsymbol{R}\_{\[:r,:r\]})^{-1}$。不难发现$\\boldsymbol{Q}\_{\[:,:r\]}\\boldsymbol{R}\_{\[:r,:r\]}$实际上就是矩阵$\\boldsymbol{M}$的$r$列，所以上式实际上给出了一个ID近似：
\\begin{equation}\\boldsymbol{M} \\approx \\boldsymbol{C}\\boldsymbol{Z},\\quad \\boldsymbol{C}=\\boldsymbol{Q}\_{\[:,:r\]}\\boldsymbol{R}\_{\[:r,:r\]},\\quad \\boldsymbol{Z}=\\big\[\\boldsymbol{I}\_r,\\boldsymbol{R}\_{\[:r,:r\]}^{-1}\\boldsymbol{R}\_{\[:r,r:\]}\\big\]\\boldsymbol{\\Pi}^{\\top}\\end{equation}
以上就是基于列驱QR分解的ID求解算法，也是SciPy内置的求解算法（rand=False）。注意该算法是无法保证$\|z\_{i,j}\| \\leq 1$或者$\|z\_{i,j}\| \\leq 2$的，但根据很多文献的反馈，在实践中它几乎不会出现$\|z\_{i,j}\| > 2$，所以这算是一个比较良好的求解算法。此外，SciPy也内置了列驱QR分解，在 `scipy.linalg.qr` 中设置 `pivoting=True` 即可打开。

## 随机求解 [\#](https://kexue.fm/archives/10501\#%E9%9A%8F%E6%9C%BA%E6%B1%82%E8%A7%A3)

列驱QR分解每一步正交化操作，需要遍历剩余的所有向量取误差最大者，这在$m$很大时往往难以接受，另一方面如果$n$很大，那么模长、内积的计算量也会很高，于是随机算法便应运而生，它设法减少$n$或$m$的值来降低计算复杂度。

首先我们来看降低$n$的思路，即降低$\\boldsymbol{M}$的每个列向量的维度，常用的方法是随机投影，跟 [《让人惊叹的Johnson-Lindenstrauss引理：理论篇》](https://kexue.fm/archives/8679) 介绍的“JL引理”如出一辙。具体来说，假设$\\boldsymbol{\\Omega}\\in\\mathbb{R}^{d\\times n}$是某个随机投影矩阵（其中$d\\ll n$），它的元素是从某个分布如$\\mathcal{N}(0,1/n)$独立重复采样出来的，那么我们考虑在小矩阵$\\boldsymbol{\\Omega}\\boldsymbol{M}\\in\\mathbb{R}^{d\\times m}$上执行列驱QR分解来确定被选中的$r$列的位置。更详细的介绍可以参考 [《Randomized algorithms for pivoting and for computing interpolatory and CUR factorizations》](https://users.oden.utexas.edu/~pgm/Talks/2021_ENLA.pdf)。

根据笔者有限的调研显示，SciPy求解ID的随机算法也是用的是类似思路，只是把随机采样的矩阵换成了更加结构化的“Subsampled Randomized Fourier Transform（SRFT）”，使得$\\boldsymbol{\\Omega}\\boldsymbol{M}$这一步的计算量可以从$\\mathcal{O}(mnd)$降到$\\mathcal{O}(mn\\log d)$。不过SRFT以及SciPy的实现细节笔者也不了解，有兴趣的读者可以参考 [《Enabling very large-scale matrix computations via randomization》](https://amath.colorado.edu/faculty/martinss/Talks/2010_banff.pdf)、 [《A brief introduction to Randomized Linear Algebra》](https://anthony-nouy.github.io/tutorials/morss/morss_2019_rla.pdf) 等资料进一步深究。

没有深究SRFT等复杂随机投影方法的另一个原因，是论文 [《Efficient Algorithms for Constructing an Interpolative Decomposition》](https://papers.cool/arxiv/2105.07076) 发现更简单的列采样往往能得到更优的结果，而且还特别好理解，就是从$\\boldsymbol{M}$中随机采样$k > r$列，然后用列驱QR分解从这$k$列中选出$r$列作为$\\boldsymbol{C}$，最后再来根据$\\boldsymbol{C}$求解$\\boldsymbol{Z}$，这样就将列驱QR分解的矩阵大小从$n\\times m$降低到$n\\times k$。

实验显示这样的简单思路顶多在个别任务上增大了$\|z\_{i,j}\| > 2$的风险，但在误差上有明显优势：

列采样（Optim-RID）与SciPy内置算法（SciPy-RID）的Z矩阵最大绝对值比较

列采样（Optim-RID）与SciPy内置算法（SciPy-RID）的误差比较

列采样（Optim-RID）与SciPy内置算法（SciPy-RID）的效率比较

## 提高精度 [\#](https://kexue.fm/archives/10501\#%E6%8F%90%E9%AB%98%E7%B2%BE%E5%BA%A6)

从上述表格可以留意到一个也许会让人觉得意外的结果：随机列采样的Optim-RID，在误差方面不仅优于同样是随机算法的SciPy-RID，在个别任务上甚至还优于确定性算法SciPy-ID和Optim-ID（它们数学上是等价的，都是基于完整的列驱QR分解，只是实现上的效率有所不同）。

这个看似反直觉的现象，实则说明了一个事实：列驱QR分解虽然可以作为ID的一个较好的baseline，但它选择基的能力可能跟随机选择差不了多少，列驱QR分解的主要作用只是保证大概率成立$\|z\_{i,j}\| < 2$。其实这也不难理解，我们以$r=1$为例，这时候列驱QR分解就是返回模长最大的那一列，可是模长最大的那列一定是好的（能使得重构误差最小的）基底吗？显然不是，好的基底应该是多数向量共同指向的方向，模长最大不能体现这一点。

对于ID来说，列驱QR分解本质上是一种贪心算法，它将选$r$列贪心地转化为多个选$1$列的递归，而当$r=1$时，在$m$不算太大或者要求高精度的场景，通过枚举来精确求解的复杂度是可以接受的
\\begin{equation}\\mathop{\\text{argmin}}\_i \\sum\_{j=1}^m \\left\\Vert\\boldsymbol{m}\_j - \\frac{(\\boldsymbol{m}\_j^{\\top} \\boldsymbol{m}\_i)\\boldsymbol{m}\_i}{\\Vert\\boldsymbol{m}\_i\\Vert^2}\\right\\Vert^2\\end{equation}
即遍历所有的$\\boldsymbol{m}\_i$，将剩下的所有列都投影到$\\boldsymbol{m}\_i$上来计算总误差，选择总误差最小的$\\boldsymbol{m}\_i$，其复杂度跟$m^2$成正比。如果将列驱QR分解每一步选择模长最大的操作改为选择总误差最小的上式，那么就能找出更好的基底，从而实现更低的重构误差（代价自然是复杂度更高了，而且更加无法保证$\|z\_{i,j}\| < 2$了）。

总的来说，由于精确求解的NP-Hard性，所以ID有非常多的求解思路，上面列举的只是非常有限的几种，有兴趣的读者可以可以围绕着Randomized Linear Algebra、Column Subset Selection等关键词深入搜索。特别要指出的是，Randomized Linear Algebra，旨在通过随机方法来加速各种矩阵运算，本身已经成为了一个内容丰富的学科，本文的随机ID和上一篇基于采样的CR近似，都是这个学科的经典例子。

## 文章小结 [\#](https://kexue.fm/archives/10501\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文介绍了ID（Interpolative Decomposition，插值分解），它通过从原矩阵中选择若干列来作为“骨架”来逼近原矩阵，是一种具有特定结构的低秩分解，几何意义相对来说更加直观，其核心难度是列的选择，本质上是一个NP-Hard的离散优化问题。

_**转载到请包括本文地址：** [https://kexue.fm/archives/10501](https://kexue.fm/archives/10501)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/10501#share)/ [打赏](https://kexue.fm/archives/10501#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Oct. 30, 2024). 《低秩近似之路（四）：ID 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/10501](https://kexue.fm/archives/10501)

@online{kexuefm-10501,
        title={低秩近似之路（四）：ID},
        author={苏剑林},
        year={2024},
        month={Oct},
        url={\\url{https://kexue.fm/archives/10501}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [近似](https://kexue.fm/tag/%E8%BF%91%E4%BC%BC/), [最优](https://kexue.fm/tag/%E6%9C%80%E4%BC%98/), [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/), [低秩](https://kexue.fm/tag/%E4%BD%8E%E7%A7%A9/)[5 评论](https://kexue.fm/archives/10501#comments)

< [VQ的旋转技巧：梯度直通估计的一般推广](https://kexue.fm/archives/10489) \| [VQ的又一技巧：给编码表加一个线性变换](https://kexue.fm/archives/10519) >

### 你也许还对下面的内容感兴趣

- [msign的导数](https://kexue.fm/archives/11025)
- [通过msign来计算mclip（奇异值裁剪）](https://kexue.fm/archives/11006)
- [msign算子的Newton-Schulz迭代（下）](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [msign算子的Newton-Schulz迭代（上）](https://kexue.fm/archives/10922)
- [SVD的导数](https://kexue.fm/archives/10878)
- [矩阵的有效秩（Effective Rank）](https://kexue.fm/archives/10847)
- [MoE环游记：3、换个思路来分配](https://kexue.fm/archives/10757)
- [Muon续集：为什么我们选择尝试Muon？](https://kexue.fm/archives/10739)
- [低秩近似之路（五）：CUR](https://kexue.fm/archives/10662)

[发表你的看法](https://kexue.fm/archives/10501#comment_form)

GGbond

February 12th, 2025

想问一下公式3中，为什么不是$c\_i \\cdot z\_i^T$,而是$z\_i \\cdot c\_i$

[回复评论](https://kexue.fm/archives/10501/comment-page-1?replyTo=26581#respond-post-10501)

[苏剑林](https://kexue.fm) 发表于
February 15th, 2025

那是$z\_i \\boldsymbol{c}\_i$，$z\_i$是一个标量，$\\boldsymbol{c}\_i$是一个向量。

[回复评论](https://kexue.fm/archives/10501/comment-page-1?replyTo=26628#respond-post-10501)

GGbond

February 12th, 2025

想问一下公式6是怎么来的呢？

[回复评论](https://kexue.fm/archives/10501/comment-page-1?replyTo=26582#respond-post-10501)

[苏剑林](https://kexue.fm) 发表于
February 15th, 2025

就是正交投影啊。

[回复评论](https://kexue.fm/archives/10501/comment-page-1?replyTo=26629#respond-post-10501)

Mikeboat

June 3rd, 2025

好文，请你喝杯瑞幸 哈哈

[回复评论](https://kexue.fm/archives/10501/comment-page-1?replyTo=27755#respond-post-10501)

[取消回复](https://kexue.fm/archives/10501#respond-post-10501)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[基本定义](https://kexue.fm/archives/10501#%E5%9F%BA%E6%9C%AC%E5%AE%9A%E4%B9%89)
[几何意义](https://kexue.fm/archives/10501#%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89)
[QR分解](https://kexue.fm/archives/10501#QR%E5%88%86%E8%A7%A3)
[列驱QR](https://kexue.fm/archives/10501#%E5%88%97%E9%A9%B1QR)
[随机求解](https://kexue.fm/archives/10501#%E9%9A%8F%E6%9C%BA%E6%B1%82%E8%A7%A3)
[提高精度](https://kexue.fm/archives/10501#%E6%8F%90%E9%AB%98%E7%B2%BE%E5%BA%A6)
[文章小结](https://kexue.fm/archives/10501#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [【NASA每日一图】天文城的夏季星空](https://kexue.fm/archives/120)
- [最小熵原理（六）：词向量的维度应该怎么选择？](https://kexue.fm/archives/7695)
- [从动力学角度看优化算法（三）：一个更整体的视角](https://kexue.fm/archives/6261)
- [2010年全年天象](https://kexue.fm/archives/1144)
- [缅怀金庸 \| 愿你登上10930小行星继续翱翔](https://kexue.fm/archives/6131)
- [2012年天象](https://kexue.fm/archives/1788)
- [《向量》系列——3.当天体力学遇到向量(1)](https://kexue.fm/archives/740)
- [通过互信息思想来缓解类别不平衡问题](https://kexue.fm/archives/7615)
- [网站统计总结\|来访信息综合](https://kexue.fm/archives/91)
- [深度学习中的Lipschitz约束：泛化与生成模型](https://kexue.fm/archives/6051)

### 最近评论

- [1](https://kexue.fm/reward.html/comment-page-1#comment-27905): 1\[comment=14986\]Daniel Cheng\[/comment\]\[comment=...
- [1](https://kexue.fm/reward.html/comment-page-1#comment-27904): 1\[comment=14986\]Daniel Cheng\[/comment\]\[comment=...
- [1](https://kexue.fm/links.html/comment-page-6#comment-27903): 1\[comment=25585\]Evan-wyl\[/comment\]\[comment=2564...
- [1](https://kexue.fm/links.html/comment-page-6#comment-27902): 1\[comment=25585\]Evan-wyl\[/comment\]\[comment=2564...
- [tll1945tll1937](https://kexue.fm/archives/10266/comment-page-1#comment-27901): 真心实意的向大家请教问题：看了文章“对齐全量微调！这是我看过最精彩的LoRA改进（二）”，我实...
- [oYo\_logan](https://kexue.fm/archives/10757/comment-page-1#comment-27897): \[comment=27017\]苏剑林\[/comment\]苏神，想请教一下，我理解在一个batc...
- [z123](https://kexue.fm/archives/10592/comment-page-1#comment-27896): 在参数矩阵较多的CNN小模型上，Muon会明显慢于Adam，这方面有什么优化提速的方案吗？
- [dry](https://kexue.fm/archives/10958/comment-page-2#comment-27895): 苏神好，一直有个疑问，ReFlow构建的ODE是$dx\_t/dt=x\_1-x\_0$，为什么这并...
- [tyj](https://kexue.fm/archives/10958/comment-page-2#comment-27894): 感觉和之前的一篇文章很像，应该算是concurrent work： https://arxiv...
- [li6626](https://kexue.fm/archives/10667/comment-page-1#comment-27893): 苏老师，Normalizing Flow有了新进展，论文链接:https://arxiv.or...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。