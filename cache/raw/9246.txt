## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)

## COMMENTS

- [PengchengMa: 牛啊](https://kexue.fm/archives/10996/comment-page-1#comment-27811)
- [xczh: 已使用mean flow policy，一步推理效果确实惊人，...](https://kexue.fm/archives/10958/comment-page-1#comment-27810)
- [Cosine: 是不是因为shared experts每次都激活，而route...](https://kexue.fm/archives/10945/comment-page-1#comment-27809)
- [rpsun: 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减...](https://kexue.fm/archives/10699/comment-page-1#comment-27808)
- [贵阳机场接机: 怎么不更新啦](https://kexue.fm/archives/1490/comment-page-1#comment-27807)
- [czvzb: 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。...](https://kexue.fm/archives/10958/comment-page-1#comment-27806)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27802)
- [OceanYU: 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）...](https://kexue.fm/archives/9164/comment-page-4#comment-27801)
- [jorjiang: 训练和prefill这个compute-bound阶段不做矩阵...](https://kexue.fm/archives/10907/comment-page-2#comment-27800)
- [amy: 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工...](https://kexue.fm/archives/10907/comment-page-2#comment-27799)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 生成扩散模型漫谈（八）：最优扩散方差估计（下）

18Aug

# [生成扩散模型漫谈（八）：最优扩散方差估计（下）](https://kexue.fm/archives/9246)

By 苏剑林 \|
2022-08-18 \|
55292位读者\|

在上一篇文章 [《生成扩散模型漫谈（七）：最优扩散方差估计（上）》](https://kexue.fm/archives/9245) 中，我们介绍并推导了Analytic-DPM中的扩散模型最优方差估计结果，它是直接给出了已经训练好的生成扩散模型的最优方差的一个解析估计，实验显示该估计结果确实能有效提高扩散模型的生成质量。

这篇文章我们继续介绍Analytic-DPM的升级版，出自同一作者团队的论文 [《Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models》](https://papers.cool/arxiv/2206.07309)，在官方Github中被称为“Extended-Analytic-DPM”，下面我们也用这个称呼。

## 结果回顾 [\#](https://kexue.fm/archives/9246\#%E7%BB%93%E6%9E%9C%E5%9B%9E%E9%A1%BE)

上一篇文章是在DDIM的基础上，推出DDIM的生成过程最优方差应该是
\\begin{equation}\\sigma\_t^2 + \\gamma\_t^2\\bar{\\sigma}\_t^2\\end{equation}
其中$\\bar{\\sigma}\_t^2$是分布$p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)$的方差，它有如下的估计结果（这里取“ [方差估计2](https://kexue.fm/archives/9245#%E6%96%B9%E5%B7%AE%E4%BC%B0%E8%AE%A12)”的结果）：
\\begin{equation}\\bar{\\sigma}\_t^2 = \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\left(1 - \\frac{1}{d}\\mathbb{E}\_{\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)}\\left\[ \\Vert\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\Vert^2\\right\]\\right)\\label{eq:basic}\\end{equation}

事后来看，其实估计思路也不算难，假设
\\begin{equation}\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t) = \\frac{1}{\\bar{\\alpha}\_t}\\left(\\boldsymbol{x}\_t - \\bar{\\beta}\_t \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)\\label{eq:bar-mu}\\end{equation}
已经准确预测了分布$p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)$的均值向量，那么根据定义可以得到协方差为
\\begin{equation}\\begin{aligned}
\\boldsymbol{\\Sigma}(\\boldsymbol{x}\_t)=&\\, \\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{x}\_0 - \\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)\\right)\\left(\\boldsymbol{x}\_0 - \\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)\\right)^{\\top}\\right\] \\\
=&\\, \\frac{1}{\\bar{\\alpha}\_t^2}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0\\right)\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0\\right)^{\\top}\\right\] - \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2} \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top}\\\
\\end{aligned}\\label{eq:full-cov}\\end{equation}
两端对$\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)$求平均，以消除对$\\boldsymbol{x}\_t$的依赖
\\begin{equation}
\\boldsymbol{\\Sigma}\_t = \\mathbb{E}\_{\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)}\[\\boldsymbol{\\Sigma}(\\boldsymbol{x}\_t)\] = \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\left(\\boldsymbol{I} - \\mathbb{E}\_{\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)}\\left\[ \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top}\\right\]\\right)\\label{eq:uncond-var-2}\\end{equation}
最后，对角线元素取平均，使其变为一个标量（或者说协方差是单位阵的倍数），即$\\bar{\\sigma}\_t^2 = \\text{Tr}(\\boldsymbol{\\Sigma}\_t)/d$，便可得到估计式$\\eqref{eq:basic}$。

## 如何改进 [\#](https://kexue.fm/archives/9246\#%E5%A6%82%E4%BD%95%E6%94%B9%E8%BF%9B)

在正式介绍Extended-Analytic-DPM之前，我们可以先想想，Analytic-DPM还有什么改进空间？

其实稍加思考就可以发现很多，比如Analytic-DPM假设用来逼近$p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)$的正态分布协方差矩阵设计为为$\\bar{\\sigma}\_t^2\\boldsymbol{I}$，即对角线元素相同的对角阵，那么一个直接的改进就是允许对角线元素互不相同了，即$\\text{diag}(\\bar{\\boldsymbol{\\sigma}}\_t^2)$，这里约定向量的乘法都是基于Hadamard积进行，比如$\\boldsymbol{x}^2=\\boldsymbol{x}\\otimes \\boldsymbol{x}$。对应的结果就是只考虑$\\boldsymbol{\\Sigma}\_t$的对角线部分，所以从式$\\eqref{eq:uncond-var-2}$出发，可以得到相应的估计是
\\begin{equation}\\bar{\\boldsymbol{\\sigma}}\_t^2 = \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\left(\\boldsymbol{1}\_d - \\mathbb{E}\_{\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)}\\left\[ \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}^2(\\boldsymbol{x}\_t, t)\\right\]\\right) \\end{equation}
其中$\\boldsymbol{1}\_d$是$d$维全1向量。还有一个更进一步的改进是保留$\\bar{\\boldsymbol{\\sigma}}\_t^2$对$\\boldsymbol{x}\_t$的依赖关系，即考虑$\\bar{\\boldsymbol{\\sigma}}\_t^2(\\boldsymbol{x}\_t)$，这就跟$\\boldsymbol{\\mu}(\\boldsymbol{x}\_t)$类似，需要用一个以$\\boldsymbol{x}\_t$为输入的模型来学习它。

那么可不可以考虑完整的$\\boldsymbol{\\Sigma}\_t$呢？理论上可以，实际上基本不可行，因为完整的$\\boldsymbol{\\Sigma}\_t$是一个$d\\times d$矩阵，对于图片场景来说，$d$是图片的总像素个数，即便是对于cifar10来说也已经有$d=32^2\\times 3=3072$了，更不用说更高分辨率的图片。所以结合实验背景，$d\\times d$矩阵在储存和计算上的成本都过大了。

除此之外，可能有一个问题不少读者都没意识到，就是前面的解析解推导都依赖于$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t) = \\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\[\\boldsymbol{x}\_0\]$，事实上$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$是由模型学习出来的，它未必能够精确等于均值$\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\[\\boldsymbol{x}\_0\]$，这就是Extended-Analytic-DPM的论文标题所提到的Imperfect Mean的含义。如果在Imperfect Mean下改进估计结果，更加有实践意义。

## 最大似然 [\#](https://kexue.fm/archives/9246\#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6)

假设均值模型$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$已经事先训练好，那么待定分布$\\mathcal{N}(\\boldsymbol{x}\_0;\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t),\\bar{\\sigma}\_t^2\\boldsymbol{I})$的参数就只剩下了$\\bar{\\sigma}\_t^2$，对应的负对数似然为
\\begin{equation}\\begin{aligned}
&\\, \\mathbb{E}\_{\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[-\\log \\mathcal{N}(\\boldsymbol{x}\_0;\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t),\\bar{\\sigma}\_t^2\\boldsymbol{I})\\right\] \\\
=&\\, \\frac{\\mathbb{E}\_{\\boldsymbol{x}\_t,\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_t\|\\boldsymbol{x}\_0)\\tilde{p}(\\boldsymbol{x}\_0)}\\left\[\\Vert\\boldsymbol{x}\_0 - \\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)\\Vert^2\\right\]}{2\\bar{\\sigma}\_t^2} + \\frac{d}{2}\\log \\bar{\\sigma}\_t^2 + \\frac{d}{2}\\log 2\\pi \\\
\\end{aligned}\\label{eq:neg-log}\\end{equation}
可以解得取最小值正好是
\\begin{equation}\\bar{\\sigma}\_t^2 = \\frac{1}{d}\\mathbb{E}\_{\\boldsymbol{x}\_t,\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_t\|\\boldsymbol{x}\_0)\\tilde{p}(\\boldsymbol{x}\_0)}\\left\[\\Vert\\boldsymbol{x}\_0 - \\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)\\Vert^2\\right\]\\end{equation}
它的特点是$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$未必是准确的均值结果，因此式$\\eqref{eq:full-cov}$的第二个等号不成立，只能成立第一个等号。将式$\\eqref{eq:bar-mu}$代入，得到
\\begin{equation}\\bar{\\sigma}\_t^2 = \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2 d}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim \\tilde{p}(\\boldsymbol{x}\_0),\\boldsymbol{\\varepsilon}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})}\\left\[\\left\\Vert\\boldsymbol{\\varepsilon} - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\bar{\\alpha}\_t\\boldsymbol{x}\_0 + \\bar{\\beta}\_t\\boldsymbol{\\varepsilon}, t)\\right\\Vert^2\\right\]\\end{equation}
当然，这里只分析了协方差矩阵为$\\bar{\\sigma}\_t^2\\boldsymbol{I}$的简单情形，我们也可以考虑更一般的对角阵协方差，即$\\mathcal{N}(\\boldsymbol{x}\_0;\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t),\\text{diag}(\\bar{\\boldsymbol{\\sigma}}\_t^2))$，对应的结果是
\\begin{equation}\\bar{\\boldsymbol{\\sigma}}\_t^2 = \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2 }\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim \\tilde{p}(\\boldsymbol{x}\_0),\\boldsymbol{\\varepsilon}\\sim\\mathcal{N}(\\boldsymbol{0},\\boldsymbol{I})}\\left\[\\left(\\boldsymbol{\\varepsilon} - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\bar{\\alpha}\_t\\boldsymbol{x}\_0 + \\bar{\\beta}\_t\\boldsymbol{\\varepsilon}, t)\\right)^2\\right\]\\end{equation}

## 条件方差 [\#](https://kexue.fm/archives/9246\#%E6%9D%A1%E4%BB%B6%E6%96%B9%E5%B7%AE)

如果想要得到带条件$\\boldsymbol{x}\_t$的协方差$\\text{diag}(\\bar{\\boldsymbol{\\sigma}}\_t^2(\\boldsymbol{x}\_t))$，那么就相当于每个分量独立计算，结果是免除了$\\mathbb{E}\_{\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)}$这一步平均：
\\begin{equation}\\bar{\\boldsymbol{\\sigma}}\_t^2(\\boldsymbol{x}\_t) = \\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[(\\boldsymbol{x}\_0 - \\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t))^2\\right\] = \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{\\epsilon}\_t - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)^2\\right\] \\end{equation}
其中$\\boldsymbol{\\epsilon}\_t = \\frac{\\boldsymbol{x}\_t - \\bar{\\alpha}\_t \\boldsymbol{x}\_0}{\\bar{\\beta}\_t}$。跟上一篇文章一样，利用
\\begin{equation}\\mathbb{E}\_{\\boldsymbol{x}}\[\\boldsymbol{x}\] = \\mathop{\\text{argmin}}\_{\\boldsymbol{\\mu}}\\mathbb{E}\_{\\boldsymbol{x}}\\left\[\\Vert \\boldsymbol{x} - \\boldsymbol{\\mu}\\Vert^2\\right\]\\label{eq:mean-opt}\\end{equation}
得到
\\begin{equation}\\begin{aligned}
\\bar{\\boldsymbol{\\sigma}}\_t^2(\\boldsymbol{x}\_t) =&\\, \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{\\epsilon}\_t - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)^2\\right\] \\\
=&\\, \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\mathop{\\text{argmin}}\_{\\boldsymbol{g}}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left\\Vert\\left(\\boldsymbol{\\epsilon}\_t - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)^2-\\boldsymbol{g}\\right\\Vert^2\\right\] \\\
=&\\, \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\mathop{\\text{argmin}}\_{\\boldsymbol{g}(\\boldsymbol{x}\_t)}\\mathbb{E}\_{\\boldsymbol{x}\_t\\sim p(\\boldsymbol{x}\_t)}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left\\Vert\\left(\\boldsymbol{\\epsilon}\_t - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)^2-\\boldsymbol{g}(\\boldsymbol{x}\_t)\\right\\Vert^2\\right\] \\\
=&\\, \\frac{\\bar{\\beta}\_t^2}{\\bar{\\alpha}\_t^2}\\mathop{\\text{argmin}}\_{\\boldsymbol{g}(\\boldsymbol{x}\_t)}\\mathbb{E}\_{\\boldsymbol{x}\_t,\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_t\|\\boldsymbol{x}\_0)\\tilde{p}(\\boldsymbol{x}\_0)}\\left\[\\left\\Vert\\left(\\boldsymbol{\\epsilon}\_t - \\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)^2-\\boldsymbol{g}(\\boldsymbol{x}\_t)\\right\\Vert^2\\right\] \\\
\\end{aligned}\\end{equation}
这就是Extended-Analytic-DPM中学习条件方差的“NPR-DPM”方案。另外，原论文还提了个“SN-DPM”方案，它是基于Perfect Mean假设而不是Imperfect Mean的。然而论文的实验结果却是SN-DPM要优于NPR-DPM，也就是说论文号称自己在解决Imperfect Mean问题，结果实验显示Perfect Mean假设的方案更好，这就反过来说明Perfect Mean假设其实很贴合实践情况，换句话说Imperfect Mean问题可以视为不存在了。

## 两个阶段 [\#](https://kexue.fm/archives/9246\#%E4%B8%A4%E4%B8%AA%E9%98%B6%E6%AE%B5)

可能读者有疑问，一开始不是说 [《Improved Denoising Diffusion Probabilistic Models》](https://papers.cool/arxiv/2006.11239) 的可学习方差增加了训练难度吗？那Extended-Analytic-DPM为啥又重新去做可训练的方差模型呢？

我们知道，DDPM提供了方差的两种方案$\\sigma\_t = \\frac{\\bar{\\beta}\_{t-1}}{\\bar{\\beta}\_t}\\beta\_t$和$\\sigma\_t = \\beta\_t$，这两种简单方案的效果其实已经相当不错了。这侧面说明，更精细地调整方差对生成结果的影响不大（至少对于完整的$T$步扩散是这样），主要的还是$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$的学习，方差只是“锦上添花”的作用。如果将方差视为可学习参数或者模型，跟均值模型$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$一同学习，那么随着训练过程变化的方差就会严重干扰均值模型$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$的学习过程，违反了“$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$为主、方差为辅”的原则。

Extended-Analytic-DPM的聪明之处在于，它提出了两阶段的训练方案，即用原始固定方差的测试训练好均值模型$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$，然后固定该模型，并重用该模型的大部分参数来学一个方差模型，这样一来反而“一举三得”：

> 一、降低了参数量和训练成本；
>
> 二、允许重用已经训练好的均值模型；
>
> 三、训练过程更加稳定。

## 个人思考 [\#](https://kexue.fm/archives/9246\#%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83)

到这里，Extended-Analytic-DPM的介绍就基本完成了。有心的读者可能会感觉到，如果说上一篇Analytic-DPM的结果给人“惊艳”之感，那么这一篇Extended-Analytic-DPM就显得中规中矩，没什么太动人心弦的地方。可以说，Extended-Analytic-DPM就是Analytic-DPM的平凡推广，尽管实验结果显示它还是能带来不错的提升，但总体而言给人的感觉就是很平淡了。当然，大体上是因为Analytic-DPM“珠玉在前”，对比之下才显得它暗淡一些，本身也算是一篇比较扎实的工作。

此外，前面我们已经提到，实验结果显示，基于Perfect Mean假设的SN-DPM，效果要比基于Imperfect Mean假设的NPR-DPM要好，同时这一结果也使得原论文的标题有点“名不副实”了——既然实验显示Perfect Mean假设的方案更好，反过来意味着Imperfect Mean问题可以视为不存在了。原论文并没有对此结果做进一步的分析和评价，笔者想会不会跟方差估计的有偏性有关？大家知道，直接用“除以$n$”的公式去估计方差是有偏的，而NPR-DPM正是基于它来操作的，相比之下SN-DPM则是直接取估计二阶矩，二阶矩的估计是无偏的。总感觉有点道理，但也不能完全说通，有点迷～

最后，不知道读者会不会跟笔者一样有个疑问：在给定$\\bar{\\boldsymbol{\\mu}}(\\boldsymbol{x}\_t)$的前提下，为什么不直接用像式$\\eqref{eq:neg-log}$的负对数似然为损失函数来学习方差，而是要重新设计NPR-DPM或SN-DPM这两种MSE形式的loss？MSE形式的loss有什么特别的好处吗？笔者暂时也没想到答案。

## 文章小结 [\#](https://kexue.fm/archives/9246\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文介绍了论文Analytic-DPM的升级版——“Extended-Analytic-DPM”中的扩散模型最优方差估计结果，它主要针对不完美均值情形进行了推导，并提出了有条件方差的学习方案。

_**转载到请包括本文地址：** [https://kexue.fm/archives/9246](https://kexue.fm/archives/9246)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/9246#share)/ [打赏](https://kexue.fm/archives/9246#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Aug. 18, 2022). 《生成扩散模型漫谈（八）：最优扩散方差估计（下） 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/9246](https://kexue.fm/archives/9246)

@online{kexuefm-9246,
        title={生成扩散模型漫谈（八）：最优扩散方差估计（下）},
        author={苏剑林},
        year={2022},
        month={Aug},
        url={\\url{https://kexue.fm/archives/9246}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/), [生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/), [DDPM](https://kexue.fm/tag/DDPM/), [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/)[20 评论](https://kexue.fm/archives/9246#comments)

< [生成扩散模型漫谈（七）：最优扩散方差估计（上）](https://kexue.fm/archives/9245) \| [生成扩散模型漫谈（九）：条件控制生成结果](https://kexue.fm/archives/9257) >

### 你也许还对下面的内容感兴趣

- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [Transformer升级之路：20、MLA究竟好在哪里？](https://kexue.fm/archives/10907)
- [MoE环游记：4、难处应当多投入](https://kexue.fm/archives/10815)
- [生成扩散模型漫谈（二十九）：用DDPM来离散编码](https://kexue.fm/archives/10711)
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
- [为什么梯度裁剪的默认模长是1？](https://kexue.fm/archives/10657)
- [从谱范数梯度到新式权重衰减的思考](https://kexue.fm/archives/10648)
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633)
- [生成扩散模型漫谈（二十七）：将步长作为条件输入](https://kexue.fm/archives/10617)

[发表你的看法](https://kexue.fm/archives/9246#comment_form)

qiuhao

September 2nd, 2022

请问公式（8)下一行说训练得到的$\\bar{\\mu}(x\_t)$不一定是准确的均值结果，所以（4）的第二个等号不成立。但是第二个等式仅仅是把（3）带入了。那是否意味着（3）不一定成立？但如果（3）不成立，就不该得到（9）。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=19720#respond-post-9246)

qiuhao 发表于
September 2nd, 2022

(13)式，第二行是因为 argmin 估计的$(\\epsilon\_t -\\epsilon\_{\\theta})^2$和g误差最小的g，就是$\\sigma\_t^2$的最优估计

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=19721#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
September 2nd, 2022

如果“仅仅”代入，那么得到的应该是
\\begin{equation}
\\boldsymbol{\\Sigma}(\\boldsymbol{x}\_t) = \\frac{1}{\\bar{\\alpha}\_t^2}\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0 - \\bar{\\beta}\_t\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0 - \\bar{\\beta}\_t\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\right)^{\\top}\\right\]\\end{equation}
将$\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0$看成一个整体，展开后应该有4项，不能化简成式$\\eqref{eq:full-cov}$第二个等号的结果（因为此时$\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\boldsymbol{x}\_0\\right\]\\neq \\boldsymbol{\\mu}(\\boldsymbol{x}\_t)$。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=19724#respond-post-9246)

[fanbao](https://baofff.github.io/)

October 10th, 2022

感谢关注我们的工作！解答一下作者的concern。(1)考虑imperfect mean带来的收益体现在似然上，这也是和我们极大似然(即最小化kl散度)的目标是一致的。此外，fid指标和似然指标未必是一致的(可以参考论文a note on the evaluation of generative models)，所以是有可能出现似然好fid差的情况。(2) MSE loss一个比较直观的好处是，他不涉及除法，如果是用elbo训练，那么方差项会出现在分母里。相比之下，MSE的训练方式应该会更稳定一些。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=20038#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
October 11th, 2022

感谢作者莅临指导！

其实这两个原因，我后面也大致想到了。然而还是有一个问题，即如果考虑似然指标的话，那么应该负对数似然为loss更贴近目标才对呀。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=20049#respond-post-9246)

xzy

December 19th, 2022

苏老师你好，这里我也没看懂。即使看成整体，中间项

$E\[(x\_t - \\bar{\\alpha}\_t x\_0))(\\bar{\\beta}\_t\\epsilon\_{\\theta}(x\_t, t))^T\] = 0 \\rightarrow E\[(x\_t - \\bar{\\alpha}\_t x\_0))\] = 0 \\rightarrow x\_t = \\alpha\_t E\[x\_0\]$

似乎也不成立呐... 苏老师方便具体解释下嘛？

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=20577#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
December 20th, 2022

没人说$\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0\\right)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top}\\right\]=0$啊，而且就算$\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0\\right)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top}\\right\]=0$，能推出$(4)$么？这反推是乱来的么...

$$\\begin{aligned}&\\,\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0\\right)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top}\\right\] \\\
=&\\,\\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\boldsymbol{x}\_t - \\bar{\\alpha}\_t\\boldsymbol{x}\_0\\right\]\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top} \\\
=&\\,\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t \\mathbb{E}\_{\\boldsymbol{x}\_0\\sim p(\\boldsymbol{x}\_0\|\\boldsymbol{x}\_t)}\\left\[\\boldsymbol{x}\_0\\right\]\\right)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top} \\\
=&\\,\\left(\\boldsymbol{x}\_t - \\bar{\\alpha}\_t \\boldsymbol{\\mu}(\\boldsymbol{x}\_t)\\right)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top} \\\
=&\\,\\bar{\\beta}\_t\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)\\boldsymbol{\\epsilon}\_{\\boldsymbol{\\theta}}(\\boldsymbol{x}\_t, t)^{\\top} \\\
\\end{aligned}$$

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=20596#respond-post-9246)

xzy 发表于
December 23rd, 2022

原来如此…麻烦苏老师细心指导了hh

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=20623#respond-post-9246)

Noreason

May 17th, 2023

13式第四行E\_xt,x0是否应该改为E\_xt,xt，与上一篇写的不一样

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=21666#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
May 17th, 2023

看上去$(13)$式是没错的，你指的是跟上一篇哪个公式不一样？

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=21672#respond-post-9246)

Noreason 发表于
May 18th, 2023

与上一篇的(6)式的第四行不一样，下角标那块

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=21675#respond-post-9246)

chenluyu

June 13th, 2023

苏神 为什么（11）式子的，分母部分$ \\bar{a\_t}$ 没有平方，不太明白为什么

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=21961#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
June 15th, 2023

应该是写漏了，已修正。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=21984#respond-post-9246)

一切尽在不言中

December 2nd, 2023

苏老师好，想问下您有读过dpm-solver的论文吗？听说那个工作的结论还挺深刻的，不知道有没有兴趣介绍下

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=23194#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
December 4th, 2023

有听闻，没细读。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=23208#respond-post-9246)

GRS

March 4th, 2024

苏老师，看完您《生成扩散模型漫谈（一）》到《（八）》获益良多，但是我还有一个疑问，就是这些文章中的所有推导似乎都将$x\_0$处理成是一个向量（实际上不仅您的文章是这样，我看关于diffusion模型的很多论文似乎都是这样处理的）。但实际上，每个image都只能用一个shape是(width,height,3)的3d array去描述，所以这里就存在一个问题，就是说，实际运用的时候是不是需要把所有的多元分布改成相对应的矩阵分布，再按文中思路推出一个对3d array实际可用的优化目标？

还是说我在运用的时候可以直接把image拉成一个向量，这样一来文中的所有结论都可以直接运用了？（后来我思考了一下，实际上似乎也没有必要真的把image拉成一个向量，因为diffusion模型要确定的无非就是$p(x\_t\|x\_0)$、由此推导出的$p(x\_{t-1}\|x\_t)$（SDE框架下，用数值方法求解time-reverse SDE后所得到的$x\_t \\to x\_{t-1}$往往也能根据重参数技巧来写出一个$p(x\_{t-1}\|x\_t)$）以及用unet拟合出来的$\\epsilon\_\\theta(x\_t,t)$，也就是两个过程和一个优化目标：一个是如$x\_t = \\bar{\\alpha}\_t x\_0+\\bar{\\beta}\_t \\epsilon$的$x\_0 \\to x\_t$过程；另一个是如$x\_{t-1}=k x\_t+b\\epsilon$的$x\_t \\to x\_{t-1}$过程；以及如$\|\|\\epsilon-\\epsilon\_\\theta(\\bar{\\alpha}\_tx\_0+\\bar{\\beta}\_t \\epsilon,t)\|\|^2$的优化目标。对于上述的两个过程和优化目标，在实际计算时并不需要将$x\_i(i=0,1,2,...,T)$拉直成一个向量，而直接将由$N(0,I)$生成的 $\\epsilon$ reshape成(width,height,3)的array即可）

不知道上述分析是否正确，还请苏老师指点一二，谢谢

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=23860#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
March 7th, 2024

在推导的时候，直接将$\\boldsymbol{x}$想象为一个向量就行，因为扩散模型的理论本身，不限制$\\boldsymbol{x}$是向量还是矩阵。

那么哪里体现出$\\boldsymbol{x}$是3d-array而不是向量的区别呢？答案是U-Net本身，因为它是width\*height\*channels的形式，我们就会使用Conv2D去实现这个U-Net，或者Transformer也会加上2D形式的位置编码，这就是区别，即模型内部实现上会根据对$\\boldsymbol{x}$结构的先验认知来进行不同的设计，但在模型输入之前、输出之后，它是向量还是矩阵还是nd-array，没有实质区别。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=23885#respond-post-9246)

GRS 发表于
March 10th, 2024

想通了，谢谢苏老师的解答！

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=23902#respond-post-9246)

alex yuan

July 11th, 2024

想请问一下，（13）式的分母部分at¯
的平方是怎么消掉的？

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=24783#respond-post-9246)

[苏剑林](https://kexue.fm) 发表于
July 12th, 2024

这个是笔误，感谢指出，已经修正。

[回复评论](https://kexue.fm/archives/9246/comment-page-1?replyTo=24799#respond-post-9246)

[取消回复](https://kexue.fm/archives/9246#respond-post-9246)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请不要重复点击提交。

### 内容速览

[结果回顾](https://kexue.fm/archives/9246#%E7%BB%93%E6%9E%9C%E5%9B%9E%E9%A1%BE)
[如何改进](https://kexue.fm/archives/9246#%E5%A6%82%E4%BD%95%E6%94%B9%E8%BF%9B)
[最大似然](https://kexue.fm/archives/9246#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6)
[条件方差](https://kexue.fm/archives/9246#%E6%9D%A1%E4%BB%B6%E6%96%B9%E5%B7%AE)
[两个阶段](https://kexue.fm/archives/9246#%E4%B8%A4%E4%B8%AA%E9%98%B6%E6%AE%B5)
[个人思考](https://kexue.fm/archives/9246#%E4%B8%AA%E4%BA%BA%E6%80%9D%E8%80%83)
[文章小结](https://kexue.fm/archives/9246#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [注意力和Softmax的两点有趣发现：鲁棒性和信息量](https://kexue.fm/archives/9593)
- [BERT可以上几年级了？Seq2Seq“硬刚”小学数学应用题](https://kexue.fm/archives/7809)
- [从动力学角度看优化算法（四）：GAN的第三个阶段](https://kexue.fm/archives/6583)
- [【中文分词系列】 7\. 深度学习分词？只需一个词典！](https://kexue.fm/archives/4245)
- [【NASA每日一图】猎户座与彗星](https://kexue.fm/archives/145)
- [素数之美2：Bertrand假设的证明](https://kexue.fm/archives/2800)
- [基于Conv1D的光谱分类模型（一维序列分类）](https://kexue.fm/archives/5505)
- [\[欧拉数学\]素数倒数之和](https://kexue.fm/archives/1510)
- [【空间天文网】2010年天文月历](https://kexue.fm/archives/303)
- [居然是他！奥巴马获得2009年诺贝尔和平奖！](https://kexue.fm/archives/188)

### 最近评论

- [PengchengMa](https://kexue.fm/archives/10996/comment-page-1#comment-27811): 牛啊
- [xczh](https://kexue.fm/archives/10958/comment-page-1#comment-27810): 已使用mean flow policy，一步推理效果确实惊人，性能跟多步推理的diffusio...
- [Cosine](https://kexue.fm/archives/10945/comment-page-1#comment-27809): 是不是因为shared experts每次都激活，而routed experts是依概率被选中...
- [rpsun](https://kexue.fm/archives/10699/comment-page-1#comment-27808): 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减掉之后做正交分解。那么如果单纯地...
- [贵阳机场接机](https://kexue.fm/archives/1490/comment-page-1#comment-27807): 怎么不更新啦
- [czvzb](https://kexue.fm/archives/10958/comment-page-1#comment-27806): 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。
苏神推荐你看这几篇文章：
1....
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27802): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...
- [OceanYU](https://kexue.fm/archives/9164/comment-page-4#comment-27801): 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）只能保证关于x\_t-1是二次函数...
- [jorjiang](https://kexue.fm/archives/10907/comment-page-2#comment-27800): 训练和prefill这个compute-bound阶段不做矩阵吸收，这个用我这个解释更好理解了...
- [amy](https://kexue.fm/archives/10907/comment-page-2#comment-27799): 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工作的看法是什么，这篇工作可以wo...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。