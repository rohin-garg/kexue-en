## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [通过msign来计算mclip（奇...](https://kexue.fm/archives/11006)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [从无穷范数求导到等值振荡定理](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)

## COMMENTS

- [PengchengMa: 牛啊](https://kexue.fm/archives/10996/comment-page-1#comment-27811)
- [xczh: 已使用mean flow policy，一步推理效果确实惊人，...](https://kexue.fm/archives/10958/comment-page-1#comment-27810)
- [Cosine: 是不是因为shared experts每次都激活，而route...](https://kexue.fm/archives/10945/comment-page-1#comment-27809)
- [rpsun: 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减...](https://kexue.fm/archives/10699/comment-page-1#comment-27808)
- [贵阳机场接机: 怎么不更新啦](https://kexue.fm/archives/1490/comment-page-1#comment-27807)
- [czvzb: 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。...](https://kexue.fm/archives/10958/comment-page-1#comment-27806)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27802)
- [OceanYU: 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）...](https://kexue.fm/archives/9164/comment-page-4#comment-27801)
- [jorjiang: 训练和prefill这个compute-bound阶段不做矩阵...](https://kexue.fm/archives/10907/comment-page-2#comment-27800)
- [amy: 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工...](https://kexue.fm/archives/10907/comment-page-2#comment-27799)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 如何划分一个跟测试集更接近的验证集？

16Oct

# [如何划分一个跟测试集更接近的验证集？](https://kexue.fm/archives/7805)

By 苏剑林 \|
2020-10-16 \|
70169位读者\|

不管是打比赛、做实验还是搞工程，我们经常会遇到训练集与测试集分布不一致的情况。一般来说我们会从训练集中划分出来一个验证集，通过这个验证集来调整一些超参数（参考 [《训练集、验证集和测试集的意义》](https://kexue.fm/archives/4638)），比如控制模型的训练轮数以防止过拟合。然而，如果验证集本身跟测试集差别比较大，那么验证集上很好的模型也不代表在测试集上很好，因此如何让划分出来验证集跟测试集的分布差异更小一些，是一个值得研究的题目。

## 两种情况 [\#](https://kexue.fm/archives/7805\#%E4%B8%A4%E7%A7%8D%E6%83%85%E5%86%B5)

首先，明确一下，本文所考虑的，是能给拿到测试集数据本身、但不知道测试集标签的场景。如果是那种提交模型封闭评测的场景，我们完全看不到测试集的，那就没什么办法了。为什么会出现测试集跟训练集分布不一致的现象呢？主要有两种情况。

第一种是 **标签** 的分布不一致。也就是说，如果只看输入$x$，那么分布基本上是差不多的，但是对应的$y$分布不一样，典型的例子就是信息抽取任务，训练集往往是通过“远程监督 + 人工粗标”的方式构建的，量很大，但是里边可能错漏比较多，而测试集可能是通过“人工反复精标”构建的，错漏很少。这种情况下就无法通过划分数据的方式构建一个更好的验证集了。

第二种是 **输入** 的分布不一致。说白了就是$x$的分布不一致，但是$y$的标注情况基本上是正确的。比如分类问题中，训练集的类别分布跟测试集的类别分布可能不一样；又或者在阅读理解问题中，训练集的事实类/非事实类题型比例跟测试集不一样，等等。这种情况下我们可以适当调整采样策略，使得验证集跟测试集分布更一致些，从而验证集的结果能够更好反映测试集的结果。

## 判别器 [\#](https://kexue.fm/archives/7805\#%E5%88%A4%E5%88%AB%E5%99%A8)

为了达到我们的目的，我们让训练集的标签为0，测试集的标签为1，训练一个二分类判别器$D(x)$：
\\begin{equation}-\\mathbb{E}\_{x\\sim p(x)}\[\\log (1 - D(x))\] - \\mathbb{E}\_{x\\sim q(x)}\[\\log D(x)\]\\end{equation}
其中$p(x)$代表了训练集的分布，$q(x)$则是测试集的分布。要注意的是，我们不是要将训练集和测试集直接混合起来采样训练，而是分别从训练集和测试集采样同样多的样本来组成每一个batch，也就是说需要过采样到类别均衡。

可能有读者担心过拟合问题，即判别器彻底地训练集和测试集分开了。事实上，在训练判别器的时候，我们应该也要像普通监督训练一样，划分个验证集出来，通过验证集决定训练的epoch数，这样就不会严重过拟合了；或者像网上有些案例一样，直接用逻辑回归做判别器，因为逻辑回归足够简单，过拟合风险也更小了。

跟GAN的判别器类似，不难推导$D(x)$的理论最优解是
\\begin{equation}D(x) = \\frac{q(x)}{p(x)+q(x)}\\label{eq:d}\\end{equation}
也就是说，判别器训练完后，可以认为它就等于测试集分布的相对大小。

## 重要性采样 [\#](https://kexue.fm/archives/7805\#%E9%87%8D%E8%A6%81%E6%80%A7%E9%87%87%E6%A0%B7)

优化模型也好，算指标也好，其实我们是希望在测试集上进行，也就是说，对于给定目标$f(x)$（比如模型的loss），我们希望算的是
\\begin{equation}\\mathbb{E}\_{x\\sim q(x)}\[f(x)\] = \\int q(x) f(x) dx\\end{equation}
但是要算目标$f(x)$通常要知道$x$的真实标签，但对于测试集来说我们不知道它的标签，所以不能直接算。不过我们知道训练集的标签，于是我们可以解决它来做重要性采样：
\\begin{equation}\\int q(x) f(x) dx=\\int p(x)\\frac{q(x)}{p(x)} f(x) dx=\\mathbb{E}\_{x\\sim p(x)}\\left\[\\frac{q(x)}{p(x)} f(x)\\right\]\\end{equation}
根据公式$\\eqref{eq:d}$，我们知道$\\frac{q(x)}{p(x)}=\\frac{D(x)}{1-D(x)}$，所以最终变成
\\begin{equation}\\mathbb{E}\_{x\\sim q(x)}\[f(x)\] = \\mathbb{E}\_{x\\sim p(x)}\\left\[\\frac{D(x)}{1-D(x)} f(x)\\right\]\\label{eq:w}\\end{equation}
说白了，重要性采样的思想就是从训练集里边“挑出”那些跟测试集相近的样本，赋予更高的权重。

## 最终策略 [\#](https://kexue.fm/archives/7805\#%E6%9C%80%E7%BB%88%E7%AD%96%E7%95%A5)

从公式$\\eqref{eq:w}$，我们可以得到两个策略：

第一是直接按照公式加权，也就是说，还是按随机打乱的方式划分训练集和验证集，但是给每个样本配上权重$w(x)=\\frac{D(x)}{1-D(x)}$。值得指出的是，类似的做法有些选手做比赛时已经用过了，只不过流传的权重是$D(x)$，当然哪个好我没法断言，只是从理论推导的角度来看应该是$\\frac{D(x)}{1-D(x)}$更加合理一些。

另一个策略就是实际地把对应的验证集采样出来。这也不难，假设训练集的所有样本为$x\_1,x\_2,\\dots,x\_N$，我们把权重归一化
\\begin{equation}p\_i = \\frac{w(x\_i)}{\\sum\\limits\_{i=1}^N w(x\_i)}\\end{equation}
然后按照$p\_1,p\_2,\\dots,p\_N$为分布做独立重复采样，直到采样到指定数目即可。注意需要做有放回的独立重复采样，因此同一个样本可能被采样多次，在验证集里边也要保留多次，不能去重，去重后分布就不一致了。

## 文末小结 [\#](https://kexue.fm/archives/7805\#%E6%96%87%E6%9C%AB%E5%B0%8F%E7%BB%93)

本文从训练判别器的角度来比较训练集和测试集的差异，并且结合重要性采样，我们可以得到一个跟测试集更接近的验证集，或者对训练样本进行加权，从而使得训练集的优化过程和测试集差异性更小。

_**转载到请包括本文地址：** [https://kexue.fm/archives/7805](https://kexue.fm/archives/7805)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/7805#share)/ [打赏](https://kexue.fm/archives/7805#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Oct. 16, 2020). 《如何划分一个跟测试集更接近的验证集？ 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/7805](https://kexue.fm/archives/7805)

@online{kexuefm-7805,
        title={如何划分一个跟测试集更接近的验证集？},
        author={苏剑林},
        year={2020},
        month={Oct},
        url={\\url{https://kexue.fm/archives/7805}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/), [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/), [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/), [采样](https://kexue.fm/tag/%E9%87%87%E6%A0%B7/)[16 评论](https://kexue.fm/archives/7805#comments)

< [从动力学角度看优化算法（五）：为什么学习率不宜过小？](https://kexue.fm/archives/7787) \| [BERT可以上几年级了？Seq2Seq“硬刚”小学数学应用题](https://kexue.fm/archives/7809) >

### 你也许还对下面的内容感兴趣

- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [Transformer升级之路：20、MLA究竟好在哪里？](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [MoE环游记：4、难处应当多投入](https://kexue.fm/archives/10815)
- [MoE环游记：1、从几何意义出发](https://kexue.fm/archives/10699)
- [为什么梯度裁剪的默认模长是1？](https://kexue.fm/archives/10657)
- [从谱范数梯度到新式权重衰减的思考](https://kexue.fm/archives/10648)
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633)
- [生成扩散模型漫谈（二十七）：将步长作为条件输入](https://kexue.fm/archives/10617)

[发表你的看法](https://kexue.fm/archives/7805#comment_form)

陈建忠

October 19th, 2020

完全看不懂，(1)式用来干啥呢 ？D(x)既然是训练得到的判别器，那(2)代表什么呢？f(x)实际对应什么呢？逻辑完全串不起来

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14586#respond-post-7805)

[苏剑林](https://kexue.fm) 发表于
October 19th, 2020

$(1)$式是判别器的训练目标，$(2)$是判别器的理论最优解，$f(x)$对应着我们要求期望的目标（损失函数、acc等）。如果看不懂，可以选择不看或者只看结论。

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14587#respond-post-7805)

王晶

October 21st, 2020

第一种直接按照公式加权，指的是训练集的数据加权训练吗？
还有一个问题，为什么判别器是要用稍微简单一些的模型？感觉稍微有些过拟合会更好一些吧

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14602#respond-post-7805)

[苏剑林](https://kexue.fm) 发表于
October 22nd, 2020

1、训练集和验证集都加权；

2、简单是为了在没有验证集的情况下防止过拟合罢了，如果你用复杂的模型，那么训练判别器的过程中也需要按照常规方式划分一个验证集出来做earlystop，不然按照神经网络的万能拟合能力，只要训练集和测试集的样本没有全匹配的，就能彻底区分开来。

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14604#respond-post-7805)

Mowar

October 23rd, 2020

有现成的代码资源供参考

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14611#respond-post-7805)

没有名字

October 26th, 2020

请问公式（2）是怎么推导出来了，能详细解释一下吗？谢谢

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14642#respond-post-7805)

[苏剑林](https://kexue.fm) 发表于
October 27th, 2020

$$-\\mathbb{E}\_{x\\sim p(x)}\[\\log (1 - D(x))\] - \\mathbb{E}\_{x\\sim q(x)}\[\\log D(x)\]=-\\int \\left\[p(x)\\log (1 - D(x)) + q(x)\\log D(x)\\right\]dx$$
所以也就是求$p(x)\\log (1 - D(x)) + q(x)\\log D(x)$的最大值（如果每一点都取最大，那么积分肯定也最大），省去$(x)$，就相当于求$p\\log (1 - D) + q\\log D$的最大值，这不用问了吧～

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14652#respond-post-7805)

没有名字 发表于
October 28th, 2020

非常感谢，有泛函的入门书推荐吗？

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14655#respond-post-7805)

[苏剑林](https://kexue.fm) 发表于
October 28th, 2020

估计你只是想学变分法相关部分而不是真正要学泛函？如果是这样的话，你可以看看朗道《力学》第一章。

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14657#respond-post-7805)

没有名字 发表于
October 28th, 2020

$F=p \\log(1-D) + q \\log(D)$

$\\frac{\\partial F}{\\partial D} = - \\frac{p}{1-D} + \\frac{q}{D}=0$

$\\frac{p}{1-D} = \\frac{q}{D}$

$D=\\frac{q}{p+q}$

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=14656#respond-post-7805)

jotline

April 25th, 2021

如何从真实的在线数据抽样得到测试数据集，苏神有没有一套方法论呢？
因为真实的模型上线，评估的往往是业务指标，有两个问题就是
1\. 业务指标和模型测试阶段所用的指标有很大差距。
2\. 真实在线数据往往和我们所用的测试数据也存在较大差距。

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=16207#respond-post-7805)

[苏剑林](https://kexue.fm) 发表于
April 25th, 2021

这个就是根据你们自己的真实业务数据做采样吧，这方面我没啥方法论呀。

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=16209#respond-post-7805)

[JiaxiangBU](https://github.com/JiaxiangBU)

December 13th, 2021

苏神这个方法(苏剑林 2020)我关注了一段时间了，一直没有找到学术上的索引，
大部分看到的研究是 OOD 相关的(Deng and Zheng 2020)，或者是欠规范（Underspecification）(D’Amour et al. 2020)、LeCun 最近给的 interpolation(Balestriero, Pesenti, and LeCun 2021)，但是都不是苏神这种在 train 和 test 上比较的思想。

最近找文献终于看到了相关研究，Conformal inference，Vladimir Vovk 1990年的研究。苏神这种方法对应 Weighted conformal prediction(Tibshirani et al. 2020)，其实就是看 test to train ratio 来构建 ‘non-conformity scores’。

补充下相关文献历史，也算回馈一直依赖这个受益匪浅的博客。

Balestriero, Randall, Jerome Pesenti, and Yann LeCun. 2021. “Learning in High Dimension Always Amounts to Extrapolation.” http://arxiv.org/abs/2110.09485.
D’Amour, Alexander, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel, Christina Chen, et al. 2020. “Underspecification Presents Challenges for Credibility in Modern Machine Learning.” http://arxiv.org/abs/2011.03395.
Deng, Weijian, and Liang Zheng. 2020. “Are Labels Necessary for Classifier Accuracy Evaluation?” arXiv Preprint arXiv:2007.02915.
Tibshirani, Ryan J., Rina Foygel Barber, Emmanuel J. Candes, and Aaditya Ramdas. 2020. “Conformal Prediction Under Covariate Shift.” http://arxiv.org/abs/1904.06019.
苏剑林. 2020\. “如何划分一个跟测试集更接近的验证集？.” 科学空间. 2020. [https://kexue.fm/archives/7805.](https://kexue.fm/archives/7805.)

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=18016#respond-post-7805)

[苏剑林](https://kexue.fm) 发表于
December 14th, 2021

感谢你的追根溯源哈，非常宝贵的参考资料～

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=18026#respond-post-7805)

[JiaxiangBU](https://jiaxiangli.netlify.app) 发表于
January 19th, 2022

最近又看了一部分文献，发现这个 idea 也是 "Adversarial Validation"，但是没有找到和 conformal inference 的关联性文献。

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=18270#respond-post-7805)

[JiaxiangBU](https://jiaxiangli.netlify.app) 发表于
January 19th, 2022

如 Pan et al. (2020) 这不是一个学术很关注的领域。

Pan, Jing, Vincent Pham, Mohan Dorairaj, Huigang Chen, and Jeong-Yoon Lee. 2020. “Adversarial Validation Approach to Concept Drift Problem in User Targeting Automation Systems at Uber.” https://arxiv.org/abs/2004.03045.

[回复评论](https://kexue.fm/archives/7805/comment-page-1?replyTo=18271#respond-post-7805)

[取消回复](https://kexue.fm/archives/7805#respond-post-7805)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请不要重复点击提交。

### 内容速览

[两种情况](https://kexue.fm/archives/7805#%E4%B8%A4%E7%A7%8D%E6%83%85%E5%86%B5)
[判别器](https://kexue.fm/archives/7805#%E5%88%A4%E5%88%AB%E5%99%A8)
[重要性采样](https://kexue.fm/archives/7805#%E9%87%8D%E8%A6%81%E6%80%A7%E9%87%87%E6%A0%B7)
[最终策略](https://kexue.fm/archives/7805#%E6%9C%80%E7%BB%88%E7%AD%96%E7%95%A5)
[文末小结](https://kexue.fm/archives/7805#%E6%96%87%E6%9C%AB%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [《自然极值》系列——3.平衡态公理](https://kexue.fm/archives/1072)
- [Naive Bayes is all you need ?](https://kexue.fm/archives/9648)
- [你的CRF层的学习率可能不够大](https://kexue.fm/archives/7196)
- [从动力学角度看优化算法（六）：为什么SimSiam不退化？](https://kexue.fm/archives/7980)
- [把Python脚本放到手机上定时运行](https://kexue.fm/archives/3477)
- [【竖直上抛】炮弹能够射多高(第二宇宙速度)？](https://kexue.fm/archives/342)
- [三次方程求根器(VB程序+源码,“低手”拙作)](https://kexue.fm/archives/840)
- [《自然极值》系列——2.费马原理](https://kexue.fm/archives/1068)
- [变分与理论力学略览](https://kexue.fm/archives/1304)
- [话说金属活动性顺序](https://kexue.fm/archives/89)

### 最近评论

- [PengchengMa](https://kexue.fm/archives/10996/comment-page-1#comment-27811): 牛啊
- [xczh](https://kexue.fm/archives/10958/comment-page-1#comment-27810): 已使用mean flow policy，一步推理效果确实惊人，性能跟多步推理的diffusio...
- [Cosine](https://kexue.fm/archives/10945/comment-page-1#comment-27809): 是不是因为shared experts每次都激活，而routed experts是依概率被选中...
- [rpsun](https://kexue.fm/archives/10699/comment-page-1#comment-27808): 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减掉之后做正交分解。那么如果单纯地...
- [贵阳机场接机](https://kexue.fm/archives/1490/comment-page-1#comment-27807): 怎么不更新啦
- [czvzb](https://kexue.fm/archives/10958/comment-page-1#comment-27806): 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。
苏神推荐你看这几篇文章：
1....
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27802): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...
- [OceanYU](https://kexue.fm/archives/9164/comment-page-4#comment-27801): 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）只能保证关于x\_t-1是二次函数...
- [jorjiang](https://kexue.fm/archives/10907/comment-page-2#comment-27800): 训练和prefill这个compute-bound阶段不做矩阵吸收，这个用我这个解释更好理解了...
- [amy](https://kexue.fm/archives/10907/comment-page-2#comment-27799): 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工作的看法是什么，这篇工作可以wo...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。