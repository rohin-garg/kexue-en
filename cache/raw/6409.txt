## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [生成扩散模型漫谈（三十一）：预测数...](https://kexue.fm/archives/11428)
- [Muon优化器指南：快速上手与关键细节](https://kexue.fm/archives/11416)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11404)
- [n个正态随机数的最大值的渐近估计](https://kexue.fm/archives/11390)
- [流形上的最速下降：5\. 对偶梯度下降](https://kexue.fm/archives/11388)
- [低精度Attention可能存在有...](https://kexue.fm/archives/11371)
- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328)
- [为什么线性注意力要加Short C...](https://kexue.fm/archives/11320)

## COMMENTS

- [ssuycbmbfNVCLxxsyhs: EFWcYHwLOnRqnHufHKZfJxsB](https://kexue.fm/archives/3913/comment-page-2#comment-28934)
- [qsh: 用muon的时候weights initialization有...](https://kexue.fm/archives/11416/comment-page-1#comment-28933)
- [夺宇: 苏老师的解释和推导好自然啊，比原论文更容易看懂](https://kexue.fm/archives/9152/comment-page-3#comment-28932)
- [夺宇: 苏老师，(17)式中的噪声项可以直接在(8)式中直接添加吗？(...](https://kexue.fm/archives/9119/comment-page-13#comment-28931)
- [Xiaozhi Zhu: 我觉得这个work摆脱了two stages，真正做到E2E，...](https://kexue.fm/archives/11428/comment-page-1#comment-28930)
- [wednesday: 想问问苏老师的数据挖掘学习思路或者学习路径是怎样的](https://kexue.fm/archives/3319/comment-page-1#comment-28929)
- [wednesday: 因为我们只对p(Y\|X)建模，因此$p\_{\\theta}(X)...](https://kexue.fm/archives/5239/comment-page-3#comment-28928)
- [ykwen: 不动点迭代的时候 有没有可能迭代到0附近呢？](https://kexue.fm/archives/10592/comment-page-3#comment-28927)
- [wednesday: 这是针对评论区一位同学问题的提问，现在已经懂了](https://kexue.fm/archives/5253/comment-page-18#comment-28926)
- [wednesday: 针对一个样本和针对一个batch有什么特别的区别吗](https://kexue.fm/archives/5253/comment-page-18#comment-28925)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) O-GAN：简单修改，让GAN的判别器变成一个编码器！

6Mar

# [O-GAN：简单修改，让GAN的判别器变成一个编码器！](https://kexue.fm/archives/6409)

By 苏剑林 \|
2019-03-06 \|
327399位读者\|

本文来给大家分享一下笔者最近的一个工作：通过简单地修改原来的GAN模型，就可以让判别器变成一个编码器，从而让GAN同时具备生成能力和编码能力，并且几乎不会增加训练成本。这个新模型被称为 **O-GAN**（正交GAN，即Orthogonal Generative Adversarial Network），因为它是基于对判别器的正交分解操作来完成的，是对判别器自由度的最充分利用。

> **Arxiv链接：** [https://papers.cool/arxiv/1903.01931](https://papers.cool/arxiv/1903.01931)
>
> **开源代码：** [https://github.com/bojone/o-gan](https://github.com/bojone/o-gan)

## 背景 [\#](https://kexue.fm/kexue.fm\#%E8%83%8C%E6%99%AF)

笔者掉进生成模型的大坑已经很久时间了，不仅在博客中写了多篇有关生成模型的博文，而且还往arxiv上也提交了好几篇跟生成模型相关的小paper。自掉坑以来，虽然说对生成模型尤其是GAN的理解渐深，有时也觉得自己做出了一点改进工作（所以才提交到arxiv上），但事实上那些东西都是无关痛痒的修修补补，意义实在不大。

而本文要介绍的这个模型，自认为比以往我做的所有GAN相关工作的价值总和还要大：它提供了目前最简单的方案，来训练一个具有编码能力的GAN模型。

现如今，GAN已经越来越成熟，越做越庞大，诸如BigGAN、StyleGAN等算是目前最先进的GAN模型也已被人熟知，甚至玩得不亦乐乎。不过，这几个最先进的GAN模型，目前都只有生成器功能，没有编码器功能，也就是说可以源源不断地生成新图片，却不能对已有的图片提取特征。

当然，带有编码器的GAN也有不少研究，甚至本博客中就曾做过（参考 [《BiGAN-QP：简单清晰的编码&生成模型》](https://kexue.fm/archives/6214)）。但不管有没有编码能力，大部分GAN都有一个特点：训练完成后，判别器都是没有用的。因为理论上越训练，判别器越退化（比如趋于一个常数）。

做过GAN的读者都知道，GAN的判别器和生成器两个网络的复杂度是相当的（如果还有编码器，那么复杂度也跟它们相当），训练完GAN后判别器就不要了，那实在是对判别器这个庞大网络的严重浪费！一般来说，判别器的架构跟编码器是很相似的，那么一个很自然的想法是能不能让判别器和编码器共享大部分权重？据笔者所知，过去所有的GAN相关的模型中，只有 [IntroVAE](https://papers.cool/arxiv/1807.06358) 做到了这一点。但相对而言IntroVAE的做法还是比较复杂的，而且目前网上还没有成功复现IntroVAE的开源代码（笔者也尝试复现过，但也失败了。）。

而本文的方案则极为简单——通过稍微修改原来的GAN模型，就可以让判别器转变为一个编码器，不管是复杂度还是计算量都几乎没有增加。

## 模型 [\#](https://kexue.fm/kexue.fm\#%E6%A8%A1%E5%9E%8B)

事不宜迟，马上来介绍这个模型。首先引入一般的GAN写法
\\begin{equation}\\begin{aligned}D =& \\mathop{\\text{argmin}}\_{D} \\mathbb{E}\_{x\\sim p(x), z\\sim q(z)}\\Big\[f(D(x)) + g(D(G(z)))\\Big\]\\\
G =& \\mathop{\\text{argmin}}\_{G} \\mathbb{E}\_{z\\sim q(z)}\\Big\[h(D(G(z)))\\Big\]
\\end{aligned}\\end{equation}
为了不至于混淆，这里还是不厌其烦地对符号做一些说明。其中$x\\in \\mathbb{R}^{n\_x},z\\in \\mathbb{R}^{n\_z}$， $p(x)$是真实图片集的“证据分布”，$q(z)$是噪声的分布（在本文中，它是$n\_z$元标准正态分布）；而$G: \\mathbb{R}^{n\_z} \\to \\mathbb{R}^{n\_x}$和$D: \\mathbb{R}^{n\_x} \\to \\mathbb{R}$自然就是生成器和判别器了，$f,g,h$则是一些确定的函数，不同的GAN对应着不同的$f,h,g$。有时候我们会加一些标准化或者正则化手段上去，比如谱归一化或者梯度惩罚，简单起见，这些手段就不明显地写出来了。

然后定义几个向量算符：
\\begin{equation}\\text{avg}(z)=\\frac{1}{n\_z}\\sum\_{i=1}^{n\_z} z\_i,\\quad \\text{std}(z)=\\sqrt{\\frac{1}{n\_z}\\sum\_{i=1}^{n\_z} (z\_i-\\text{avg}(z))^2}, \\quad \\mathcal{N}(z)=\\frac{z - \\text{avg}(z)}{\\text{std}(z)}\\end{equation}
写起来貌似挺高大上的，但其实就是向量各元素的均值、方差，以及标准化的向量。特别指出的是，当$n\_z \\geq 3$时（真正有价值的GAN都满足这个条件），$\\left\[\\text{avg}(z), \\text{std}(z), \\mathcal{N}(z)\\right\]$是函数无关的，也就是说它相当于是原来向量$z$的一个“正交分解”。

接着，我们已经说了判别器的结构其实和编码器有点类似，只不过编码器输出一个向量而判别器输出一个标量罢了，那么我可以把判别器写成复合函数：
\\begin{equation}D(x)\\triangleq T(E(x))\\end{equation}
这里$E$是$\\mathbb{R}^{n\_x} \\to \\mathbb{R}^{n\_z}$的映射，而$T$是$\\mathbb{R}^{n\_z} \\to \\mathbb{R}$的映射。不难想象，$E$的参数量会远远多于$T$的参数量，我们希望$E(x)$具有编码功能。

怎么实现呢？只需要加一个loss：Pearson相关系数！
\\begin{equation}\\begin{aligned}T,E =& \\mathop{\\text{argmin}}\_{T,E} \\mathbb{E}\_{x\\sim p(x), z\\sim q(z)}\\Big\[f(T(E(x))) + g(T(E(G(z)))) - \\lambda \\rho(z, E(G(z)))\\Big\]\\\
G =& \\mathop{\\text{argmin}}\_{G} \\mathbb{E}\_{z\\sim q(z)}\\Big\[h(T(E(G(z)))) - \\lambda \\rho(z, E(G(z)))\\Big\]
\\end{aligned}\\end{equation}
其中
\\begin{equation}\\rho(z, \\hat{z})=\\frac{\\sum\\limits\_{i=1}^{n\_z} (z\_i - \\text{avg}(z))(\\hat{z}\_i - \\text{avg}(\\hat{z}))/n\_z}{\\text{std}(z)\\times \\text{std}(\\hat{z})}=\\cos(\\mathcal{N}(z), \\mathcal{N}(E(G(z))))\\end{equation}

如果$\\lambda=0$，那么就是普通的GAN而已（只不过判别器被分解为两部分$E$和$T$两部分）。加上了这个相关系数，直观上来看，就是希望$z$和$E(G(z))$越线性相关越好。为什么要这样加？我们留到最后讨论。

显然这个相关系数可以嵌入到任意现成的GAN中，改动量显然也很小（拆分一下判别器、加一个loss），笔者也做了多种GAN的实验，发现都能成功训练。

这样一来，GAN的判别器$D$分为了$E$和$T$两部分，$E$变成了编码器，也就是说，判别器的大部分参数已经被利用上了。但是还剩下$T$，训练完成后$T$也是没用的，虽然$T$的参数量比较少，这个浪费量是很少的，但对于有“洁癖”的人（比如笔者）来说还是很难受的。

能不能把$T$也省掉？经过笔者多次试验，结论是：还真能！因为我们可以直接用$\\text{avg}(E(x))$做判别器：
\\begin{equation}\\begin{aligned}E =& \\mathop{\\text{argmin}}\_{E} \\mathbb{E}\_{x\\sim p(x), z\\sim q(z)}\\Big\[f(\\text{avg}(E(x))) + g(\\text{avg}(E(G(z)))) - \\lambda \\rho(z, E(G(z)))\\Big\]\\\
G =& \\mathop{\\text{argmin}}\_{G} \\mathbb{E}\_{z\\sim q(z)}\\Big\[h(\\text{avg}(E(G(z)))) - \\lambda \\rho(z, E(G(z)))\\Big\]
\\end{aligned}\\label{eq:simplest}\\end{equation}
这样一来整个模型中已经没有$T$了，只有纯粹的生成器$G$和编码器$E$，整个模型没有丝毫冗余的地方～（洁癖患者可以不纠结了）

## 实验 [\#](https://kexue.fm/kexue.fm\#%E5%AE%9E%E9%AA%8C)

这样做为什么可以？我们放到最后再说。先看看实验效果，毕竟实验不好的话，原理说得再漂亮也没有意义。

注意，理论上来讲，本文引入的相关系数项并不能提高生成模型的质量，所以实验的目标主要有两个：1、这个额外的loss会不会有损原来生成模型的质量；2、这个额外的loss是不是真的可以让$E$变成一个有效的编码器？

刚才也说，这个方法可以嵌入到任意GAN中，这次实验用的是GAN是我之前的 [GAN-QP](https://kexue.fm/archives/6163) 的变种：
\\begin{equation}\\begin{aligned}E =& \\mathop{\\text{argmin}}\_{E} \\mathbb{E}\_{x\\sim p(x), z\\sim q(z)}\\Big\[\\text{avg}(E(x)) - \\text{avg}(E(G(z))) + \\lambda\_1 R\_{x,z} - \\lambda\_2 \\rho(z, E(G(z)))\\Big\]\\\
G =& \\mathop{\\text{argmin}}\_{G} \\mathbb{E}\_{z\\sim q(z)}\\Big\[\\text{avg}(E(G(z))) - \\lambda\_2 \\rho(z, E(G(z)))\\Big\]
\\end{aligned}\\label{eq:simplest-2}\\end{equation}
其中
\\begin{equation}R\_{x,z} = \\frac{\[\\text{avg}(E(x)) - \\text{avg}(E(G(z)))\]^2}{\\Vert x - G(z)\\Vert^2}\\end{equation}

数据集上，这次的实验做得比较完整，在CelebA HQ、FFHQ、LSUN-churchoutdoor、LSUN-bedroom四个数据集上都做了实验，分辨率都是$128\\times 128$（其实还做了一点$256\\times 256$的实验，结果也不错，但是没放到论文上）。模型架构跟以往一样都是DCGAN，其余细节直接看论文或者代码吧。

上图：

CelebA HQ随机生成

CelebA HQ重构效果

CelebA HQ线性插值

FFHQ随机生成

FFHQ重构效果

FFHQ线性插值

LSUN-church随机生成

LSUN-church重构效果

LSUN-church线性插值

LSUN-bedroom随机生成

LSUN-bedroom重构效果

LSUN-bedroom线性插值

不管你们觉得好不好，反正我是觉得还好了～

> 1、 **随机生成** 效果还不错，说明新引入的相关系数项没有降低生成质量；
>
> 2、 **重构** 效果还不错，说明$E(x)$确实提取到了$x$的主要特征；
>
> 3、 **线性插值** 效果还不错，说明$E(x)$确实学习到了接近线性可分的特征。

## 原理 [\#](https://kexue.fm/kexue.fm\#%E5%8E%9F%E7%90%86)

好，确认过眼神，哦不对，是效果，就可以来讨论一下原理了。

很明显，这个额外的重构项的作用就是让$z$尽可能与$E(G(z))$“相关”，对于它，相信大多数读者的第一想法应该是mse损失$\\Vert z - E(G(z))\\Vert^2$而非本文用的$\\rho(z, E(G(z)))$。但事实上，如果加入$\\Vert z - E(G(z))\\Vert^2$那么训练基本上都会失败。那为什么$\\rho(z, E(G(z)))$又会成功呢？

根据前面的定义，$E(x)$输出一个$n\_z$维的向量，但是$T(E(x))$只输出一个标量，也就是说，$E(x)$输出了$n\_z$个自由度，而作为判别器，$T(E(x))$至少要占用一个自由度（当然，理论上它也只需要占用一个自由度）。如果最小化$\\Vert z - E(G(z))\\Vert^2$，那么训练过程会强迫$E(G(z))$完全等于$z$，也就是说$n\_z$个自由度全部被它占用了，没有多余的自由度给判别器来判别真假了，所以加入$\\Vert z - E(G(z))\\Vert^2$大概率都会失败。但是$\\rho(z, E(G(z)))$不一样，$\\rho(z, E(G(z)))$跟$\\text{avg}(E(G(z)))$和$\\text{std}(E(G(z)))$都没关系（只改变向量$E(G(z))$的$\\text{avg}$和$\\text{std}$，不会改变$\\rho(z, E(G(z)))$的值，因为$\\rho$本身就先减均值除标准差了），这意味着就算我们最大化$\\rho(z, E(G(z)))$，我们也留了至少两个自由度给判别器。

这也是为什么在$\\eqref{eq:simplest}$中我们甚至可以直接用$\\text{avg}(E(x))$做判别器，因为它不会被$\\rho(z, E(G(z)))$的影响的。

一个相似的例子是InfoGAN。InfoGAN也包含了一个重构输入信息的模块，这个模块也和判别器共享大部分权重（编码器），而因为InfoGAN事实上只重构部分输入信息，因此重构项也没占满编码器的所有自由度，所以InfoGAN那样做是合理的——只要给判别器留下至少一个自由度。

另外还有一个事实也能帮助我们理解。因为我们在对抗训练的时候，噪声是$z\\sim \\mathcal{N}(0,I\_{n\_z})$的，当生成器训练好之后，那么理论上对所有的$z\\sim \\mathcal{N}(0,I\_{n\_z})$，$G(z)$都会是一张逼真的图片，事实上，反过来也是成立的，如果$G(z)$是一张逼真的图片，那么应该有$z\\sim \\mathcal{N}(0,I\_{n\_z})$（即位于$\\mathcal{N}(0,I\_{n\_z})$的高概率区域）。进一步推论下去，对于$z\\sim \\mathcal{N}(0,I\_{n\_z})$，我们有$\\text{avg}(z)\\approx 0$以及$\\text{std}(z)\\approx 1$。那么，如果$G(z)$是一张逼真的图片，那么必要的条件是$\\text{avg}(z)\\approx 0$以及$\\text{std}(z)\\approx 1$。

应用这个结论，如果我们希望重构效果好，也就是希望$G(E(x))$是一张逼真的图片，那么必要的条件是$\\text{avg}(E(x))\\approx 0$以及$\\text{std}(E(x))\\approx 1$。这就说明，对于一个好的$E(x)$，我们可以认为$\\text{avg}(E(x))$和$\\text{std}(E(x))$都是已知的（分别等于0和1），既然它们是已知的，我们就没有必要拟合它们，换言之，在重构项中可以把它们排除掉。而事实上：
\\begin{equation}-\\rho(z, E(G(z)))\\sim \\left\\Vert \\mathcal{N}(z) - \\mathcal{N}(E(G(z)))\\right\\Vert^2\\end{equation}
也就是说在mse损失中排除掉$\\text{avg}(E(x))$和$\\text{std}(E(x))$的话，然后省去常数，它其实就是$-\\rho(z, E(G(z)))$，这再次说明了$\\rho(z, E(G(z)))$的合理性。并且由这个推导，重构过程并不是$G(E(x))$而是
\\begin{equation}\\hat{x}=G(\\mathcal{N}(E(x)))\\end{equation}

最后，这个额外的重构项理论上还能防止mode collapse的出现。其实很明显，因为重构质量都不错了，生成质量再差也差不到哪里去，自然就不会怎么mode collapse了～非要说数学依据的话，我们可以将$\\rho(z, E(G(z)))$理解为$Z$和$G(Z)$的互信息下界，所以最小化$-\\rho(z, E(G(z)))$事实上在最大化$Z$与$G(Z)$的互信息，这又等价于最大化$G(Z)$的熵。而$G(Z)$的熵大了，表明它的多样性增加了，也就远离了mode collapse。类似的推导可以参考 [《能量视角下的GAN模型（二）：GAN＝“分析”＋“采样”》](https://kexue.fm/archives/6331)。

## 结语 [\#](https://kexue.fm/kexue.fm\#%E7%BB%93%E8%AF%AD)

本文介绍了一个方案，只需要对原来的GAN进行简单的修改，就可以将原来GAN的判别器转化为一个有效的编码器。多个实验表明这样的方案是可行的，而对原理的进一步思考得出，这其实就是对原始判别器（编码器）的一种正交分解，并且对正交分解后的自由度的充分利用，所以模型也被称为“正交GAN（O-GAN）”。

小改动就收获一个编码器，何乐而不为呢？欢迎大家试用～

> **后记：**
>
> 事后看，本文模型的思想其实本质上就是“直径和方向”的分解，并不难理解，但做到这件事情不是那么轻松的。
>
> 最开始我也一直陷入到$\\Vert z - E(G(z))\\Vert^2$的困境中，难以自拔，后来我想了很多技巧，终于在$\\Vert z - E(G(z))\\Vert^2$的重构损失下也稳定住了模型（耗了几个月），但模型变得非常丑陋（引入了三重对抗GAN），于是我着手简化模型。后来我尝试用$\\cos$值用重构损失，发现居然能够简单地收敛了，于是我思考背后的原理，这可能涉及到自由度的问题。
>
> 接着我尝试将$E(x)$分解为模长和方向向量，然后用模长$\\Vert E(x)\\Vert$做判别器，用$\\cos$做重构损失，判别器的loss用hinge loss。这样做其实几何意义很明显，说起来更漂亮些，部分数据集是work的，但是通用性不好（CelebA还行，LSUN不行），而且还有一个问题是$\\Vert E(x)\\Vert$非负，无法嵌入到一般的GAN，很多稳定GAN的技巧都不能用。
>
> 然后我想怎么把模长变成可正可负，开始想着可以对模长取对数，这样小于1的模长取对数后变成负数，大于1的模长取对数变成正数，思然达成了目的。但是很遗憾，效果还是不好。后来陆续实验了诸多方案都不成功，最后终于想到可以放弃模长（对应于方差）做判别器的loss，直接用均值就行了～～所以后来转换成$\\text{avg}(E(x))$，这个转变经历了相当长的时间。
>
> 还有，重构损失一般认为要度量$x$和$G(E(x))$的差异，而我发现只需要度量$z$和$E(G(z))$的差异，这是最低成本的方案，因为重构是需要额外的时间的。最后，我还做过很多实验，很多想法哪怕在CelebA上都能成功，但LSUN上就不行。所以，最后看上去简单的模型，实际上是艰难的沉淀。
>
> 整个模型源于我的一个执念：判别器既然具有编码器的结构，那么就不能被浪费掉。加上有IntroVAE的成功案例在先，我相信一定会有更简单的方案实现这一点。前前后后实验了好几个月，跑了上百个模型，直到最近终于算是完整地解决了这个问题。
>
> 对了，除了IntroVAE，对我启发特别大的还有 [Deep Infomax](https://kexue.fm/archives/6024) 这篇论文，Deep Infomax最后的附录里边提供了一种新的做GAN的思路，我开始也是从那里的方法着手思考新模型的。

_**转载到请包括本文地址：** [https://kexue.fm/archives/6409](https://kexue.fm/archives/6409)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Mar. 06, 2019). 《O-GAN：简单修改，让GAN的判别器变成一个编码器！ 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/6409](https://kexue.fm/archives/6409)

@online{kexuefm-6409,
        title={O-GAN：简单修改，让GAN的判别器变成一个编码器！},
        author={苏剑林},
        year={2019},
        month={Mar},
        url={\\url{https://kexue.fm/archives/6409}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/), [GAN](https://kexue.fm/tag/GAN/), [生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/), [编码](https://kexue.fm/tag/%E7%BC%96%E7%A0%81/)[101 评论](https://kexue.fm/archives/6409#comments)

< [构造一个显式的、总是可逆的矩阵](https://kexue.fm/archives/6407) \| [“让Keras更酷一些！”：分层的学习率和自由的梯度](https://kexue.fm/archives/6418) >

### 你也许还对下面的内容感兴趣

- [生成扩散模型漫谈（三十一）：预测数据而非噪声](https://kexue.fm/archives/11428)
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328)
- [为什么线性注意力要加Short Conv？](https://kexue.fm/archives/11320)
- [Transformer升级之路：21、MLA好在哪里?（下）](https://kexue.fm/archives/11111)
- [线性注意力简史：从模仿、创新到反哺](https://kexue.fm/archives/11033)
- [生成扩散模型漫谈（三十）：从瞬时速度到平均速度](https://kexue.fm/archives/10958)
- [Transformer升级之路：20、MLA好在哪里?（上）](https://kexue.fm/archives/10907)
- [生成扩散模型漫谈（二十九）：用DDPM来离散编码](https://kexue.fm/archives/10711)
- [细水长flow之TARFLOW：流模型满血归来？](https://kexue.fm/archives/10667)
- [生成扩散模型漫谈（二十八）：分步理解一致性模型](https://kexue.fm/archives/10633)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

1. [«](https://kexue.fm/archives/6409/comment-page-3#comments)
2. [1](https://kexue.fm/archives/6409/comment-page-1#comments)
3. [2](https://kexue.fm/archives/6409/comment-page-2#comments)
4. [3](https://kexue.fm/archives/6409/comment-page-3#comments)
5. [4](https://kexue.fm/archives/6409/comment-page-4#comments)

wh

October 28th, 2021

苏神，你好。我使用你的O-GAN代码。训练了几十个epoch后，得到的图像还是纯黑色的。不知道你当时跑代码的时候，遇到过这个问题没有？

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17655#respond-post-6409)

[苏剑林](https://kexue.fm) 发表于
November 1st, 2021

我没有遇到过～

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17684#respond-post-6409)

p\_glay

October 31st, 2021

用pytorch实现了一个https://github.com/GlassyWing/ogan-torch，效果还不错，不过不知道为何加上相关系数损失总是会使得生成样本偏向固定样式，在小样本（样本量 < 5k）时这个问题较明显，celeba这样的数据集倒是看不出来。

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17678#respond-post-6409)

[苏剑林](https://kexue.fm) 发表于
November 1st, 2021

没试验过5k以下的（捂脸～）

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17692#respond-post-6409)

p\_glay 发表于
November 1st, 2021

应该是数据量太少了，判别器太强导致，加了随机数据增强后，就大大缓解了这个问题。

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17695#respond-post-6409)

[苏剑林](https://kexue.fm) 发表于
November 2nd, 2021

那其他GAN变种在小样本的情况下效果更优吗？

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17703#respond-post-6409)

p\_glay 发表于
November 3rd, 2021

其实都一样，在不加数据增强时，都会倾向于生成固定样式，包括WGAN、StyleGAN。只是在OGAN这里，loss项里将相关系数损失移除，多样性确实要好一点，加上后和其它GAN变种在小样本上的情况差不太多。

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17720#respond-post-6409)

[苏剑林](https://kexue.fm) 发表于
November 3rd, 2021

嗯嗯，感谢反馈

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=17723#respond-post-6409)

Ranchod

September 6th, 2022

如果皮尔逊系数改为互信息呢？正常来说，编码器的提取的特征应该是让x和z更相关的

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=19756#respond-post-6409)

[苏剑林](https://kexue.fm) 发表于
September 8th, 2022

$x$与$z$的互信息怎么算？

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=19770#respond-post-6409)

章彦博 发表于
June 29th, 2023

如果x、z的分布都能用多元正态分布的话，倒是不难计算。但你推过之后就会发现，它和皮尔逊系数非常相似。两个正态分布的互信息是他们协方差矩阵行列式之和的对数，再减去他们联合分布的协方差矩阵行列式的对数。但这个会导致z和编码不一致：不论皮尔逊系数是1还是-1，在互信息的度量下都是一样的。

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=22103#respond-post-6409)

[苏剑林](https://kexue.fm) 发表于
July 1st, 2023

对，互信息只能说明相关，不区分正相关还是负相关

[回复评论](https://kexue.fm/archives/6409/comment-page-4?replyTo=22119#respond-post-6409)

1. [«](https://kexue.fm/archives/6409/comment-page-3#comments)
2. [1](https://kexue.fm/archives/6409/comment-page-1#comments)
3. [2](https://kexue.fm/archives/6409/comment-page-2#comments)
4. [3](https://kexue.fm/archives/6409/comment-page-3#comments)
5. [4](https://kexue.fm/archives/6409/comment-page-4#comments)

[取消回复](https://kexue.fm/archives/6409#respond-post-6409)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[背景](https://kexue.fm/kexue.fm#%E8%83%8C%E6%99%AF)
[模型](https://kexue.fm/kexue.fm#%E6%A8%A1%E5%9E%8B)
[实验](https://kexue.fm/kexue.fm#%E5%AE%9E%E9%AA%8C)
[原理](https://kexue.fm/kexue.fm#%E5%8E%9F%E7%90%86)
[结语](https://kexue.fm/kexue.fm#%E7%BB%93%E8%AF%AD)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [节省显存的重计算技巧也有了Keras版了](https://kexue.fm/archives/7367)
- [素数之美1：所有素数之积](https://kexue.fm/archives/2789)
- [隐藏在动量中的梯度累积：少更新几步，效果反而更好？](https://kexue.fm/archives/8634)
- [11月03日美国“发现号”航天飞机“绝唱”](https://kexue.fm/archives/1034)
- [Transformer升级之路：14、当HWFA遇见ReRoPE](https://kexue.fm/archives/9731)
- [《自然极值》系列——1.前言](https://kexue.fm/archives/1065)
- [关于WhiteningBERT原创性的疑问和沟通](https://kexue.fm/archives/8715)
- [班门弄斧：Python的代码能有多简洁？](https://kexue.fm/archives/2971)
- [欢迎注册@spaces.ac.cn的邮箱(更新!)](https://kexue.fm/archives/119)
- [等值振荡定理：最优多项式逼近的充要条件](https://kexue.fm/archives/10972)

### 最近评论

- [ssuycbmbfNVCLxxsyhs](https://kexue.fm/archives/3913/comment-page-2#comment-28934): EFWcYHwLOnRqnHufHKZfJxsB
- [qsh](https://kexue.fm/archives/11416/comment-page-1#comment-28933): 用muon的时候weights initialization有什么讲究吗？还是直接pytorc...
- [夺宇](https://kexue.fm/archives/9152/comment-page-3#comment-28932): 苏老师的解释和推导好自然啊，比原论文更容易看懂
- [夺宇](https://kexue.fm/archives/9119/comment-page-13#comment-28931): 苏老师，(17)式中的噪声项可以直接在(8)式中直接添加吗？(8)式中添加一个噪声项似乎对后续...
- [Xiaozhi Zhu](https://kexue.fm/archives/11428/comment-page-1#comment-28930): 我觉得这个work摆脱了two stages，真正做到E2E，让feature extract...
- [wednesday](https://kexue.fm/archives/3319/comment-page-1#comment-28929): 想问问苏老师的数据挖掘学习思路或者学习路径是怎样的
- [wednesday](https://kexue.fm/archives/5239/comment-page-3#comment-28928): 因为我们只对p(Y\|X)建模，因此$p\_{\\theta}(X)$我们认为就是$\\tilde{p...
- [ykwen](https://kexue.fm/archives/10592/comment-page-3#comment-28927): 不动点迭代的时候 有没有可能迭代到0附近呢？
- [wednesday](https://kexue.fm/archives/5253/comment-page-18#comment-28926): 这是针对评论区一位同学问题的提问，现在已经懂了
- [wednesday](https://kexue.fm/archives/5253/comment-page-18#comment-28925): 针对一个样本和针对一个batch有什么特别的区别吗

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。