## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)
- [随机矩阵的谱范数的快速估计](https://kexue.fm/archives/11335)
- [DiVeQ：一种非常简洁的VQ训练方案](https://kexue.fm/archives/11328)
- [为什么线性注意力要加Short C...](https://kexue.fm/archives/11320)
- [AdamW的Weight RMS的...](https://kexue.fm/archives/11307)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11301)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11285)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11280)
- [为什么Adam的Update RM...](https://kexue.fm/archives/11267)
- [重新思考学习率与Batch Siz...](https://kexue.fm/archives/11260)

## COMMENTS

- [Zhan-Wang Mao: 苏老师，请教一下(4)式的泰勒展开式为什么严格来说和$t$有关...](https://kexue.fm/archives/9257/comment-page-4#comment-28676)
- [yzlnew: 可以相呼应的是，这样的好模型能被浮点数以误差比较低的方式表示和...](https://kexue.fm/archives/11340/comment-page-1#comment-28675)
- [Henry: 想请问苏老师，方程7是如何推导到方程10的，是否有化简的一些小技巧？](https://kexue.fm/archives/9181/comment-page-5#comment-28673)
- [szsheep: 牛啊，还可以从这方面推出loss的函数最终式。原本是从KL散度...](https://kexue.fm/archives/9119/comment-page-13#comment-28672)
- [pang: 对于目前的MLA算法softmax(X×WQ×WukT×CjT...](https://kexue.fm/archives/10862/comment-page-1#comment-28671)
- [苏剑林: 你是说 chatglm2-6b 里边的？那个没用，预设的常数是...](https://kexue.fm/archives/11126/comment-page-3#comment-28670)
- [苏剑林: 已发](https://kexue.fm/archives/443/comment-page-1#comment-28669)
- [苏剑林: 只想要“方向”，步长只是个标量，另外手工控制。](https://kexue.fm/archives/10592/comment-page-2#comment-28668)
- [苏剑林: 参考 https://kexue.fm/archives/10795](https://kexue.fm/archives/11241/comment-page-1#comment-28667)
- [苏剑林: $KV$本身通常就不是low-rank的，所以就无所谓升不升秩...](https://kexue.fm/archives/7546/comment-page-4#comment-28666)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [信息时代](https://kexue.fm/category/Big-Data) 让炼丹更科学一些（一）：SGD的平均损失收敛

19Dec

# [让炼丹更科学一些（一）：SGD的平均损失收敛](https://kexue.fm/archives/9902)

By 苏剑林 \|
2023-12-19 \|
48685位读者\|

很多时候我们将深度学习模型的训练过程戏称为“炼丹”，因为整个过程跟古代的炼丹术一样，看上去有一定的科学依据，但整体却给人一种“玄之又玄”的感觉。尽管本站之前也关注过一些 [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) 相关的工作，甚至也写过 [《从动力学角度看优化算法》](https://kexue.fm/search/%E4%BB%8E%E5%8A%A8%E5%8A%9B%E5%AD%A6%E8%A7%92%E5%BA%A6%E7%9C%8B%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/) 系列，但都是比较表面的介绍，并没有涉及到更深入的理论。为了让以后的炼丹更科学一些，笔者决定去补习一些优化相关的理论结果，争取让炼丹之路多点理论支撑。

在本文中，我们将学习随机梯度下降（SGD）的一个非常基础的收敛结论。虽然现在看来，该结论显得很粗糙且不实用，但它是优化器收敛性证明的一次非常重要的尝试，特别是它考虑了我们实际使用的是随机梯度下降（SGD）而不是全量梯度下降（GD）这一特性，使得结论更加具有参考意义。

## 问题设置 [\#](https://kexue.fm/kexue.fm\#%E9%97%AE%E9%A2%98%E8%AE%BE%E7%BD%AE)

设损失函数是$L(\\boldsymbol{x},\\boldsymbol{\\theta})$，其实$\\boldsymbol{x}$是训练集，而$\\boldsymbol{\\theta}\\in\\mathbb{R}^d$是训练参数。受限于算力，我们通常只能执行随机梯度下降（SGD），即每步只能采样一个训练子集来计算损失函数并更新参数，假设采样是独立同分布的，第$t$步采样到的子集为$\\boldsymbol{x}\_t$，那么我们可以合理地认为实际优化的最终目标是
\\begin{equation}L(\\boldsymbol{\\theta}) = \\lim\_{T\\to\\infty}\\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta})\\label{eq:loss}\\end{equation}
实际情况下，我们也只能训练有限步，所以我们假设$T$是一个足够大的正整常数。我们的目标是寻找$L(\\boldsymbol{\\theta})$的最小值点，即希望找到$\\boldsymbol{\\theta}^\*$：
\\begin{equation}\\boldsymbol{\\theta}^\* = \\mathop{\\text{argmin}}\_{\\boldsymbol{\\theta}\\in\\mathbb{R}^d} L(\\boldsymbol{\\theta})\\label{eq:argmin}\\end{equation}
现在，我们考虑如下SGD迭代：
\\begin{equation}\\boldsymbol{\\theta}\_{t+1} = \\boldsymbol{\\theta}\_t - \\eta\_t \\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\label{eq:sgd}\\end{equation}
其中$\\eta\_t > 0$是学习率，其中$\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta})\\triangleq \\nabla\_{\\boldsymbol{\\theta}}L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta})$是$L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta})$关于$\\boldsymbol{\\theta}$的梯度。我们的任务就是分析如此迭代下去，$\\boldsymbol{\\theta}\_t$是否能够收敛到到目标点$\\boldsymbol{\\theta}^\*$。

## 结论初探 [\#](https://kexue.fm/kexue.fm\#%E7%BB%93%E8%AE%BA%E5%88%9D%E6%8E%A2)

首先，我们给出最终要证明的不等式：在适当的假设之下，有
\\begin{equation}\\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq \\frac{D^2}{2T\\eta\_T} + \\frac{G^2}{2T}\\sum\_{t=1}^T\\eta\_t\\label{neq:core}\\end{equation}

其中$D,G$是跟优化过程无关的常数。后面我们会逐一介绍“适当的假设”具体是什么，在此之前我们先来观察一下不等式$\\eqref{neq:core}$所表达的具体含义：

> 1、左端第一项，是优化过程中每一步的损失函数的平均结果；
>
> 2、左端第二项，根据式$\\eqref{eq:loss}$，当$T$足够大时可以认为它就是$L(\\boldsymbol{\\theta}^\*)$；
>
> 3、左端合并起来，就是优化过程中损失函数的平均与损失函数的理论最小值之差；
>
> 4、右端是一个只与学习率策略$\\{\\eta\_t\\}$有关的式子。

综合1、2、3、4点，不等式$\\eqref{neq:core}$就是说：在适当的假设之下，SGD的平均损失与我们要寻找的理想目标的差距，可以被一个只与学习率策略有关的式子控制，如果我们可以选择适当的学习率让该式趋于零，那么意味着SGD的平均损失一定能收敛到理论最优点。（当然，从理论上来说，该结论只能保证找到损失函数的最小值$L(\\boldsymbol{\\theta}^\*)$，但无法保证找到具体的最小值点$\\boldsymbol{\\theta}^\*$。）

说白了，这就是关于SGD在什么情况下会收敛的一个理论结果。对了，不等式$\\eqref{neq:core}$左端有一个特别的名字，叫做“遗憾”（Regret，有些教程也直接翻译为“悔”）。

## 两个例子 [\#](https://kexue.fm/kexue.fm\#%E4%B8%A4%E4%B8%AA%E4%BE%8B%E5%AD%90)

例如，假设学习率是常数$\\eta$，那么我们有不等式$\\eqref{neq:core}$右端有
\\begin{equation}\\frac{D^2}{2T\\eta} + \\frac{G^2}{2T}\\sum\_{t=1}^T\\eta = \\frac{D^2}{2T\\eta} + \\frac{G^2\\eta}{2}\\geq \\frac{DG}{\\sqrt{T}}\\end{equation}
等号成立时$\\eta=\\frac{D}{G\\sqrt{T}}$，也就是说学习率取常数$\\frac{D}{G\\sqrt{T}}$，那么就有
\\begin{equation}\\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq \\frac{DG}{\\sqrt{T}}\\label{neq:case-1}\\end{equation}
当$T\\to\\infty$时，右端趋于零，这意味着当训练步数$T$足够大时，将学习率设为常数$\\frac{D}{G\\sqrt{T}}$，就可以让SGD迭代的平均与理论最优点的差距任意小。

另一个例子是考虑衰减策略$\\eta\_t = \\frac{\\alpha}{\\sqrt{t}}$，利用
\\begin{equation}\\sum\_{t=1}^T \\frac{1}{\\sqrt{t}} = 1+\\sum\_{t=2}^T \\frac{1}{\\sqrt{t}}\\leq 1+\\sum\_{t=2}^T \\frac{2}{\\sqrt{t-1} + \\sqrt{t}}=1+\\sum\_{t=2}^T 2(\\sqrt{t}-\\sqrt{t-1})=2\\sqrt{T}-1 < 2\\sqrt{T}\\end{equation}
代入式$\\eqref{neq:core}$得到
\\begin{equation}\\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\frac{1}{T}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*) < \\frac{D^2}{2\\alpha\\sqrt{T}} + \\frac{G^2\\alpha}{\\sqrt{T}}\\label{neq:case-2}\\end{equation}
式$\\eqref{neq:case-2}$和式$\\eqref{neq:case-1}$关于$T$都是$\\mathcal{O}\\left(\\frac{1}{\\sqrt{T}}\\right)$的，因此理论上它们都能收敛。跟式$\\eqref{neq:case-1}$相比，式$\\eqref{neq:case-2}$的常数更大，这意味着$\\eta\_t\\equiv\\frac{D}{G\\sqrt{T}}$的收敛速度很可能比$\\eta\_t = \\frac{\\alpha}{\\sqrt{t}}$快。然而，在实际中我们更愿意用后者，因为前者的需要提前确定训练总步数$T$，训练完就结束了并且精度也固定了，后者并没有这些限制，甚至$\\alpha$也不需要调，直接$\\eta\_t = \\frac{1}{\\sqrt{t}}$就可以持续训练下去，并且理论上平均损失与理论最小值的差距会越来越小。

可即便如此，$\\eta\_t = \\frac{1}{\\sqrt{t}}$这种学习率策略，不管在量级或者变化规律上都依然与我们平时训练所用的相距甚远，因此不难猜测里边必然加了不少很强的假设。事不宜迟，我们马上来展开证明过程，逐一展开其中的假设。

## 证明过程 [\#](https://kexue.fm/kexue.fm\#%E8%AF%81%E6%98%8E%E8%BF%87%E7%A8%8B)

证明的开始，我们假设对于任意$\\boldsymbol{x}$，$L(\\boldsymbol{x},\\boldsymbol{\\theta})$都是关于$\\boldsymbol{\\theta}$的凸函数。这是一个非常强且通常非常不符合训练事实的假设，但没办法，理论分析通常都只能做一些很强的假设，然后将这些假设之下的结论启发性地用到实际场景。

凸函数有很多不同的定义方式，这里直接采用如下定义：
\\begin{equation}L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_2) - L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_1) \\geq (\\boldsymbol{\\theta}\_2-\\boldsymbol{\\theta}\_1)\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_1),\\quad \\forall \\boldsymbol{\\theta}\_1,\\boldsymbol{\\theta}\_2\\label{eq:convex}\\end{equation}
其中$\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_1)\\triangleq \\nabla\_{\\boldsymbol{\\theta}}L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta})$是$L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta})$关于$\\boldsymbol{\\theta}$的梯度，$\\cdot$是向量内积，上述定义的几何意义就是凸函数的图像总在其切线（面）的上方。

证明的要点，是考虑$\\boldsymbol{\\theta}\_{t+1}$与$\\boldsymbol{\\theta}^\*$的距离：
\\begin{equation}\\begin{aligned}
\\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\theta}^\*\\Vert^2=&\\, \\Vert\\boldsymbol{\\theta}\_t - \\eta\_t \\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)- \\boldsymbol{\\theta}^\*\\Vert^2 \\\
=&\\, \\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert^2 - 2\\eta\_t (\\boldsymbol{\\theta}\_t- \\boldsymbol{\\theta}^\*)\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) + \\eta\_t^2\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2
\\end{aligned}\\end{equation}
将它改写成
\\begin{equation}(\\boldsymbol{\\theta}\_t- \\boldsymbol{\\theta}^\*)\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) = \\frac{\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t} - \\frac{\\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t} + \\frac{1}{2}\\eta\_t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\\end{equation}
根据式$\\eqref{eq:convex}$，我们有$L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq (\\boldsymbol{\\theta}\_t- \\boldsymbol{\\theta}^\*)\\cdot\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)$，代入上式有
\\begin{equation}L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq \\frac{\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t} - \\frac{\\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t} + \\frac{1}{2}\\eta\_t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\\end{equation}
两端对$t=1,2,\\cdots,T$求和：
\\begin{equation}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\sum\_{t=1}^TL(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq \\sum\_{t=1}^T\\left(\\frac{\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t} - \\frac{\\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t}\\right) + \\sum\_{t=1}^T\\frac{1}{2}\\eta\_t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\\label{neq:base}\\end{equation}
再次引入一个新的假设——$\\eta\_t$是关于$t$的单调递减函数（即$\\eta\_t\\geq \\eta\_{t+1}$），并且记$D = \\max\_t \\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert$，那么就有
\\begin{equation}\\begin{aligned}
&\\,\\sum\_{t=1}^T\\left(\\frac{\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t} - \\frac{\\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_t}\\right)\\\
=&\\,\\frac{\\Vert\\boldsymbol{\\theta}\_1 - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_1} - \\frac{\\Vert\\boldsymbol{\\theta}\_{T+1} - \\boldsymbol{\\theta}^\*\\Vert^2}{2\\eta\_T} + \\sum\_{t=2}^T\\left(\\frac{1}{2\\eta\_t} - \\frac{1}{2\\eta\_{t-1}}\\right)\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert^2\\\
\\leq&\\,\\frac{D^2}{2\\eta\_1} + \\sum\_{t=2}^T\\left(\\frac{1}{2\\eta\_t} - \\frac{1}{2\\eta\_{t-1}}\\right)D^2\\\
=&\\, \\frac{D^2}{2\\eta\_T}
\\end{aligned}\\end{equation}
最后我们记$G = \\max\_t \\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert$，然后将上式代入式$\\eqref{neq:base}$得到
\\begin{equation}\\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\sum\_{t=1}^T L(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}^\*)\\leq \\frac{D^2}{2\\eta\_T} + \\sum\_{t=1}^T\\frac{1}{2}\\eta\_t\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert^2\\leq \\frac{D^2}{2\\eta\_T} + \\frac{G^2}{2}\\sum\_{t=1}^T\\eta\_t\\end{equation}
最后两端除以$T$即得不等式$\\eqref{neq:core}$。

注意现在的常数$D,G$是优化相关的，即先要确定学习率策略$\\{\\eta\_t\\}$，然后完成优化过程才能得到$D,G$。要想$D,G$成为优化无关的常数，我们需要假设对于任意的$\\{\\eta\_t\\}$，$\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert$和$\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert$都分别不超过某个常数$D,G$，这样才能使得不等式$\\eqref{neq:core}$右端只与学习率策略有关。

## 域内投影 [\#](https://kexue.fm/kexue.fm\#%E5%9F%9F%E5%86%85%E6%8A%95%E5%BD%B1)

然而，最后的假设“对于任意的$\\{\\eta\_t\\}$，$\\Vert\\boldsymbol{\\theta}\_t - \\boldsymbol{\\theta}^\*\\Vert$和$\\Vert\\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\Vert$都分别不超过某个常数$D,G$”总有种“本末倒置”的感觉：看上去需要先完成优化才能确定$D,G$，而我们的目的却是要通过所证明的结果来改进优化。为了去掉这种奇怪的感觉，我们干脆将这两个假设改为：

> 1、式$\\eqref{eq:argmin}$中的$\\boldsymbol{\\theta}\\in\\mathbb{R}^d$改为$\\boldsymbol{\\theta}\\in\\boldsymbol{\\Theta}$，其中$\\boldsymbol{\\Theta}\\subseteq \\mathbb{R}^d$是一个有界凸集；
>
> 1.1） **有界**：$D=\\max\\limits\_{\\boldsymbol{\\theta}\_1,\\boldsymbol{\\theta}\_2\\in \\boldsymbol{\\Theta}}\\Vert\\boldsymbol{\\theta}\_1-\\boldsymbol{\\theta}\_2\\Vert < \\infty$；
>
> 1.2） **凸集**：$\\forall \\boldsymbol{\\theta}\_1,\\boldsymbol{\\theta}\_2\\in \\boldsymbol{\\Theta}$以及$\\forall\\lambda\\in\[0,1\]$，都有$\\lambda \\boldsymbol{\\theta}\_1 + (1-\\lambda)\\boldsymbol{\\theta}\_2 \\in \\boldsymbol{\\Theta}$。
>
> 2、对于任意$\\boldsymbol{\\theta}\\in \\boldsymbol{\\Theta}$以及任意$\\boldsymbol{x}$，都有$\\Vert\\boldsymbol{g}(\\boldsymbol{x},\\boldsymbol{\\theta})\\Vert\\leq G$

第2点可能更容易接受，无非是给损失函数$L(\\boldsymbol{x},\\boldsymbol{\\theta})$再加了个假设而已，就好比“债多不愁”，凸函数这么强的假设都加了，再多加点也无妨。但第1点假设似乎不那么容易理解：凸集是因为凸函数本身只能定义在凸集上，这个也能接受，但有界如何保证呢？即如何保证迭代$\\eqref{eq:sgd}$的输出一定有界？

答案是“多加一步投影”。我们定义投影运算：
\\begin{equation}\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi}) = \\mathop{\\text{argmin}}\_{\\boldsymbol{\\theta}\\in\\boldsymbol{\\Theta}}\\Vert\\boldsymbol{\\varphi}-\\boldsymbol{\\theta}\\Vert\\end{equation}
即在$\\boldsymbol{\\Theta}$中找到与$\\boldsymbol{\\varphi}$最相近的向量，于是我们可以将式$\\eqref{eq:sgd}$改为
\\begin{equation}\\boldsymbol{\\theta}\_{t+1} = \\Pi\_{\\boldsymbol{\\Theta}}\\big(\\boldsymbol{\\theta}\_t - \\eta\_t \\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t)\\big)\\in \\boldsymbol{\\Theta}\\label{eq:sgd-p}\\end{equation}
这就能保证迭代结果一定在集合$\\boldsymbol{\\Theta}$中。

然而，这样修改之后，上一节的证明和前面的结论（主要是不等式$\\eqref{neq:core}$）还成立吗？很幸运，还成立，我们只需要证明对于式$\\eqref{eq:sgd-p}$所定义的投影SGD有
\\begin{equation}\\Vert\\boldsymbol{\\theta}\_{t+1} - \\boldsymbol{\\theta}^\*\\Vert \\leq \\Vert\\boldsymbol{\\theta}\_t - \\eta\_t \\boldsymbol{g}(\\boldsymbol{x}\_t,\\boldsymbol{\\theta}\_t) - \\boldsymbol{\\theta}^\*\\Vert\\end{equation}
那么“ [证明过程](https://kexue.fm/kexue.fm#%E8%AF%81%E6%98%8E%E8%BF%87%E7%A8%8B)”一节的推导依然可以进行下去，只不过部分等号变成$\\leq$而已。为此，我们只需要证明$\\forall \\boldsymbol{\\varphi}\\in\\mathbb{R}^d, \\boldsymbol{\\theta}\\in \\boldsymbol{\\Theta}$，都有
\\begin{equation}\\Vert\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi}) - \\boldsymbol{\\theta}\\Vert \\leq \\Vert \\boldsymbol{\\varphi} - \\boldsymbol{\\theta}\\Vert\\end{equation}

> **证明**：证明的关键是将凸集和$\\Pi\_{\\boldsymbol{\\Theta}}$的定义结合起来。首先，根据凸集的定义，我们知道$\\forall \\lambda\\in(0,1)$都有$\\lambda\\boldsymbol{\\theta} + (1-\\lambda)\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\in \\boldsymbol{\\Theta}$，于是根据$\\Pi\_{\\boldsymbol{\\Theta}}$的定义，恒成立
> \\begin{equation}\\Vert\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\Vert\\leq \\Vert\\boldsymbol{\\varphi} - \\lambda\\boldsymbol{\\theta} - (1-\\lambda)\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\Vert = \\Vert(\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})) + \\lambda(\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta})\\Vert\\end{equation}
> 两端平方然后相减，得到
> \\begin{equation}\\lambda^2\\Vert\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta}\\Vert^2 + 2\\lambda(\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta})\\cdot(\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi}))\\geq 0\\end{equation}
> 注意我们刚限制了$\\lambda\\in(0,1)$，所以两端可以除以$\\lambda$：
> \\begin{equation}\\lambda\\Vert\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta}\\Vert^2 + 2(\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta})\\cdot(\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi}))\\geq 0\\end{equation}
> 这是个恒成立的式子，那么对于$\\lambda\\to 0^+$依然是恒成立的，于是
> \\begin{equation}(\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta})\\cdot(\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi}))\\geq 0\\end{equation}
> 两端加上$\\Vert\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta}\\Vert^2 + \\Vert\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\Vert^2$，左端正好是$\\Vert\\boldsymbol{\\varphi}-\\boldsymbol{\\theta}\\Vert^2$，所以有
> \\begin{equation}\\Vert\\boldsymbol{\\varphi}-\\boldsymbol{\\theta}\\Vert^2\\geq \\Vert\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta}\\Vert^2 + \\Vert\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\Vert^2 \\geq \\Vert\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})-\\boldsymbol{\\theta}\\Vert^2\\end{equation}

## 假设分析 [\#](https://kexue.fm/kexue.fm\#%E5%81%87%E8%AE%BE%E5%88%86%E6%9E%90)

至此，我们已经完整了证明过程。以上结果出自 [《Online Convex Programming and Generalized Infinitesimal Gradient Ascent》](https://www.cs.cmu.edu/~maz/publications/techconvex.pdf)，是2003年的论文。特别地，优化相关的文献非常多，笔者作为一个初学者，在后面的文献溯源方面大概率会有错漏，请了解的读者不吝指正。

现在我们可以来“盘点”一下完整的证明过程用到的所有假设：

> 1、$\\boldsymbol{\\Theta}$是一个有界凸集，$D=\\max\\limits\_{\\boldsymbol{\\theta}\_1,\\boldsymbol{\\theta}\_2\\in \\boldsymbol{\\Theta}}\\Vert\\boldsymbol{\\theta}\_1-\\boldsymbol{\\theta}\_2\\Vert < \\infty$；
>
> 2、对于任意$\\boldsymbol{\\theta}\\in \\boldsymbol{\\Theta}$以及任意$\\boldsymbol{x}$，$L(\\boldsymbol{x},\\boldsymbol{\\theta})$都是关于$\\boldsymbol{\\theta}$的凸函数；
>
> 3、对于任意$\\boldsymbol{\\theta}\\in \\boldsymbol{\\Theta}$以及任意$\\boldsymbol{x}$，都有$\\Vert\\nabla\_{\\boldsymbol{\\theta}}L(\\boldsymbol{x},\\boldsymbol{\\theta})\\Vert\\leq G < \\infty$；
>
> 4、学习率$\\eta\_t$是关于$t$的单调递减函数（即$\\eta\_t\\geq \\eta\_{t+1}$）；

在这些假设之下，投影SGD即式$\\eqref{eq:sgd-p}$成立不等式$\\eqref{neq:core}$。

其中，第1、4点假设都无可厚非，甚至可以说非常合理，比如第1点，对于实际计算来说，一个充分大的球体跟$\\mathbb{R}^d$并没有实质区别了，而第4点递减的学习率更是符合已有认知；最强且最不符合事实的是第2点凸函数假设，但没办法，多看几篇优化相关的文献就释然了，因为几乎所有优化理论都是基于凸函数假设进行的，我们只能寄望于优化进入一定区域后损失函数能部分符合凸函数的性质；第3点本质上也是很强的假设，但实际运算中如果初始化做得好，并且学习率也设置得适当，基本上能将梯度模长控制在一定范围内，因此也通常能接受。

## 文章小结 [\#](https://kexue.fm/kexue.fm\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

在这篇文章中，我们重温了一篇凸优化的旧论文，介绍了SGD的一个非常基础的收敛性证明：在适当（实际上非常强）的假设下，SGD的收敛性可以得到保证。尽管这些假设在实际应用中可能并不总是成立，例如凸函数假设和梯度模长的限制，但这些理论结果仍能为我们提供了关于SGD收敛性的重要见解。

_**转载到请包括本文地址：** [https://kexue.fm/archives/9902](https://kexue.fm/archives/9902)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/kexue.fm#share)/ [打赏](https://kexue.fm/kexue.fm#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Dec. 19, 2023). 《让炼丹更科学一些（一）：SGD的平均损失收敛 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/9902](https://kexue.fm/archives/9902)

@online{kexuefm-9902,
        title={让炼丹更科学一些（一）：SGD的平均损失收敛},
        author={苏剑林},
        year={2023},
        month={Dec},
        url={\\url{https://kexue.fm/archives/9902}},
}

分类： [信息时代](https://kexue.fm/category/Big-Data)    标签： [不等式](https://kexue.fm/tag/%E4%B8%8D%E7%AD%89%E5%BC%8F/), [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/), [sgd](https://kexue.fm/tag/sgd/), [炼丹](https://kexue.fm/tag/%E7%82%BC%E4%B8%B9/)[6 评论](https://kexue.fm/archives/9902#comments)

< [注意力机制真的可以“集中注意力”吗？](https://kexue.fm/archives/9889) \| [写了个刷论文的辅助网站：Cool Papers](https://kexue.fm/archives/9907) >

### 你也许还对下面的内容感兴趣

- [MuP之上：1. 好模型的三个特征](https://kexue.fm/archives/11340)
- [AdamW的Weight RMS的渐近估计](https://kexue.fm/archives/11307)
- [重新思考学习率与Batch Size（四）：EMA](https://kexue.fm/archives/11301)
- [重新思考学习率与Batch Size（三）：Muon](https://kexue.fm/archives/11285)
- [重新思考学习率与Batch Size（二）：平均场](https://kexue.fm/archives/11280)
- [为什么Adam的Update RMS是0.2？](https://kexue.fm/archives/11267)
- [重新思考学习率与Batch Size（一）：现状](https://kexue.fm/archives/11260)
- [流形上的最速下降：4\. Muon + 谱球面](https://kexue.fm/archives/11241)
- [流形上的最速下降：3\. Muon + Stiefel](https://kexue.fm/archives/11221)
- [流形上的最速下降：2\. Muon + 正交](https://kexue.fm/archives/11215)

[发表你的看法](https://kexue.fm/kexue.fm#comment_form)

[让炼丹更科学一些（一）：SGD的平均收敛趋势 R11; AI 資訊](https://news.aitime.space/2023/12/77228/)

December 19th, 2023

\[...\]​Read More \[...\]

[回复评论](https://kexue.fm/archives/9902/comment-page-1?replyTo=23313#respond-post-9902)

Jeffyang

January 9th, 2024

最近在学优化器，在全量更新模型的场景，想替换共轭梯度这些传统的。有什么好的论文推荐吗？

[回复评论](https://kexue.fm/archives/9902/comment-page-1?replyTo=23491#respond-post-9902)

[苏剑林](https://kexue.fm) 发表于
January 16th, 2024

如果只是使用上的替换，直接试用不就好了吗？

[回复评论](https://kexue.fm/archives/9902/comment-page-1?replyTo=23509#respond-post-9902)

broq

January 30th, 2024

苏神能解释下式20的不等式部分是如何通过凸函数性质推导出来的么? 我好像用\|\|投影向量+平面向量\|\|>=\|\|投影向量\|\|+\|\|平面向量\|\|这种方式可以理解? 但似乎是从式20从右往左推导

[回复评论](https://kexue.fm/archives/9902/comment-page-1?replyTo=23626#respond-post-9902)

[苏剑林](https://kexue.fm) 发表于
January 31st, 2024

不是通过凸函数的定义，而是通过$\\Pi\_{\\boldsymbol{\\Theta}}$和凸集的定义。

首先，$\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})$定义为$\\boldsymbol{\\Theta}$中与$\\boldsymbol{\\varphi}$距离最近的点，所以$\\Vert\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\Vert$本身已经是最小值；又根据凸集的定义，$\\lambda\\boldsymbol{\\theta} + (1-\\lambda)\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\in\\boldsymbol{\\Theta}$，所以自然成立
$$\\Vert\\boldsymbol{\\varphi} - \\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\Vert\\leq \\Vert\\boldsymbol{\\varphi} - \\lambda\\boldsymbol{\\theta} - (1-\\lambda)\\Pi\_{\\boldsymbol{\\Theta}} (\\boldsymbol{\\varphi})\\Vert$$

[回复评论](https://kexue.fm/archives/9902/comment-page-1?replyTo=23640#respond-post-9902)

broq 发表于
February 8th, 2024

理解了!感谢!

[回复评论](https://kexue.fm/archives/9902/comment-page-1?replyTo=23688#respond-post-9902)

[取消回复](https://kexue.fm/archives/9902#respond-post-9902)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请 **不要重复点击提交**。

### 内容速览

[问题设置](https://kexue.fm/kexue.fm#%E9%97%AE%E9%A2%98%E8%AE%BE%E7%BD%AE)
[结论初探](https://kexue.fm/kexue.fm#%E7%BB%93%E8%AE%BA%E5%88%9D%E6%8E%A2)
[两个例子](https://kexue.fm/kexue.fm#%E4%B8%A4%E4%B8%AA%E4%BE%8B%E5%AD%90)
[证明过程](https://kexue.fm/kexue.fm#%E8%AF%81%E6%98%8E%E8%BF%87%E7%A8%8B)
[域内投影](https://kexue.fm/kexue.fm#%E5%9F%9F%E5%86%85%E6%8A%95%E5%BD%B1)
[假设分析](https://kexue.fm/kexue.fm#%E5%81%87%E8%AE%BE%E5%88%86%E6%9E%90)
[文章小结](https://kexue.fm/kexue.fm#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [【NASA每日一图】神秘的Voynich(伏尼契)手稿](https://kexue.fm/archives/385)
- [动手做个DialoGPT：基于LM的生成式多轮对话模型](https://kexue.fm/archives/7718)
- [Linux下的误删大坑与简单的恢复技巧](https://kexue.fm/archives/4491)
- [厨房，菜市场，其实都是武林](https://kexue.fm/archives/5570)
- [日出东方,重逢,最美的风采](https://kexue.fm/archives/815)
- [大气光学质量(Airmass)](https://kexue.fm/archives/396)
- [矩阵化简二次型（无穷小近似处理抛物型）](https://kexue.fm/archives/1841)
- [【外微分浅谈】7\. 有力的计算](https://kexue.fm/archives/4076)
- [再谈非方阵的行列式](https://kexue.fm/archives/6096)
- [三个相切圆的公切圆](https://kexue.fm/archives/2320)

### 最近评论

- [Zhan-Wang Mao](https://kexue.fm/archives/9257/comment-page-4#comment-28676): 苏老师，请教一下(4)式的泰勒展开式为什么严格来说和$t$有关？不是在$x\_t$处关于$x$的...
- [yzlnew](https://kexue.fm/archives/11340/comment-page-1#comment-28675): 可以相呼应的是，这样的好模型能被浮点数以误差比较低的方式表示和训练，并且也易于量化。
- [Henry](https://kexue.fm/archives/9181/comment-page-5#comment-28673): 想请问苏老师，方程7是如何推导到方程10的，是否有化简的一些小技巧？
- [szsheep](https://kexue.fm/archives/9119/comment-page-13#comment-28672): 牛啊，还可以从这方面推出loss的函数最终式。原本是从KL散度入手，没想到作者完全用另外一种方...
- [pang](https://kexue.fm/archives/10862/comment-page-1#comment-28671): 对于目前的MLA算法softmax(X×WQ×WukT×CjT)×Cj×Wuv来说其实X,WQ...
- [苏剑林](https://kexue.fm/archives/11126/comment-page-3#comment-28670): 你是说 chatglm2-6b 里边的？那个没用，预设的常数是压不住的...
- [苏剑林](https://kexue.fm/archives/443/comment-page-1#comment-28669): 已发
- [苏剑林](https://kexue.fm/archives/10592/comment-page-2#comment-28668): 只想要“方向”，步长只是个标量，另外手工控制。
- [苏剑林](https://kexue.fm/archives/11241/comment-page-1#comment-28667): 参考 https://kexue.fm/archives/10795
- [苏剑林](https://kexue.fm/archives/7546/comment-page-4#comment-28666): $KV$本身通常就不是low-rank的，所以就无所谓升不升秩了。主要问题是，这种最基础的线性...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [Zhang's blog](https://armcvai.cn/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。