## SEARCH

## MENU

- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

## CATEGORIES

- [千奇百怪](https://kexue.fm/category/Everything)
- [天文探索](https://kexue.fm/category/Astronomy)
- [数学研究](https://kexue.fm/category/Mathematics)
- [物理化学](https://kexue.fm/category/Phy-chem)
- [信息时代](https://kexue.fm/category/Big-Data)
- [生物自然](https://kexue.fm/category/Biology)
- [图片摄影](https://kexue.fm/category/Photograph)
- [问题百科](https://kexue.fm/category/Questions)
- [生活/情感](https://kexue.fm/category/Life-Feeling)
- [资源共享](https://kexue.fm/category/Resources)

## NEWPOSTS

- [msign算子的Newton-Sc...](https://kexue.fm/archives/10996)
- [从无穷范数求导到等值振荡定理](https://kexue.fm/archives/10972)
- [生成扩散模型漫谈（三十）：从瞬时速...](https://kexue.fm/archives/10958)
- [MoE环游记：5、均匀分布的反思](https://kexue.fm/archives/10945)
- [msign算子的Newton-Sc...](https://kexue.fm/archives/10922)
- [Transformer升级之路：2...](https://kexue.fm/archives/10907)
- [一道概率不等式：盯着它到显然成立为止！](https://kexue.fm/archives/10902)
- [SVD的导数](https://kexue.fm/archives/10878)
- [智能家居之手搓一套能接入米家的零冷水装置](https://kexue.fm/archives/10869)
- [Transformer升级之路：1...](https://kexue.fm/archives/10862)

## COMMENTS

- [rpsun: 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减...](https://kexue.fm/archives/10699/comment-page-1#comment-27808)
- [贵阳机场接机: 怎么不更新啦](https://kexue.fm/archives/1490/comment-page-1#comment-27807)
- [czvzb: 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。...](https://kexue.fm/archives/10958/comment-page-1#comment-27806)
- [Shawn\_yang: 不好意思，以为网页卡了0.0点了三下](https://kexue.fm/archives/10945/comment-page-1#comment-27805)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27804)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27803)
- [Shawn\_yang: 苏神，关于您所说的：“推理阶段可以事先预估Routed Exp...](https://kexue.fm/archives/10945/comment-page-1#comment-27802)
- [OceanYU: 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）...](https://kexue.fm/archives/9164/comment-page-4#comment-27801)
- [jorjiang: 训练和prefill这个compute-bound阶段不做矩阵...](https://kexue.fm/archives/10907/comment-page-2#comment-27800)
- [amy: 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工...](https://kexue.fm/archives/10907/comment-page-2#comment-27799)

## USERLOGIN

- [登录](https://kexue.fm/admin/login.php)

[科学空间\|Scientific Spaces](https://kexue.fm)

- [登录](https://kexue.fm/admin/login.php)
- [打赏](https://kexue.fm/reward.html)
- [公式](https://kexue.fm/latex.html)
- [天象](https://kexue.fm/ac.html)
- [链接](https://kexue.fm/links.html)
- [时光](https://kexue.fm/me.html)
- [博览](https://kexue.fm/science.html)
- [归档](https://kexue.fm/content.html)

渴望成为一个小飞侠

- [欢迎订阅](https://kexue.fm/feed)
- [个性邮箱](https://kexue.fm/archives/119)
- [天象信息](https://kexue.fm/ac.html)
- [观测ISS](https://kexue.fm/archives/41)
- [LaTeX](https://kexue.fm/latex.html)
- [关于博主](https://kexue.fm/me.html)

欢迎访问“科学空间”，这里将与您共同探讨自然科学，回味人生百态；也期待大家的分享～

- [**千奇百怪** Everything](https://kexue.fm/category/Everything)
- [**天文探索** Astronomy](https://kexue.fm/category/Astronomy)
- [**数学研究** Mathematics](https://kexue.fm/category/Mathematics)
- [**物理化学** Phy-chem](https://kexue.fm/category/Phy-chem)
- [**信息时代** Big-Data](https://kexue.fm/category/Big-Data)
- [**生物自然** Biology](https://kexue.fm/category/Biology)
- [**图片摄影** Photograph](https://kexue.fm/category/Photograph)
- [**问题百科** Questions](https://kexue.fm/category/Questions)
- [**生活/情感** Life-Feeling](https://kexue.fm/category/Life-Feeling)
- [**资源共享** Resources](https://kexue.fm/category/Resources)

- [**千奇百怪**](https://kexue.fm/category/Everything)
- [**天文探索**](https://kexue.fm/category/Astronomy)
- [**数学研究**](https://kexue.fm/category/Mathematics)
- [**物理化学**](https://kexue.fm/category/Phy-chem)
- [**信息时代**](https://kexue.fm/category/Big-Data)
- [**生物自然**](https://kexue.fm/category/Biology)
- [**图片摄影**](https://kexue.fm/category/Photograph)
- [**问题百科**](https://kexue.fm/category/Questions)
- [**生活/情感**](https://kexue.fm/category/Life-Feeling)
- [**资源共享**](https://kexue.fm/category/Resources)

[首页](https://kexue.fm) [数学研究](https://kexue.fm/category/Mathematics) 低秩近似之路（二）：SVD

1Oct

# [低秩近似之路（二）：SVD](https://kexue.fm/archives/10407)

By 苏剑林 \|
2024-10-01 \|
26178位读者\|

上一篇文章中我们介绍了“ [伪逆](https://kexue.fm/archives/10366)”，它关系到给定矩阵$\\boldsymbol{M}$和$\\boldsymbol{A}$（或$\\boldsymbol{B}$）时优化目标$\\Vert \\boldsymbol{A}\\boldsymbol{B} - \\boldsymbol{M}\\Vert\_F^2$的最优解。这篇文章我们来关注$\\boldsymbol{A},\\boldsymbol{B}$都不给出时的最优解，即
\\begin{equation}\\mathop{\\text{argmin}}\_{\\boldsymbol{A},\\boldsymbol{B}}\\Vert \\boldsymbol{A}\\boldsymbol{B} - \\boldsymbol{M}\\Vert\_F^2\\label{eq:loss-ab}\\end{equation}
其中$\\boldsymbol{A}\\in\\mathbb{R}^{n\\times r}, \\boldsymbol{B}\\in\\mathbb{R}^{r\\times m}, \\boldsymbol{M}\\in\\mathbb{R}^{n\\times m},r < \\min(n,m)$。说白了，这就是要寻找矩阵$\\boldsymbol{M}$的“最优$r$秩近似（秩不超过$r$的最优近似）”。而要解决这个问题，就需要请出大名鼎鼎的“SVD（奇异值分解）”了。虽然本系列把伪逆作为开篇，但它的“名声”远不如SVD，听过甚至用过SVD但没听说过伪逆的应该大有人在，包括笔者也是先了解SVD后才看到伪逆。

接下来，我们将围绕着矩阵的最优低秩近似来展开介绍SVD。

## 结论初探 [\#](https://kexue.fm/archives/10407\#%E7%BB%93%E8%AE%BA%E5%88%9D%E6%8E%A2)

对于任意矩阵$\\boldsymbol{M}\\in\\mathbb{R}^{n\\times m}$，都可以找到如下形式的奇异值分解（SVD，Singular Value Decomposition）：
\\begin{equation}\\boldsymbol{M} = \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\end{equation}
其中$\\boldsymbol{U}\\in\\mathbb{R}^{n\\times n},\\boldsymbol{V}\\in\\mathbb{R}^{m\\times m}$都是正交矩阵，$\\boldsymbol{\\Sigma}\\in\\mathbb{R}^{n\\times m}$是非负对角矩阵：
\\begin{equation}\\boldsymbol{\\Sigma}\_{i,j} = \\left\\{\\begin{aligned}&\\sigma\_i, &i = j \\\ &0,&i \\neq j\\end{aligned}\\right.\\end{equation}
对角线元素默认从大到小排序，即$\\sigma\_1\\geq \\sigma\_2\\geq\\sigma\_3\\geq\\cdots\\geq 0$，这些对角线元素就称为奇异值（Singular Value）。从数值计算角度看，我们可以只保留$\\boldsymbol{\\Sigma}$中非零元素，将$\\boldsymbol{U},\\boldsymbol{\\Sigma},\\boldsymbol{V}$的大小降低到$n\\times r, r\\times r, m\\times r$（$r$是$\\boldsymbol{M}$的秩），保留完整的正交矩阵则更便于理论分析。

SVD对于复矩阵同样成立，但需要将正交矩阵改为酉矩阵，转置改为共轭转置，但这里我们主要聚焦于跟机器学习关系更为密切的实矩阵结果。SVD的基础理论包括存在性、计算方法以及它与最优低秩近似的联系等，这些内容笔者后面都会给出自己的理解。

在二维平面下，SVD有非常直观的几何意义。二维的正交矩阵主要就是旋转（还有反射，但几何直观的话可以不那么严谨），所以$\\boldsymbol{M}\\boldsymbol{x}=\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\boldsymbol{x}$意味着任何对（列）向量$x$的线性变换，都可以分解为 **旋转**、 **拉伸**、 **旋转** 三个步骤，如下图所示：

SVD的几何意义

## 一些应用 [\#](https://kexue.fm/archives/10407\#%E4%B8%80%E4%BA%9B%E5%BA%94%E7%94%A8)

不管是理论分析还是数值计算，SVD都有非常广泛的应用，其背后的原理之一是常用的矩阵/向量范数对正交变换具有不变性，所以SVD左右两个正交矩阵夹着中间一个对角矩阵的特点，往往能用来将很多矩阵相关的优化目标转换为等价的非负对角矩阵特例，起到简化问题的作用。

### 伪逆通解 [\#](https://kexue.fm/archives/10407\#%E4%BC%AA%E9%80%86%E9%80%9A%E8%A7%A3)

以伪逆为例，当$\\boldsymbol{A}\\in\\mathbb{R}^{n\\times r}$的秩为$r$时，我们有
\\begin{equation}\\boldsymbol{A}^{\\dagger} = \\mathop{\\text{argmin}}\_{\\boldsymbol{B}\\in\\mathbb{R}^{r\\times n}}\\Vert \\boldsymbol{A}\\boldsymbol{B} - \\boldsymbol{I}\_n\\Vert\_F^2\\end{equation}
上一篇文章我们通过求导得出了$\\boldsymbol{A}^{\\dagger}$的表达式，然后又花了一些心思推广到$\\boldsymbol{A}$的秩小于$r$的情形。但如果引入SVD的话，那么问题就简化得多了。我们可以将$\\boldsymbol{A}$分解为$\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}$，然后将$\\boldsymbol{B}$表示成$\\boldsymbol{V} \\boldsymbol{Z} \\boldsymbol{U}^{\\top}$，注意我们没有规定$\\boldsymbol{Z}$是对角阵，所以$\\boldsymbol{B}=\\boldsymbol{V} \\boldsymbol{Z} \\boldsymbol{U}^{\\top}$总是可以做到的，于是
\\begin{equation}\\begin{aligned}
\\min\_\\boldsymbol{B}\\Vert \\boldsymbol{A}\\boldsymbol{B} - \\boldsymbol{I}\_n\\Vert\_F^2 =&\\, \\min\_\\boldsymbol{Z}\\Vert \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\boldsymbol{V} \\boldsymbol{Z} \\boldsymbol{U}^{\\top} - \\boldsymbol{I}\_n\\Vert\_F^2 \\\
=&\\, \\min\_\\boldsymbol{Z}\\Vert \\boldsymbol{U}(\\boldsymbol{\\Sigma} \\boldsymbol{Z} - \\boldsymbol{I}\_n) \\boldsymbol{U}^{\\top}\\Vert\_F^2 \\\
=&\\, \\min\_\\boldsymbol{Z}\\Vert \\boldsymbol{\\Sigma} \\boldsymbol{Z} - \\boldsymbol{I}\_n\\Vert\_F^2
\\end{aligned}\\end{equation}
最后一个等号是基于我们上一篇文章证明过的结论“正交变换不改变$F$范数”，这样我们就将问题简化成对角阵$\\boldsymbol{\\Sigma}$的伪逆了。接着我们可以用分块矩阵的形式将$\\boldsymbol{\\Sigma} \\boldsymbol{Z} - \\boldsymbol{I}\_n$表示为
\\begin{equation}\\begin{aligned}\\boldsymbol{\\Sigma} \\boldsymbol{Z} - \\boldsymbol{I}\_n =&\\, \\begin{pmatrix}\\boldsymbol{\\Sigma}\_{\[:r,:r\]} \\\ \\boldsymbol{0}\_{(n-r)\\times r}\\end{pmatrix} \\begin{pmatrix}\\boldsymbol{Z}\_{\[:r,:r\]} & \\boldsymbol{Z}\_{\[:r,r:\]}\\end{pmatrix} - \\begin{pmatrix}\\boldsymbol{I}\_r & \\boldsymbol{0}\_{r\\times(n-r)} \\\ \\boldsymbol{0}\_{(n-r)\\times r} & \\boldsymbol{I}\_{n-r}\\end{pmatrix} \\\
=&\\, \\begin{pmatrix}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}\\boldsymbol{Z}\_{\[:r,:r\]} - \\boldsymbol{I}\_r & \\boldsymbol{\\Sigma}\_{\[:r,:r\]}\\boldsymbol{Z}\_{\[:r,r:\]}\\\ \\boldsymbol{0}\_{(n-r)\\times r} & -\\boldsymbol{I}\_{n-r}\\end{pmatrix}
\\end{aligned}\\end{equation}
这里的切片就按照Python数组的规则来理解。从最后的形式可以看出，要使得$\\boldsymbol{\\Sigma} \\boldsymbol{Z} - \\boldsymbol{I}\_n$的$F$范数最小，唯一解是$\\boldsymbol{Z}\_{\[:r,:r\]}=\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}$，$\\boldsymbol{Z}\_{\[:r,r:\]}=\\boldsymbol{0}\_{r\\times(n-r)}$，说白了，$\\boldsymbol{Z}$就是将$\\boldsymbol{\\Sigma}^{\\top}$的非零元素都取倒数然后转置，我们将它记为$\\boldsymbol{\\Sigma}^{\\dagger}$，于是在SVD下就有
\\begin{equation}\\boldsymbol{A}=\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\quad\\Rightarrow\\quad \\boldsymbol{A}^{\\dagger} = \\boldsymbol{V}\\boldsymbol{\\Sigma}^{\\dagger}\\boldsymbol{U}^{\\top}\\end{equation}
可以进一步证明这个结果也适用于秩小于$r$的$\\boldsymbol{A}$，所以它是一个通用的形式，一些教程也直接将它作为伪逆的定义。此外，我们也可以观察到这个形式不区分左伪逆和右伪逆，这表明同一个矩阵的左伪逆和右伪逆是相等的，因此在说伪逆的时候不用特别区分左右。

### 矩阵范数 [\#](https://kexue.fm/archives/10407\#%E7%9F%A9%E9%98%B5%E8%8C%83%E6%95%B0)

利用正交变换不改变$F$范数的结论，我们还可以得到
\\begin{equation}\\Vert \\boldsymbol{M}\\Vert\_F^2 = \\Vert \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\Vert\_F^2 = \\Vert \\boldsymbol{\\Sigma} \\Vert\_F^2 = \\sum\_{i=1}^{\\min(n,m)}\\sigma\_i^2\\end{equation}
也就是说奇异值的平方和等于$F$范数的平方。除了$F$范数外，SVD也可以用来计算“谱范数”。上一篇文章我们提到，$F$范数只是矩阵范数的一种，另一种常用的矩阵范数是基于向量的范数诱导出来的谱范数，它定义为：
\\begin{equation}\\Vert \\boldsymbol{M}\\Vert\_2 = \\max\_{\\Vert \\boldsymbol{x}\\Vert = 1} \\Vert \\boldsymbol{M}\\boldsymbol{x}\\Vert\\end{equation}
注意等号右端出现的范数都是向量的范数（模长，$2$-范数），因此上述定义是明确的。由于它是向量的$2$-范数所诱导出来的，所以它也称为矩阵的$2$-范数。数值上，矩阵的谱范数等于它的最大奇异值，即$\\Vert \\boldsymbol{M}\\Vert\_2 = \\sigma\_1$。要证明这一点，只需要将$\\boldsymbol{M}$做SVD为$\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}$，然后代入谱范数的定义
\\begin{equation}\\max\_{\\Vert \\boldsymbol{x}\\Vert = 1} \\Vert \\boldsymbol{M}\\boldsymbol{x}\\Vert = \\max\_{\\Vert \\boldsymbol{x}\\Vert = 1} \\Vert \\boldsymbol{U}\\boldsymbol{\\Sigma} (\\boldsymbol{V}^{\\top}\\boldsymbol{x})\\Vert = \\max\_{\\Vert \\boldsymbol{y}\\Vert = 1} \\Vert \\boldsymbol{\\Sigma} \\boldsymbol{y}\\Vert\\end{equation}
第二个等号正是利用了正交矩阵不改变向量范数的特点。现在我们相当于将问题简化成为对角阵$\\boldsymbol{\\Sigma}$的谱范数，这个比较简单，设$\\boldsymbol{y} = (y\_1,y\_2,\\cdots,y\_m)$，那么
\\begin{equation}\\Vert \\boldsymbol{\\Sigma} \\boldsymbol{y}\\Vert^2 = \\sum\_{i=1}^m \\sigma\_i^2 y\_i^2 \\leq \\sum\_{i=1}^m \\sigma\_1^2 y\_i^2 = \\sigma\_1^2\\sum\_{i=1}^m y\_i^2 = \\sigma\_1^2\\end{equation}
所以$\\Vert \\boldsymbol{\\Sigma} \\boldsymbol{y}\\Vert$不超过$\\sigma\_1$，并且$\\boldsymbol{y}=(1,0,\\cdots,0)$时取到等号，因此$\\Vert \\boldsymbol{M}\\Vert\_2=\\sigma\_1$。对比$F$范数的结果，我们还可以发现恒成立$\\Vert \\boldsymbol{M}\\Vert\_2\\leq \\Vert \\boldsymbol{M}\\Vert\_F$。

### 低秩近似 [\#](https://kexue.fm/archives/10407\#%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC)

最后我们再回到本文的主题最优低秩近似，也就是目标$\\eqref{eq:loss-ab}$。将$\\boldsymbol{M}$分解为$\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}$，那么我们就可以写出
\\begin{equation}\\begin{aligned}
\\Vert \\boldsymbol{A}\\boldsymbol{B} - \\boldsymbol{M}\\Vert\_F^2 =&\\, \\Vert \\boldsymbol{U}\\boldsymbol{U}^{\\top}\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{V}\\boldsymbol{V}^{\\top} - \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\Vert\_F^2 \\\
=&\\, \\Vert \\boldsymbol{U}(\\boldsymbol{U}^{\\top}\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{V} - \\boldsymbol{\\Sigma}) \\boldsymbol{V}^{\\top}\\Vert\_F^2 \\\
=&\\, \\Vert \\boldsymbol{U}^{\\top}\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{V} - \\boldsymbol{\\Sigma}\\Vert\_F^2
\\end{aligned}\\end{equation}
注意$\\boldsymbol{U}^{\\top}\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{V}$仍可以代表任意秩不超过$r$的矩阵，所以通过SVD我们将矩阵$\\boldsymbol{M}$的最优$r$秩近似简化成了非负对角阵$\\boldsymbol{\\Sigma}$的最优$r$秩近似。

在 [《对齐全量微调！这是我看过最精彩的LoRA改进（一）》](https://kexue.fm/archives/10226) 中我们用同样思路求解过一个类似的优化问题：
\\begin{equation}\\mathop{\\text{argmin}}\_{\\boldsymbol{A},\\boldsymbol{B}} \\Vert \\boldsymbol{A}\\boldsymbol{A}^{\\top}\\boldsymbol{M} + \\boldsymbol{M}\\boldsymbol{B}^{\\top}\\boldsymbol{B} - \\boldsymbol{M}\\Vert\_F^2\\end{equation}
利用SVD和正交变换不改变$F$范数，可以得到
\\begin{equation}\\begin{aligned}
&\\,\\Vert \\boldsymbol{A}\\boldsymbol{A}^{\\top}\\boldsymbol{M} + \\boldsymbol{M}\\boldsymbol{B}^{\\top}\\boldsymbol{B} - \\boldsymbol{M}\\Vert\_F^2 \\\
=&\\, \\Vert \\boldsymbol{A}\\boldsymbol{A}^{\\top}\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top} + \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\boldsymbol{B}^{\\top}\\boldsymbol{B} - \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\Vert\_F^2 \\\
=&\\, \\Vert \\boldsymbol{U}\\boldsymbol{U}^{\\top}\\boldsymbol{A}\\boldsymbol{A}^{\\top}\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top} + \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\boldsymbol{B}^{\\top}\\boldsymbol{B}\\boldsymbol{V}\\boldsymbol{V}^{\\top} - \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\Vert\_F^2 \\\
=&\\, \\Vert \\boldsymbol{U}\[(\\boldsymbol{U}^{\\top}\\boldsymbol{A})(\\boldsymbol{U}^{\\top}\\boldsymbol{A})^{\\top}\\boldsymbol{\\Sigma} + \\boldsymbol{\\Sigma} (\\boldsymbol{B}\\boldsymbol{V})^{\\top} (\\boldsymbol{B}\\boldsymbol{V}) - \\boldsymbol{\\Sigma}\] \\boldsymbol{V}^{\\top}\\Vert\_F^2 \\\
=&\\, \\Vert (\\boldsymbol{U}^{\\top}\\boldsymbol{A})(\\boldsymbol{U}^{\\top}\\boldsymbol{A})^{\\top}\\boldsymbol{\\Sigma} + \\boldsymbol{\\Sigma} (\\boldsymbol{B}\\boldsymbol{V})^{\\top} (\\boldsymbol{B}\\boldsymbol{V}) - \\boldsymbol{\\Sigma}\\Vert\_F^2 \\\
\\end{aligned}\\end{equation}
这就将原本一般矩阵$\\boldsymbol{M}$的优化问题转化为$\\boldsymbol{M}$是非负对角阵的特例，降低了分析难度。注意如果$\\boldsymbol{A},\\boldsymbol{B}$的秩不超过$r$，那么$\\boldsymbol{A}\\boldsymbol{A}^{\\top}\\boldsymbol{M} + \\boldsymbol{M}\\boldsymbol{B}^{\\top}\\boldsymbol{B}$的秩顶多为$2r$（假设$2r < \\min(n,m)$），所以原始问题也是在求$\\boldsymbol{M}$的最优$2r$秩近似，转化为非负对角阵后就是求非负对角阵的最优$2r$秩近似，跟前一个问题本质上是一样的。

## 理论基础 [\#](https://kexue.fm/archives/10407\#%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80)

肯定了SVD的作用后，我们就需要补充一些理论证明了。首先要确保SVD的存在性，其次要找出至少一种计算方案，这样SVD的各种应用才算是切实可行的，接下来我们将用同一个过程把这两个问题一起解决掉。

### 谱之定理 [\#](https://kexue.fm/archives/10407\#%E8%B0%B1%E4%B9%8B%E5%AE%9A%E7%90%86)

在此之前，我们需要先引入一个“谱定理”，它既可以说是SVD的特例，也可以说是SVD的基础：

> **谱定理** 对于任意实对称矩阵$\\boldsymbol{M}\\in\\mathbb{R}^{n\\times n}$，都存在谱分解（也称特征值分解）
> \\begin{equation}\\boldsymbol{M} = \\boldsymbol{U}\\boldsymbol{\\Lambda} \\boldsymbol{U}^{\\top}\\end{equation}
> 其中$\\boldsymbol{U},\\boldsymbol{\\Lambda}\\in\\mathbb{R}^{n\\times n}$，$\\boldsymbol{U}$是正交矩阵，$\\boldsymbol{\\Lambda}=\\text{diag}(\\lambda\_1,\\cdots,\\lambda\_n)$是对角矩阵。

说白了，谱定理就是断言任何实对称矩阵都可以被正交矩阵对角化，这基于如下两点性质：

> 1、实对称矩阵的特征值和特征向量都是实的；
>
> 2、实对称矩阵不同特征值对应的特征向量是正交的。

这两点性质的证明其实很简单，这里就不展开了。基于这两点我们可以立马得出，如果实对称矩阵$\\boldsymbol{M}$有$n$个不同的特征值，那么谱定理成立：
\\begin{equation}\\begin{aligned} \\boldsymbol{M}\\boldsymbol{u}\_1 = \\lambda\_1 \\boldsymbol{u}\_1 \\\
\\boldsymbol{M}\\boldsymbol{u}\_2 = \\lambda\_2 \\boldsymbol{u}\_2\\\
\\vdots \\\
\\boldsymbol{M}\\boldsymbol{u}\_n = \\lambda\_n \\boldsymbol{u}\_n\\end{aligned} \\quad\\Rightarrow\\quad \\boldsymbol{M}\\underbrace{(\\boldsymbol{u}\_1, \\boldsymbol{u}\_2, \\cdots, \\boldsymbol{u}\_n)}\_\\boldsymbol{U} = \\underbrace{(\\boldsymbol{u}\_1, \\boldsymbol{u}\_2, \\cdots, \\boldsymbol{u}\_n)}\_\\boldsymbol{U}\\underbrace{\\begin{pmatrix}\\lambda\_1 & 0 & \\cdots & 0 \\\
0 & \\lambda\_2 & \\cdots & 0 \\\
\\vdots & \\vdots & \\ddots & \\vdots \\\
0 & 0 & \\cdots & \\lambda\_n \\\
\\end{pmatrix}}\_{\\boldsymbol{\\Lambda}}\\end{equation}
其中$\\lambda\_1,\\lambda\_2,\\cdots,\\lambda\_n$是特征值，$\\boldsymbol{u}\_1,\\boldsymbol{u}\_2,\\cdots,\\boldsymbol{u}\_n$是对应的单位特征（列）向量，写成矩阵乘法形式就是$\\boldsymbol{M}\\boldsymbol{U}=\\boldsymbol{U}\\boldsymbol{\\Lambda}$，所以$\\boldsymbol{M} = \\boldsymbol{U}\\boldsymbol{\\Lambda} \\boldsymbol{U}^{\\top}$。证明的难点是如何拓展到有相等特征值的情形，但在思考完整的证明之前，我们可以先从一个不严谨的角度感受一下，这个不等特征值的结果是一定可以推广到一般情形的。

为什么这样说呢？从数值角度看，两个实数绝对相等的概率几乎为零，所以根本不需要考虑特征值相等的情形；用更数学的话说，那就是特征值不等的实矩阵在全体实矩阵中稠密，所以我们总可以找到一簇矩阵$\\boldsymbol{M}\_{\\epsilon}$，当$\\epsilon > 0$时它的特征值两两不等，当$\\epsilon \\to 0$时它等于$\\boldsymbol{M}$。这样一来，每个$\\boldsymbol{M}\_{\\epsilon}$我们都可以分解为$\\boldsymbol{U}\_{\\epsilon}\\boldsymbol{\\Lambda} \_{\\epsilon}\\boldsymbol{U}\_{\\epsilon}^{\\top}$，取$\\epsilon\\to 0$就得到$\\boldsymbol{M}$的谱分解。

### 数学归纳 [\#](https://kexue.fm/archives/10407\#%E6%95%B0%E5%AD%A6%E5%BD%92%E7%BA%B3)

不幸的是，上面这段话只能作为一个直观但不严谨的理解方式，因为将这段话转化为严格的证明还是很困难的。事实上，严格证明谱定理的最简单方法可能是数学归纳法，即在任意$n-1$阶实对称方阵都可以谱分解的假设上，我们证明$\\boldsymbol{M}$也可以谱分解。

证明的关键思路是将$\\boldsymbol{M}$分解为某个特征向量及其$n-1$维正交子空间，从而可以应用归纳假设。具体来说，设$\\lambda\_1$是$\\boldsymbol{M}$的一个非零特征值，$\\boldsymbol{u}\_1$是对应的单位特征向量，那么有$\\boldsymbol{M}\\boldsymbol{u}\_1 = \\lambda\_1 \\boldsymbol{u}\_1$，我们可以补充$n-1$个跟$\\boldsymbol{u}\_1$正交的单位向量$\\boldsymbol{Q}=(\\boldsymbol{q}\_2,\\cdots,\\boldsymbol{q}\_n)$，使得$(\\boldsymbol{u}\_1,\\boldsymbol{q}\_2,\\cdots,\\boldsymbol{q}\_n)=(\\boldsymbol{u}\_1,\\boldsymbol{Q})$成为一个正交矩阵。现在我们考虑
\\begin{equation}(\\boldsymbol{u}\_1,\\boldsymbol{Q})^{\\top} \\boldsymbol{M} (\\boldsymbol{u}\_1, \\boldsymbol{Q}) = \\begin{pmatrix}\\boldsymbol{u}\_1^{\\top} \\boldsymbol{M} \\boldsymbol{u}\_1 & \\boldsymbol{u}\_1^{\\top} \\boldsymbol{M} \\boldsymbol{Q} \\\ \\boldsymbol{Q}^{\\top} \\boldsymbol{M} \\boldsymbol{u}\_1 & \\boldsymbol{Q}^{\\top} \\boldsymbol{M} \\boldsymbol{Q}\\end{pmatrix} = \\begin{pmatrix}\\lambda\_1 & \\boldsymbol{0}\_{1\\times (n-1)} \\\ \\boldsymbol{0}\_{(n-1)\\times 1} & \\boldsymbol{Q}^{\\top} \\boldsymbol{M} \\boldsymbol{Q}\\end{pmatrix}\\end{equation}
注意到$\\boldsymbol{Q}^{\\top} \\boldsymbol{M} \\boldsymbol{Q}$是一个$n-1$阶方阵，并且很明显是一个实对称矩阵，所以根据假设它可以谱分解为$\\boldsymbol{V} \\boldsymbol{\\Lambda}\_2 \\boldsymbol{V}^{\\top}$，这里$\\boldsymbol{V}$是$n-1$阶正交矩阵，$\\boldsymbol{\\Lambda}\_2$是$n-1$阶对角阵，那么我们有$(\\boldsymbol{Q}\\boldsymbol{V})^{\\top} \\boldsymbol{M} \\boldsymbol{Q}\\boldsymbol{V}= \\boldsymbol{\\Lambda}\_2$。根据这个结果，我们考虑$\\boldsymbol{U} = (\\boldsymbol{u}\_1, \\boldsymbol{Q}\\boldsymbol{V})$，可以验证它也是一个正交矩阵，并且
\\begin{equation}\\boldsymbol{U}^{\\top}\\boldsymbol{M} \\boldsymbol{U} = (\\boldsymbol{u}\_1,\\boldsymbol{Q}\\boldsymbol{V})^{\\top} \\boldsymbol{M} (\\boldsymbol{u}\_1, \\boldsymbol{Q}\\boldsymbol{V}) = \\begin{pmatrix}\\lambda\_1 & \\boldsymbol{0}\_{1\\times (n-1)} \\\ \\boldsymbol{0}\_{(n-1)\\times 1} & \\boldsymbol{\\Lambda}\_2\\end{pmatrix}\\end{equation}
也就是说$\\boldsymbol{U}$正是可以将$\\boldsymbol{M}$对角化的正交矩阵，所以$\\boldsymbol{M}$可以完成谱分解，这就完成了数学归纳法最关键的一步。

### 奇异分解 [\#](https://kexue.fm/archives/10407\#%E5%A5%87%E5%BC%82%E5%88%86%E8%A7%A3)

至此，所有准备工作都已经就绪，我们可以正式证明SVD的存在性，并给出一个实际计算的方案。

上一节我们引入了谱分解，不难发现它跟SVD的相似性，但也有两点明显区别：1、谱分解只适用于实对称矩阵，SVD适用于任意实矩阵；2、SVD的对角阵$\\boldsymbol{\\Sigma}$是非负的，但谱分解的$\\boldsymbol{\\Lambda}$则未必。那么，它们具体联系是什么呢？容易验证，如果$\\boldsymbol{M}$的SVD为$\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}$，那么
\\begin{equation}\\begin{aligned}
\\boldsymbol{M}\\boldsymbol{M}^{\\top} = \\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\boldsymbol{V}\\boldsymbol{\\Sigma}^{\\top} \\boldsymbol{U}^{\\top} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^{\\top} \\boldsymbol{U}^{\\top}\\\
\\boldsymbol{M}^{\\top}\\boldsymbol{M} = \\boldsymbol{V}\\boldsymbol{\\Sigma}^{\\top} \\boldsymbol{U}^{\\top}\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top} = \\boldsymbol{V}\\boldsymbol{\\Sigma}^{\\top}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}\\\
\\end{aligned}\\end{equation}
注意到$\\boldsymbol{\\Sigma}\\boldsymbol{\\Sigma}^{\\top}$和$\\boldsymbol{\\Sigma}^{\\top}\\boldsymbol{\\Sigma}$都是对角阵，所以这意味着$\\boldsymbol{M}\\boldsymbol{M}^{\\top}$和$\\boldsymbol{M}^{\\top}\\boldsymbol{M}$的谱分解分别是$\\boldsymbol{U}\\boldsymbol{\\Sigma}^2 \\boldsymbol{U}^{\\top}$和$\\boldsymbol{V}\\boldsymbol{\\Sigma}^2 \\boldsymbol{V}^{\\top}$。这看起来将$\\boldsymbol{M}\\boldsymbol{M}^{\\top}$、$\\boldsymbol{M}^{\\top}\\boldsymbol{M}$分别做谱分解就可以得到$\\boldsymbol{M}$的SVD了？确实没错，这可以作为SVD的一种计算方式，但我们无法直接通过它证明这样得出的$\\boldsymbol{U},\\boldsymbol{\\Sigma},\\boldsymbol{V}$满足$\\boldsymbol{M}=\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}$。

解决问题的关键是只对$\\boldsymbol{M}\\boldsymbol{M}^{\\top}$或$\\boldsymbol{M}^{\\top}\\boldsymbol{M}$之一做谱分解，然后通过另外的方法构造另一侧的正交矩阵。不失一般性，我们设$\\boldsymbol{M}$的秩为$r \\leq m$，考虑对$\\boldsymbol{M}^{\\top}\\boldsymbol{M}$做谱分解为$\\boldsymbol{V}\\boldsymbol{\\Lambda} \\boldsymbol{V}^{\\top}$，注意$\\boldsymbol{M}^{\\top}\\boldsymbol{M}$是一个半正定矩阵，所以$\\boldsymbol{\\Lambda}$是非负的，并且假设对角线元素已经从大到小排列，秩$r$意味着只有前$r$个$\\lambda\_i$是大于0的，我们定义
\\begin{equation}\\boldsymbol{\\Sigma}\_{\[:r,:r\]} = (\\boldsymbol{\\Lambda}\_{\[:r,:r\]})^{1/2},\\quad \\boldsymbol{U}\_{\[:n,:r\]} = \\boldsymbol{M}\\boldsymbol{V}\_{\[:m,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}\\end{equation}
可以验证
\\begin{equation}\\begin{aligned}
\\boldsymbol{U}\_{\[:n,:r\]}^{\\top}\\boldsymbol{U}\_{\[:n,:r\]} =&\\, \\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top} \\boldsymbol{M}^{\\top}\\boldsymbol{M}\\boldsymbol{V}\_{\[:m,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1} \\\
=&\\, \\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top} \\boldsymbol{V}\\boldsymbol{\\Lambda} \\boldsymbol{V}^{\\top}\\boldsymbol{V}\_{\[:m,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1} \\\
=&\\, \\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}\\boldsymbol{I}\_{\[:r,:m\]}\\boldsymbol{\\Lambda} \\boldsymbol{I}\_{\[:m,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1} \\\
=&\\, \\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}\\boldsymbol{\\Lambda}\_{\[:r,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1} \\\
=&\\, \\boldsymbol{I}\_r \\\
\\end{aligned}\\end{equation}
这里约定切片的优先级高于转置、求逆等矩阵运算，即$\\boldsymbol{U}\_{\[:n,:r\]}^{\\top}=(\\boldsymbol{U}\_{\[:n,:r\]})^{\\top}$、$\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}=(\\boldsymbol{\\Sigma}\_{\[:r,:r\]})^{-1}$等。上述结果表明$\\boldsymbol{U}\_{\[:n,:r\]}$是正交矩阵的一部份。接着我们有
\\begin{equation}\\boldsymbol{U}\_{\[:n,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top} = \\boldsymbol{M}\\boldsymbol{V}\_{\[:m,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}^{-1}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top} = \\boldsymbol{M}\\boldsymbol{V}\_{\[:m,:r\]}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top}\\end{equation}
注意$\\boldsymbol{M}\\boldsymbol{V}\\boldsymbol{V}^{\\top} = \\boldsymbol{M}$是恒成立的，而$\\boldsymbol{V}\_{\[:m,:r\]}$是$\\boldsymbol{V}$的前$r$列，根据$\\boldsymbol{M}^{\\top}\\boldsymbol{M}=\\boldsymbol{V}\\boldsymbol{\\Lambda} \\boldsymbol{V}^{\\top}$我们有可以写出$(\\boldsymbol{M}\\boldsymbol{V})^{\\top}\\boldsymbol{M}\\boldsymbol{V} = \\boldsymbol{\\Lambda}$，我们记$\\boldsymbol{V}=(\\boldsymbol{v}\_1,\\boldsymbol{v}\_2,\\cdots,\\boldsymbol{v}\_m)$，那么就有$\\Vert \\boldsymbol{M}\\boldsymbol{v}\_i\\Vert^2=\\lambda\_i$，由于秩$r$的设定，所以当$i > r$时$\\lambda\_i=0$，这意味着此时的$\\boldsymbol{M}\\boldsymbol{v}\_i$实际上是一个零向量，所以
\\begin{equation}\\begin{aligned}\\boldsymbol{M} = \\boldsymbol{M}\\boldsymbol{V}\\boldsymbol{V}^{\\top} =&\\, (\\boldsymbol{M}\\boldsymbol{V}\_{\[:m,:r\]}, \\boldsymbol{M}\\boldsymbol{V}\_{\[:m,r:\]})\\begin{pmatrix}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top} \\\ \\boldsymbol{V}\_{\[:m,r:\]}^{\\top}\\end{pmatrix} \\\\[8pt\]
=&\\, (\\boldsymbol{M}\\boldsymbol{V}\_{\[:m,:r\]}, \\boldsymbol{0}\_{m\\times(m-r)} )\\begin{pmatrix}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top} \\\ \\boldsymbol{V}\_{\[:m,r:\]}^{\\top}\\end{pmatrix}\\\\[8pt\]
=&\\, \\boldsymbol{M}\\boldsymbol{V}\_{\[:m,:r\]}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top}
\\end{aligned}\\end{equation}
这表明$\\boldsymbol{U}\_{\[:n,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]}\\boldsymbol{V}\_{\[:m,:r\]}^{\\top}=\\boldsymbol{M}$，再结合$\\boldsymbol{U}\_{\[:n,:r\]}$是正交矩阵的一部分这一事实，我们已经得到了$\\boldsymbol{M}$的SVD的关键部分，我们只需要将$\\boldsymbol{\\Sigma}\_{\[:r,:r\]}$补零成$n\\times m$大小的$\\boldsymbol{\\Sigma}$，将$\\boldsymbol{U}\_{\[:n,:r\]}$补全为$n\\times n$的正交矩阵$\\boldsymbol{U}$，那么就得到完整的SVD形式$\\boldsymbol{M}=\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}$。

## 近似定理 [\#](https://kexue.fm/archives/10407\#%E8%BF%91%E4%BC%BC%E5%AE%9A%E7%90%86)

最后，别忘了我们的最终目标是开始的优化问题$\\eqref{eq:loss-ab}$。有了SVD后，我们就可以给出答案了：

> 如果$\\boldsymbol{M}\\in\\mathbb{R}^{n\\times m}$的SVD为$\\boldsymbol{U}\\boldsymbol{\\Sigma} \\boldsymbol{V}^{\\top}$，那么$\\boldsymbol{M}$的最优$r$秩近似为$\\boldsymbol{U}\_{\[:n,:r\]}\\boldsymbol{\\Sigma}\_{\[:r,:r\]} \\boldsymbol{V}\_{\[:m,:r\]}^{\\top}$。

这称为“ **Eckart-Young-Mirsky定理**”。在介绍SVD应用的“ [低秩近似](https://kexue.fm/archives/10407#%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC)”一节中，我们表明通过SVD可以将一般矩阵的最优$r$秩近似问题简化为非负对角阵的$r$秩近似，所以“Eckart-Young-Mirsky定理”相当于说非负对角阵的最优$r$秩近似就是只保留对角线最大的$r$个元素的矩阵。

可能有读者认为“这难道不是显然成立吗？”，但事实是虽然结论很符合直觉，但它确实不是显然成立的。下面我们就聚焦于求解：
\\begin{equation}\\min\_{\\boldsymbol{A},\\boldsymbol{B}}\\Vert \\boldsymbol{A}\\boldsymbol{B} - \\boldsymbol{\\Sigma}\\Vert\_F^2\\end{equation}
其中$\\boldsymbol{A}\\in\\mathbb{R}^{n\\times r}, \\boldsymbol{B}\\in\\mathbb{R}^{r\\times m}, \\boldsymbol{\\Sigma}\\in\\mathbb{R}^{n\\times m},r < \\min(n,m)$。如果给定$\\boldsymbol{A}$的话，$\\boldsymbol{B}$的最优解我们在上一篇文章中已经求出，结果是$\\boldsymbol{A}^{\\dagger} \\boldsymbol{\\Sigma}$，所以我们有
\\begin{equation}\\min\_{\\boldsymbol{A},\\boldsymbol{B}}\\Vert \\boldsymbol{A}\\boldsymbol{B} - \\boldsymbol{\\Sigma}\\Vert\_F^2 = \\min\_\\boldsymbol{A}\\Vert (\\boldsymbol{A}\\boldsymbol{A}^{\\dagger} - \\boldsymbol{I}\_n)\\boldsymbol{\\Sigma}\\Vert\_F^2\\end{equation}
设矩阵$\\boldsymbol{A}$的SVD为$\\boldsymbol{U}\_\\boldsymbol{A}\\boldsymbol{\\Sigma}\_\\boldsymbol{A} \\boldsymbol{V}\_\\boldsymbol{A}^{\\top}$，那么$\\boldsymbol{A}^{\\dagger}=\\boldsymbol{V}\_\\boldsymbol{A} \\boldsymbol{\\Sigma}\_\\boldsymbol{A}^{\\dagger} \\boldsymbol{U}\_\\boldsymbol{A}^{\\top}$，以及
\\begin{equation}\\begin{aligned}
\\Vert (\\boldsymbol{A}\\boldsymbol{A}^{\\dagger} - \\boldsymbol{I}\_n)\\boldsymbol{\\Sigma}\\Vert\_F^2 =&\\, \\Vert (\\boldsymbol{U}\_\\boldsymbol{A}\\boldsymbol{\\Sigma}\_\\boldsymbol{A} \\boldsymbol{V}\_\\boldsymbol{A}^{\\top}\\boldsymbol{V}\_\\boldsymbol{A} \\boldsymbol{\\Sigma}\_\\boldsymbol{A}^{\\dagger} \\boldsymbol{U}\_\\boldsymbol{A}^{\\top} - \\boldsymbol{I}\_n)\\boldsymbol{\\Sigma}\\Vert\_F^2 \\\
=&\\, \\Vert (\\boldsymbol{U}\_\\boldsymbol{A}\\boldsymbol{\\Sigma}\_\\boldsymbol{A} \\boldsymbol{\\Sigma}\_\\boldsymbol{A}^{\\dagger} \\boldsymbol{U}\_\\boldsymbol{A}^{\\top} - \\boldsymbol{I}\_n)\\boldsymbol{\\Sigma}\\Vert\_F^2 \\\
=&\\, \\Vert \\boldsymbol{U}\_\\boldsymbol{A} (\\boldsymbol{\\Sigma}\_\\boldsymbol{A} \\boldsymbol{\\Sigma}\_\\boldsymbol{A}^{\\dagger} - \\boldsymbol{I}\_n)\\boldsymbol{U}\_\\boldsymbol{A}^{\\top}\\boldsymbol{\\Sigma}\\Vert\_F^2 \\\
=&\\, \\Vert (\\boldsymbol{\\Sigma}\_\\boldsymbol{A} \\boldsymbol{\\Sigma}\_\\boldsymbol{A}^{\\dagger} - \\boldsymbol{I}\_n)\\boldsymbol{U}\_\\boldsymbol{A}^{\\top}\\boldsymbol{\\Sigma}\\Vert\_F^2 \\\
\\end{aligned}\\end{equation}
由伪逆的计算公式知$\\boldsymbol{\\Sigma}\_\\boldsymbol{A} \\boldsymbol{\\Sigma}\_\\boldsymbol{A}^{\\dagger}$是一个对角阵，并且对角线上前$r\_\\boldsymbol{A}$个元素为1（$r\_\\boldsymbol{A}\\leq r$是$\\boldsymbol{A}$的秩），其余都是0，所以$(\\boldsymbol{\\Sigma}\_\\boldsymbol{A} \\boldsymbol{\\Sigma}\_\\boldsymbol{A}^{\\dagger} - \\boldsymbol{I}\_n)\\boldsymbol{U}\_\\boldsymbol{A}^{\\top}$相当于只保留正交矩阵$\\boldsymbol{U}\_\\boldsymbol{A}^{\\top}$的后$k=n-r\_\\boldsymbol{A}$行，所以最终可以简化成
\\begin{equation}\\min\_\\boldsymbol{A}\\Vert (\\boldsymbol{A}\\boldsymbol{A}^{\\dagger} - \\boldsymbol{I}\_n)\\boldsymbol{\\Sigma}\\Vert\_F^2 = \\min\_{k,\\boldsymbol{U}}\\Vert \\boldsymbol{U}\\boldsymbol{\\Sigma}\\Vert\_F^2\\quad\\text{s.t.}\\quad k\\geq n-r, \\boldsymbol{U}\\in\\mathbb{R}^{k\\times n}, \\boldsymbol{U}\\boldsymbol{U}^{\\top} = \\boldsymbol{I}\_k\\end{equation}
现在根据$F$范数定义可以写出
\\begin{equation}\\Vert \\boldsymbol{U}\\boldsymbol{\\Sigma}\\Vert\_F^2=\\sum\_{i=1}^k \\sum\_{j=1}^n u\_{i,j}^2 \\sigma\_j^2 =\\sum\_{j=1}^n \\sigma\_j^2 \\underbrace{\\sum\_{i=1}^k u\_{i,j}^2}\_{w\_j}=\\sum\_{j=1}^n \\sigma\_j^2 w\_j\\end{equation}
注意到$0 \\leq w\_j \\leq 1$，以及$w\_1+w\_2+\\cdots+w\_n = k$，在此约束下最右端的最小值只能是最小的$k$个$\\sigma\_j^2$之和，又因为$\\sigma\_j$已经从大到小排好序，所以
\\begin{equation}\\min\_{k,\\boldsymbol{U}}\\Vert \\boldsymbol{U}\\boldsymbol{\\Sigma}\\Vert\_F^2=\\min\_k \\sum\_{j=n-k+1}^n \\sigma\_j^2 = \\sum\_{j=r+1}^n \\sigma\_j^2\\end{equation}
也就是说，$\\boldsymbol{\\Sigma}$与它的最优$r$秩近似的误差（$F$范数平方）是$\\sum\\limits\_{j=r+1}^n \\sigma\_j^2$，这正好是保留对角线最大的$r$个元素后所产生的误差，所以我们证明了“非负对角阵的最优$r$秩近似就是只保留对角线最大的$r$个元素的矩阵”。当然，这只能说是一个解，我们没有否定多解的可能性。

值得指出的是，Eckart-Young-Mirsky定理不仅对$F$范数成立，还对谱范数成立，谱范数的证明实际上还简单一点，这里就不展开了，有兴趣的读者自行参考维基百科“ [Low-rank approximation](https://en.wikipedia.org/wiki/Low-rank_approximation)”条目。

## 文章小结 [\#](https://kexue.fm/archives/10407\#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

本文的主角是声名显赫的SVD（奇异值分解），想必不少读者已经对它有所了解。在这篇文章中，我们主要围绕着SVD与低秩近似的相关内容进行展开，对SVD的存在性、计算以及与低秩近似的联系等理论内容给出了尽可能简单的证明过程。

_**转载到请包括本文地址：** [https://kexue.fm/archives/10407](https://kexue.fm/archives/10407)_

_**更详细的转载事宜请参考：**_ [《科学空间FAQ》](https://kexue.fm/archives/6508#%E6%96%87%E7%AB%A0%E5%A6%82%E4%BD%95%E8%BD%AC%E8%BD%BD/%E5%BC%95%E7%94%A8)

**如果您还有什么疑惑或建议，欢迎在下方评论区继续讨论。**

**如果您觉得本文还不错，欢迎 [分享](https://kexue.fm/archives/10407#share)/ [打赏](https://kexue.fm/archives/10407#pay) 本文。打赏并非要从中获得收益，而是希望知道科学空间获得了多少读者的真心关注。当然，如果你无视它，也不会影响你的阅读。再次表示欢迎和感谢！**

打赏

微信打赏

支付宝打赏

因为网站后台对打赏并无记录，因此欢迎在打赏时候备注留言。你还可以 [**点击这里**](http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=tN7d1drY3drrx8H0xcWa19vZ) 或在下方评论区留言来告知你的建议或需求。

**如果您需要引用本文，请参考：**

苏剑林. (Oct. 01, 2024). 《低秩近似之路（二）：SVD 》\[Blog post\]. Retrieved from [https://kexue.fm/archives/10407](https://kexue.fm/archives/10407)

@online{kexuefm-10407,
        title={低秩近似之路（二）：SVD},
        author={苏剑林},
        year={2024},
        month={Oct},
        url={\\url{https://kexue.fm/archives/10407}},
}

分类： [数学研究](https://kexue.fm/category/Mathematics)    标签： [近似](https://kexue.fm/tag/%E8%BF%91%E4%BC%BC/), [最优](https://kexue.fm/tag/%E6%9C%80%E4%BC%98/), [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/), [低秩](https://kexue.fm/tag/%E4%BD%8E%E7%A7%A9/)[4 评论](https://kexue.fm/archives/10407#comments)

< [利用“熄火保护 \+ 通断器”实现燃气灶智能关火](https://kexue.fm/archives/10394) \| [低秩近似之路（三）：CR](https://kexue.fm/archives/10427) >

### 你也许还对下面的内容感兴趣

- [msign算子的Newton-Schulz迭代（下）](https://kexue.fm/archives/10996)
- [从无穷范数求导到等值振荡定理](https://kexue.fm/archives/10972)
- [msign算子的Newton-Schulz迭代（上）](https://kexue.fm/archives/10922)
- [SVD的导数](https://kexue.fm/archives/10878)
- [矩阵的有效秩（Effective Rank）](https://kexue.fm/archives/10847)
- [MoE环游记：3、换个思路来分配](https://kexue.fm/archives/10757)
- [Muon续集：为什么我们选择尝试Muon？](https://kexue.fm/archives/10739)
- [低秩近似之路（五）：CUR](https://kexue.fm/archives/10662)
- [从谱范数梯度到新式权重衰减的思考](https://kexue.fm/archives/10648)
- [Muon优化器赏析：从向量到矩阵的本质跨越](https://kexue.fm/archives/10592)

[发表你的看法](https://kexue.fm/archives/10407#comment_form)

刘洋

January 8th, 2025

你好，公式23下面第二行，是不是应该是：把U补为n\*n的矩阵？

[回复评论](https://kexue.fm/archives/10407/comment-page-1?replyTo=26212#respond-post-10407)

[苏剑林](https://kexue.fm) 发表于
January 13th, 2025

不是。这里的SVD是完整的SVD，即$\\boldsymbol{M}=\\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\top}$，其中$\\boldsymbol{M},\\boldsymbol{\\Sigma}\\in\\mathbb{R}^{n\\times m}$，$\\boldsymbol{U}\\in\\mathbb{R}^{n\\times n}$，$\\boldsymbol{V}\\in\\mathbb{R}^{m\\times m}$。

[回复评论](https://kexue.fm/archives/10407/comment-page-1?replyTo=26252#respond-post-10407)

赵宇

March 11th, 2025

您好，我这里有个问题想付费咨询一下，两千元一个小时，您是否方便呢。

[回复评论](https://kexue.fm/archives/10407/comment-page-1?replyTo=27082#respond-post-10407)

[苏剑林](https://kexue.fm) 发表于
March 13th, 2025

不做付费咨询，抱歉。

[回复评论](https://kexue.fm/archives/10407/comment-page-1?replyTo=27103#respond-post-10407)

[取消回复](https://kexue.fm/archives/10407#respond-post-10407)

你的大名

电子邮箱

个人网站（选填）

1\. 可以使用LaTeX代码，点击“预览效果”可查看效果；2. 可以通过点击评论楼层编号来引用该楼层；3. 网站可能会有点卡，如非确认评论失败，请不要重复点击提交。

### 内容速览

[结论初探](https://kexue.fm/archives/10407#%E7%BB%93%E8%AE%BA%E5%88%9D%E6%8E%A2)
[一些应用](https://kexue.fm/archives/10407#%E4%B8%80%E4%BA%9B%E5%BA%94%E7%94%A8)
[伪逆通解](https://kexue.fm/archives/10407#%E4%BC%AA%E9%80%86%E9%80%9A%E8%A7%A3)
[矩阵范数](https://kexue.fm/archives/10407#%E7%9F%A9%E9%98%B5%E8%8C%83%E6%95%B0)
[低秩近似](https://kexue.fm/archives/10407#%E4%BD%8E%E7%A7%A9%E8%BF%91%E4%BC%BC)
[理论基础](https://kexue.fm/archives/10407#%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80)
[谱之定理](https://kexue.fm/archives/10407#%E8%B0%B1%E4%B9%8B%E5%AE%9A%E7%90%86)
[数学归纳](https://kexue.fm/archives/10407#%E6%95%B0%E5%AD%A6%E5%BD%92%E7%BA%B3)
[奇异分解](https://kexue.fm/archives/10407#%E5%A5%87%E5%BC%82%E5%88%86%E8%A7%A3)
[近似定理](https://kexue.fm/archives/10407#%E8%BF%91%E4%BC%BC%E5%AE%9A%E7%90%86)
[文章小结](https://kexue.fm/archives/10407#%E6%96%87%E7%AB%A0%E5%B0%8F%E7%BB%93)

### 智能搜索

支持整句搜索！网站自动使用 [结巴分词](https://github.com/fxsjy/jieba) 进行分词，并结合ngrams排序算法给出合理的搜索结果。

### 热门标签

[生成模型](https://kexue.fm/tag/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/) [attention](https://kexue.fm/tag/attention/) [优化](https://kexue.fm/tag/%E4%BC%98%E5%8C%96/) [语言模型](https://kexue.fm/tag/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/) [模型](https://kexue.fm/tag/%E6%A8%A1%E5%9E%8B/) [网站](https://kexue.fm/tag/%E7%BD%91%E7%AB%99/) [概率](https://kexue.fm/tag/%E6%A6%82%E7%8E%87/) [梯度](https://kexue.fm/tag/%E6%A2%AF%E5%BA%A6/) [转载](https://kexue.fm/tag/%E8%BD%AC%E8%BD%BD/) [微分方程](https://kexue.fm/tag/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B/) [天象](https://kexue.fm/tag/%E5%A4%A9%E8%B1%A1/) [矩阵](https://kexue.fm/tag/%E7%9F%A9%E9%98%B5/) [分析](https://kexue.fm/tag/%E5%88%86%E6%9E%90/) [深度学习](https://kexue.fm/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/) [积分](https://kexue.fm/tag/%E7%A7%AF%E5%88%86/) [python](https://kexue.fm/tag/python/) [优化器](https://kexue.fm/tag/%E4%BC%98%E5%8C%96%E5%99%A8/) [力学](https://kexue.fm/tag/%E5%8A%9B%E5%AD%A6/) [无监督](https://kexue.fm/tag/%E6%97%A0%E7%9B%91%E7%9D%A3/) [扩散](https://kexue.fm/tag/%E6%89%A9%E6%95%A3/) [几何](https://kexue.fm/tag/%E5%87%A0%E4%BD%95/) [节日](https://kexue.fm/tag/%E8%8A%82%E6%97%A5/) [生活](https://kexue.fm/tag/%E7%94%9F%E6%B4%BB/) [文本生成](https://kexue.fm/tag/%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/) [数论](https://kexue.fm/tag/%E6%95%B0%E8%AE%BA/)

### 随机文章

- [朋友们，来瓶汽水吧！有趣的换汽水问题](https://kexue.fm/archives/3495)
- [浅谈神经网络中激活函数的设计](https://kexue.fm/archives/4647)
- [生成扩散模型漫谈（二十五）：基于恒等式的蒸馏（上）](https://kexue.fm/archives/10085)
- [绿色和平：工厂排污36计](https://kexue.fm/archives/195)
- [一个非线性差分方程的隐函数解](https://kexue.fm/archives/3696)
- [有限内存下全局打乱几百G文件（Python）](https://kexue.fm/archives/8662)
- [《向量》系列——2.曲率半径](https://kexue.fm/archives/714)
- [与向量的渊源极深的四元数](https://kexue.fm/archives/898)
- [exp(x)在x=0处的偶次泰勒展开式总是正的](https://kexue.fm/archives/7919)
- [细水长flow之f-VAEs：Glow与VAEs的联姻](https://kexue.fm/archives/5977)

### 最近评论

- [rpsun](https://kexue.fm/archives/10699/comment-page-1#comment-27808): 这样似乎与传统的经验正交函数之类的有相似之处。把样本的平均值减掉之后做正交分解。那么如果单纯地...
- [贵阳机场接机](https://kexue.fm/archives/1490/comment-page-1#comment-27807): 怎么不更新啦
- [czvzb](https://kexue.fm/archives/10958/comment-page-1#comment-27806): 具身智能模型目前主流也是在使用扩散和流匹配这类方法来预测动作。
苏神推荐你看这几篇文章：
1....
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27805): 不好意思，以为网页卡了0.0点了三下
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27804): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27803): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...
- [Shawn\_yang](https://kexue.fm/archives/10945/comment-page-1#comment-27802): 苏神，关于您所说的：“推理阶段可以事先预估Routed Expert的实际分布，只要细致地进行...
- [OceanYU](https://kexue.fm/archives/9164/comment-page-4#comment-27801): 您好，关于由式（7）推导出高斯分布，我这里有一点问题，式（7）只能保证关于x\_t-1是二次函数...
- [jorjiang](https://kexue.fm/archives/10907/comment-page-2#comment-27800): 训练和prefill这个compute-bound阶段不做矩阵吸收，这个用我这个解释更好理解了...
- [amy](https://kexue.fm/archives/10907/comment-page-2#comment-27799): 苏老师，您有关注傅里叶旋转位置编码这篇工作吗，想知道您对这篇工作的看法是什么，这篇工作可以wo...

### 友情链接

- [Cool Papers](https://papers.cool)
- [数学研发](https://bbs.emath.ac.cn)
- [Seatop](http://www.seatop.com.cn/)
- [Xiaoxia](https://xiaoxia.org/)
- [积分表-网络版](https://kexue.fm/sci/integral/index.html)
- [丝路博傲](http://blog.dvxj.com/)
- [ph4ntasy 饭特稀](http://www.ph4ntasy.com/)
- [数学之家](http://www.2math.cn/)
- [有趣天文奇观](http://interesting-sky.china-vo.org/)
- [TwistedW](http://www.twistedwg.com/)
- [godweiyang](https://godweiyang.com/)
- [AI柠檬](https://blog.ailemon.net/)
- [王登科-DK博客](https://greatdk.com)
- [ESON](https://blog.eson.org/)
- [枫之羽](https://fzhiy.net/)
- [Mathor's blog](https://wmathor.com/)
- [coding-zuo](https://coding-zuo.github.io/)
- [博科园](https://www.bokeyuan.net/)
- [孔皮皮的博客](https://www.kppkkp.top/)
- [运鹏的博客](https://yunpengtai.top/)
- [jiming.site](https://jiming.site/)
- [OmegaXYZ](https://www.omegaxyz.com/)
- [Blog by Eacls](https://www.eacls.top/)
- [EAI猩球](https://www.robotech.ink/)
- [文举的博客](https://liwenju0.com/)
- [用代码打点酱油](https://bruceyuan.com/)
- [申请链接](https://kexue.fm/links.html)

本站采用创作共用版权协议，要求署名、非商业用途和保持一致。转载本站内容必须也遵循“ [署名-非商业用途-保持一致](http://creativecommons.org/licenses/by-nc-nd/2.5/cn/)”的创作共用协议。
© 2009-2025 Scientific Spaces. All rights reserved. Theme by [laogui](http://www.laogui.com). Powered by [Typecho](http://typecho.org). 备案号: [粤ICP备09093259号-1/2](https://beian.miit.gov.cn/)。