
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      tags: 'ams',
      packages: {'[+]': ['ams']}
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<h1><a href="https://kexue.fm/archives/6270">Couplet Robot Based on CNN and Sequence Labeling</a></h1>

    <p>By 苏剑林 | January 14, 2019</p>


<p>
  <strong>Origin #</strong> A few days ago, I saw an article titled <a href="https://mp.weixin.qq.com/s/77F8xR9XvQeF51X-oW9pHA" target="_blank">"This Brain-Twisting Couplet AI is Driving Everyone Crazy"</a> on the <i>Liangziju</i> (Quantum Bit) WeChat official account. I found it quite interesting, and more importantly, the author organized and released the dataset, so I decided to try it myself.
</p>

<h2>Action #</h2>
<p>
  "Writing couplets" can be viewed as a sentence generation task, which can be completed using seq2seq, similar to my previous post <a href="translation_5861.html" target="_blank">"Playing with Keras: seq2seq Automatic Title Generation,"</a> just with a slight modification to the input. The method used in the aforementioned article was also seq2seq, which seems to be the standard approach.
</p>

<h2>Analysis #</h2>
<p>
  However, if we think about it further, we will find that compared to general sentence generation tasks, "writing couplets" is much more regular: 1. The number of characters in the upper and lower scrolls is the same; 2. There is a character-to-character correspondence between almost every character in the upper and lower scrolls. In this way, writing couplets can be directly treated as a <strong>sequence labeling</strong> task, following the same approach as word segmentation or Named Entity Recognition (NER). This is the starting point of this article.
</p>
<p>
  Speaking of which, this article actually has very little "technical content," as sequence labeling is a very common task, much simpler than general seq2seq. Sequence labeling refers to inputting a sequence of vectors and outputting another sequence of typically the same length, and finally classifying "each frame" of this sequence. Related concepts can be further explored in the article <a href="translation_5542.html" target="_blank">"A Brief Introduction to Conditional Random Fields (CRF) with a Pure Keras Implementation."</a>
</p>

<h2>Model #</h2>
<p>
  I will introduce the model while writing the code. Readers who need to further understand the underlying basic knowledge can also refer to: <a href="translation_3924.html" target="_blank">"[Chinese Word Segmentation Series] 4. seq2seq Character Labeling Based on Bidirectional LSTM,"</a> <a href="translation_4089.html" target="_blank">"[Chinese Word Segmentation Series] 6. Chinese Word Segmentation Based on Fully Convolutional Networks,"</a> and <a href="translation_5335.html" target="_blank">"Poetry-Writing Robot Based on CNN and VAE: Random Poem Generation."</a>
</p>
<p>
  The model code we use is as follows:
</p>

<pre><code>x_in = Input(shape=(None,))
x = x_in
x = Embedding(len(chars)+1, char_size)(x)
x = Dropout(0.25)(x)
x = gated_resnet(x)
x = gated_resnet(x)
x = gated_resnet(x)
x = gated_resnet(x)
x = gated_resnet(x)
x = gated_resnet(x)
x = Dense(len(chars)+1, activation='softmax')(x)
model = Model(x_in, x)
model.compile(loss='sparse_categorical_crossentropy',
              optimizer='adam')</code></pre>

<p>
  Where <code>gated_resnet</code> is the gated convolution module I defined (also introduced in the article <a href="translation_5409.html" target="_blank">"A Reading Comprehension Question-Answering Model Based on CNN: DGCNN"</a>):
</p>

<pre><code>def gated_resnet(x, ksize=3):
    # Gated Convolution + Residual
    x_dim = K.int_shape(x)[-1]
    xo = Conv1D(x_dim*2, ksize, padding='same')(x)
    return Lambda(lambda x: x[0] * K.sigmoid(x[1][..., :x_dim]) \
                            + x[1][..., x_dim:] * K.sigmoid(-x[1][..., :x_dim]))([x, xo])</code></pre>

<p>
  And that's it! The rest is just data preprocessing. Of course, readers can also try replacing <code>gated_resnet</code> with a standard bidirectional LSTM, but in my experiments, I found that bidirectional LSTM did not perform as well as <code>gated_resnet</code>, and LSTM is also relatively slower, so LSTM was abandoned here.
</p>

<h2>Effect #</h2>
<p>
  The training dataset comes from: <a href="https://github.com/wb14123/couplet-dataset" target="_blank">https://github.com/wb14123/couplet-dataset</a>, thanks to the author for organizing it.
</p>
<p>
  Complete code: <a href="https://github.com/bojone/seq2seq/blob/master/couplet_by_seq_tagging.py" target="_blank">https://github.com/bojone/seq2seq/blob/master/couplet_by_seq_tagging.py</a>
</p>
<p>
  Training process:<br>
  <img src="https://kexue.fm/usr/uploads/2019/01/91325785.png" alt="Couplet robot training process">
</p>
<p>
  Partial results:
</p>
<ul>
  <li>Upper: 晚风摇树树还挺 (Evening breeze shakes the trees, the trees still stand firm)<br>Lower: 夜雨敲花花更香 (Night rain knocks the flowers, the flowers are more fragrant)</li>
  <li>Upper: 今天天气不错 (Today's weather is not bad)<br>Lower: 昨日人情无明 (Yesterday's human sentiment was unclear)</li>
  <li>Upper: 鱼跃此时海 (Fish leap in the sea at this time)<br>Lower: 鸟鸣何日人 (Birds sing on what day's people [?])</li>
  <li>Upper: 只有香如故 (Only the fragrance remains as before)<br>Lower: 不无月若新 (Not without the moon appearing as new)</li>
  <li>Upper: 科学空间 (Science Space [Blog Name])<br>Lower: 文明大中 (Civilization Great Middle)</li>
</ul>
<p>
  It seems to have a bit of flair. Note that "晚风摇树树还挺" is an upper scroll from the training set; the standard lower scroll is "晨露润花花更红" (Morning dew moistens the flowers, the flowers are redder), while the model gave "夜雨敲花花更香." This shows that the model isn't simply memorizing the training set but has some level of "understanding"; I even feel the lower scroll provided by the model is somewhat more vivid.
</p>
<p>
  Overall, basic character correspondence seems achievable, but it lacks a sense of global unity. The overall effect is not as good as the two below, but as a small toy, it should be satisfactory.
</p>
<ul>
  <li>Wang Bin's AI Couplet: <a href="https://ai.binwang.me/couplet/" target="_blank">https://ai.binwang.me/couplet/</a></li>
  <li>Microsoft Couplets: <a href="https://duilian.msra.cn/default.htm" target="_blank">https://duilian.msra.cn/default.htm</a></li>
</ul>

<h2>Conclusion #</h2>
<p>
  Finally, there isn't much to summarize. I just felt that writing couplets should be considered a sequence labeling task, so I wanted to try using a sequence labeling model to see how it goes, and the results turned out okay. Of course, to perform better, adjustments to the model are needed. One could also consider introducing Attention, etc., and during decoding, more prior knowledge needs to be introduced to ensure the results comply with the requirements of couplets. I'll leave these tasks for interested readers to continue.
</p>

<hr />
<p>
  <strong>Cite as:</strong>
  Su Jianlin. (Jan. 14, 2019). "Couplet Robot Based on CNN and Sequence Labeling" [Blog post]. Retrieved from <a href="https://kexue.fm/archives/6270">https://kexue.fm/archives/6270</a>
</p>

<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/6270" style="color: #005fcc;">https://kexue.fm/archives/6270</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
