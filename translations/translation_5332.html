
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      tags: 'ams',
      packages: {'[+]': ['ams']}
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<article>
    <h1><a href="https://kexue.fm/archives/5332">Poetry Robot Based on CNN and VAE: Random Poetry Generation</a></h1>
    <p>By 苏剑林 | March 24, 2018</p>

    <p>A few days ago, I wrote a <a href="translation_5253.html">popular science interpretation of VAE</a>, which received recognition from some readers. However, are you tired of every introduction only featuring a MNIST-level demo? Don't worry, I'm bringing you a more classic VAE toy: a poetry-composing robot.</p>

    <p>Why do I say "more classic"? In the previous article, we mentioned that images generated by VAE tend to be blurrier than those generated by GANs, meaning VAE is at a disadvantage in the image "battle." However, in the realm of text generation, VAE has won quite handsomely. This is because GANs attempt to directly train a discriminator (metric); however, for text, this metric is likely discrete and non-differentiable, making pure GANs very difficult to train. VAE does not have this step; it operates by reconstructing the input, a process that can be performed for both images and text. Therefore, text generation is a basic, direct application for VAE, much like image generation; for (current) GANs, however, it remains a symbol of hardship and a persistent "headache."</p>

    <p>Well, in ancient times Cao Zhi composed poetry in seven steps; today we have VAE generating poetry randomly. Let's begin~</p>

    <h2 id="模型">Model</h2>
    <p>For many people, poetry is a wonderful thing. The beauty lies in the fact that most people don't truly understand poetry, yet everyone has a superficial understanding of what poetry looks like. Therefore, as long as the generated "poetry" looks somewhat decent, we usually believe the robot can compose poetry. Thus, the so-called poetry robot is a pure toy; being able to compose a few lines of poetry does not mean its general language generation ability is high, nor does it mean our understanding of NLP has deepened significantly.</p>

    <h3 id="CNN + VAE">CNN + VAE</h3>
    <p>As far as the toy in this article is concerned, it is actually a relatively simple model, primarily combining 1D CNN with VAE. Since the length of the generated poetry is fixed, I used pure CNN for both the encoder and the decoder. The model structure diagram looks something like this:</p>

    <p style="text-align:center;"><img src="https://kexue.fm/usr/uploads/2018/03/3295055057.png" alt="cnn + vae poetry generation model" /></p>

    <p>Specifically, each character is first embedded into a vector, then stacked CNNs are used for encoding, followed by pooling to obtain an encoder result. Based on this result, the mean and variance are calculated, a normal distribution is generated, and re-sampling is performed. In the decoding stage, since there is currently only one encoder output result but multiple characters need to be output at the end, I first connected multiple different fully connected layers to obtain diverse outputs, followed by more fully connected layers.</p>

    <h3 id="GCNN">GCNN</h3>
    <p>The CNN here is not an ordinary CNN+ReLU, but the GCNN proposed by Facebook. It essentially involves creating two different CNNs with the same shape: one without an activation function and one using a sigmoid activation, then multiplying the results together. In this way, the sigmoid part acts as a "gate."</p>

    <p>The first time I saw GCNN was in the paper <a href="https://arxiv.org/pdf/1612.08083v1.pdf">"Language Modeling with Gated Convolutional Networks"</a>, and I saw it again in <a href="https://arxiv.org/pdf/1705.03122.pdf">"Convolutional Sequence to Sequence Learning"</a>. There is also a brief introduction in my post <a href="translation_4823.html">"Sharing a Slide: Fancy Natural Language Processing"</a>.</p>

    <p>Based on actual tests, GCNN performs significantly better than ordinary CNN+ReLU on many NLP tasks.</p>

    <h2 id="实验">Experiment</h2>
    <p>The experiment was completed based on Python 2.7 and Keras (Tensorflow backend)~</p>

    <h3 id="代码">Code</h3>
    <p>With the previous discussion and by combining Keras's built-in VAE example, implementing the entire model is not difficult. For demonstration purposes, I only selected the simplest five-character poetry, and I didn't require the generation of a complete poem—just a single line (10 characters), which is actually more like composing couplets.</p>

    <p>Code: <a href="https://github.com/bojone/vae/blob/master/vae_shi.py">https://github.com/bojone/vae/blob/master/vae_shi.py</a></p>

    <p>The training corpus used is the Complete Tang Poems (Quan Tangshi), which has also been placed on GitHub. The model has not undergone extensive hyperparameter tuning, which is left for interested readers to tinker with and enhance.</p>

    <h3 id="训练">Training</h3>
    <p>To observe the changes in the generated poetry lines during the training process, I wrote an evaluator. The effect is shown below:</p>

    <p style="text-align:center;"><img src="https://kexue.fm/usr/uploads/2018/03/4096055869.png" alt="Poetry robot training process" /></p>

    <p>As can be seen, as the number of training iterations increases, the quality of the poetry lines indeed improves.</p>

    <h3 id="测试">Testing</h3>
    <p>Below are some poetry lines randomly generated by the trained model. Strictly speaking, they aren't great—this is, after all, just a mapping from random numbers to poetry lines, essentially "randomly producing poetry"~ It can be seen that these "poetry lines" look somewhat decent in terms of antithesis and tonal patterns (pingze).</p>

    <blockquote>
        出上无花客，相来一日时。<br />
        从瞻大车策，萧盖偃车矛。<br />
        今见青衣去，萧凉白叶风。<br />
        帝城今不战，征罪在天兵。<br />
        鹤仰临山里，逶留出太回。<br />
        画关斜过水，残色迥过杨。<br />
        上道皆有战，四门不如兵。<br />
        涧烟含雨沥，风影动风风。<br />
        登回一落景，一处更相期。<br />
        芳酒不无醉，长楼酒更春。<br />
        天月满云管，楚女长南闻。<br />
        明今今有矣，不得道无生。<br />
        朝明开绿菊，香影下红枝。<br />
        世外相扁处，逍遥无旧目。<br />
        唯闻含玉色，讵见月光光。<br />
        春风将乐节，风服未谁娱。<br />
        万年君何在，今年酒未新。<br />
        回辔参相召，乘歌会使程。<br />
        今有千人醉，不然一子心。<br />
        今风泛云会，清日白衣新。<br /><br />
        Note: The demo model only generates single lines of poetry; therefore, there is no correlation between the lines themselves.
    </blockquote>

    <h2 id="最后">Conclusion</h2>
    <p>The experiment in this article was not intended to produce high-quality poetry, but rather to serve as a demonstration of text generation based on VAE. There are similar poetry robots online, but most popular poetry robots are based on the "RNN + Language Model" approach, which generally requires some seed words as input to complete the poem. VAE, however, truly achieves the process of mapping random numbers to poetry lines~</p>
</article>
<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/5332" style="color: #005fcc;">https://kexue.fm/archives/5332</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
