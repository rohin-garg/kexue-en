
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    tags: 'ams',
    packages: {'[+]': ['ams']}
  },
  loader: {load: ['[tex]/ams']}
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<nav style="margin-bottom: 1.5em;">
    <a href="../index.html" style="display: inline-flex; align-items: center; color: #555; text-decoration: none; font-size: 0.95em;">
        <span style="margin-right: 0.3em;">&larr;</span> Back to Index
    </a>
</nav>

<h1><a href="https://kexue.fm/archives/4385">How to "Scrape" a Site? A Step-by-Step Guide to Crawling Baidu Baike</a></h1>

<p>By 苏剑林 | May 17, 2017</p>

<p>Recently, I had a requirement to crawl some children's story corpora to train word vectors. Therefore, I found several fairy tale websites and crawled the entire sites' worth of articles. Below, I will share the process implemented in Python and combine it with my previous experience crawling Baidu Baike. This tutorial is suitable for the following needs: requiring a traversal crawl of a specified website, where the specified website has no anti-crawler measures. Under this premise, the only challenges we face are the <strong>traversal algorithm</strong> and <strong>programming skills</strong>.</p>

<h2>Hypotheses</h2>

<p>To reiterate our assumptions:</p>
<blockquote>
    <p>1. We need to traverse the entire website to crawl the information we need;<br>
    2. The website has no anti-crawler measures;<br>
    3. Every page of the website can eventually be reached from the homepage by progressively clicking hyperlinks.</p>
</blockquote>

<p>What kind of websites fit these assumptions? The answer is: quite a few. For instance, the story website we are about to crawl, as well as Baidu Baike, Hudong Baike, etc.</p>
<p>First, let's look at how to crawl this story website:</p>
<p><a href="http://wap.xigushi.com/">http://wap.xigushi.com/</a></p>
<p>(For educational use only, no malicious intent~)</p>

<h2>Breadth-First Search</h2>

<p>The Breadth-First Search (BFS) algorithm is actually very simple: for every page crawled, save all the internal hyperlinks found on that page, and then add those hyperlinks that haven't been added to the queue yet into the queue.</p>
<p>Finished? Finished! It’s that simple. Note that the queue follows the "First-In-First-Out" (FIFO) principle; therefore, what was described above is essentially the BFS algorithm. Writing it in Python is also very straightforward:</p>

<pre><code></code></pre>

<p>In just a few lines, we have implemented a general-purpose scraping framework with multi-threaded concurrency capabilities. Much of the code follows a fixed pattern and has high reusability. This is the elegance of Python—as they say, "Life is short, I use Python."</p>

<h2>Baidu Baike</h2>

<p>The code above already completes a general scraping framework. However, if we want to crawl Baidu Baike or Hudong Baike, we will encounter new problems. Because our previous code completed all data I/O in memory, this is fine for small sites, but for sites like Baike that have millions or even tens of millions of pages, it's naturally unsustainable. Thus, two issues need consideration: 1. Resumable crawling (breakpoint continuation); 2. Memory efficiency. In fact, both of these issues are solved by the same solution: a database. Previously, we stored the queue in a <code>Queue</code> and the results in a dictionary, both of which reside in memory. If we put them in a database, these two problems are naturally resolved.</p>
<p>For databases, I personally prefer MongoDB. Putting aside other advantages, it feels very Pythonic to me—when paired with <code>pymongo</code> for operations, you hardly feel like you are operating a database; it feels like you are purely using Python (by contrast, using SQL through Python usually makes it hard to avoid writing SQL statements). I won't go into the installation of MongoDB here; assuming it is already installed along with <code>pymongo</code>, here is the reference code for crawling Baidu Baike:</p>

<pre><code></code></pre>

<p>Example Output:</p>
<blockquote>
    2017-05-17 20:20:18.428393, Crawling "Physical Anthropology", URL: http://baike.baidu.com/item/体质人类学, 167 crawled<br>
    2017-05-17 20:20:18.502221, Crawling "Group Dynamics", URL: http://baike.baidu.com/item/群体动力学, 168 crawled<br>
    2017-05-17 20:20:18.535227, Crawling "Biological Taxonomy", URL: http://baike.baidu.com/item/生物分类学, 169 crawled<br>
    2017-05-17 20:20:18.545897, Crawling "Virology", URL: http://baike.baidu.com/item/病毒学, 170 crawled<br>
    2017-05-17 20:20:18.898083, Crawling "Chromatography (Book Title)", URL: http://baike.baidu.com/item/色谱法, 171 crawled<br>
    2017-05-17 20:20:18.929467, Crawling "Molecular Biology (Natural Science Branch)", URL: http://baike.baidu.com/item/分子生物, 172 crawled<br>
    2017-05-17 20:20:18.974105, Crawling "Geochemistry (Subject Name)", URL: http://baike.baidu.com/item/地球化学, 173 crawled<br>
    2017-05-17 20:20:18.979666, Crawling "Nanotechnology (Physics Term)", URL: http://baike.baidu.com/item/纳米科技, 174 crawled<br>
    2017-05-17 20:20:19.077445, Crawling "Theoretical Chemistry", URL: http://baike.baidu.com/item/理论化学, 175 crawled<br>
    2017-05-17 20:20:19.143304, Crawling "Thermochemistry", URL: http://baike.baidu.com/item/热化学, 176 crawled<br>
    2017-05-17 20:20:19.333775, Crawling "Acoustics", URL: http://baike.baidu.com/item/声学, 177 crawled<br>
    2017-05-17 20:20:19.349983, Crawling "Mathematical Physics", URL: http://baike.baidu.com/item/数学物理, 178 crawled<br>
    2017-05-17 20:20:19.662366, Crawling "High Energy Physics", URL: http://baike.baidu.com/item/高能物理学, 179 crawled<br>
    2017-05-17 20:20:19.797841, Crawling "Physics (Natural Science Discipline)", URL: http://baike.baidu.com/item/物理学, 180 crawled<br>
    2017-05-17 20:20:19.809453, Crawling "Condensed Matter Physics", URL: http://baike.baidu.com/item/凝聚态物理学, 181 crawled<br>
    2017-05-17 20:20:19.898944, Crawling "Atom (Physics Concept)", URL: http://baike.baidu.com/item/原子, 182 crawled
</blockquote>

<p>The basic framework has been implemented here. Of course, when readers use it, they still need to adjust according to their needs—for example, strengthening regular expressions to clean up useless information like "Collect View My Collection 0 Useful +1 Voted", and extracting some structured information for separate storage (don't be lazy and use it directly, the results would have a lot of noise~ there's no such thing as a free lunch). All in all, everyone can give full play to their creativity based on this. After sufficient crawling with the above code, approximately 2.8 million entries can be crawled, which basically covers most commonly used terms.</p>

<h2>Reflection & Summary</h2>

<p>Some readers might ask: Doesn't Baidu Baike have links like <a href="http://baike.baidu.com/view/52650.htm">http://baike.baidu.com/view/52650.htm</a>? Couldn't you traverse the entire site just by iterating through those numbers?</p>
<p>If you're only considering Baidu Baike, that logic is correct. However, that approach is not universal; for example, Hudong Baike does not have such links. Since we are interested here in a universal crawling solution, we still adopt this BFS traversal approach.</p>
<p>To reiterate: the websites and demonstration code involved in this article are for teaching and demonstration purposes only, without any malicious intent~</p>
<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/4385" style="color: #005fcc;">https://kexue.fm/archives/4385</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
