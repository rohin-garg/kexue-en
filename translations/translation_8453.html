
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    tags: 'ams',
    packages: {'[+]': ['ams']}
  },
  options: {
    renderActions: {
      findScript: [10, function (doc) {
        for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
          const display = !!node.type.match(/; *mode=display/);
          const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
          const text = document.createTextNode('');
          node.parentNode.replaceChild(text, node);
          math.start = {node: text, delim: '', n: 0};
          math.end = {node: text, delim: '', n: 0};
          doc.math.push(math);
        }
      }, '']
    }
  }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<article>
    <h1><a href="https://kexue.fm/archives/8453">Orthogonal Matrix for Transforming One Unit Vector to Another</a></h1>
    <p>By 苏剑林 | June 05, 2021</p>

    <p>In this article, we discuss a practical linear algebra problem:</p>
    <blockquote>
        <p>Given two $d$-dimensional unit (column) vectors $\boldsymbol{a}, \boldsymbol{b}$, find an orthogonal matrix $\boldsymbol{T}$ such that $\boldsymbol{b} = \boldsymbol{T}\boldsymbol{a}$.</p>
    </blockquote>
    <p>Since the two vectors have the same magnitude, it is clear that such an orthogonal matrix must exist. So, how do we find it?</p>

    <h2>Two Dimensions</h2>
    <p>It is not hard to imagine that this is essentially a problem of vector transformation (such as rotation or reflection) within the two-dimensional sub-plane formed by $\boldsymbol{a}$ and $\boldsymbol{b}$. Therefore, let us first consider the case where $d=2$.</p>

    <p style="text-align:center;">
        <img src="https://kexue.fm/usr/uploads/2021/06/3313936998.png" alt="Orthogonal decomposition diagram" /><br />
        <em>Schematic of orthogonal decomposition</em>
    </p>

    <p>As shown in the figure above, through orthogonal decomposition, we can obtain a vector $\boldsymbol{b} - \boldsymbol{a}\cos\theta$ which is perpendicular to $\boldsymbol{a}$. After normalization, we can obtain an orthonormal basis:</p>
    \begin{equation}\boldsymbol{Q} = \begin{pmatrix}\boldsymbol{a} & \frac{\boldsymbol{b} - \boldsymbol{a}\cos\theta}{\Vert \boldsymbol{b} - \boldsymbol{a}\cos\theta\Vert}\end{pmatrix}\end{equation}
    <p>where $\theta$ is the angle between $\boldsymbol{a}$ and $\boldsymbol{b}$. In this coordinate basis, the coordinates of $\boldsymbol{a}$ are $(1,0)$ and the coordinates of $\boldsymbol{b}$ are $(\cos\theta, \sin\theta)$, i.e.,</p>
    \begin{equation}\boldsymbol{a}=\boldsymbol{Q}\begin{pmatrix}1 \\ 0\end{pmatrix},\quad \boldsymbol{b}=\boldsymbol{Q}\begin{pmatrix}\cos\theta \\ \sin\theta\end{pmatrix}\end{equation}
    <p>Therefore,</p>
    \begin{equation}\boldsymbol{b}=\boldsymbol{Q}\boldsymbol{R}\begin{pmatrix}1 \\ 0\end{pmatrix}=\boldsymbol{Q}\boldsymbol{R}\boldsymbol{Q}^{\top}\boldsymbol{a}\label{eq:ba}\end{equation}
    <p>Here, there are two choices for $\boldsymbol{R}$:</p>
    \begin{equation}\boldsymbol{R}=\begin{pmatrix}\cos\theta & -\sin\theta \\ \sin\theta & \cos\theta\end{pmatrix}\quad \text{or} \quad\boldsymbol{R}=\begin{pmatrix}\cos\theta & \sin\theta \\ \sin\theta & -\cos\theta\end{pmatrix}\end{equation}
    <p>From a geometric perspective, the former corresponds to a rotation of the vector, while the latter corresponds to a reflection. Both lead to slightly different final results, but from a purely mathematical standpoint, they are both orthogonal matrices that satisfy the requirements. Equation $\eqref{eq:ba}$ implies that the sought orthogonal matrix is:</p>
    \begin{equation}\boldsymbol{T}=\boldsymbol{Q}\boldsymbol{R}\boldsymbol{Q}^{\top}\end{equation}

    <h2>Multi-Dimensions</h2>
    <p>For readers who have understood the above process, the logic for the multi-dimensional case is already quite clear. We similarly choose an orthonormal basis first and then transform the problem into a simpler case. Since $d > 2$, $\boldsymbol{a}$ and $\frac{\boldsymbol{b} - \boldsymbol{a}\cos\theta}{\Vert \boldsymbol{b} - \boldsymbol{a}\cos\theta\Vert}$ are not enough to form a complete basis. However, theoretically, we can find $\boldsymbol{e}_3, \cdots, \boldsymbol{e}_d$ such that</p>
    \begin{equation}\tilde{\boldsymbol{Q}} = \begin{pmatrix}\boldsymbol{a} & \frac{\boldsymbol{b} - \boldsymbol{a}\cos\theta}{\Vert \boldsymbol{b} - \boldsymbol{a}\cos\theta\Vert} & \boldsymbol{e}_3 & \cdots & \boldsymbol{e}_d\end{pmatrix} = \begin{pmatrix}\boldsymbol{Q} & \boldsymbol{E}\end{pmatrix}\end{equation}
    <p>forms an orthonormal basis, where</p>
    \begin{equation}\boldsymbol{Q}=\begin{pmatrix}\boldsymbol{a} & \frac{\boldsymbol{b} - \boldsymbol{a}\cos\theta}{\Vert \boldsymbol{b} - \boldsymbol{a}\cos\theta\Vert} \end{pmatrix}\in\mathbb{R}^{d\times 2},\quad\boldsymbol{E}=\begin{pmatrix}\boldsymbol{e}_3 & \cdots & \boldsymbol{e}_d\end{pmatrix}\in\mathbb{R}^{d\times (d-2)}\end{equation}
    <p>In this case,</p>
    \begin{equation}\boldsymbol{a}=\tilde{\boldsymbol{Q}}\begin{pmatrix}1 \\ 0 \\ 0 \\ \vdots \\ 0\end{pmatrix},\quad \boldsymbol{b}=\tilde{\boldsymbol{Q}}\begin{pmatrix}\cos\theta \\ \sin\theta \\ 0 \\ \vdots \\ 0\end{pmatrix}=\tilde{\boldsymbol{Q}}\begin{pmatrix} \boldsymbol{R} & \boldsymbol{0}_{2\times(d-2)} \\ \boldsymbol{0}_{(d-2)\times 2} & \boldsymbol{I}_{(d-2)\times(d-2)}\end{pmatrix}\begin{pmatrix}1 \\ 0 \\ 0 \\ \vdots \\ 0\end{pmatrix}\end{equation}
    <p>The definition of $\boldsymbol{R}$ remains the same as before. Thus, the matrix we are looking for is:</p>
    \begin{equation}\boldsymbol{T}=\tilde{\boldsymbol{Q}}\begin{pmatrix} \boldsymbol{R} & \boldsymbol{0}_{2\times(d-2)} \\ \boldsymbol{0}_{(d-2)\times 2} & \boldsymbol{I}_{(d-2)\times(d-2)}\end{pmatrix}\tilde{\boldsymbol{Q}}^{\top}\label{eq:final-1}\end{equation}

    <h2>Simplification</h2>
    <p>Expressing the matrix $\eqref{eq:final-1}$ using block matrices $\boldsymbol{Q}, \boldsymbol{R}, \boldsymbol{E}$, the result is $\boldsymbol{Q}\boldsymbol{R}\boldsymbol{Q}^{\top}+\boldsymbol{E}\boldsymbol{E}^{\top}$. Noticing that we also have $\tilde{\boldsymbol{Q}}\tilde{\boldsymbol{Q}}^{\top}=\boldsymbol{I}_{d\times d}$, this means $\boldsymbol{E}\boldsymbol{E}^{\top}=\boldsymbol{I}_{d\times d} - \boldsymbol{Q}\boldsymbol{Q}^{\top}$. Therefore, the transformation $\eqref{eq:final-1}$ can finally be written as:</p>
    \begin{equation}\boldsymbol{T}=\boldsymbol{Q}\boldsymbol{R}\boldsymbol{Q}^{\top}+\boldsymbol{I}_{d\times d} - \boldsymbol{Q}\boldsymbol{Q}^{\top}\end{equation}
    <p>One surprising point about this result is that $\boldsymbol{E}$, which carries a degree of randomness, is eliminated, resulting in a deterministic outcome. We can further substitute the concrete forms of $\boldsymbol{Q}$ and $\boldsymbol{R}$ to simplify the result significantly:</p>
    \begin{equation}\boldsymbol{T} = \left\{\begin{aligned}\boldsymbol{I}_{d\times d} + 2\boldsymbol{b}\boldsymbol{a}^{\top}- 
    \frac{(\boldsymbol{a} + \boldsymbol{b})(\boldsymbol{a} + \boldsymbol{b})^{\top}}{1+\cos\theta},\quad &\text{when}\,\boldsymbol{R}=\begin{pmatrix}\cos\theta & -\sin\theta \\ \sin\theta & \cos\theta\end{pmatrix} \\ 
    \boldsymbol{I}_{d\times d} - 
    \frac{(\boldsymbol{a} - \boldsymbol{b})(\boldsymbol{a} - \boldsymbol{b})^{\top}}{1-\cos\theta},\quad &\text{when}\,\boldsymbol{R}=\begin{pmatrix}\cos\theta & \sin\theta \\ \sin\theta & -\cos\theta\end{pmatrix} 
    \end{aligned}\right.\label{eq:final-2}\end{equation}
    <p>It is worth noting that the second matrix is a symmetric orthogonal matrix (orthogonality is necessary, symmetry is not)! This means that for the same orthogonal matrix $\boldsymbol{T}$, it can transform $\boldsymbol{a}$ into $\boldsymbol{b}$ and also transform $\boldsymbol{b}$ into $\boldsymbol{a}$:</p>
    \begin{equation}\boldsymbol{b}=\boldsymbol{T}\boldsymbol{a},\quad\boldsymbol{a}=\boldsymbol{T}\boldsymbol{b}\end{equation}
    <p>This is quite an interesting result, so we select it as our final answer. Noting that $2(1-\cos\theta)=\Vert\boldsymbol{a} - \boldsymbol{b}\Vert^2$, this result can also be written as:</p>
    \begin{equation}\boldsymbol{T} = \boldsymbol{I}_{d\times d} - 2\left(\frac{\boldsymbol{a} - \boldsymbol{b}}{\Vert\boldsymbol{a} - \boldsymbol{b}\Vert}\right)\left(\frac{\boldsymbol{a} - \boldsymbol{b}}{\Vert\boldsymbol{a} - \boldsymbol{b}\Vert}\right)^{\top}\end{equation}
    <p>This is the <a href="https://en.wikipedia.org/wiki/Householder_transformation">Householder transformation</a> with $\boldsymbol{a} - \boldsymbol{b}$ as the mirror plane. Therefore, if one is already familiar with the Householder transformation, this result can be derived easily.</p>
    <p>Using the following logic, we can also obtain a more formally symmetric $\boldsymbol{T}$:</p>
    <blockquote>
        <p>To obtain $\boldsymbol{T}$ such that $\boldsymbol{b}=\boldsymbol{T}\boldsymbol{a}$, one can first find $\tilde{\boldsymbol{T}}$ such that $-\boldsymbol{b}=\tilde{\boldsymbol{T}}\boldsymbol{a}$, and then let $\boldsymbol{T}=-\tilde{\boldsymbol{T}}$.</p>
    </blockquote>
    <p>In other words, by substituting $\boldsymbol{b} \to -\boldsymbol{b}$ in result $\eqref{eq:final-2}$ and then negating the entire expression, we can also obtain a transformation that meets the requirements. Applying this logic to the second solution in $\eqref{eq:final-2}$, we get:</p>
    \begin{equation}\boldsymbol{T} = \frac{(\boldsymbol{a} + \boldsymbol{b})(\boldsymbol{a} + \boldsymbol{b})^{\top}}{1+\cos\theta} - \boldsymbol{I}_{d\times d}=\frac{(\boldsymbol{a} + \boldsymbol{b})(\boldsymbol{a} + \boldsymbol{b})^{\top}}{1+\boldsymbol{a}^{\top}\boldsymbol{b}} - \boldsymbol{I}_{d\times d}\label{eq:final-3}\end{equation}
    <p>This is what the author considers to be the simplest form of the solution. Note that this is a new solution, generally not equal to either of the two solutions in $\eqref{eq:final-2}$. This means we have provided three feasible solutions so far.</p>

    <h2>Code</h2>
    <p>Code verification gives us more confidence in the correctness of the theoretical results. Below is a reference verification code:</p>

<pre><code>#! -*- coding: utf-8 -*-
import numpy as np

def orthonormal_matrix_for_a_to_b(a, b):
    """Find orthogonal matrix T such that Ta is in the same direction as b
    """
    a = a / np.linalg.norm(a)
    b = b / np.linalg.norm(b)
    ab = (a + b).reshape((-1, 1))
    return ab.dot(ab.T) / (1 + a.dot(b)) - np.eye(a.shape[0])

a = np.array([1, 2, 3, 4, 5])
b = np.array([9, 8, 7, 6, 5])
T = orthonormal_matrix_for_a_to_b(a, b)
assert np.allclose(T.dot(T.T), np.eye(a.shape[0])) # Verify orthogonality
r = T.dot(a) / b
assert np.allclose(r, r[0]) # Verify if parallel
assert r[0] > 0 # Verify if in same direction
r = T.dot(b) / a
assert np.allclose(r, r[0]) # Verify if parallel
assert r[0] > 0 # Verify if in same direction
</code></pre>

    <p>The experimental results show that result $\eqref{eq:final-3}$ is indeed correct. Of course, one can also start from $\eqref{eq:final-3}$ and directly calculate $\boldsymbol{T}\boldsymbol{T}^{\top}=\boldsymbol{I}_{d\times d}$ as well as $\boldsymbol{b}=\boldsymbol{T}\boldsymbol{a}, \boldsymbol{a}=\boldsymbol{T}\boldsymbol{b}$ to ensure the result is correct.</p>

    <h2>Summary</h2>
    <p>In this article, we solved a linear algebra exercise: finding an orthogonal matrix that transforms one unit vector into another. We ultimately arrived at a rather simple and interesting result. This transformation can often simplify coordinate-independent problems into a specific case for handling, making it quite valuable in practice.</p>
</article>
<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/8453" style="color: #005fcc;">https://kexue.fm/archives/8453</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
