
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    packages: {'[+]': ['ams']},
    tags: 'ams'
  },
  options: {
    renderActions: {
      findScript: [10, function (doc) {
        for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
          const display = !!node.type.match(/; *mode=display/);
          const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
          const text = document.createTextNode('');
          node.parentNode.replaceChild(text, node);
          math.start = {node: text, delim: '', n: 0};
          math.end = {node: text, delim: '', n: 0};
          doc.math.push(math);
        }
      }, '']
    }
  },
  loader: {load: ['[tex]/ams']}
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<article>
    <nav style="margin-bottom: 1.5em;">
    <a href="../index.html" style="display: inline-flex; align-items: center; color: #555; text-decoration: none; font-size: 0.95em;">
        <span style="margin-right: 0.3em;">&larr;</span> Back to Index
    </a>
</nav>

    <h1><a href="https://kexue.fm/archives/3781">OCR Technology Exploration: 2. Background and Assumptions</a></h1>

    <p>By 苏剑林 | June 17, 2016</p>


    <h3>Research Background</h3>
    <p>Optical Character Recognition (OCR) refers to the process of converting text within images into computer-editable text content. Numerous researchers have studied related technologies for a long time, leading to the creation of many mature OCR technologies and products, such as Hanwang OCR, ABBYY FineReader, and Tesseract OCR. It is worth mentioning that ABBYY FineReader not only has high accuracy (including for Chinese recognition) but also preserves most of the original layout, making it a very powerful commercial OCR software. However, among the many established OCR products, except for Tesseract OCR, most are closed-source or even commercial software; we can neither embed them into our own programs nor improve upon them. The only choice for open source is Google's Tesseract OCR, but its recognition performance is not particularly good, and its Chinese recognition accuracy is relatively low, requiring further improvement. In summary, whether for academic research or practical application, it is necessary to explore and improve OCR technology.</p>
    <p>Our team has divided the complete OCR system into four aspects: "feature extraction," "text localization," "optical recognition," and "language model," solving them step by step to eventually complete a usable and integrated OCR system for printed text. This system can be preliminarily used for image text recognition on platforms such as e-commerce and WeChat to verify the authenticity of information.</p>

    <h3>Research Assumptions</h3>
    <p>In this article, we assume that the text portions of the images have the following characteristics:</p>
    <ol>
        <li>We assume the image fonts to be recognized are relatively standard printed fonts, such as Songti, Heiti, Kaiti, Xingshu, etc.;</li>
        <li>There should be a relatively obvious contrast between the text and the background;</li>
        <li>During model design, we assume the text in the images is typeset horizontally;</li>
        <li>The strokes of the text should have a certain width and should not be too thin;</li>
        <li>The color of a single character should at most be a gradient;</li>
        <li>Generally, text is formed by relatively dense strokes and often exhibits a certain degree of connectivity.</li>
    </ol>
    <p>As can be seen, these characteristics are common features of typical e-commerce promotional posters and similar media, making these assumptions quite reasonable.</p>

    <h3>Analysis Flow</h3>
    <p>Figure 1: Our experimental flow chart</p>

    <h3>Experimental Platform</h3>
    <p>The experiments in this article were completed in an environment of CentOS 7 + Python 2.7. Among them, the image processing portion utilized the following extension libraries: Numpy, SciPy, Pandas, and Pillow; the convolutional neural network model utilized the following extension libraries: Keras and Theano. Specific experimental configurations will be discussed further in later sections.</p>
</article>
<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/3781" style="color: #005fcc;">https://kexue.fm/archives/3781</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
