
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    tags: 'ams',
    packages: {'[+]': ['base', 'ams', 'amsmath', 'amssymb', 'amsfonts']}
  },
  options: {
    renderActions: {
      addMenu: []
    }
  },
  loader: {
    load: ['[tex]/amsmath', '[tex]/amssymb', '[tex]/amsfonts']
  }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<article>
    <nav style="margin-bottom: 1.5em;">
    <a href="../index.html" style="display: inline-flex; align-items: center; color: #555; text-decoration: none; font-size: 0.95em;">
        <span style="margin-right: 0.3em;">&larr;</span> Back to Index
    </a>
</nav>

    <h1><a href="https://kexue.fm/archives/8718">Using Dirac Functions to Construct Smooth Approximations of Non-smooth Functions</a></h1>
    
    <p>By 苏剑林 | October 10, 2021</p>

    <p>In machine learning, we often encounter non-smooth functions. However, our optimization methods are usually gradient-based, which means that smooth models are generally more conducive to optimization (as the gradients are continuous). Consequently, there is a demand for finding smooth approximations of non-smooth functions. In fact, this blog has discussed related topics multiple times, such as <a href="translation_3290.html">"Seeking a Smooth Maximum Function"</a> and <a href="translation_6620.html">"On Function Smoothing: Differentiable Approximations of Non-differentiable Functions"</a>. However, the previous discussions lacked generality in their methodologies.</p>

    <p>Recently, I learned a relatively general approach from the paper <a href="https://papers.cool/arxiv/2109.13210">"SAU: Smooth activation function using convolution with approximate identities"</a>: using Dirac functions to construct smooth approximations. How general is it? In theory, any function with a countable number of discontinuities can be smoothly approximated using this method! I find this quite interesting.</p>

    <h2>The Dirac Function</h2>

    <p>In a very early article, <a href="translation_1870.html">"The Eerie Dirac Function"</a>, we introduced the Dirac function. In modern mathematics, the Dirac function is defined as a "functional" rather than a "function," but for most readers, understanding it as a function is easier to grasp.</p>

    <p>Simply put, the Dirac function $\delta(x)$ satisfies:</p>
    <blockquote>
        <p>1. $\forall x \neq 0, \delta(x) = 0$;<br>
        2. $\delta(0) = \infty$;<br>
        3. $\int_{-\infty}^{\infty} \delta(x) dx = 1$.</p>
    </blockquote>

    <p>Intuitively, $\delta(x)$ can be viewed as a continuous probability density function where the sampling space is all real numbers $\mathbb{R}$, but the probability is non-zero only at $x=0$. That is, its mean is 0 and its variance is also 0; thus, any sample taken from it must be 0. Therefore, the following identity holds:</p>
    \begin{equation}\int_{-\infty}^{\infty} f(x)\delta(x) dx = f(0)\end{equation}
    <p>Or</p>
    \begin{equation}\int_{-\infty}^{\infty} f(y)\delta(x-y) dy = f(x)\label{eq:base}\end{equation}
    <p>This is arguably the most important property of the Dirac function and is the primary identity we will use moving forward.</p>

    <h2>Smooth Approximation</h2>

    <p>If we can find a smooth approximation of $\delta(x)$, denoted as $\varphi(x) \approx \delta(x)$, then according to $\eqref{eq:base}$, we have:</p>
    \begin{equation}g(x) = \int_{-\infty}^{\infty} f(y)\varphi(x-y) dy \approx f(x)\end{equation}
    <p>Since $\varphi(x)$ is smooth, $g(x)$ is also smooth. This means that $g(x)$ serves as a smooth approximation of $f(x)$! This is the core idea of constructing a smooth approximation of $f(x)$ by leveraging smooth approximations of the Dirac function. In this process, there are very few restrictions on the form or continuity of $f(x)$; for instance, $f(x)$ is allowed to have a countable number of jump discontinuities (such as the floor function $[x]$).</p>

    <p>So, what are some smooth approximations of the Dirac function? There are several readily available ones, such as:</p>
    \begin{equation}\delta(x) = \lim_{\sigma\to 0} \frac{e^{-x^2/2\sigma^2}}{\sqrt{2\pi}\sigma}\label{eq:g}\end{equation}
    <p>Or</p>
    \begin{equation}\delta(x)=\frac{1}{\pi} \lim_{a \to 0}\frac{a}{x^2+a^2}\end{equation}
    <p>Simply put, it involves finding a non-negative function with a bell-shaped curve like the normal distribution, and making the width of the bell approach zero while keeping the integral equal to 1. Another approach is to note that:</p>
    \begin{equation}\int_{-\infty}^x \delta(t)dt = \theta(x) = \left\{\begin{aligned}1,\,\, (x > 0) \\ 0,\,\, (x < 0)\end{aligned}\right.\end{equation}
    <p>That is, the integral of the Dirac function is the "unit step function" $\theta(x)$. If we can find a smooth approximation of $\theta(x)$, then its derivative will yield a smooth approximation of the Dirac function. Smooth approximations of $\theta(x)$ are the so-called "S-shaped" curves, such as the sigmoid function $\sigma(x)=1/(1+e^{-x})$. Thus, we have:</p>
    \begin{equation}\delta(x) = \lim_{t\to \infty} \frac{d}{dx}\sigma(tx) = \lim_{t\to \infty} \frac{e^{tx}t}{(1+e^{tx})^2}\label{eq:s}\end{equation}
    <p>Equations $\eqref{eq:g}$ and $\eqref{eq:s}$ are the two most commonly used approximations.</p>

    <h2>ReLU Activation</h2>

    <p>Now, let's use the aforementioned logic as a tool to derive various smooth approximations for the ReLU activation function $\max(x,0)$.</p>

    <p>By using Equation $\eqref{eq:s}$, we get:</p>
    \begin{equation}\begin{aligned}
    \max(x,0)\approx&\, \int_{-\infty}^{\infty} \frac{e^{t(x-y)}t}{(1+e^{t(x-y)})^2} \max(y,0) dy\\
    =&\,\int_0^{\infty} \frac{e^{t(x-y)}ty}{(1+e^{t(x-y)})^2}dy=\frac{\log(1+e^{tx})}{t}
    \end{aligned}\end{equation}
    <p>When $t=1$, this is the SoftPlus activation function.</p>

    <p>If we instead use Equation $\eqref{eq:g}$, the result is:</p>
    \begin{equation}\begin{aligned}
    \max(x,0)\approx&\, \int_{-\infty}^{\infty} \frac{e^{-(x-y)^2/2\sigma^2}}{\sqrt{2\pi}\sigma} \max(y,0) dy\\
    =&\,\int_0^{\infty} \frac{e^{-(x-y)^2/2\sigma^2} y}{\sqrt{2\pi}\sigma}dy\\
    =&\,\frac{1}{2} \left[x \,\text{erf}\left(\frac{x}{\sqrt{2} \sigma}\right)+x+\sqrt{\frac{2}{\pi }} \sigma e^{-\frac{x^2}{2 \sigma^2}}\right]
    \end{aligned}\end{equation}
    <p>This smooth approximation of ReLU seems not to have been studied much before.</p>

    <p>Of course, for a function as simple as ReLU, there are even simpler approaches. For example, noting that $\max(x,0) = x\theta(x)$, where $\theta(x)$ is the unit step function mentioned earlier. The problem then shifts to finding a smooth approximation for $\theta(x)$. We already know the sigmoid is one such approximation, so we quickly obtain:</p>
    \begin{equation}\max(x,0)\approx x\sigma(tx)\end{equation}
    <p>When $t=1$, this is the Swish activation function. If we perform the calculation using $\eqref{eq:g}$, we obtain:</p>
    \begin{equation}\begin{aligned}
    \max(x,0)\approx&\, x\int_{-\infty}^{\infty} \frac{e^{-(x-y)^2/2\sigma^2}}{\sqrt{2\pi}\sigma} \theta(y) dy\\
    =&\,x\int_0^{\infty} \frac{e^{-(x-y)^2/2\sigma^2}}{\sqrt{2\pi}\sigma}dy =\frac{1}{2}\left[x + x\,\text{erf}\left(\frac{x}{\sqrt{2}\sigma}\right)\right]
    \end{aligned}\end{equation}
    <p>When $\sigma=1$, this is the GeLU activation function.</p>

    <p style="text-align: center;">(Image of ReLU function and its several smooth approximations)</p>

    <h2>The Integer Function</h2>

    <p>Readers might find the previous examples trivial, as those approximations are already well-known and can be derived without the Dirac function. Now, let's provide a non-trivial example: a smooth approximation of the integer function.</p>

    <p>The integer function comes in two forms: ceiling and floor. They differ in definition but are not essentially different. Here we use the floor function as an example, denoted as:</p>
    \begin{equation}[x] = n, \,\, \text{if and only if there exists } n \in \mathbb{Z} \text{ such that } x \in [n, n + 1)\end{equation}

    <p>Assuming $\varphi(x)$ is some smooth approximation of the Dirac function, then:</p>
    \begin{equation}
    [x] \approx \int_{-\infty}^{\infty} \varphi(x-y)[y]dy = \sum_{n=-\infty}^{\infty}n\int_n^{n+1} \varphi(x-y)dy\end{equation}
    <p>Let $\Phi(x)$ be the antiderivative of $\varphi(x)$. Then the antiderivative of $\varphi(x-y)$ with respect to $y$ is $-\Phi(x-y)$. Thus, we have:</p>
    \begin{equation}\begin{aligned}[]
    [x]\approx&\,\sum_{n=-\infty}^{\infty}n\big[\Phi(x-n) - \Phi(x-n-1)\big]\\
    =&\,\lim_{M,N\to\infty}\sum_{n=-M}^{N}(n-1)\Phi(x-n) - n\Phi(x-n-1) + \Phi(x-n)\\
    =&\,\lim_{M,N\to\infty} -N\Phi(x-N-1) - (M+1)\Phi(x+M) + \sum_{n=-M}^{N} \Phi(x-n)
    \end{aligned}\end{equation}
    <p>For $\Phi(x)$, we have $\Phi(-\infty)=0$ and $\Phi(\infty)=1$. Assuming the range we care about satisfies $-M \ll x \ll N$, then $\Phi(x-N-1)\approx 0$ and $\Phi(x+M)\approx 1$. Thus, at this point:</p>
    \begin{equation}\begin{aligned}[]
    [x]\approx&\, -M-1 + \sum_{n=-M}^{N} \Phi(x-n)\\
    =&\,\sum_{n=-M}^0 \big[\Phi(x-n)-1\big] + \sum_{n=1}^N \Phi(x-n)
    \end{aligned}\end{equation}
    <p>Using $\Phi(x)=\sigma(tx)$ as an example, taking $t=10, M=5, N=10$, the result is as follows:</p>

    <p style="text-align: center;">(Visualization of the smooth approximation of the floor function)</p>

    <p>As we can see, it is indeed quite close to $[x]$, and increasing $t$ can further improve the degree of approximation.</p>

    <h2>Conclusion</h2>

    <p>This article introduced a method for constructing smooth approximations using the Dirac function. Its characteristic feature is its generality, placing no strict requirements on the original function. As examples, we used it to derive various common approximations for the ReLU function and a smooth approximation for the floor function.</p>
</article>
<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/8718" style="color: #005fcc;">https://kexue.fm/archives/8718</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
