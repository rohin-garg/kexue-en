
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    tags: 'ams'
  }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<article>
    <nav style="margin-bottom: 1.5em;">
    <a href="../index.html" style="display: inline-flex; align-items: center; color: #555; text-decoration: none; font-size: 0.95em;">
        <span style="margin-right: 0.3em;">&larr;</span> Back to Index
    </a>
</nav>

    <h1><a href="https://kexue.fm/archives/3774">A Brief Exploration of OCR Technology: 1. Overview</a></h1>
    <p>By 苏剑林 | June 17, 2016</p>

    <p><strong>Preface: As mentioned in previous blog posts, last month I participated in the 4th Teddy Cup Data Mining Competition. I worked on Problem A, which is related to OCR systems, and I promised to open-source the final results. I've been busy with graduation and moving recently, so I haven't had time to organize this content until now.</strong></p>

    <p><strong>I am sharing these results not because they are particularly groundbreaking or advanced (on the contrary, after comparing them with Baidu's paper <a href="https://kexue.fm/usr/uploads/2016/06/1002322295.pdf">"Progress in Image Recognition Based on Deep Learning: Several Practices from Baidu"</a>, I realized my approach still essentially follows the traditional framework and is far from the cutting edge). Rather, I'm sharing this because while OCR technology is relatively mature, there aren't many articles online providing a detailed explanation of an OCR system's implementation. This article aims to fill that gap. I have always believed that for technology to advance, it must be open-sourced (though this is debatable in China, as open-sourcing can easily lead to copycats). Whether it's research in mathematics and physics or data mining, I usually publish most of my work on my blog to exchange ideas with everyone.</strong></p>

    <p>To get to the point: although the results aren't exceptional, we have implemented a relatively complete and functional OCR system. In other words, we have performed basically all the steps required to build an OCR system; as for how well they were executed, I would say it was "just acceptable." <strong>There may be some hyperbolic descriptions in the narrative; I hope readers will exercise their own judgment.</strong></p>

    <p>Below is our paper abstract:</p>

    <blockquote>
        We designed a series of algorithms to complete tasks such as text feature extraction and text localization. We established a character recognition model based on Convolutional Neural Networks (CNN) and finally combined it with a statistical language model to improve performance, successfully constructing a complete OCR (Optical Character Recognition) system.<br><br>
        In terms of <strong>feature extraction</strong>, we abandoned the traditional "edge detection + erosion/dilation" method. Based on some basic assumptions, we obtained high-quality text features through steps like grayscale clustering, layer decomposition, and denoising. These text features can be used both for text localization in the second step and directly input into the model for recognition in the third step, eliminating the need for additional feature extraction work.<br><br>
        In terms of <strong>text localization</strong>, we first integrated feature fragments through proximity search to obtain single-line text features, and then segmented the single-line text into individual characters using a forward-backward statistical method. Tests indicate that this segmentation approach handles mixed Chinese and English text segmentation effectively.<br><br>
        In terms of <strong>optical recognition</strong>, we established a single-character recognition model based on a CNN deep learning model. We self-generated 1.4 million samples for training and ultimately obtained a robust single-character recognition model. The training accuracy was 99.7%, and the test accuracy was 92.1%. Even when image noise was increased to 15%, an accuracy of approximately 90% was maintained.<br><br>
        Finally, to further enhance the effectiveness based on the previous work, we integrated a <strong>language model</strong>. We calculated the transition probability matrix of common Chinese characters using hundreds of thousands of texts from WeChat and used the Viterbi algorithm for dynamic programming to find the optimal recognition combination.<br><br>
        Combining these four parts of work yields a complete OCR system. Testing shows that our system performs well in identifying printed characters and can serve as a text recognition tool for platforms like e-commerce and WeChat.
    </blockquote>

    <h3>References</h3>
    <p>
        [1] Li Meng; Research on Text Detection Algorithm Based on Multi-scale Gabor Filter and BP Neural Network; Computer Software and Theory; 2007<br>
        [2] Kernel Density Estimation; <a href="https://zh.wikipedia.org/zh-cn/核密度估计">https://zh.wikipedia.org/zh-cn/核密度估计</a>; Wikipedia<br>
        [3] Xavier Glorot, Antoine Bordes, Yoshua Bengio; Deep Sparse Rectifier Neural Networks<br>
        [4] Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton; ImageNet Classification with Deep Convolutional Neural Networks<br>
        [5] Dropout: A Simple Way to Prevent Neural Networks from Overfitting<br>
        [6] Wu Jun; "The Beauty of Mathematics" (Second Edition); Chapter 3<br>
        [7] Wu Jun; "The Beauty of Mathematics" (Second Edition); Chapter 26
    </p>
</article>
<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/3774" style="color: #005fcc;">https://kexue.fm/archives/3774</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
