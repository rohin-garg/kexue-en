
    <style type="text/css">

    body {
    margin: 48px auto;
    max-width: 68ch;              /* character-based width reads better */
    padding: 0 16px;

    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 18px;
    line-height: 1.65;
    color: #333;
    background: #fafafa;
    }

    h1, h2, h3, h4 {
    line-height: 1.25;
    margin-top: 2.2em;
    margin-bottom: 0.6em;
    font-weight: 600;
    }

    h1 {
    font-size: 2.1em;
    margin-top: 0;
    }

    h2 {
    font-size: 1.6em;
    border-bottom: 1px solid #e5e5e5;
    padding-bottom: 0.3em;
    }

    h3 {
    font-size: 1.25em;
    }

    h4 {
    font-size: 1.05em;
    color: #555;
    }

    /* Paragraphs and lists */
    p {
    margin: 1em 0;
    }

    ul, ol {
    margin: 1em 0 1em 1.5em;
    }

    li {
    margin: 0.4em 0;
    }

    a {
    color: #005fcc;
    text-decoration: none;
    }

    a:hover {
    text-decoration: underline;
    }

    code {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.95em;
    background: #f2f2f2;
    padding: 0.15em 0.35em;
    border-radius: 4px;
    }

    pre {
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    font-size: 0.9em;
    background: #f5f5f5;
    padding: 1em 1.2em;
    overflow-x: auto;
    border-radius: 6px;
    line-height: 1.45;
    }

    pre code {
    background: none;
    padding: 0;
    }

    blockquote {
    margin: 1.5em 0;
    padding-left: 1em;
    border-left: 4px solid #ddd;
    color: #555;
    }

    hr {
    border: none;
    border-top: 1px solid #e0e0e0;
    margin: 3em 0;
    }

    table {
    border-collapse: collapse;
    margin: 1.5em 0;
    width: 100%;
    font-size: 0.95em;
    }

    th, td {
    padding: 0.5em 0.7em;
    border-bottom: 1px solid #e5e5e5;
    text-align: left;
    }

    th {
    font-weight: 600;
    }

    img {
    max-width: 100%;
    display: block;
    margin: 1.5em auto;
    }

    small {
    color: #666;
    }

    mjx-container {
    margin: 1em 0;
    }

    ::selection {
    background: #cce2ff;
    }

    </style>
    

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\\[', '\\]']],
    processEscapes: true,
    tags: 'ams',
    packages: {'[+]': ['base', 'ams', 'amsmath', 'amsbsy', 'amsfonts']}
  },
  options: {
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  }
};
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<article>
    <nav style="margin-bottom: 1.5em;">
    <a href="../index.html" style="display: inline-flex; align-items: center; color: #555; text-decoration: none; font-size: 0.95em;">
        <span style="margin-right: 0.3em;">&larr;</span> Back to Index
    </a>
</nav>

    <h1><a href="https://kexue.fm/archives/6407">Constructing an Explicit, Always Invertible Matrix</a></h1>
    <p>By 苏剑林 | March 1, 2019</p>

    <p>From the article <a href="translation_6377.html">"Appreciation of the Identity det(exp(A)) = exp(Tr(A))"</a>, we learned that the matrix $\exp(\boldsymbol{A})$ is always invertible, and its inverse is $\exp(-\boldsymbol{A})$. The problem is that $\exp(\boldsymbol{A})$ is only a theoretical definition; simply writing it this way has little practical value because it requires calculating every $\boldsymbol{A}^n$.</p>

    <p>Are there any specific examples? Yes. This article will construct an explicit, always invertible matrix.</p>

    <p>The logic is actually very simple. Suppose $\boldsymbol{x}, \boldsymbol{y}$ are two $k$-dimensional column vectors. Then $\boldsymbol{x}\boldsymbol{y}^{\top}$ is a $k \times k$ matrix. Let's consider:</p>

\begin{equation}
\begin{aligned}
\exp\left(\boldsymbol{x}\boldsymbol{y}^{\top}\right)=&\sum_{n=0}^{\\infty}\frac{\left(\boldsymbol{x}\boldsymbol{y}^{\top}\right)^n}{n!}\\
=&\boldsymbol{I}+\boldsymbol{x}\boldsymbol{y}^{\top}+\frac{\boldsymbol{x}\boldsymbol{y}^{\top}\boldsymbol{x}\boldsymbol{y}^{\top}}{2}+\frac{\boldsymbol{x}\boldsymbol{y}^{\top}\boldsymbol{x}\boldsymbol{y}^{\top}\boldsymbol{x}\boldsymbol{y}^{\top}}{6}+\dots
\end{aligned}
\end{equation}

    <p>Noticing that</p>

\begin{equation}\boldsymbol{y}^{\top}\boldsymbol{x}=\langle \boldsymbol{x},\boldsymbol{y}\rangle\end{equation}

    <p>is actually just a scalar, we can continue to simplify:</p>

\begin{equation}
\begin{aligned}\exp\left(\boldsymbol{x}\boldsymbol{y}^{\top}\right)=&\boldsymbol{I}+\boldsymbol{x}\boldsymbol{y}^{\top}\left(1+\frac{\langle \boldsymbol{x},\boldsymbol{y}\rangle}{2}+\frac{\langle \boldsymbol{x},\boldsymbol{y}\rangle^2}{6}+\dots\right)\\
=&\boldsymbol{I}+\boldsymbol{x}\boldsymbol{y}^{\top}\left(\frac{e^{\langle \boldsymbol{x},\boldsymbol{y}\rangle}-1}{\langle \boldsymbol{x},\boldsymbol{y}\rangle}\right)
\end{aligned}
\end{equation}

    <p>Now this matrix is very concrete and can be calculated easily because it only involves scalar exponential operations. The term $(e^x - 1)/x$ in the parentheses has a removable discontinuity at $x=0$; when $x=0$, its value is 1.</p>

    <p>According to the identity $\det(\exp(\boldsymbol{A})) = \exp(\text{Tr}(\boldsymbol{A}))$, the determinant of this matrix is:</p>

\begin{equation}\det\left(\exp\left(\boldsymbol{x}\boldsymbol{y}^{\top}\right)\right)= e^{\langle \boldsymbol{x},\boldsymbol{y}\rangle}\end{equation}

    <p>Its inverse matrix is:</p>

\begin{equation}\exp\left(-\boldsymbol{x}\boldsymbol{y}^{\top}\right)=\boldsymbol{I}-\boldsymbol{x}\boldsymbol{y}^{\top}\left(\frac{1 - e^{-\langle \boldsymbol{x},\boldsymbol{y}\rangle}}{\langle \boldsymbol{x},\boldsymbol{y}\rangle}\right)\end{equation}

    <p>which is also an explicit result.</p>

    <p>Of course, a general matrix has $k^2$ independent parameters, whereas the matrix constructed here from two vectors only has $2k$ parameters, so its expressive power is likely insufficient. To enhance the expressive power, one could consider multiplying several such matrices together:</p>

\begin{equation}\exp\left(\boldsymbol{x}_1\boldsymbol{y}_1^{\top}\right)\exp\left(\boldsymbol{x}_2\boldsymbol{y}_2^{\top}\right)\exp\left(\boldsymbol{x}_3\boldsymbol{y}_3^{\top}\right)\dots\end{equation}

    <p>Note that this is generally not equal to:</p>

\begin{equation}\exp\left(\boldsymbol{x}_1\boldsymbol{y}_1^{\top}+\boldsymbol{x}_2\boldsymbol{y}_2^{\top}+\boldsymbol{x}_3\boldsymbol{y}_3^{\top}+\dots\right)\end{equation}

    <p>Well, after deriving all of this, what is it actually useful for?</p>

    <p>Uh... I don't know what it's useful for either; just take it as something to appreciate.</p>

    <p>(Actually, my original intention was to directly construct an invertible neural network through a constructive method. Following this ready-made matrix, constructing an invertible fully-connected network is not difficult, but I haven't figured out how to generalize it to convolutional layers. Once I have settled that generalization, I will return to discuss the applications of this matrix~)</p>

    </article>
<hr>
<footer style="margin-top: 3em; padding: 1.5em; background: #f5f5f5; border-radius: 8px; font-size: 0.9em; color: #555;">
    <p style="margin: 0 0 0.5em 0;"><strong>Citation</strong></p>
    <p style="margin: 0 0 0.5em 0;">
        This is a machine translation of the original Chinese article:<br>
        <a href="https://kexue.fm/archives/6407" style="color: #005fcc;">https://kexue.fm/archives/6407</a>
    </p>
    <p style="margin: 0 0 0.5em 0;">
        Original author: 苏剑林 (Su Jianlin)<br>
        Original publication: <a href="https://kexue.fm" style="color: #005fcc;">科学空间 (Scientific Spaces)</a>
    </p>
    <p style="margin: 0; font-style: italic;">
        Translated using Gemini 3 Flash. Please refer to the original for authoritative content.
    </p>
</footer>
